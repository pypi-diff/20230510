# Comparing `tmp/gdal_utils-3.6.4.0-py3-none-any.whl.zip` & `tmp/gdal_utils-3.7.0.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,99 +1,99 @@
-Zip file size: 325476 bytes, number of entries: 97
--rw-rw-r--  2.0 unx      432 b- defN 23-Apr-17 11:44 osgeo_utils/__init__.py
--rw-rw-r--  2.0 unx   166201 b- defN 23-Apr-11 22:51 osgeo_utils/gdal2tiles.py
--rw-rw-r--  2.0 unx    15776 b- defN 23-Mar-13 21:01 osgeo_utils/gdal2xyz.py
--rw-rw-r--  2.0 unx    36264 b- defN 23-Jan-11 18:52 osgeo_utils/gdal_calc.py
--rw-rw-r--  2.0 unx    15155 b- defN 22-Nov-03 17:38 osgeo_utils/gdal_edit.py
--rw-rw-r--  2.0 unx     8936 b- defN 22-Nov-03 17:38 osgeo_utils/gdal_fillnodata.py
--rw-rw-r--  2.0 unx    18299 b- defN 22-Nov-03 17:38 osgeo_utils/gdal_merge.py
--rw-rw-r--  2.0 unx    11772 b- defN 22-Nov-03 17:38 osgeo_utils/gdal_pansharpen.py
--rw-rw-r--  2.0 unx    10303 b- defN 22-Nov-03 17:38 osgeo_utils/gdal_polygonize.py
--rw-rw-r--  2.0 unx     7052 b- defN 22-Nov-03 17:38 osgeo_utils/gdal_proximity.py
--rw-rw-r--  2.0 unx    35616 b- defN 23-Jan-27 19:56 osgeo_utils/gdal_retile.py
--rw-rw-r--  2.0 unx     6441 b- defN 22-Nov-03 17:38 osgeo_utils/gdal_sieve.py
--rw-rw-r--  2.0 unx     4794 b- defN 22-Nov-03 17:38 osgeo_utils/gdalattachpct.py
--rw-rw-r--  2.0 unx    11855 b- defN 23-Mar-13 21:01 osgeo_utils/gdalcompare.py
--rw-rw-r--  2.0 unx     9796 b- defN 22-Nov-03 17:38 osgeo_utils/gdalmove.py
--rw-rw-r--  2.0 unx    18128 b- defN 22-Dec-12 12:52 osgeo_utils/ogr_layer_algebra.py
--rw-rw-r--  2.0 unx    22455 b- defN 23-Jan-11 18:52 osgeo_utils/ogrmerge.py
--rw-rw-r--  2.0 unx     7664 b- defN 22-Nov-03 17:38 osgeo_utils/pct2rgb.py
--rw-rw-r--  2.0 unx     7145 b- defN 22-Nov-03 17:38 osgeo_utils/rgb2pct.py
--rw-rw-r--  2.0 unx        0 b- defN 22-Nov-03 17:38 osgeo_utils/auxiliary/__init__.py
--rw-rw-r--  2.0 unx     2635 b- defN 22-Nov-03 17:38 osgeo_utils/auxiliary/array_util.py
--rw-rw-r--  2.0 unx     4044 b- defN 22-Nov-03 17:38 osgeo_utils/auxiliary/base.py
--rw-rw-r--  2.0 unx     3447 b- defN 22-Nov-03 17:38 osgeo_utils/auxiliary/batch_creator.py
--rw-rw-r--  2.0 unx    15215 b- defN 22-Nov-03 17:38 osgeo_utils/auxiliary/color_palette.py
--rw-rw-r--  2.0 unx     5649 b- defN 22-Nov-03 17:38 osgeo_utils/auxiliary/color_table.py
--rw-rw-r--  2.0 unx     5384 b- defN 22-Nov-03 17:38 osgeo_utils/auxiliary/extent_util.py
--rw-rw-r--  2.0 unx     6566 b- defN 22-Nov-03 17:38 osgeo_utils/auxiliary/gdal_argparse.py
--rw-rw-r--  2.0 unx     2721 b- defN 23-Jan-11 18:52 osgeo_utils/auxiliary/numpy_util.py
--rw-rw-r--  2.0 unx     5467 b- defN 22-Nov-03 17:38 osgeo_utils/auxiliary/osr_util.py
--rw-rw-r--  2.0 unx     3340 b- defN 22-Nov-03 17:38 osgeo_utils/auxiliary/progress.py
--rw-rw-r--  2.0 unx     6671 b- defN 22-Nov-03 17:38 osgeo_utils/auxiliary/raster_creation.py
--rw-rw-r--  2.0 unx     8828 b- defN 22-Nov-03 17:38 osgeo_utils/auxiliary/rectangle.py
--rw-rw-r--  2.0 unx    16651 b- defN 22-Nov-03 17:38 osgeo_utils/auxiliary/util.py
--rw-rw-r--  2.0 unx        0 b- defN 22-Nov-03 17:38 osgeo_utils/samples/__init__.py
--rw-rw-r--  2.0 unx     4632 b- defN 22-Nov-03 17:38 osgeo_utils/samples/assemblepoly.py
--rw-rw-r--  2.0 unx    17347 b- defN 22-Nov-03 17:38 osgeo_utils/samples/build_jp2_from_xml.py
--rw-rw-r--  2.0 unx     2828 b- defN 22-Nov-03 17:38 osgeo_utils/samples/classify.py
--rw-rw-r--  2.0 unx    12326 b- defN 22-Nov-03 17:38 osgeo_utils/samples/crs2crs2grid.py
--rw-rw-r--  2.0 unx    16769 b- defN 22-Nov-03 17:38 osgeo_utils/samples/densify.py
--rw-rw-r--  2.0 unx     8126 b- defN 22-Nov-03 17:38 osgeo_utils/samples/dump_jp2.py
--rw-rw-r--  2.0 unx     9915 b- defN 22-Nov-03 17:38 osgeo_utils/samples/epsg_tr.py
--rw-rw-r--  2.0 unx     3238 b- defN 22-Nov-03 17:38 osgeo_utils/samples/esri2wkt.py
--rw-rw-r--  2.0 unx     4274 b- defN 22-Nov-03 17:38 osgeo_utils/samples/fft.py
--rw-rw-r--  2.0 unx     3008 b- defN 22-Nov-03 17:38 osgeo_utils/samples/fix_gpkg.py
--rw-rw-r--  2.0 unx     3193 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gcps2ogr.py
--rw-rw-r--  2.0 unx     5419 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gcps2vec.py
--rw-rw-r--  2.0 unx     2580 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gcps2wld.py
--rw-rw-r--  2.0 unx     5281 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdal2grd.py
--rw-rw-r--  2.0 unx     4451 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdal_auth.py
--rw-rw-r--  2.0 unx    11309 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdal_cp.py
--rw-rw-r--  2.0 unx     2561 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdal_create_pdf.py
--rw-rw-r--  2.0 unx     8693 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdal_ls.py
--rw-rw-r--  2.0 unx     6668 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdal_lut.py
--rw-rw-r--  2.0 unx     2403 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdal_mkdir.py
--rw-rw-r--  2.0 unx     4426 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdal_remove_towgs84.py
--rw-rw-r--  2.0 unx     4035 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdal_rm.py
--rw-rw-r--  2.0 unx     2538 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdal_rmdir.py
--rw-rw-r--  2.0 unx    11900 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdal_vrtmerge.py
--rw-rw-r--  2.0 unx     4069 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdal_zip.py
--rw-rw-r--  2.0 unx     3004 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdalchksum.py
--rw-rw-r--  2.0 unx     3004 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdalcopyproj.py
--rw-rw-r--  2.0 unx     6067 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdalfilter.py
--rw-rw-r--  2.0 unx     3021 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdalident.py
--rw-rw-r--  2.0 unx     3036 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdalimport.py
--rw-rw-r--  2.0 unx    22185 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdalinfo.py
--rw-rw-r--  2.0 unx    20066 b- defN 22-Nov-03 17:38 osgeo_utils/samples/gdallocationinfo.py
--rw-rw-r--  2.0 unx     4095 b- defN 22-Nov-03 17:38 osgeo_utils/samples/get_soundg.py
--rw-rw-r--  2.0 unx     3374 b- defN 22-Nov-03 17:38 osgeo_utils/samples/histrep.py
--rw-rw-r--  2.0 unx     8150 b- defN 22-Nov-03 17:38 osgeo_utils/samples/hsv_merge.py
--rw-rw-r--  2.0 unx    10510 b- defN 22-Nov-03 17:38 osgeo_utils/samples/jpeg_in_tiff_extract.py
--rw-rw-r--  2.0 unx     6440 b- defN 22-Nov-03 17:38 osgeo_utils/samples/load2odbc.py
--rw-rw-r--  2.0 unx     8847 b- defN 22-Nov-03 17:38 osgeo_utils/samples/loslas2ntv2.py
--rw-rw-r--  2.0 unx     2739 b- defN 22-Nov-03 17:38 osgeo_utils/samples/magphase.py
--rw-rw-r--  2.0 unx     2167 b- defN 22-Nov-03 17:38 osgeo_utils/samples/make_fuzzer_friendly_archive.py
--rw-rw-r--  2.0 unx     7547 b- defN 22-Nov-03 17:38 osgeo_utils/samples/mkgraticule.py
--rw-rw-r--  2.0 unx    70278 b- defN 22-Nov-03 17:38 osgeo_utils/samples/ogr2ogr.py
--rw-rw-r--  2.0 unx    12582 b- defN 22-Nov-03 17:38 osgeo_utils/samples/ogr2vrt.py
--rw-rw-r--  2.0 unx     7567 b- defN 22-Nov-03 17:38 osgeo_utils/samples/ogr_build_junction_table.py
--rw-rw-r--  2.0 unx    14345 b- defN 22-Nov-03 17:38 osgeo_utils/samples/ogr_dispatch.py
--rw-rw-r--  2.0 unx    21229 b- defN 22-Nov-03 17:38 osgeo_utils/samples/ogrinfo.py
--rw-rw-r--  2.0 unx    19843 b- defN 22-Nov-03 17:38 osgeo_utils/samples/ogrupdate.py
--rw-rw-r--  2.0 unx     7724 b- defN 22-Nov-03 17:38 osgeo_utils/samples/rel.py
--rw-rw-r--  2.0 unx     7578 b- defN 22-Nov-03 17:38 osgeo_utils/samples/tigerpoly.py
--rw-rw-r--  2.0 unx     4368 b- defN 22-Nov-03 17:38 osgeo_utils/samples/tile_extent_from_raster.py
--rw-rw-r--  2.0 unx     4055 b- defN 22-Nov-03 17:38 osgeo_utils/samples/tolatlong.py
--rw-rw-r--  2.0 unx     4344 b- defN 22-Nov-03 17:38 osgeo_utils/samples/val_repl.py
--rw-rw-r--  2.0 unx    18476 b- defN 22-Nov-03 17:38 osgeo_utils/samples/validate_cloud_optimized_geotiff.py
--rw-rw-r--  2.0 unx   108556 b- defN 23-Jan-11 18:52 osgeo_utils/samples/validate_gpkg.py
--rw-rw-r--  2.0 unx    70659 b- defN 22-Nov-03 17:38 osgeo_utils/samples/validate_jp2.py
--rw-rw-r--  2.0 unx     4768 b- defN 22-Nov-03 17:38 osgeo_utils/samples/vec_tr.py
--rw-rw-r--  2.0 unx     4843 b- defN 22-Nov-03 17:38 osgeo_utils/samples/vec_tr_spat.py
--rw-rw-r--  2.0 unx     7103 b- defN 22-Nov-03 17:38 osgeo_utils/samples/wcs_virtds_params.py
--rw-rw-r--  2.0 unx     3882 b- defN 23-Apr-21 13:04 gdal_utils-3.6.4.0.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Apr-21 13:04 gdal_utils-3.6.4.0.dist-info/WHEEL
--rw-rw-r--  2.0 unx      828 b- defN 23-Apr-21 13:04 gdal_utils-3.6.4.0.dist-info/entry_points.txt
--rw-rw-r--  2.0 unx       12 b- defN 23-Apr-21 13:04 gdal_utils-3.6.4.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     8662 b- defN 23-Apr-21 13:04 gdal_utils-3.6.4.0.dist-info/RECORD
-97 files, 1178737 bytes uncompressed, 311746 bytes compressed:  73.6%
+Zip file size: 329370 bytes, number of entries: 97
+-rw-rw-r--  2.0 unx      432 b- defN 23-May-02 13:04 osgeo_utils/__init__.py
+-rw-rw-r--  2.0 unx   166280 b- defN 23-May-02 13:04 osgeo_utils/gdal2tiles.py
+-rw-rw-r--  2.0 unx    15776 b- defN 23-May-02 13:04 osgeo_utils/gdal2xyz.py
+-rw-rw-r--  2.0 unx    36237 b- defN 23-May-02 13:04 osgeo_utils/gdal_calc.py
+-rw-rw-r--  2.0 unx    15155 b- defN 23-May-02 13:04 osgeo_utils/gdal_edit.py
+-rw-rw-r--  2.0 unx     9085 b- defN 23-May-02 13:04 osgeo_utils/gdal_fillnodata.py
+-rw-rw-r--  2.0 unx    18296 b- defN 23-May-02 13:04 osgeo_utils/gdal_merge.py
+-rw-rw-r--  2.0 unx    11772 b- defN 23-May-02 13:04 osgeo_utils/gdal_pansharpen.py
+-rw-rw-r--  2.0 unx    11088 b- defN 23-May-02 13:04 osgeo_utils/gdal_polygonize.py
+-rw-rw-r--  2.0 unx     7052 b- defN 23-May-02 13:04 osgeo_utils/gdal_proximity.py
+-rw-rw-r--  2.0 unx    35621 b- defN 23-May-02 13:04 osgeo_utils/gdal_retile.py
+-rw-rw-r--  2.0 unx     6441 b- defN 23-May-02 13:04 osgeo_utils/gdal_sieve.py
+-rw-rw-r--  2.0 unx     4794 b- defN 23-May-02 13:04 osgeo_utils/gdalattachpct.py
+-rw-rw-r--  2.0 unx    11855 b- defN 23-May-02 13:04 osgeo_utils/gdalcompare.py
+-rw-rw-r--  2.0 unx     9796 b- defN 23-May-02 13:04 osgeo_utils/gdalmove.py
+-rw-rw-r--  2.0 unx    18278 b- defN 23-May-02 13:04 osgeo_utils/ogr_layer_algebra.py
+-rw-rw-r--  2.0 unx    42925 b- defN 23-May-02 13:04 osgeo_utils/ogrmerge.py
+-rw-rw-r--  2.0 unx     7664 b- defN 23-May-02 13:04 osgeo_utils/pct2rgb.py
+-rw-rw-r--  2.0 unx     7145 b- defN 23-May-02 13:04 osgeo_utils/rgb2pct.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-May-02 13:04 osgeo_utils/auxiliary/__init__.py
+-rw-rw-r--  2.0 unx     2635 b- defN 23-May-02 13:04 osgeo_utils/auxiliary/array_util.py
+-rw-rw-r--  2.0 unx     4044 b- defN 23-May-02 13:04 osgeo_utils/auxiliary/base.py
+-rw-rw-r--  2.0 unx     3447 b- defN 23-May-02 13:04 osgeo_utils/auxiliary/batch_creator.py
+-rw-rw-r--  2.0 unx    15215 b- defN 23-May-02 13:04 osgeo_utils/auxiliary/color_palette.py
+-rw-rw-r--  2.0 unx     5649 b- defN 23-May-02 13:04 osgeo_utils/auxiliary/color_table.py
+-rw-rw-r--  2.0 unx     5384 b- defN 23-May-02 13:04 osgeo_utils/auxiliary/extent_util.py
+-rw-rw-r--  2.0 unx     6566 b- defN 23-May-02 13:04 osgeo_utils/auxiliary/gdal_argparse.py
+-rw-rw-r--  2.0 unx     2891 b- defN 23-May-02 13:04 osgeo_utils/auxiliary/numpy_util.py
+-rw-rw-r--  2.0 unx     5467 b- defN 23-May-02 13:04 osgeo_utils/auxiliary/osr_util.py
+-rw-rw-r--  2.0 unx     3340 b- defN 23-May-02 13:04 osgeo_utils/auxiliary/progress.py
+-rw-rw-r--  2.0 unx     6671 b- defN 23-May-02 13:04 osgeo_utils/auxiliary/raster_creation.py
+-rw-rw-r--  2.0 unx     8828 b- defN 23-May-02 13:04 osgeo_utils/auxiliary/rectangle.py
+-rw-rw-r--  2.0 unx    16651 b- defN 23-May-02 13:04 osgeo_utils/auxiliary/util.py
+-rw-rw-r--  2.0 unx        0 b- defN 23-May-02 13:04 osgeo_utils/samples/__init__.py
+-rw-rw-r--  2.0 unx     4632 b- defN 23-May-02 13:04 osgeo_utils/samples/assemblepoly.py
+-rw-rw-r--  2.0 unx    17347 b- defN 23-May-02 13:04 osgeo_utils/samples/build_jp2_from_xml.py
+-rw-rw-r--  2.0 unx     2828 b- defN 23-May-02 13:04 osgeo_utils/samples/classify.py
+-rw-rw-r--  2.0 unx    12326 b- defN 23-May-02 13:04 osgeo_utils/samples/crs2crs2grid.py
+-rw-rw-r--  2.0 unx    16769 b- defN 23-May-02 13:04 osgeo_utils/samples/densify.py
+-rw-rw-r--  2.0 unx     8126 b- defN 23-May-02 13:04 osgeo_utils/samples/dump_jp2.py
+-rw-rw-r--  2.0 unx     9915 b- defN 23-May-02 13:04 osgeo_utils/samples/epsg_tr.py
+-rw-rw-r--  2.0 unx     3238 b- defN 23-May-02 13:04 osgeo_utils/samples/esri2wkt.py
+-rw-rw-r--  2.0 unx     4274 b- defN 23-May-02 13:04 osgeo_utils/samples/fft.py
+-rw-rw-r--  2.0 unx     3008 b- defN 23-May-02 13:04 osgeo_utils/samples/fix_gpkg.py
+-rw-rw-r--  2.0 unx     3193 b- defN 23-May-02 13:04 osgeo_utils/samples/gcps2ogr.py
+-rw-rw-r--  2.0 unx     5419 b- defN 23-May-02 13:04 osgeo_utils/samples/gcps2vec.py
+-rw-rw-r--  2.0 unx     2580 b- defN 23-May-02 13:04 osgeo_utils/samples/gcps2wld.py
+-rw-rw-r--  2.0 unx     5281 b- defN 23-May-02 13:04 osgeo_utils/samples/gdal2grd.py
+-rw-rw-r--  2.0 unx     4451 b- defN 23-May-02 13:04 osgeo_utils/samples/gdal_auth.py
+-rw-rw-r--  2.0 unx     8460 b- defN 23-May-02 13:04 osgeo_utils/samples/gdal_cp.py
+-rw-rw-r--  2.0 unx     2561 b- defN 23-May-02 13:04 osgeo_utils/samples/gdal_create_pdf.py
+-rw-rw-r--  2.0 unx     8693 b- defN 23-May-02 13:04 osgeo_utils/samples/gdal_ls.py
+-rw-rw-r--  2.0 unx     6668 b- defN 23-May-02 13:04 osgeo_utils/samples/gdal_lut.py
+-rw-rw-r--  2.0 unx     2403 b- defN 23-May-02 13:04 osgeo_utils/samples/gdal_mkdir.py
+-rw-rw-r--  2.0 unx     4426 b- defN 23-May-02 13:04 osgeo_utils/samples/gdal_remove_towgs84.py
+-rw-rw-r--  2.0 unx     4035 b- defN 23-May-02 13:04 osgeo_utils/samples/gdal_rm.py
+-rw-rw-r--  2.0 unx     2538 b- defN 23-May-02 13:04 osgeo_utils/samples/gdal_rmdir.py
+-rw-rw-r--  2.0 unx    11900 b- defN 23-May-02 13:04 osgeo_utils/samples/gdal_vrtmerge.py
+-rw-rw-r--  2.0 unx     4069 b- defN 23-May-02 13:04 osgeo_utils/samples/gdal_zip.py
+-rw-rw-r--  2.0 unx     3004 b- defN 23-May-02 13:04 osgeo_utils/samples/gdalchksum.py
+-rw-rw-r--  2.0 unx     3004 b- defN 23-May-02 13:04 osgeo_utils/samples/gdalcopyproj.py
+-rw-rw-r--  2.0 unx     6067 b- defN 23-May-02 13:04 osgeo_utils/samples/gdalfilter.py
+-rw-rw-r--  2.0 unx     3021 b- defN 23-May-02 13:04 osgeo_utils/samples/gdalident.py
+-rw-rw-r--  2.0 unx     3036 b- defN 23-May-02 13:04 osgeo_utils/samples/gdalimport.py
+-rw-rw-r--  2.0 unx    22278 b- defN 23-May-02 13:04 osgeo_utils/samples/gdalinfo.py
+-rw-rw-r--  2.0 unx    20066 b- defN 23-May-02 13:04 osgeo_utils/samples/gdallocationinfo.py
+-rw-rw-r--  2.0 unx     4095 b- defN 23-May-02 13:04 osgeo_utils/samples/get_soundg.py
+-rw-rw-r--  2.0 unx     3374 b- defN 23-May-02 13:04 osgeo_utils/samples/histrep.py
+-rw-rw-r--  2.0 unx     8150 b- defN 23-May-02 13:04 osgeo_utils/samples/hsv_merge.py
+-rw-rw-r--  2.0 unx    10510 b- defN 23-May-02 13:04 osgeo_utils/samples/jpeg_in_tiff_extract.py
+-rw-rw-r--  2.0 unx     6440 b- defN 23-May-02 13:04 osgeo_utils/samples/load2odbc.py
+-rw-rw-r--  2.0 unx     8847 b- defN 23-May-02 13:04 osgeo_utils/samples/loslas2ntv2.py
+-rw-rw-r--  2.0 unx     2739 b- defN 23-May-02 13:04 osgeo_utils/samples/magphase.py
+-rw-rw-r--  2.0 unx     2167 b- defN 23-May-02 13:04 osgeo_utils/samples/make_fuzzer_friendly_archive.py
+-rw-rw-r--  2.0 unx     7547 b- defN 23-May-02 13:04 osgeo_utils/samples/mkgraticule.py
+-rw-rw-r--  2.0 unx    70440 b- defN 23-May-02 13:04 osgeo_utils/samples/ogr2ogr.py
+-rw-rw-r--  2.0 unx    12810 b- defN 23-May-02 13:04 osgeo_utils/samples/ogr2vrt.py
+-rw-rw-r--  2.0 unx     7567 b- defN 23-May-02 13:04 osgeo_utils/samples/ogr_build_junction_table.py
+-rw-rw-r--  2.0 unx    14345 b- defN 23-May-02 13:04 osgeo_utils/samples/ogr_dispatch.py
+-rw-rw-r--  2.0 unx    21229 b- defN 23-May-02 13:04 osgeo_utils/samples/ogrinfo.py
+-rw-rw-r--  2.0 unx    19843 b- defN 23-May-02 13:04 osgeo_utils/samples/ogrupdate.py
+-rw-rw-r--  2.0 unx     7724 b- defN 23-May-02 13:04 osgeo_utils/samples/rel.py
+-rw-rw-r--  2.0 unx     7578 b- defN 23-May-02 13:04 osgeo_utils/samples/tigerpoly.py
+-rw-rw-r--  2.0 unx     4368 b- defN 23-May-02 13:04 osgeo_utils/samples/tile_extent_from_raster.py
+-rw-rw-r--  2.0 unx     4055 b- defN 23-May-02 13:04 osgeo_utils/samples/tolatlong.py
+-rw-rw-r--  2.0 unx     4344 b- defN 23-May-02 13:04 osgeo_utils/samples/val_repl.py
+-rw-rw-r--  2.0 unx    18476 b- defN 23-May-02 13:04 osgeo_utils/samples/validate_cloud_optimized_geotiff.py
+-rw-rw-r--  2.0 unx   109775 b- defN 23-May-02 13:04 osgeo_utils/samples/validate_gpkg.py
+-rw-rw-r--  2.0 unx    70659 b- defN 23-May-02 13:04 osgeo_utils/samples/validate_jp2.py
+-rw-rw-r--  2.0 unx     4768 b- defN 23-May-02 13:04 osgeo_utils/samples/vec_tr.py
+-rw-rw-r--  2.0 unx     4843 b- defN 23-May-02 13:04 osgeo_utils/samples/vec_tr_spat.py
+-rw-rw-r--  2.0 unx     7103 b- defN 23-May-02 13:04 osgeo_utils/samples/wcs_virtds_params.py
+-rw-rw-r--  2.0 unx     3878 b- defN 23-May-10 15:25 gdal_utils-3.7.0.0.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-May-10 15:25 gdal_utils-3.7.0.0.dist-info/WHEEL
+-rw-rw-r--  2.0 unx      828 b- defN 23-May-10 15:25 gdal_utils-3.7.0.0.dist-info/entry_points.txt
+-rw-rw-r--  2.0 unx       12 b- defN 23-May-10 15:25 gdal_utils-3.7.0.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     8661 b- defN 23-May-10 15:25 gdal_utils-3.7.0.0.dist-info/RECORD
+97 files, 1199363 bytes uncompressed, 315640 bytes compressed:  73.7%
```

## zipnote {}

```diff
@@ -270,23 +270,23 @@
 
 Filename: osgeo_utils/samples/vec_tr_spat.py
 Comment: 
 
 Filename: osgeo_utils/samples/wcs_virtds_params.py
 Comment: 
 
-Filename: gdal_utils-3.6.4.0.dist-info/METADATA
+Filename: gdal_utils-3.7.0.0.dist-info/METADATA
 Comment: 
 
-Filename: gdal_utils-3.6.4.0.dist-info/WHEEL
+Filename: gdal_utils-3.7.0.0.dist-info/WHEEL
 Comment: 
 
-Filename: gdal_utils-3.6.4.0.dist-info/entry_points.txt
+Filename: gdal_utils-3.7.0.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: gdal_utils-3.6.4.0.dist-info/top_level.txt
+Filename: gdal_utils-3.7.0.0.dist-info/top_level.txt
 Comment: 
 
-Filename: gdal_utils-3.6.4.0.dist-info/RECORD
+Filename: gdal_utils-3.7.0.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## osgeo_utils/__init__.py

```diff
@@ -1,9 +1,9 @@
 __package_name__ = "gdal-utils"
-gdal_utils_version = (3, 6, 4, 0)
+gdal_utils_version = (3, 7, 0, 0)
 __version__ = ".".join(str(i) for i in gdal_utils_version)
 __author__ = "Frank Warmerdam"
 __author_email__ = "warmerdam@pobox.com"
 __maintainer__ = "Idan Miara"
 __maintainer_email__ = "idan@miara.com"
 __description__ = (
     "gdal-utils: An extension library for GDAL - Geospatial Data Abstraction Library"
```

## osgeo_utils/gdal2tiles.py

```diff
@@ -32,19 +32,20 @@
 #  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
 #  THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 #  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
 #  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
 #  DEALINGS IN THE SOFTWARE.
 # ******************************************************************************
 
-from __future__ import division, print_function
+from __future__ import division
 
 import contextlib
 import glob
 import json
+import logging
 import math
 import optparse
 import os
 import shutil
 import stat
 import sys
 import tempfile
@@ -84,14 +85,16 @@
     "min",
     "med",
     "q1",
     "q3",
 )
 webviewer_list = ("all", "google", "openlayers", "leaflet", "mapml", "none")
 
+logger = logging.getLogger("gdal2tiles")
+
 
 def makedirs(path):
     """Wrapper for os.makedirs() that can work with /vsi files too"""
     if path.startswith("/vsi"):
         if gdal.MkdirRecursive(path, 0o755) != 0:
             raise Exception(f"Cannot create {path}")
     else:
@@ -277,22 +280,22 @@
     for tmsfilename in glob.glob(os.path.join(dirname, "tms_*.json")):
         data = open(tmsfilename, "rb").read()
         try:
             j = json.loads(data.decode("utf-8"))
         except Exception:
             j = None
         if j is None:
-            print("Cannot parse " + tmsfilename)
+            logger.error("Cannot parse " + tmsfilename)
             continue
         try:
             tms = TileMatrixSet.parse(j)
         except UnsupportedTileMatrixSet:
             continue
         except Exception:
-            print("Cannot parse " + tmsfilename)
+            logger.error("Cannot parse " + tmsfilename)
             continue
         tmsMap[tms.identifier] = tms
         profile_list.append(tms.identifier)
 
 threadLocal = threading.local()
 
 # =============================================================================
@@ -988,15 +991,15 @@
                 ):
                     # We should possibly do similar check for other data types
                     in_nodata = []
                     break
                 in_nodata.append(raster_no_data)
 
     if options.verbose:
-        print("NODATA: %s" % in_nodata)
+        logger.debug("NODATA: %s" % in_nodata)
 
     return in_nodata
 
 
 def setup_input_srs(
     input_dataset: gdal.Dataset, options: Options
 ) -> Tuple[Optional[osr.SpatialReference], Optional[str]]:
@@ -1108,15 +1111,15 @@
                     )
 
         to_dataset = gdal.AutoCreateWarpedVRT(
             from_dataset, from_srs.ExportToWkt(), to_srs.ExportToWkt()
         )
 
         if options and options.verbose:
-            print(
+            logger.debug(
                 "Warping of the raster by AutoCreateWarpedVRT (result saved into 'tiles.vrt')"
             )
             to_dataset.GetDriver().CreateCopy("tiles.vrt", to_dataset)
 
         return to_dataset
     else:
         return from_dataset
@@ -1178,15 +1181,15 @@
 
     # set NODATA_VALUE metadata
     corrected_dataset.SetMetadataItem(
         "NODATA_VALUES", " ".join([str(i) for i in nodata_values])
     )
 
     if options and options.verbose:
-        print("Modified warping result saved into 'tiles1.vrt'")
+        logger.debug("Modified warping result saved into 'tiles1.vrt'")
 
         with open("tiles1.vrt", "w") as f:
             f.write(corrected_dataset.GetMetadata("xml:VRT")[0])
 
     return corrected_dataset
 
 
@@ -1259,15 +1262,15 @@
         vrt_string = warped_vrt_dataset.GetMetadata("xml:VRT")[0]
 
         vrt_string = add_alpha_band_to_string_vrt(vrt_string)
 
         warped_vrt_dataset = gdal.Open(vrt_string)
 
         if options and options.verbose:
-            print("Modified -dstalpha warping result saved into 'tiles1.vrt'")
+            logger.debug("Modified -dstalpha warping result saved into 'tiles1.vrt'")
 
             with open("tiles1.vrt", "w") as f:
                 f.write(warped_vrt_dataset.GetMetadata("xml:VRT")[0])
 
     return warped_vrt_dataset
 
 
@@ -1332,16 +1335,16 @@
     # Tile dataset in memory
     tilefilename = os.path.join(output, str(tz), str(tx), "%s.%s" % (ty, tileext))
     dstile = mem_drv.Create("", tile_size, tile_size, tilebands)
 
     data = alpha = None
 
     if options.verbose:
-        print(
-            "\tReadRaster Extent: ", (rx, ry, rxsize, rysize), (wx, wy, wxsize, wysize)
+        logger.debug(
+            f"\tReadRaster Extent: ({rx}, {ry}, {rxsize}, {rysize}), ({wx}, {wy}, {wxsize}, {wysize})"
         )
 
     # Query is in 'nearest neighbour' but can be bigger in then the tile_size
     # We scale down the query to the tile_size by supplied algorithm.
 
     if rxsize != 0 and rysize != 0 and wxsize != 0 and wysize != 0:
         alpha = alphaband.ReadRaster(rx, ry, rxsize, rysize, wxsize, wysize)
@@ -1452,18 +1455,18 @@
     tilefilename = os.path.join(
         output_folder,
         str(overview_tz),
         str(overview_tx),
         "%s.%s" % (overview_ty_real, tile_job_info.tile_extension),
     )
     if options.verbose:
-        print(tilefilename)
+        logger.debug(tilefilename)
     if options.resume and isfile(tilefilename):
         if options.verbose:
-            print("Tile generation skipped because of --resume")
+            logger.debug("Tile generation skipped because of --resume")
         return
 
     mem_driver = gdal.GetDriverByName("MEM")
     tile_driver = tile_job_info.tile_driver
     out_driver = gdal.GetDriverByName(tile_driver)
 
     tilebands = tile_job_info.nb_data_bands + 1
@@ -1556,15 +1559,15 @@
         )
         # Remove useless side car file
         aux_xml = tilefilename + ".aux.xml"
         if gdal.VSIStatL(aux_xml) is not None:
             gdal.Unlink(aux_xml)
 
     if options.verbose:
-        print("\tbuild from zoom", base_tz, " tiles:", *base_tiles)
+        logger.debug(f"\tbuild from zoom {base_tz}, tiles: %s" % ",".join(base_tiles))
 
     # Create a KML file for this tile.
     if tile_job_info.kml:
         swne = get_tile_swne(tile_job_info, options)
         if swne is not None:
             with my_open(
                 os.path.join(
@@ -1848,15 +1851,15 @@
         bingkey="INSERT_YOUR_KEY_HERE",
         processes=1,
     )
 
     return p
 
 
-def process_args(argv: List[str]) -> Tuple[str, str, Options]:
+def process_args(argv: List[str], called_from_main=False) -> Tuple[str, str, Options]:
     parser = optparse_init()
     options, args = parser.parse_args(args=argv)
 
     # Args should be either an input file OR an input file and an output folder
     if not args:
         exit_with_error(
             "You need to specify at least an input file as argument to the script"
@@ -1881,14 +1884,20 @@
         output_folder = os.path.splitext(os.path.basename(input_file))[0]
 
     if options.webviewer == "mapml":
         options.xyz = True
         if options.profile == "geodetic":
             options.tmscompatible = True
 
+    if called_from_main:
+        if options.verbose:
+            logging.basicConfig(level=logging.DEBUG, format="%(message)s")
+        elif not options.quiet:
+            logging.basicConfig(level=logging.INFO, format="%(message)s")
+
     options = options_post_processing(options, input_file, output_folder)
 
     return input_file, output_folder, options
 
 
 def options_post_processing(
     options: Options, input_file: str, output_folder: str
@@ -1941,19 +1950,18 @@
         if not options.webp_lossless:
             if options.webp_quality <= 0 or options.webp_quality > 100:
                 exit_with_error("webp_quality should be in the range [1-100]")
             options.webp_quality = int(options.webp_quality)
 
     # Output the results
     if options.verbose:
-        print("Options:", options)
-        print("Input:", input_file)
-        print("Output:", output_folder)
-        print("Cache: %s MB" % (gdal.GetCacheMax() / 1024 / 1024))
-        print("")
+        logger.debug("Options: %s" % str(options))
+        logger.debug(f"Input: {input_file}")
+        logger.debug(f"Output: {output_folder}")
+        logger.debug("Cache: %d MB" % (gdal.GetCacheMax() / 1024 / 1024))
 
     return options
 
 
 class TileDetail(object):
     tx = 0
     ty = 0
@@ -2121,17 +2129,16 @@
 
         if self.input_file:
             input_dataset: gdal.Dataset = gdal.Open(self.input_file, gdal.GA_ReadOnly)
         else:
             raise Exception("No input file was specified")
 
         if self.options.verbose:
-            print(
-                "Input file:",
-                "( %sP x %sL - %s bands)"
+            logger.debug(
+                "Input file: (%dP x %dL - %d bands)"
                 % (
                     input_dataset.RasterXSize,
                     input_dataset.RasterYSize,
                     input_dataset.RasterCount,
                 ),
             )
 
@@ -2162,17 +2169,16 @@
                 "then run:\n"
                 "gdal2tiles temp.vrt" % self.input_file,
             )
 
         in_nodata = setup_no_data_values(input_dataset, self.options)
 
         if self.options.verbose:
-            print(
-                "Preprocessed file:",
-                "( %sP x %sL - %s bands)"
+            logger.debug(
+                "Preprocessed file:(%dP x %dL - %d bands)"
                 % (
                     input_dataset.RasterXSize,
                     input_dataset.RasterYSize,
                     input_dataset.RasterCount,
                 ),
             )
 
@@ -2214,18 +2220,16 @@
                     )
                 else:
                     self.warped_input_dataset = update_alpha_value_for_non_alpha_inputs(
                         self.warped_input_dataset, options=self.options
                     )
 
             if self.warped_input_dataset and self.options.verbose:
-                print(
-                    "Projected file:",
-                    "tiles.vrt",
-                    "( %sP x %sL - %s bands)"
+                logger.debug(
+                    "Projected file: tiles.vrt (%dP x %dL - %d bands)"
                     % (
                         self.warped_input_dataset.RasterXSize,
                         self.warped_input_dataset.RasterYSize,
                         self.warped_input_dataset.RasterCount,
                     ),
                 )
 
@@ -2244,15 +2248,15 @@
         srs4326.ImportFromEPSG(4326)
         srs4326.SetAxisMappingStrategy(osr.OAMS_TRADITIONAL_GIS_ORDER)
         if self.out_srs and srs4326.ExportToProj4() == self.out_srs.ExportToProj4():
             self.isepsg4326 = True
             if self.kml is None:
                 self.kml = True
             if self.kml and self.options.verbose:
-                print("KML autotest OK!")
+                logger.debug("KML autotest OK!")
 
         if self.kml is None:
             self.kml = False
 
         # Read the georeference
         self.out_gt = self.warped_input_dataset.GetGeoTransform()
 
@@ -2275,20 +2279,17 @@
         self.omaxy = self.out_gt[3]
         self.ominy = (
             self.out_gt[3] - self.warped_input_dataset.RasterYSize * self.out_gt[1]
         )
         # Note: maybe round(x, 14) to avoid the gdal_translate behavior, when 0 becomes -1e-15
 
         if self.options.verbose:
-            print(
-                "Bounds (output srs):",
-                round(self.ominx, 13),
-                self.ominy,
-                self.omaxx,
-                self.omaxy,
+            logger.debug(
+                "Bounds (output srs): %f, %f, %f, %f"
+                % (round(self.ominx, 13), self.ominy, self.omaxx, self.omaxy)
             )
 
         # Calculating ranges for tiles in different zoom levels
         if self.options.profile == "mercator":
 
             self.mercator = GlobalMercator(tile_size=self.tile_size)
 
@@ -2323,26 +2324,23 @@
             if self.tmaxz is None:
                 self.tmaxz = self.mercator.ZoomForPixelSize(self.out_gt[1])
                 self.tmaxz = max(self.tminz, self.tmaxz)
 
             self.tminz = min(self.tminz, self.tmaxz)
 
             if self.options.verbose:
-                print(
-                    "Bounds (latlong):",
-                    self.mercator.MetersToLatLon(self.ominx, self.ominy),
-                    self.mercator.MetersToLatLon(self.omaxx, self.omaxy),
+                logger.debug(
+                    "Bounds (latlong): %s, %s",
+                    str(self.mercator.MetersToLatLon(self.ominx, self.ominy)),
+                    str(self.mercator.MetersToLatLon(self.omaxx, self.omaxy)),
                 )
-                print("MinZoomLevel:", self.tminz)
-                print(
-                    "MaxZoomLevel:",
-                    self.tmaxz,
-                    "(",
-                    self.mercator.Resolution(self.tmaxz),
-                    ")",
+                logger.debug("MinZoomLevel: %d" % self.tminz)
+                logger.debug(
+                    "MaxZoomLevel: %d (%f)"
+                    % (self.tmaxz, self.mercator.Resolution(self.tmaxz))
                 )
 
         elif self.options.profile == "geodetic":
 
             self.geodetic = GlobalGeodetic(
                 self.options.tmscompatible, tile_size=self.tile_size
             )
@@ -2379,16 +2377,17 @@
             if self.tmaxz is None:
                 self.tmaxz = self.geodetic.ZoomForPixelSize(self.out_gt[1])
                 self.tmaxz = max(self.tminz, self.tmaxz)
 
             self.tminz = min(self.tminz, self.tmaxz)
 
             if self.options.verbose:
-                print(
-                    "Bounds (latlong):", self.ominx, self.ominy, self.omaxx, self.omaxy
+                logger.debug(
+                    "Bounds (latlong): %f, %f, %f, %f"
+                    % (self.ominx, self.ominy, self.omaxx, self.omaxy)
                 )
 
         elif self.options.profile == "raster":
 
             def log2(x):
                 return math.log10(x) / math.log10(2)
 
@@ -2409,15 +2408,15 @@
                             )
                         ),
                     )
                 ),
             )
 
             if self.options.verbose:
-                print("Native zoom of the raster:", self.nativezoom)
+                logger.debug("Native zoom of the raster: %d" % self.nativezoom)
 
             # Get the minimal zoom level (whole raster in one tile)
             if self.tminz is None:
                 self.tminz = 0
 
             # Get the maximal zoom level (native resolution of the raster)
             if self.tmaxz is None:
@@ -2532,19 +2531,20 @@
             if self.tmaxz is None:
                 self.tmaxz = tms.ZoomForPixelSize(self.out_gt[1], self.tile_size)
                 self.tmaxz = max(self.tminz, self.tmaxz)
 
             self.tminz = min(self.tminz, self.tmaxz)
 
             if self.options.verbose:
-                print(
-                    "Bounds (georef):", self.ominx, self.ominy, self.omaxx, self.omaxy
+                logger.debug(
+                    "Bounds (georef): %f, %f, %f, %f"
+                    % (self.ominx, self.ominy, self.omaxx, self.omaxy)
                 )
-                print("MinZoomLevel:", self.tminz)
-                print("MaxZoomLevel:", self.tmaxz)
+                logger.debug("MinZoomLevel: %d" % self.tminz)
+                logger.debug("MaxZoomLevel: %d" % self.tmaxz)
 
     def generate_metadata(self) -> None:
         """
         Generation of main metadata files and HTML viewers (metadata related to particular
         tiles are generated during the tile processing).
         """
 
@@ -2668,32 +2668,32 @@
 
     def generate_base_tiles(self) -> Tuple[TileJobInfo, List[TileDetail]]:
         """
         Generation of the base tiles (the lowest in the pyramid) directly from the input raster
         """
 
         if not self.options.quiet:
-            print("Generating Base Tiles:")
+            logger.info("Generating Base Tiles:")
 
         if self.options.verbose:
-            print("")
-            print("Tiles generated from the max zoom level:")
-            print("----------------------------------------")
-            print("")
+            logger.debug("")
+            logger.debug("Tiles generated from the max zoom level:")
+            logger.debug("----------------------------------------")
+            logger.debug("")
 
         # Set the bounds
         tminx, tminy, tmaxx, tmaxy = self.tminmax[self.tmaxz]
 
         ds = self.warped_input_dataset
         tilebands = self.dataBandsCount + 1
         querysize = self.querysize
 
         if self.options.verbose:
-            print("dataBandsCount: ", self.dataBandsCount)
-            print("tilebands: ", tilebands)
+            logger.debug("dataBandsCount: %d" % self.dataBandsCount)
+            logger.debug("tilebands: %d" % tilebands)
 
         tcount = (1 + abs(tmaxx - tminx)) * (1 + abs(tmaxy - tminy))
         ti = 0
 
         tile_details = []
 
         tz = self.tmaxz
@@ -2711,19 +2711,19 @@
                 tilefilename = os.path.join(
                     self.output_folder,
                     str(tz),
                     str(tx),
                     "%s.%s" % (ytile, self.tileext),
                 )
                 if self.options.verbose:
-                    print(ti, "/", tcount, tilefilename)
+                    logger.debug("%d / %d, %s" % (ti, tcount, tilefilename))
 
                 if self.options.resume and isfile(tilefilename):
                     if self.options.verbose:
-                        print("Tile generation skipped because of --resume")
+                        logger.debug("Tile generation skipped because of --resume")
                     continue
 
                 if self.options.profile == "mercator":
                     # Tile bounds in EPSG:3857
                     b = self.mercator.TileBounds(tx, ty, tz)
                 elif self.options.profile == "geodetic":
                     b = self.geodetic.TileBounds(tx, ty, tz)
@@ -2737,15 +2737,17 @@
 
                 if self.options.profile != "raster":
                     rb, wb = self.geo_query(ds, b[0], b[3], b[2], b[1])
 
                     # Pixel size in the raster covering query geo extent
                     nativesize = wb[0] + wb[2]
                     if self.options.verbose:
-                        print("\tNative Extent (querysize", nativesize, "): ", rb, wb)
+                        logger.debug(
+                            f"\tNative Extent (querysize {nativesize}): {rb}, {wb}"
+                        )
 
                     # Tile bounds in raster coordinates for ReadRaster query
                     rb, wb = self.geo_query(
                         ds, b[0], b[3], b[2], b[1], querysize=querysize
                     )
 
                     rx, ry, rxsize, rysize = rb
@@ -3472,28 +3474,28 @@
    * @property {Boolean} [restrictY] Whether to restrict move in Y direction
    */
 
  // End of https://github.com/gavinharriss/google-maps-v3-opacity-control/blob/master/ExtDraggableObject.js
 """
 
         s = (
-            r"""<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
-            <html xmlns="http://www.w3.org/1999/xhtml" xmlns:v="urn:schemas-microsoft-com:vml">
+            r"""<!DOCTYPE html>
+            <html>
               <head>
                 <title>%(xml_escaped_title)s</title>
                 <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
                 <meta http-equiv='imagetoolbar' content='no'/>
                 <style type="text/css"> v\:* {behavior:url(#default#VML);}
                     html, body { overflow: hidden; padding: 0; height: 100%%; width: 100%%; font-family: 'Lucida Grande',Geneva,Arial,Verdana,sans-serif; }
                     body { margin: 10px; background: #fff; }
                     h1 { margin: 0; padding: 6px; border:0; font-size: 20pt; }
                     #header { height: 43px; padding: 0; background-color: #eee; border: 1px solid #888; }
-              #subheader { height: 12px; text-align: right; font-size: 10px; color: #555;}
-              #map { height: 95%%; border: 1px solid #888; }
-          </style>
+                    #subheader { height: 12px; text-align: right; font-size: 10px; color: #555;}
+                    #map { height: 95%%; border: 1px solid #888; }
+                 </style>
           %(googlemapsurl_hint)s
           <script src='%(googlemapsurl)s'></script>
           <script>
           //<![CDATA[
 
                 /*
                  * Constants for given map
@@ -3895,18 +3897,19 @@
         args["ominy"] = self.ominy
         args["omaxx"] = self.omaxx
         args["omaxy"] = self.omaxy
         args["center_x"] = (self.ominx + self.omaxx) / 2
         args["center_y"] = (self.ominy + self.omaxy) / 2
 
         s = (
-            r"""<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
-<html xmlns="http://www.w3.org/1999/xhtml">
+            r"""<!DOCTYPE html>
+<html>
     <head>
     <title>%(xml_escaped_title)s</title>
+    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
     <meta http-equiv='imagetoolbar' content='no'/>
     <style type="text/css"> v\:* {behavior:url(#default#VML);}
         html, body { overflow: hidden; padding: 0; height: 100%%; width: 100%%; font-family: 'Lucida Grande',Geneva,Arial,Verdana,sans-serif; }
         body { margin: 10px; background: #fff; }
         h1 { margin: 0; padding: 6px; border:0; font-size: 20pt; }
         #header { height: 43px; padding: 0; background-color: #eee; border: 1px solid #888; }
         #subheader { height: 12px; text-align: right; font-size: 10px; color: #555;}
@@ -4289,40 +4292,26 @@
     gdal2tiles.open_input()
     gdal2tiles.generate_metadata()
     tile_job_info, tile_details = gdal2tiles.generate_base_tiles()
     return tile_job_info, tile_details
 
 
 class ProgressBar(object):
-    def __init__(self, total_items: int) -> None:
+    def __init__(self, total_items: int, progress_cbk=gdal.TermProgress_nocb) -> None:
         self.total_items = total_items
         self.nb_items_done = 0
-        self.current_progress = 0
-        self.STEP = 2.5
+        self.progress_cbk = progress_cbk
 
     def start(self) -> None:
-        sys.stdout.write("0")
+        self.progress_cbk(0, "", None)
 
     def log_progress(self, nb_items: int = 1) -> None:
         self.nb_items_done += nb_items
-        progress = float(self.nb_items_done) / self.total_items * 100
-        if progress >= self.current_progress + self.STEP:
-            done = False
-            while not done:
-                if self.current_progress + self.STEP <= progress:
-                    self.current_progress += self.STEP
-                    if self.current_progress % 10 == 0:
-                        sys.stdout.write(str(int(self.current_progress)))
-                        if self.current_progress == 100:
-                            sys.stdout.write("\n")
-                    else:
-                        sys.stdout.write(".")
-                else:
-                    done = True
-        sys.stdout.flush()
+        progress = float(self.nb_items_done) / self.total_items
+        self.progress_cbk(progress, "", None)
 
 
 def get_tile_swne(tile_job_info, options):
     if options.profile == "mercator":
         mercator = GlobalMercator()
         tile_swne = mercator.TileLatLonBounds
     elif options.profile == "geodetic":
@@ -4377,19 +4366,19 @@
     input_file: str, output_folder: str, options: Options
 ) -> None:
     """
     Keep a single threaded version that stays clear of multiprocessing, for platforms that would not
     support it
     """
     if options.verbose:
-        print("Begin tiles details calc")
+        logger.debug("Begin tiles details calc")
     conf, tile_details = worker_tile_details(input_file, output_folder, options)
 
     if options.verbose:
-        print("Tiles details calc complete.")
+        logger.debug("Tiles details calc complete.")
 
     if not options.verbose and not options.quiet:
         base_progress_bar = ProgressBar(len(tile_details))
         base_progress_bar.start()
 
     for tile_detail in tile_details:
         create_base_tile(conf, tile_detail)
@@ -4399,15 +4388,15 @@
 
     if getattr(threadLocal, "cached_ds", None):
         del threadLocal.cached_ds
 
     if not options.quiet:
         count = count_overview_tiles(conf)
         if count:
-            print("Generating Overview Tiles:")
+            logger.info("Generating Overview Tiles:")
 
             if not options.verbose:
                 overview_progress_bar = ProgressBar(count)
                 overview_progress_bar.start()
 
     for base_tz in range(conf.tmaxz, conf.tminz, -1):
         base_tile_groups = group_overview_base_tiles(base_tz, output_folder, conf)
@@ -4421,20 +4410,20 @@
 
 def multi_threaded_tiling(
     input_file: str, output_folder: str, options: Options, pool
 ) -> None:
     nb_processes = options.nb_processes or 1
 
     if options.verbose:
-        print("Begin tiles details calc")
+        logger.debug("Begin tiles details calc")
 
     conf, tile_details = worker_tile_details(input_file, output_folder, options)
 
     if options.verbose:
-        print("Tiles details calc complete.")
+        logger.debug("Tiles details calc complete.")
 
     if not options.verbose and not options.quiet:
         base_progress_bar = ProgressBar(len(tile_details))
         base_progress_bar.start()
 
     # TODO: gbataille - check the confs for which each element is an array... one useless level?
     # TODO: gbataille - assign an ID to each job for print in verbose mode "ReadRaster Extent ..."
@@ -4444,15 +4433,15 @@
     ):
         if not options.verbose and not options.quiet:
             base_progress_bar.log_progress()
 
     if not options.quiet:
         count = count_overview_tiles(conf)
         if count:
-            print("Generating Overview Tiles:")
+            logger.info("Generating Overview Tiles:")
 
             if not options.verbose:
                 overview_progress_bar = ProgressBar(count)
                 overview_progress_bar.start()
 
     for base_tz in range(conf.tmaxz, conf.tminz, -1):
         base_tile_groups = group_overview_base_tiles(base_tz, output_folder, conf)
@@ -4498,15 +4487,15 @@
         set_cache_max(gdal_cache_max_per_process)
 
     def __exit__(self, type, value, tb):
         # Set the maximum cache back to the original value
         set_cache_max(self.gdal_cache_max)
 
 
-def main(argv: List[str] = sys.argv) -> int:
+def main(argv: List[str] = sys.argv, called_from_main=False) -> int:
     # TODO: gbataille - use mkdtemp to work in a temp directory
     # TODO: gbataille - debug intermediate tiles.vrt not produced anymore?
     # TODO: gbataille - Refactor generate overview tiles to not depend on self variables
 
     # For multiprocessing, we need to propagate the configuration options to
     # the environment, so that forked processes can inherit them.
     for i in range(len(argv)):
@@ -4518,25 +4507,29 @@
         from mpi4py.futures import MPICommExecutor
 
         with UseExceptions(), MPICommExecutor(MPI.COMM_WORLD, root=0) as pool:
             if pool is None:
                 return 0
             # add interface of multiprocessing.Pool to MPICommExecutor
             pool.imap_unordered = partial(pool.map, unordered=True)
-            return submain(argv, pool, MPI.COMM_WORLD.Get_size())
+            return submain(
+                argv, pool, MPI.COMM_WORLD.Get_size(), called_from_main=called_from_main
+            )
     else:
-        return submain(argv)
+        return submain(argv, called_from_main=called_from_main)
 
 
-def submain(argv: List[str], pool=None, pool_size=0) -> int:
+def submain(argv: List[str], pool=None, pool_size=0, called_from_main=False) -> int:
 
     argv = gdal.GeneralCmdLineProcessor(argv)
     if argv is None:
         return 0
-    input_file, output_folder, options = process_args(argv[1:])
+    input_file, output_folder, options = process_args(
+        argv[1:], called_from_main=called_from_main
+    )
     if pool_size:
         options.nb_processes = pool_size
     nb_processes = options.nb_processes or 1
 
     with UseExceptions():
         if pool is not None:  # MPI
             multi_threaded_tiling(input_file, output_folder, options, pool)
@@ -4558,8 +4551,8 @@
 
 
 # vim: set tabstop=4 shiftwidth=4 expandtab:
 
 # Running main() must be protected that way due to use of multiprocessing on Windows:
 # https://docs.python.org/3/library/multiprocessing.html#the-spawn-and-forkserver-start-methods
 if __name__ == "__main__":
-    sys.exit(main(sys.argv))
+    sys.exit(main(sys.argv, called_from_main=True))
```

## osgeo_utils/gdal_calc.py

```diff
@@ -56,14 +56,15 @@
 
 # create alphabetic list (lowercase + uppercase) for storing input layers
 AlphaList = list(string.ascii_letters)
 
 # set up some default nodatavalues for each datatype
 DefaultNDVLookup = {
     gdal.GDT_Byte: 255,
+    gdal.GDT_Int8: None,
     gdal.GDT_UInt16: 65535,
     gdal.GDT_Int16: -32768,
     gdal.GDT_UInt32: 4294967293,
     gdal.GDT_Int32: -2147483647,
     gdal.GDT_UInt64: None,
     gdal.GDT_Int64: None,
     gdal.GDT_Float32: 3.402823466e38,
@@ -116,14 +117,15 @@
     projectionCheck: bool = False,
     color_table: Optional[ColorTableLike] = None,
     extent: Optional[Extent] = None,
     projwin: Optional[Union[Tuple, GeoRectangle]] = None,
     user_namespace: Optional[Dict] = None,
     debug: bool = False,
     quiet: bool = False,
+    progress_callback: Optional = gdal.TermProgress_nocb,
     **input_files,
 ):
 
     if debug:
         print(f"gdal_calc.py starting calculation {calc}")
 
     if outfile and os.path.isfile(outfile) and not overwrite:
@@ -484,15 +486,14 @@
     myBufSize = myBlockSize[0] * myBlockSize[1]
 
     if debug:
         print(f"using blocksize {myBlockSize[0]} x {myBlockSize[1]}")
 
     # variables for displaying progress
     ProgressCt = -1
-    ProgressMk = -1
     ProgressEnd = nXBlocks * nYBlocks * allBandsCount
 
     ################################################################
     # start looping through each band in allBandsCount
     ################################################################
 
     for bandNo in range(1, allBandsCount + 1):
@@ -539,17 +540,16 @@
             # reset buffer size for start of Y loop
             nYValid = myBlockSize[1]
             myBufSize = nXValid * nYValid
 
             # loop through Y lines
             for Y in range(0, nYBlocks):
                 ProgressCt += 1
-                if 10 * ProgressCt / ProgressEnd % 10 != ProgressMk and not quiet:
-                    ProgressMk = 10 * ProgressCt / ProgressEnd % 10
-                    print("%d.." % (10 * ProgressMk), end=" ")
+                if not quiet:
+                    progress_callback(float(ProgressCt) / ProgressEnd, "", None)
 
                 # change the block size of the final piece
                 if Y == nYBlocks - 1:
                     nYValid = DimensionsCheck[1] - Y * myBlockSize[1]
                     myBufSize = nXValid * nYValid
 
                 # find Y offset
@@ -661,15 +661,15 @@
 
     gdal.ErrorReset()
     myOut.FlushCache()
     if gdal.GetLastErrorMsg() != "":
         raise Exception("Dataset writing failed")
 
     if not quiet:
-        print("100 - Done")
+        progress_callback(1.0, "", None)
 
     return myOut
 
 
 def doit(opts):
     kwargs = vars(opts)
     if "outF" in kwargs:
```

## osgeo_utils/gdal_fillnodata.py

```diff
@@ -240,18 +240,20 @@
             help="Select the output format. Use the short format name.",
         )
 
         parser.add_argument(
             "-co",
             dest="creation_options",
             type=str,
-            action="extend",
-            nargs="*",
+            default=[],
+            action="append",
             metavar="name=value",
-            help="Creation options for the destination dataset.",
+            help="Passes a creation option to the output format driver. Multiple "
+            "options may be listed. See format specific documentation for legal "
+            "creation options for each format.",
         )
 
         parser.add_argument(
             "src_filename",
             type=str,
             help="The source raster file used to identify target pixels. "
             "Only one band is used.",
```

## osgeo_utils/gdal_merge.py

```diff
@@ -522,17 +522,16 @@
         psize_x = file_infos[0].geotransform[1]
         psize_y = file_infos[0].geotransform[5]
 
     if band_type is None:
         band_type = file_infos[0].band_type
 
     # Try opening as an existing file.
-    gdal.PushErrorHandler("CPLQuietErrorHandler")
-    t_fh = gdal.Open(out_file, gdal.GA_Update)
-    gdal.PopErrorHandler()
+    with gdal.quiet_errors(), gdal.ExceptionMgr(useExceptions=False):
+        t_fh = gdal.Open(out_file, gdal.GA_Update)
 
     # Create output file if it does not already exist.
     if t_fh is None:
 
         if bTargetAlignedPixels:
             ulx = math.floor(ulx / psize_x) * psize_x
             lrx = math.ceil(lrx / psize_x) * psize_x
```

## osgeo_utils/gdal_polygonize.py

```diff
@@ -46,14 +46,15 @@
     dst_filename: Optional[str] = None,
     driver_name: Optional[str] = None,
     dst_layername: Optional[str] = None,
     dst_fieldname: Optional[str] = None,
     quiet: bool = False,
     mask: str = "default",
     options: Optional[list] = None,
+    layer_creation_options: Optional[list] = None,
     connectedness8: bool = False,
 ):
 
     if isinstance(band_number, str) and not band_number.startswith("mask"):
         band_number = int(band_number)
 
     options = options or []
@@ -124,27 +125,37 @@
     except Exception:
         dst_layer = None
 
     dst_field: int = -1
     if dst_layer is None:
 
         srs = src_ds.GetSpatialRef()
-        dst_layer = dst_ds.CreateLayer(dst_layername, geom_type=ogr.wkbPolygon, srs=srs)
+        dst_layer = dst_ds.CreateLayer(
+            dst_layername,
+            geom_type=ogr.wkbPolygon,
+            srs=srs,
+            options=layer_creation_options if layer_creation_options else [],
+        )
 
         if dst_fieldname is None:
             dst_fieldname = "DN"
 
         data_type = ogr.OFTInteger
         if srcband.DataType == gdal.GDT_Int64 or srcband.DataType == gdal.GDT_UInt64:
             data_type = ogr.OFTInteger64
 
         fd = ogr.FieldDefn(dst_fieldname, data_type)
         dst_layer.CreateField(fd)
         dst_field = 0
     else:
+        if layer_creation_options:
+            print(
+                "Warning: layer_creation_options will be ignored as the layer already exists"
+            )
+
         if dst_fieldname is not None:
             dst_field = dst_layer.GetLayerDefn().GetFieldIndex(dst_fieldname)
             if dst_field < 0:
                 print(
                     "Warning: cannot find field '%s' in layer '%s'"
                     % (dst_fieldname, dst_layername)
                 )
@@ -154,17 +165,22 @@
     # =============================================================================
 
     if quiet:
         prog_func = None
     else:
         prog_func = gdal.TermProgress_nocb
 
+    dst_layer.StartTransaction()
     result = gdal.Polygonize(
         srcband, maskband, dst_layer, dst_field, options, callback=prog_func
     )
+    if result == gdal.CE_None:
+        dst_layer.CommitTransaction()
+    else:
+        dst_layer.RollbackTransaction()
 
     srcband = None
     src_ds = None
     dst_ds = None
     mask_ds = None
 
     return result
@@ -205,18 +221,17 @@
             help="Use 8 connectedness. Default is 4 connectedness.",
         )
 
         parser.add_argument(
             "-o",
             dest="options",
             type=str,
-            action="extend",
-            nargs="*",
+            action="append",
             metavar="name=value",
-            help="Specify a special argument to the algorithm.",
+            help="Specify a special argument to the algorithm. This may be specified multiple times.",
         )
 
         parser.add_argument(
             "-mask",
             dest="mask",
             type=str,
             metavar="filename",
@@ -255,14 +270,23 @@
             metavar="ogr_format",
             help="Select the output format. "
             "if not specified, the format is guessed from the extension. "
             "Use the short format name.",
         )
 
         parser.add_argument(
+            "-lco",
+            dest="layer_creation_options",
+            type=str,
+            action="append",
+            metavar="name=value",
+            help="Specify a layer creation option. This may be specified multiple times.",
+        )
+
+        parser.add_argument(
             "src_filename",
             type=str,
             help="The source raster file from which polygons are derived.",
         )
 
         parser.add_argument(
             "dst_filename",
```

## osgeo_utils/gdal_retile.py

```diff
@@ -880,15 +880,15 @@
 
 
 def Usage():
     print("Usage: gdal_retile.py ")
     print("        [-v] [-q] [-co NAME=VALUE]* [-of out_format]")
     print("        [-ps pixelWidth pixelHeight]")
     print("        [-overlap val_in_pixel]")
-    print("        [-ot  {Byte/Int16/UInt16/UInt32/Int32/Float32/Float64/")
+    print("        [-ot  {Byte/Int8/Int16/UInt16/UInt32/Int32/Float32/Float64/")
     print("               CInt16/CInt32/CFloat32/CFloat64}]")
     print("        [ -tileIndex tileIndexName [-tileIndexField fieldName]]")
     print("        [ -csv fileName [-csvDelim delimiter]]")
     print("        [-s_srs srs_def]  [-pyramidOnly] -levels numberoflevels")
     print("        [-r {near/bilinear/cubic/cubicspline/lanczos}]")
     print("        [-useDirForEachRow] [-resume]")
     print("        -targetDir TileDirectory input_files")
```

## osgeo_utils/ogr_layer_algebra.py

```diff
@@ -408,17 +408,19 @@
             )
         elif srs is not None and srs2 is not None and srs.IsSame(srs2) != 1:
             print(
                 "Warning: input and method layers have SRS defined, but they are not identical. No on-the-fly reprojection will be done."
             )
 
     # Result layer
-    output_ds = ogr.Open(output_ds_name, update=1)
+    with ogr.ExceptionMgr(useExceptions=False), gdal.quiet_errors():
+        output_ds = ogr.Open(output_ds_name, update=1)
     if output_ds is None:
-        output_ds = ogr.Open(output_ds_name)
+        with ogr.ExceptionMgr(useExceptions=False), gdal.quiet_errors():
+            output_ds = ogr.Open(output_ds_name)
         if output_ds is not None:
             print(
                 'Output datasource "%s" exists, but cannot be opened in update mode'
                 % output_ds_name
             )
             return 1
```

## osgeo_utils/ogrmerge.py

```diff
@@ -32,15 +32,15 @@
 
 import glob
 import os
 import os.path
 import sys
 from typing import Optional, Sequence
 
-from osgeo import gdal, ogr
+from osgeo import gdal, ogr, osr
 from osgeo_utils.auxiliary.base import PathLikeOrStr
 from osgeo_utils.auxiliary.util import GetOutputDriverFor
 
 
 def Usage():
     print("Usage: ogrmerge.py -o out_dsname src_dsname [src_dsname]*")
     print("            [-f format] [-single] [-nln layer_name_template]")
@@ -179,14 +179,16 @@
     src_layer_field_name = None
     src_layer_field_content = None
     a_srs = None
     s_srs = None
     t_srs = None
     dsco = []
     lco = []
+    # WARNING: if adding a new option, make sure to update _gpkg_ogrmerge()
+    # optimized code path, or use the general case.
 
     i = 0
     while i < len(argv):
         arg = argv[i]
         if (arg == "-f" or arg == "-of") and i + 1 < len(argv):
             i = i + 1
             driver_name = argv[i]
@@ -283,14 +285,548 @@
         dsco=dsco,
         lco=lco,
         progress_callback=progress,
         progress_arg=progress_arg,
     )
 
 
+#############################################################################
+
+
+def _build_layer_name_non_single_mode(
+    layer_name_template,
+    src_ds_idx,
+    src_dsname,
+    src_lyr_idx,
+    src_lyr_name,
+    skip_failures,
+):
+    layer_name = layer_name_template
+    basename = None
+    if os.path.exists(src_dsname):
+        basename = os.path.basename(src_dsname)
+        if "." in basename:
+            basename = ".".join(basename.split(".")[0:-1])
+
+    if basename == src_lyr_name:
+        layer_name = layer_name.replace("{AUTO_NAME}", basename)
+    elif basename is None:
+        layer_name = layer_name.replace(
+            "{AUTO_NAME}", "Dataset%d_%s" % (src_ds_idx, src_lyr_name)
+        )
+    else:
+        layer_name = layer_name.replace("{AUTO_NAME}", basename + "_" + src_lyr_name)
+
+    if basename is not None:
+        layer_name = layer_name.replace("{DS_BASENAME}", basename)
+    elif "{DS_BASENAME}" in layer_name:
+        if skip_failures:
+            if "{DS_INDEX}" not in layer_name:
+                layer_name = layer_name.replace(
+                    "{DS_BASENAME}", "Dataset%d" % src_ds_idx
+                )
+        else:
+            print(
+                "ERROR: Layer name template %s "
+                "includes {DS_BASENAME} "
+                "but %s is not a file" % (layer_name_template, src_dsname)
+            )
+            return None
+    layer_name = layer_name.replace("{DS_NAME}", "%s" % src_dsname)
+    layer_name = layer_name.replace("{DS_INDEX}", "%d" % src_ds_idx)
+    layer_name = layer_name.replace("{LAYER_NAME}", src_lyr_name)
+    layer_name = layer_name.replace("{LAYER_INDEX}", "%d" % src_lyr_idx)
+    return layer_name
+
+
+#############################################################################
+
+
+def _quote_literal(x):
+    return x.replace("'", "''")
+
+
+#############################################################################
+
+
+def _quote_id(x):
+    return x.replace('"', '""')
+
+
+#############################################################################
+
+
+def _gpkg_get_src_table_size(src_ds, table_name):
+    try:
+        # sqlite >= 3.31
+        sql_lyr = src_ds.ExecuteSQL(
+            "SELECT pgsize FROM temp.stat WHERE name = '%s' AND aggregate = TRUE"
+            % _quote_literal(table_name)
+        )
+    except Exception:
+        sql_lyr = src_ds.ExecuteSQL(
+            "SELECT SUM(pgsize) FROM temp.stat WHERE name = '%s'"
+            % _quote_literal(table_name)
+        )
+    f = sql_lyr.GetNextFeature()
+    src_table_size = f.GetField(0)
+    src_ds.ReleaseResultSet(sql_lyr)
+    return src_table_size
+
+
+#############################################################################
+
+
+def _gpkg_has_spatial_index(ds, lyr):
+    has_spatial_index = False
+    if lyr.GetGeomType() != ogr.wkbNone:
+        sql_lyr = ds.ExecuteSQL(
+            "SELECT HasSpatialIndex('%s', '%s')"
+            % (_quote_literal(lyr.GetName()), _quote_literal(lyr.GetGeometryColumn()))
+        )
+        f = sql_lyr.GetNextFeature()
+        has_spatial_index = f.GetField(0)
+        ds.ReleaseResultSet(sql_lyr)
+    return has_spatial_index
+
+
+#############################################################################
+# Estimate the final .gpkg file size from the contributing source layers
+
+
+def _gpkg_get_estimated_final_size(
+    src_datasets, src_geom_types, can_reuse_spatial_index
+):
+
+    estimated_final_size = 0
+
+    for src_dsname in src_datasets:
+        src_ds = ogr.Open(src_dsname)
+        if src_ds is None:
+            continue
+
+        dbstat_available = False
+        try:
+            src_ds.ExecuteSQL("CREATE VIRTUAL TABLE temp.stat USING dbstat(main)")
+            dbstat_available = True
+        except Exception:
+            pass
+
+        use_src_file_size = True
+        if dbstat_available:
+            for src_lyr in src_ds:
+                if src_geom_types:
+                    gt = ogr.GT_Flatten(src_lyr.GetGeomType())
+                    if gt not in src_geom_types:
+                        use_src_file_size = False
+                        break
+
+                if not can_reuse_spatial_index and _gpkg_has_spatial_index(
+                    src_ds, src_lyr
+                ):
+                    use_src_file_size = False
+                    break
+
+        if use_src_file_size:
+            # Wrong if not all layers are selected...
+            estimated_final_size += gdal.VSIStatL(src_dsname).size
+        else:
+            for src_lyr in src_ds:
+                if src_geom_types:
+                    gt = ogr.GT_Flatten(src_lyr.GetGeomType())
+                    if gt not in src_geom_types:
+                        continue
+
+                estimated_final_size += _gpkg_get_src_table_size(
+                    src_ds, src_lyr.GetName()
+                )
+                if can_reuse_spatial_index and _gpkg_has_spatial_index(src_ds, src_lyr):
+                    src_rtree_prefix = "rtree_%s_%s" % (
+                        src_lyr.GetName(),
+                        src_lyr.GetGeometryColumn(),
+                    )
+                    estimated_final_size += _gpkg_get_src_table_size(
+                        src_ds, src_rtree_prefix + "_node"
+                    )
+                    estimated_final_size += _gpkg_get_src_table_size(
+                        src_ds, src_rtree_prefix + "_rowid"
+                    )
+                    estimated_final_size += _gpkg_get_src_table_size(
+                        src_ds, src_rtree_prefix + "_parent"
+                    )
+
+    return estimated_final_size
+
+
+#############################################################################
+
+
+def _gpkg_get_srs_id(ds, lyr):
+    sql = (
+        "SELECT srs_id FROM gpkg_geometry_columns WHERE table_name = '%s'"
+        % _quote_literal(lyr.GetName())
+    )
+    sql_lyr = ds.ExecuteSQL(sql)
+    f = sql_lyr.GetNextFeature()
+    srs_id = f.GetField(0)
+    ds.ReleaseResultSet(sql_lyr)
+    return srs_id
+
+
+#############################################################################
+# Optimized implementation of general case for geopackage output, that can be used only:
+# - in non-single mode
+# - when all sources are geopackages
+# - for a newly created dataset
+
+
+def _gpkg_ogrmerge(
+    src_datasets: Optional[Sequence[str]] = None,
+    dst_filename: Optional[PathLikeOrStr] = None,
+    driver_name: Optional[str] = None,
+    layer_name_template: Optional[str] = None,
+    skip_failures: bool = False,
+    src_geom_types: Optional[Sequence[int]] = None,
+    a_srs: Optional[str] = None,
+    s_srs: Optional[str] = None,
+    t_srs: Optional[str] = None,
+    dsco: Optional[Sequence[str]] = None,
+    lco: Optional[Sequence[str]] = None,
+    progress_callback: Optional = None,
+    progress_arg: Optional = None,
+):
+
+    driver_name = "GPKG"
+    drv = gdal.GetDriverByName(driver_name)
+    if drv is None:
+        print("ERROR: Invalid driver: %s" % driver_name)
+        return 1
+    dst_ds = drv.Create(dst_filename, 0, 0, 0, gdal.GDT_Unknown, dsco)
+    if dst_ds is None:
+        return 1
+
+    ogr.UseExceptions()
+    gdal.UseExceptions()
+    osr.UseExceptions()
+
+    class ThreadedProgress:
+        def __init__(self, dst_filename, estimated_final_size):
+            self.stop_thread = False
+
+            import time
+            from threading import Thread
+
+            def myfunc():
+                while not self.stop_thread:
+                    dst_file_size = gdal.VSIStatL(dst_filename).size
+                    pct = min(1.0, dst_file_size / estimated_final_size)
+                    progress_callback(pct, "", progress_arg)
+                    time.sleep(0.1)
+
+            t = Thread(target=myfunc)
+            t.start()
+
+        def stop(self):
+            self.stop_thread = True
+
+    create_spatial_index = "SPATIAL_INDEX=NO" not in [x.upper() for x in lco]
+    can_reuse_spatial_index = t_srs is None and create_spatial_index
+
+    estimated_final_size = 0
+    if progress_callback:
+        estimated_final_size = _gpkg_get_estimated_final_size(
+            src_datasets, src_geom_types, can_reuse_spatial_index
+        )
+
+    for src_ds_idx, src_dsname in enumerate(src_datasets):
+        src_ds = ogr.Open(src_dsname)
+        if src_ds is None:
+            print("ERROR: Cannot open %s" % src_dsname)
+            if skip_failures:
+                continue
+            return 1
+
+        for src_lyr_idx, src_lyr in enumerate(src_ds):
+
+            if src_geom_types:
+                gt = ogr.GT_Flatten(src_lyr.GetGeomType())
+                if gt not in src_geom_types:
+                    continue
+
+            has_geom = src_lyr.GetGeomType() != ogr.wkbNone
+            if has_geom and not any(
+                opt.upper().startswith("GEOMETRY_NAME=") for opt in lco
+            ):
+                modified_lco = ["GEOMETRY_NAME=" + src_lyr.GetGeometryColumn()] + lco
+            else:
+                modified_lco = lco
+
+            if t_srs and has_geom:
+                srs = osr.SpatialReference()
+                srs.SetFromUserInput(t_srs)
+            elif a_srs and has_geom:
+                srs = osr.SpatialReference()
+                srs.SetFromUserInput(a_srs)
+            else:
+                srs = src_lyr.GetSpatialRef()
+
+            layer_name = _build_layer_name_non_single_mode(
+                layer_name_template,
+                src_ds_idx,
+                src_dsname,
+                src_lyr_idx,
+                src_lyr.GetName(),
+                skip_failures,
+            )
+            if layer_name is None:
+                return 1
+
+            lyr = dst_ds.CreateLayer(
+                layer_name,
+                geom_type=src_lyr.GetGeomType(),
+                srs=srs,
+                options=modified_lco,
+            )
+            for field_idx in range(src_lyr.GetLayerDefn().GetFieldCount()):
+                lyr.CreateField(src_lyr.GetLayerDefn().GetFieldDefn(field_idx))
+
+            md = src_lyr.GetMetadata()
+            if md:
+                lyr.SetMetadata(md)
+
+            lyr.SyncToDisk()
+
+            if has_geom:
+                src_srs_id = _gpkg_get_srs_id(src_ds, src_lyr)
+                dst_srs_id = _gpkg_get_srs_id(dst_ds, lyr)
+                rtree_prefix = "rtree_%s_%s" % (lyr.GetName(), lyr.GetGeometryColumn())
+            else:
+                rtree_prefix = "__invalid__"
+                src_srs_id = -1
+                dst_srs_id = -1
+
+            # Collect triggers that we can safely temporary disable, and drop them
+            sql = (
+                "SELECT name, sql FROM sqlite_master WHERE type = 'trigger' AND (name LIKE '%s_%%' OR name LIKE 'trigger_insert_feature_count_%s' OR name LIKE 'trigger_delete_feature_count_%s')"
+                % (
+                    _quote_literal(rtree_prefix),
+                    _quote_literal(lyr.GetName()),
+                    _quote_literal(lyr.GetName()),
+                )
+            )
+            triggers = []
+            sql_lyr = dst_ds.ExecuteSQL(sql)
+            for f in sql_lyr:
+                trigger_name = f["name"]
+                dst_ds.ExecuteSQL('DROP TRIGGER "%s"' % _quote_id(trigger_name))
+                triggers.append(f["sql"])
+            dst_ds.ReleaseResultSet(sql_lyr)
+
+            def get_normalized_field_names(ds, lyr):
+                fields = []
+                sql_lyr = ds.ExecuteSQL(
+                    "PRAGMA table_info('%s')" % _quote_literal(lyr.GetName())
+                )
+                for f in sql_lyr:
+                    col_name = f["name"]
+                    if col_name == lyr.GetFIDColumn():
+                        fields.append("__FID__")
+                    elif col_name == lyr.GetGeometryColumn():
+                        fields.append("__GEOMETRY_COLUMN__")
+                    else:
+                        fields.append(col_name)
+                ds.ReleaseResultSet(sql_lyr)
+                return fields
+
+            # Build list of field names to select
+            if (
+                src_srs_id == dst_srs_id
+                and s_srs is None
+                and t_srs is None
+                and get_normalized_field_names(src_ds, src_lyr)
+                == get_normalized_field_names(dst_ds, lyr)
+            ):
+                # If fields in source and target layers are ordered the same, using * is slightly faster
+                # than selecting individual fields
+                fields = "*"
+            else:
+                fields = '"%s"' % _quote_id(src_lyr.GetFIDColumn())
+                if has_geom:
+                    if src_srs_id == dst_srs_id:
+                        fields += ', "%s"' % _quote_id(src_lyr.GetGeometryColumn())
+                    elif t_srs:
+                        # Reproject
+                        if s_srs:
+                            s_srs_obj = osr.SpatialReference()
+                            s_srs_obj.SetFromUserInput(s_srs)
+                            assert s_srs_obj.GetAuthorityName(None) == "EPSG"
+                            src_srs_id = int(s_srs_obj.GetAuthorityCode(None))
+                            fields += ', ST_Transform(SetSRID("%s", %d), %d)' % (
+                                _quote_id(src_lyr.GetGeometryColumn()),
+                                src_srs_id,
+                                dst_srs_id,
+                            )
+                        else:
+                            fields += ', ST_Transform("%s", %d)' % (
+                                _quote_id(src_lyr.GetGeometryColumn()),
+                                dst_srs_id,
+                            )
+                    else:
+                        # Just remap the geometry SRID to the one of the destination dataset
+                        fields += ', SetSRID("%s", %d)' % (
+                            _quote_id(src_lyr.GetGeometryColumn()),
+                            dst_srs_id,
+                        )
+                for field_idx in range(src_lyr.GetLayerDefn().GetFieldCount()):
+                    fields += ', "%s"' % _quote_id(
+                        src_lyr.GetLayerDefn().GetFieldDefn(field_idx).GetName()
+                    )
+
+            dst_ds.ExecuteSQL(
+                "ATTACH DATABASE '%s' AS source_db" % _quote_literal(src_dsname)
+            )
+
+            threaded_progress = None
+            if progress_callback:
+                threaded_progress = ThreadedProgress(dst_filename, estimated_final_size)
+
+            # Copy features
+            try:
+                dst_ds.ExecuteSQL(
+                    'INSERT INTO "%s" SELECT %s FROM source_db."%s"'
+                    % (_quote_id(lyr.GetName()), fields, _quote_id(src_lyr.GetName()))
+                )
+            finally:
+                if threaded_progress:
+                    threaded_progress.stop()
+
+            # Update gpkg_ogr_contents
+            sql_lyr = dst_ds.ExecuteSQL("SELECT changes()")
+            f = sql_lyr.GetNextFeature()
+            num_rows_inserted = f.GetField(0)
+            f = None
+            dst_ds.ReleaseResultSet(sql_lyr)
+            src_feature_count = src_lyr.GetFeatureCount(force=0)
+            if src_feature_count >= 0 and num_rows_inserted != src_feature_count:
+                print(
+                    "Warning: %d rows inserted into %s whereas %d expected"
+                    % (num_rows_inserted, lyr.GetName(), src_feature_count)
+                )
+            dst_ds.ExecuteSQL(
+                "INSERT OR REPLACE INTO gpkg_ogr_contents VALUES('%s',%d)"
+                % (_quote_literal(lyr.GetName()), num_rows_inserted)
+            )
+
+            recreateSpatialIndex = False
+            if has_geom and create_spatial_index:
+                if can_reuse_spatial_index and _gpkg_has_spatial_index(src_ds, src_lyr):
+                    # print("Copying spatial index")
+
+                    src_rtree_prefix = "rtree_%s_%s" % (
+                        src_lyr.GetName(),
+                        src_lyr.GetGeometryColumn(),
+                    )
+
+                    if progress_callback:
+                        threaded_progress = ThreadedProgress(
+                            dst_filename, estimated_final_size
+                        )
+                    try:
+                        dst_ds.ExecuteSQL(
+                            'DELETE FROM "%s_node" ' % _quote_id(rtree_prefix)
+                        )
+                        dst_ds.ExecuteSQL(
+                            'INSERT INTO "%s_node" SELECT * FROM source_db."%s_node"'
+                            % (_quote_id(rtree_prefix), _quote_id(src_rtree_prefix))
+                        )
+                        dst_ds.ExecuteSQL(
+                            'INSERT INTO "%s_rowid" SELECT * FROM source_db."%s_rowid"'
+                            % (_quote_id(rtree_prefix), _quote_id(src_rtree_prefix))
+                        )
+                        dst_ds.ExecuteSQL(
+                            'INSERT INTO "%s_parent" SELECT * FROM source_db."%s_parent"'
+                            % (_quote_id(rtree_prefix), _quote_id(src_rtree_prefix))
+                        )
+                    finally:
+                        if threaded_progress:
+                            threaded_progress.stop()
+
+                else:
+                    recreateSpatialIndex = True
+
+            dst_ds.ExecuteSQL("DETACH DATABASE source_db")
+
+            # Manually register gpkg_geom_* extensions, if not already done
+            # at layer creation time.
+            sql_lyr = src_ds.ExecuteSQL(
+                "SELECT 1 FROM sqlite_master WHERE type = 'table' AND name = 'gpkg_extensions'"
+            )
+            has_gpkg_extensions = sql_lyr.GetFeatureCount() == 1
+            src_ds.ReleaseResultSet(sql_lyr)
+            if has_geom and has_gpkg_extensions:
+                sql = (
+                    "SELECT extension_name FROM gpkg_extensions WHERE table_name = '%s' AND column_name = '%s' AND extension_name LIKE 'gpkg_geom_%%'"
+                    % (
+                        _quote_literal(src_lyr.GetName()),
+                        _quote_literal(src_lyr.GetGeometryColumn()),
+                    )
+                )
+                sql_lyr = src_ds.ExecuteSQL(sql)
+                for f in sql_lyr:
+                    geom_type = f.GetField(0)[len("gpkg_geom_") :]
+                    dst_ds.ReleaseResultSet(
+                        dst_ds.ExecuteSQL(
+                            "SELECT RegisterGeometryExtension('%s', '%s', '%s')"
+                            % (lyr.GetName(), lyr.GetGeometryColumn(), geom_type)
+                        )
+                    )
+                src_ds.ReleaseResultSet(sql_lyr)
+
+            # Update extent
+            if has_geom:
+                res = src_lyr.GetExtent(force=1, can_return_null=True)
+                if res:
+                    minx, maxx, miny, maxy = res
+                    sql = (
+                        "UPDATE gpkg_contents SET min_x=%.18g, min_y=%.18g, max_x=%.18g, max_y=%.18g WHERE table_name = '%s'"
+                        % (minx, miny, maxx, maxy, _quote_literal(lyr.GetName()))
+                    )
+                    dst_ds.ExecuteSQL(sql)
+
+            # Re-install triggers
+            for sql in triggers:
+                dst_ds.ExecuteSQL(sql)
+
+            if recreateSpatialIndex:
+                # print("Recreating spatial index")
+                dst_ds.ReleaseResultSet(
+                    dst_ds.ExecuteSQL(
+                        "SELECT DisableSpatialIndex('%s', '%s')"
+                        % (
+                            _quote_literal(lyr.GetName()),
+                            _quote_literal(lyr.GetGeometryColumn()),
+                        )
+                    )
+                )
+                dst_ds.ReleaseResultSet(
+                    dst_ds.ExecuteSQL(
+                        "SELECT CreateSpatialIndex('%s', '%s')"
+                        % (
+                            _quote_literal(lyr.GetName()),
+                            _quote_literal(lyr.GetGeometryColumn()),
+                        )
+                    )
+                )
+
+    if progress_callback:
+        progress_callback(1.0, "", progress_arg)
+
+    return 0
+
+
 def ogrmerge(
     src_datasets: Optional[Sequence[str]] = None,
     dst_filename: Optional[PathLikeOrStr] = None,
     driver_name: Optional[str] = None,
     overwrite_ds: bool = False,
     overwrite_layer: bool = False,
     update: bool = False,
@@ -349,17 +885,68 @@
 
     if layer_name_template is None:
         if single_layer:
             layer_name_template = "merged"
         else:
             layer_name_template = "{AUTO_NAME}"
 
+    def get_vector_file_in_update_no_exception(filename):
+        with gdal.ExceptionMgr(useExceptions=False), gdal.quiet_errors():
+            return gdal.OpenEx(filename, gdal.OF_VECTOR | gdal.OF_UPDATE)
+
+    if (
+        not single_layer
+        and EQUAL(driver_name, "GPKG")
+        and get_vector_file_in_update_no_exception(dst_filename) is None
+        and EQUAL(gdal.GetConfigOption("OGR_MERGE_ENABLE_GPKG_OPTIM", "YES"), "YES")
+    ):
+
+        def are_sources_gpkg():
+            for src_dsname in src_datasets:
+                if src_dsname.lower().endswith(".gpkg"):
+                    src_ds = ogr.Open(src_dsname)
+                    if src_ds is None:
+                        return False
+                    for src_lyr in src_ds:
+                        if src_lyr.GetLayerDefn().GetGeomFieldCount() > 1:
+                            # shouldn't happen for now...
+                            print("Code is not ready for multi-geometry column GPKG")
+                            return False
+                else:
+                    return False
+            return True
+
+        compat_of_gpkg_optim = are_sources_gpkg()
+        if compat_of_gpkg_optim:
+            if s_srs:
+                s_srs_obj = osr.SpatialReference()
+                s_srs_obj.SetFromUserInput(s_srs)
+                if s_srs_obj.GetAuthorityName(None) != "EPSG":
+                    compat_of_gpkg_optim = False
+
+        if compat_of_gpkg_optim:
+            return _gpkg_ogrmerge(
+                src_datasets,
+                dst_filename,
+                driver_name,
+                layer_name_template,
+                skip_failures,
+                src_geom_types,
+                a_srs,
+                s_srs,
+                t_srs,
+                dsco,
+                lco,
+                progress_callback,
+                progress_arg,
+            )
+
     vrt_filename = None
     if not EQUAL(driver_name, "VRT"):
-        dst_ds = gdal.OpenEx(dst_filename, gdal.OF_VECTOR | gdal.OF_UPDATE)
+        dst_ds = get_vector_file_in_update_no_exception(dst_filename)
         if dst_ds is not None:
             if not update and not overwrite_ds:
                 print(
                     "ERROR: Destination dataset already exists, "
                     + "but -update nor -overwrite_ds are specified"
                 )
                 return 1
@@ -521,54 +1108,26 @@
 
                 src_lyr_name = src_lyr.GetName()
                 try:
                     src_lyr_name = src_lyr_name.decode("utf-8")
                 except AttributeError:
                     pass
 
-                layer_name = layer_name_template
-                basename = None
-                if os.path.exists(src_dsname):
-                    basename = os.path.basename(src_dsname)
-                    if "." in basename:
-                        basename = ".".join(basename.split(".")[0:-1])
-
-                if basename == src_lyr_name:
-                    layer_name = layer_name.replace("{AUTO_NAME}", basename)
-                elif basename is None:
-                    layer_name = layer_name.replace(
-                        "{AUTO_NAME}", "Dataset%d_%s" % (src_ds_idx, src_lyr_name)
-                    )
-                else:
-                    layer_name = layer_name.replace(
-                        "{AUTO_NAME}", basename + "_" + src_lyr_name
-                    )
-
-                if basename is not None:
-                    layer_name = layer_name.replace("{DS_BASENAME}", basename)
-                elif "{DS_BASENAME}" in layer_name:
-                    if skip_failures:
-                        if "{DS_INDEX}" not in layer_name:
-                            layer_name = layer_name.replace(
-                                "{DS_BASENAME}", "Dataset%d" % src_ds_idx
-                            )
-                    else:
-                        print(
-                            "ERROR: Layer name template %s "
-                            "includes {DS_BASENAME} "
-                            "but %s is not a file" % (layer_name_template, src_dsname)
-                        )
-
-                        gdal.VSIFCloseL(f)
-                        gdal.Unlink(vrt_filename)
-                        return 1
-                layer_name = layer_name.replace("{DS_NAME}", "%s" % src_dsname)
-                layer_name = layer_name.replace("{DS_INDEX}", "%d" % src_ds_idx)
-                layer_name = layer_name.replace("{LAYER_NAME}", src_lyr_name)
-                layer_name = layer_name.replace("{LAYER_INDEX}", "%d" % src_lyr_idx)
+                layer_name = _build_layer_name_non_single_mode(
+                    layer_name_template,
+                    src_ds_idx,
+                    src_dsname,
+                    src_lyr_idx,
+                    src_lyr.GetName(),
+                    skip_failures,
+                )
+                if layer_name is None:
+                    gdal.VSIFCloseL(f)
+                    gdal.Unlink(vrt_filename)
+                    return 1
 
                 if t_srs is not None:
                     writer.open_element("OGRVRTWarpedLayer")
 
                 writer.open_element("OGRVRTLayer", attrs={"name": layer_name})
                 attrs = {}
                 if (
```

## osgeo_utils/auxiliary/numpy_util.py

```diff
@@ -41,19 +41,23 @@
 
     if buf_type == gdal.GDT_Byte and signed_byte:
         typecode = np.int8
     return typecode
 
 
 def GDALTypeCodeAndNumericTypeCodeFromDataSet(ds):
-    buf_type = ds.GetRasterBand(1).DataType
-    signed_byte = (
-        ds.GetRasterBand(1).GetMetadataItem("PIXELTYPE", "IMAGE_STRUCTURE")
-        == "SIGNEDBYTE"
-    )
+    band = ds.GetRasterBand(1)
+    buf_type = band.DataType
+    signed_byte = False
+    if buf_type == gdal.GDT_Byte:
+        band._EnablePixelTypeSignedByteWarning(False)
+        signed_byte = (
+            band.GetMetadataItem("PIXELTYPE", "IMAGE_STRUCTURE") == "SIGNEDBYTE"
+        )
+        band._EnablePixelTypeSignedByteWarning(True)
     np_typecode = GDALTypeCodeToNumericTypeCodeEx(
         buf_type, signed_byte=signed_byte, default=np.float32
     )
     return buf_type, np_typecode
 
 
 def array_dist(
```

## osgeo_utils/samples/gdal_cp.py

```diff
@@ -45,57 +45,23 @@
 
 
 def Usage():
     print("Usage: gdal_cp [-progress] [-r] [-skipfailures] source_file target_file")
     return 2
 
 
-class TermProgress(object):
-    def __init__(self):
-        self.nLastTick = -1
-        self.nThisTick = 0
-
-    def Progress(self, dfComplete, message):
-        # pylint: disable=unused-argument
-        self.nThisTick = int(dfComplete * 40.0)
-        if self.nThisTick > 40:
-            self.nThisTick = 40
-
-        # // Have we started a new progress run?
-        if self.nThisTick < self.nLastTick and self.nLastTick >= 39:
-            self.nLastTick = -1
-
-        if self.nThisTick <= self.nLastTick:
-            return True
-
-        while self.nThisTick > self.nLastTick:
-            self.nLastTick = self.nLastTick + 1
-            if self.nLastTick % 4 == 0:
-                val = int((self.nLastTick / 4) * 10)
-                sys.stdout.write("%d" % val)
-            else:
-                sys.stdout.write(".")
-
-        if self.nThisTick == 40:
-            print(" - done.")
-
-        sys.stdout.flush()
-
-        return True
-
-
 class ScaledProgress(object):
     def __init__(self, dfMin, dfMax, UnderlyingProgress):
         self.dfMin = dfMin
         self.dfMax = dfMax
         self.UnderlyingProgress = UnderlyingProgress
 
-    def Progress(self, dfComplete, message):
-        return self.UnderlyingProgress.Progress(
-            dfComplete * (self.dfMax - self.dfMin) + self.dfMin, message
+    def Progress(self, dfComplete, message, user_data):
+        return self.UnderlyingProgress(
+            dfComplete * (self.dfMax - self.dfMin) + self.dfMin, message, user_data
         )
 
 
 def gdal_cp_single(srcfile, targetfile, progress):
     if targetfile.endswith("/"):
         stat_res = gdal.VSIStatL(targetfile)
     else:
@@ -111,63 +77,17 @@
             targetfile = targetfile + "/" + tail
 
     fin = gdal.VSIFOpenL(srcfile, "rb")
     if fin is None:
         print("Cannot open %s" % srcfile)
         return -1
 
-    fout = gdal.VSIFOpenL(targetfile, "wb")
-    if fout is None:
-        print("Cannot create %s" % targetfile)
-        gdal.VSIFCloseL(fin)
-        return -1
-
-    version_num = int(gdal.VersionInfo("VERSION_NUM"))
-    total_size = 0
-    if version_num < 1900 or progress is not None:
-        gdal.VSIFSeekL(fin, 0, 2)
-        total_size = gdal.VSIFTellL(fin)
-        gdal.VSIFSeekL(fin, 0, 0)
-
-    buf_max_size = 4096
-    copied = 0
-    ret = 0
-    # print('Copying %s...' % srcfile)
-    if progress is not None:
-        if not progress.Progress(0.0, "Copying %s" % srcfile):
-            print("Copy stopped by user")
-            ret = -2
-
-    while ret == 0:
-        if total_size != 0 and copied + buf_max_size > total_size:
-            to_read = total_size - copied
-        else:
-            to_read = buf_max_size
-        buf = gdal.VSIFReadL(1, to_read, fin)
-        if buf is None:
-            if copied == 0:
-                print("Cannot read %d bytes in %s" % (to_read, srcfile))
-                ret = -1
-            break
-        buf_size = len(buf)
-        if gdal.VSIFWriteL(buf, 1, buf_size, fout) != buf_size:
-            print("Error writing %d bytes" % buf_size)
-            ret = -1
-            break
-        copied += buf_size
-        if progress is not None and total_size != 0:
-            if not progress.Progress(copied * 1.0 / total_size, "Copying %s" % srcfile):
-                print("Copy stopped by user")
-                ret = -2
-                break
-        if to_read < buf_max_size or buf_size != buf_max_size:
-            break
+    ret = gdal.CopyFile(srcfile, targetfile, fin, callback=progress)
 
     gdal.VSIFCloseL(fin)
-    gdal.VSIFCloseL(fout)
 
     return ret
 
 
 def gdal_cp_recurse(srcdir, targetdir, progress, skip_failure):
 
     if srcdir[-1] == "/":
@@ -239,15 +159,15 @@
         i = 0
         for srcfile in lst2:
             if filesizelst[i] != 0:
                 dfMin = cursize * 1.0 / total_size
                 dfMax = (cursize + filesizelst[i]) * 1.0 / total_size
                 scaled_progress = ScaledProgress(dfMin, dfMax, progress)
 
-                ret = gdal_cp_single(srcfile, targetfile, scaled_progress)
+                ret = gdal_cp_single(srcfile, targetfile, scaled_progress.Progress)
                 if ret == -2 or (ret == -1 and not skip_failure):
                     return ret
 
                 cursize += filesizelst[i]
 
             i = i + 1
 
@@ -268,22 +188,16 @@
 
     argv = gdal.GeneralCmdLineProcessor(argv)
     if argv is None:
         return -1
 
     for i in range(1, len(argv)):
         if argv[i] == "-progress":
-            progress = TermProgress()
+            progress = gdal.TermProgress_nocb
         elif argv[i] == "-r":
-            version_num = int(gdal.VersionInfo("VERSION_NUM"))
-            if version_num < 1900:
-                print(
-                    "ERROR: Python bindings of GDAL 1.9.0 or later required for -r option"
-                )
-                return -1
             recurse = True
         elif len(argv[i]) >= 5 and argv[i][0:5] == "-skip":
             skip_failure = True
         elif argv[i][0] == "-":
             print("Unrecognized option : %s" % argv[i])
             return Usage()
         elif srcfile is None:
@@ -338,16 +252,12 @@
         return gdal_cp_pattern_match(
             srcdir, pattern, targetfile, progress, skip_failure
         )
     return gdal_cp_single(srcfile, targetfile, progress)
 
 
 def main(argv=sys.argv):
-    version_num = int(gdal.VersionInfo("VERSION_NUM"))
-    if version_num < 1800:
-        print("ERROR: Python bindings of GDAL 1.8.0 or later required")
-        return 1
     return gdal_cp(argv)
 
 
 if __name__ == "__main__":
     sys.exit(main(sys.argv))
```

## osgeo_utils/samples/gdalinfo.py

```diff
@@ -177,20 +177,21 @@
     # --------------------------------------------------------------------
     #      Report projection.
     # --------------------------------------------------------------------
     pszProjection = hDataset.GetProjectionRef()
     if pszProjection is not None:
 
         hSRS = osr.SpatialReference()
-        if hSRS.ImportFromWkt(pszProjection) == gdal.CE_None:
-            pszPrettyWkt = hSRS.ExportToPrettyWkt(False)
+        with gdal.quiet_errors(), osr.ExceptionMgr(useExceptions=False):
+            if hSRS.ImportFromWkt(pszProjection) == gdal.CE_None:
+                pszPrettyWkt = hSRS.ExportToPrettyWkt(False)
 
-            print("Coordinate System is:\n%s" % pszPrettyWkt)
-        else:
-            print("Coordinate System is `%s'" % pszProjection)
+                print("Coordinate System is:\n%s" % pszPrettyWkt)
+            else:
+                print("Coordinate System is `%s'" % pszProjection)
 
     # --------------------------------------------------------------------
     #      Report Geotransform.
     # --------------------------------------------------------------------
     adfGeoTransform = hDataset.GetGeoTransform(can_return_null=True)
     if adfGeoTransform is not None:
```

## osgeo_utils/samples/ogr2ogr.py

```diff
@@ -589,19 +589,21 @@
     # --------------------------------------------------------------------
     #      Try opening the output datasource as an existing, writable
     # --------------------------------------------------------------------
     poODS = None
     poDriver = None
 
     if bUpdate:
-        poODS = ogr.Open(pszDestDataSource, True)
+        with ogr.ExceptionMgr(useExceptions=False), gdal.quiet_errors():
+            poODS = ogr.Open(pszDestDataSource, True)
         if poODS is None:
 
             if bOverwrite or bAppend:
-                poODS = ogr.Open(pszDestDataSource, False)
+                with ogr.ExceptionMgr(useExceptions=False), gdal.quiet_errors():
+                    poODS = ogr.Open(pszDestDataSource, False)
                 if poODS is None:
                     # the datasource doesn't exist at all
                     bUpdate = False
                 else:
                     poODS.delete()
                     poODS = None
```

## osgeo_utils/samples/ogr2vrt.py

```diff
@@ -320,14 +320,18 @@
                 vrt += ' src="%s"' % Esc(src_fd.GetName())
             if src_fd.GetWidth() > 0:
                 vrt += ' width="%d"' % src_fd.GetWidth()
             if src_fd.GetPrecision() > 0:
                 vrt += ' precision="%d"' % src_fd.GetPrecision()
             if src_fd.IsNullable() == 0:
                 vrt += ' nullable="false"'
+            if src_fd.GetAlternativeName():
+                vrt += ' alternativeName="%s"' % Esc(src_fd.GetAlternativeName())
+            if src_fd.GetComment():
+                vrt += ' comment="%s"' % Esc(src_fd.GetComment())
             try:
                 if src_fd.IsUnique():
                     vrt += ' unique="true"'
             except AttributeError:  # if run with GDAL < 3.2
                 pass
             vrt += "/>\n"
```

## osgeo_utils/samples/validate_gpkg.py

```diff
@@ -273,14 +273,26 @@
                 (3, "organization_coordsys_id", "INTEGER", 1, None, 0),
                 (4, "definition", "TEXT", 1, None, 0),
                 (5, "description", "TEXT", 0, None, 0),
                 (6, "definition_12_063", "TEXT", 1, None, 0),
             ]
             if has_epoch:
                 expected_columns += [(7, "epoch", "DOUBLE", 0, None, 0)]
+
+            # "Previous versions of this extension specified default values for
+            # definition and definition_12_063. Those defaults have been removed
+            # for interoperability reasons but implementers should be aware that
+            # some GeoPackages may have these defaults in place."
+            columns = [[v for v in column] for column in columns]
+            for column in columns:
+                if (
+                    column[1] in ("definition", "definition_12_063")
+                    and column[4] == "''"
+                ):
+                    column[4] = None
         else:
             expected_columns = [
                 (0, "srs_name", "TEXT", 1, None, 0),
                 (1, "srs_id", "INTEGER", 1, None, 1),
                 (2, "organization", "TEXT", 1, None, 0),
                 (3, "organization_coordsys_id", "INTEGER", 1, None, 0),
                 (4, "definition", "TEXT", 1, None, 0),
@@ -657,14 +669,15 @@
         geometry_type_name = rows_gpkg_geometry_columns[0][3]
         srs_id = rows_gpkg_geometry_columns[0][4]
 
         c.execute("PRAGMA table_info(%s)" % _esc_id(table_name))
         cols = c.fetchall()
         found_geom = False
         count_pkid = 0
+        pkid_column_name = None
         for (_, name, typ, notnull, default, pk) in cols:
             if name.lower() == geom_column_name.lower():
                 found_geom = True
                 self._assert(
                     typ in GPKGChecker.BASE_GEOM_TYPES
                     or typ in GPKGChecker.EXT_GEOM_TYPES,
                     25,
@@ -679,14 +692,16 @@
                         + "SQL and %s in geometry_type_name of "
                         + "gpkg_geometry_columns"
                     )
                     % (table_name, typ, geometry_type_name),
                 )
 
             elif pk == 1:
+                if pkid_column_name is None:
+                    pkid_column_name = name
                 count_pkid += 1
                 self._assert(
                     typ == "INTEGER",
                     29,
                     ("table %s has a PRIMARY KEY of type %s " + "instead of INTEGER")
                     % (table_name, typ),
                 )
@@ -757,19 +772,24 @@
                 68,
                 "gpkg_geom_%s extension should be declared for "
                 "table %s" % (geometry_type_name, table_name),
             )
 
         wkb_geometries = GPKGChecker.BASE_GEOM_TYPES + GPKGChecker.EXT_GEOM_TYPES
         c.execute(
-            "SELECT %s FROM %s " % (_esc_id(geom_column_name), _esc_id(table_name))
+            "SELECT %s, %s FROM %s "
+            % (
+                _esc_id(pkid_column_name) if pkid_column_name else -1,
+                _esc_id(geom_column_name),
+                _esc_id(table_name),
+            )
         )
         found_geom_types = set()
         warning_messages = set()
-        for (blob,) in c.fetchall():
+        for (rowid, blob) in c.fetchall():
             if blob is None:
                 continue
 
             self._assert(len(blob) >= 8, 19, "Invalid geometry")
             max_size_needed = min(len(blob), 8 + 4 * 2 * 8 + 5)
             blob_ar = struct.unpack("B" * max_size_needed, blob[0:max_size_needed])
             self._assert(blob_ar[0] == ord("G"), 19, "Invalid geometry")
@@ -854,23 +874,28 @@
                     "m found in geometry, but not in " "gpkg_geometry_columns",
                 )
 
             found_geom_types.add(wkb_geometries[wkb_geom_type % 1000])
 
             if has_gdal:
                 geom = ogr.CreateGeometryFromWkb(blob[header_len:])
-                self._assert(geom is not None, 19, "Invalid geometry")
-
                 self._assert(
-                    (geom.IsEmpty() and empty_flag)
-                    or (not geom.IsEmpty() and not empty_flag),
-                    152,
-                    "Inconsistent empty_flag vs geometry content",
+                    geom is not None,
+                    19,
+                    f"Invalid geometry for fid {rowid} of " f"table {table_name}",
                 )
 
+                if geom is not None:
+                    self._assert(
+                        (geom.IsEmpty() and empty_flag)
+                        or (not geom.IsEmpty() and not empty_flag),
+                        152,
+                        "Inconsistent empty_flag vs geometry content",
+                    )
+
         if geometry_type_name in (
             "POINT",
             "LINESTRING",
             "POLYGON",
             "MULTIPOINT",
             "MULTILINESTRING",
             "MULTIPOLYGON",
@@ -1604,25 +1629,26 @@
         )
         ret = c.fetchall()
         self._assert(
             len(ret) == 1,
             "gpkg_2d_gridded_coverage#3",
             "gpkg_spatial_ref_sys shall have a row for srs_id=4979",
         )
-        self._assert(
-            ret[0][1].lower() == "epsg",
-            "gpkg_2d_gridded_coverage#3",
-            "wrong value for organization for srs_id = 4979: %s" % ret[0][1],
-        )
-        self._assert(
-            ret[0][2] == 4979,
-            "gpkg_2d_gridded_coverage#3",
-            ("wrong value for organization_coordsys_id for " + "srs_id = 4979: %s")
-            % ret[0][2],
-        )
+        if len(ret) == 1:
+            self._assert(
+                ret[0][1].lower() == "epsg",
+                "gpkg_2d_gridded_coverage#3",
+                "wrong value for organization for srs_id = 4979: %s" % ret[0][1],
+            )
+            self._assert(
+                ret[0][2] == 4979,
+                "gpkg_2d_gridded_coverage#3",
+                ("wrong value for organization_coordsys_id for " + "srs_id = 4979: %s")
+                % ret[0][2],
+            )
 
         c.execute("SELECT 1 FROM sqlite_master WHERE name = 'gpkg_extensions'")
         self._assert(
             c.fetchone() is not None,
             "gpkg_2d_gridded_coverage#6",
             "gpkg_extensions does not exist",
         )
@@ -2351,28 +2377,29 @@
                 (scope,) = row
                 self._assert(
                     scope == "read-write",
                     141,
                     "Wrong scope for gpkg_schema in " "gpkg_extensions",
                 )
 
-                self._assert(
-                    c.fetchone() is not None,
-                    141,
-                    "There should be exactly 2 rows with "
-                    + "extension_name = "
-                    + "'gpkg_schema' in gpkg_extensions",
-                )
-                self._assert(
-                    c.fetchone() is None,
-                    141,
-                    "There should be exactly 2 rows with "
-                    + "extension_name = "
-                    + "'gpkg_schema' in gpkg_extensions",
-                )
+                if self.version >= (1, 2, 1):
+                    self._assert(
+                        c.fetchone() is not None,
+                        141,
+                        "There should be exactly 2 rows with "
+                        + "extension_name = "
+                        + "'gpkg_schema' in gpkg_extensions",
+                    )
+                    self._assert(
+                        c.fetchone() is None,
+                        141,
+                        "There should be exactly 2 rows with "
+                        + "extension_name = "
+                        + "'gpkg_schema' in gpkg_extensions",
+                    )
 
                 c.execute(
                     "SELECT 1 FROM gpkg_extensions WHERE "
                     "extension_name = 'gpkg_schema' AND "
                     "column_name IS NOT NULL"
                 )
                 row = c.fetchone()
@@ -2912,15 +2939,15 @@
     )
     if not abort_at_first_error:
         if not ret:
             return 0
         else:
             for (req, msg) in ret:
                 if req:
-                    print("Req %d: %s" % (req, msg))
+                    print("Req %s: %s" % (str(req), msg))
                 else:
                     print(msg)
             return 1
     return 0
 
 
 if __name__ == "__main__":
```

## Comparing `gdal_utils-3.6.4.0.dist-info/METADATA` & `gdal_utils-3.7.0.0.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: gdal-utils
-Version: 3.6.4.0
+Version: 3.7.0.0
 Summary: gdal-utils: An extension library for GDAL - Geospatial Data Abstraction Library
 Home-page: http://www.gdal.org
 Author: Frank Warmerdam
 Author-email: warmerdam@pobox.com
 Maintainer: Idan Miara
 Maintainer-email: idan@miara.com
 License: MIT
@@ -62,15 +62,15 @@
 ``python path/to/gdal_edit.py`` for example.
 
 
 Packaging
 ---------
 
 Starting March 2022 installing gdal-utils with pip will use Setuptools'
-_console_scripts_, which turn the the scripts into native platform
+_console_scripts_, which turn the scripts into native platform
 executables that call the script using the appropriate platform interpreter.
 This means you no longer need to something similar as a post-install step.
 If this causes problems with your distribution please file an issue on
 Github.
 
 Recipe for testing gdal-utils compatibility against your installed GDAL
 binaries::
```

## Comparing `gdal_utils-3.6.4.0.dist-info/entry_points.txt` & `gdal_utils-3.7.0.0.dist-info/entry_points.txt`

 * *Files identical despite different names*

## Comparing `gdal_utils-3.6.4.0.dist-info/RECORD` & `gdal_utils-3.7.0.0.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,35 +1,35 @@
-osgeo_utils/__init__.py,sha256=XQsxNwQCi4S6jsPkegPcfJBYWyMHlvq7ezoInqhbuaU,432
-osgeo_utils/gdal2tiles.py,sha256=WclOdpxKkvyiiRcWypA3hncmw0KqRVIzEbMWdAVHryg,166201
+osgeo_utils/__init__.py,sha256=jWHmbr8m6Z-of1vY3_4DooUNhtc0BYjh4-h5hsTWu-o,432
+osgeo_utils/gdal2tiles.py,sha256=P1E_C8E0p-FBdfC6HTFI2hpAWRzZuS7tTsGBr0Zyt_Q,166280
 osgeo_utils/gdal2xyz.py,sha256=Y1iwvxl0HTQnLwF2daPLL8Mlv2zgQX418BciPwxKoE0,15776
-osgeo_utils/gdal_calc.py,sha256=EqATSaV8N4-M2vKdmd2LUF2gQoyO7j-wek7VZmI8lPw,36264
+osgeo_utils/gdal_calc.py,sha256=1ahubsbwUBinh-sCOzBNiqLyVxNPrUnq7Uie6vHTnr0,36237
 osgeo_utils/gdal_edit.py,sha256=bZ_yxV6cM1nTA4IU5OdM7zqbbxQ7qRr9uNvBOlXGgkY,15155
-osgeo_utils/gdal_fillnodata.py,sha256=78X2731llygm1H9RTE_QiKmxzNfQ3nleiYkG9UlxNGk,8936
-osgeo_utils/gdal_merge.py,sha256=gWfQJgz21K_ukHlTz9ky6dQOFa-73haWz9k7_NwZJww,18299
+osgeo_utils/gdal_fillnodata.py,sha256=MZ1kulgqnt6Vlwe6TpfUJVOk-UnJucntxxMQ0g1MLqQ,9085
+osgeo_utils/gdal_merge.py,sha256=HMoQt9AwXH8kynSNXxq3YRIEu6EtYrHrB0od2yA5oDc,18296
 osgeo_utils/gdal_pansharpen.py,sha256=8e9jMyE0WCQ2P1TY_DIkZf29Dt35TVap940nfo7X6Ig,11772
-osgeo_utils/gdal_polygonize.py,sha256=jQEjSSKRRd_LIxpzGU3o9QDbLIryxDFcMIww1Ht-Vus,10303
+osgeo_utils/gdal_polygonize.py,sha256=vKLmZWlQRp0OMV550RAZiTUnjllU7FlaYJrReVqTO_g,11088
 osgeo_utils/gdal_proximity.py,sha256=IveoTXyQMO5SsNeyLk_0ACP3x2LppCxH7EyN0gX5wJw,7052
-osgeo_utils/gdal_retile.py,sha256=YlK7JQJug404WXQS960Q-OxVdkeo-FYlNEF6TKKsBiM,35616
+osgeo_utils/gdal_retile.py,sha256=YW9KvlMN8D4_de7dFUAurctCmLsfrI6VwRKX9XFjUQg,35621
 osgeo_utils/gdal_sieve.py,sha256=TkJ-jSR7BNgcjdasLdhOJJFcf2bacMPCL6fkwCju97A,6441
 osgeo_utils/gdalattachpct.py,sha256=IUHnWklzE5eM6Tbhc5e5q5Ehk7C2RjSKxB0K0wpW99w,4794
 osgeo_utils/gdalcompare.py,sha256=PHHbSLVsdxWDC0UYFVGUIgtnsOg5kI_6QyjLzFcdzH4,11855
 osgeo_utils/gdalmove.py,sha256=BSP62cbCXEJe1B93lR74ZOoDQULz_6_AIvhCfzaLJgo,9796
-osgeo_utils/ogr_layer_algebra.py,sha256=UrR2gh65MMoJdj0njfb1G5BmfM7RM2LszEcHA54w0DY,18128
-osgeo_utils/ogrmerge.py,sha256=O4ibCQSTy8y0EMwK0Wdftj53Y6B_75jyoJ-cEcFuMIE,22455
+osgeo_utils/ogr_layer_algebra.py,sha256=Ox1ErNC8qJjFon38irP-mEreXuDQt7k5gKRGMRHzS2s,18278
+osgeo_utils/ogrmerge.py,sha256=BK8CjCfM61y11M-9IqK53goOSbYTiG-I9imE3m3mcps,42925
 osgeo_utils/pct2rgb.py,sha256=l5zJ_mvcSALhNjV4HlpzitXcOse62XebJihvGVGVTMc,7664
 osgeo_utils/rgb2pct.py,sha256=gT8PxciYYvtG0s79NscjvYEsIe09Xb03l8PWGoVfP_U,7145
 osgeo_utils/auxiliary/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 osgeo_utils/auxiliary/array_util.py,sha256=rgPFir9aVZIpJyorb_-E14xF0fF6tX45-G3Bwofqbx0,2635
 osgeo_utils/auxiliary/base.py,sha256=7-BTbMFWJaDd0KhFnzR2FLSmyrkR-JyUPOIprju-3pQ,4044
 osgeo_utils/auxiliary/batch_creator.py,sha256=L1SELbeJ3ZW3IsOANsT4N7tz6gNh-Bv9jjQh3r7cup0,3447
 osgeo_utils/auxiliary/color_palette.py,sha256=xswV7J_XRinemK-8S0O6El2K6sW5zWvdx9ZlfhsWlZ8,15215
 osgeo_utils/auxiliary/color_table.py,sha256=FK2C06dujq0x3lv-7lLlFwW8TwedjFPbDg3iDxPGB1Q,5649
 osgeo_utils/auxiliary/extent_util.py,sha256=TyJpJ8Fq40lAioTSVtRlD8kq-O23ZzqOzAUnf4BguEM,5384
 osgeo_utils/auxiliary/gdal_argparse.py,sha256=fXPwBqQQ3jP7-sVynP6RuYnJsdwi1jj0dFtDIQKgRGo,6566
-osgeo_utils/auxiliary/numpy_util.py,sha256=ANGqGUzayqhHEogKD6DPWCEV6NRgi_0Rl6cNOJNbcqk,2721
+osgeo_utils/auxiliary/numpy_util.py,sha256=IA0WJ1WYQWdQHUirJ1jZb6PD_LUtdRrMmV7obt7QzkU,2891
 osgeo_utils/auxiliary/osr_util.py,sha256=5pU58O3AzGA4xwvAxBl2KNkiwaZxaDbj5b2e4glSAao,5467
 osgeo_utils/auxiliary/progress.py,sha256=YLGdmAWd_QVZtIrTVXDjLQEwIfUEbUCdtT__6hHfu8M,3340
 osgeo_utils/auxiliary/raster_creation.py,sha256=75fWh5IlXEGwtaHTCw1r52fhqs6iV7f24yY7v7N5WaY,6671
 osgeo_utils/auxiliary/rectangle.py,sha256=4jyIE7z_VZuYbQeS2q2VPcXj7edV_S2YbtU8sHWpoy4,8828
 osgeo_utils/auxiliary/util.py,sha256=ILKIGQeQjQwjLxW1hvSRFrzozMkCcUvO7TQ13Fd7DHE,16651
 osgeo_utils/samples/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 osgeo_utils/samples/assemblepoly.py,sha256=UbQn_aPN-TZsUG64zqSJznOFH-uig-Mh_4mRTvGm3go,4632
@@ -43,55 +43,55 @@
 osgeo_utils/samples/fft.py,sha256=evHlcequNbKaXI1Bx_SfivjIH3pAd1uoNmOK205ARlw,4274
 osgeo_utils/samples/fix_gpkg.py,sha256=0DEoOkydUMx3brMe_5A6EzjvTgwdMvChsdSrseIC5hE,3008
 osgeo_utils/samples/gcps2ogr.py,sha256=tokjZfnaGjMkAqJZDcwra4dJEQgsBlL3SFhl605BuNk,3193
 osgeo_utils/samples/gcps2vec.py,sha256=V_kBfngpf299NeZpksXaVR1c5--hDi2g0tYxewhDrdQ,5419
 osgeo_utils/samples/gcps2wld.py,sha256=fOVDQU05QzTBm0w9Qeotz4qcg4J7ESEQHLzwEoyCUXI,2580
 osgeo_utils/samples/gdal2grd.py,sha256=PD6GDmGCifkjlcyJ4CbGmQVvfHrNz0rRKIRecYCqZb0,5281
 osgeo_utils/samples/gdal_auth.py,sha256=Kih7CEyYuEO2aplXQNsTnluYGvTLVRP5Ew1ptswbG2Q,4451
-osgeo_utils/samples/gdal_cp.py,sha256=dLSNfG3Y55R3WqWVRPemg5TQvbPGc8lZ7aiijlpasls,11309
+osgeo_utils/samples/gdal_cp.py,sha256=QUXQciew1lbphv-8dD4MmbabzRhj9AscW3waKIo_DpE,8460
 osgeo_utils/samples/gdal_create_pdf.py,sha256=hhEmvotxhI31QVoH3lJ8Qlxn-cJHny7ANYHi5dWo1f4,2561
 osgeo_utils/samples/gdal_ls.py,sha256=DV-XEW__cyDZjAYmLENvxrxjHWH1BXaqntJzIp9wlQA,8693
 osgeo_utils/samples/gdal_lut.py,sha256=EYs0I-Rca-GXaeTOOqMXwJR9KC12E2gwg0M4K361Im8,6668
 osgeo_utils/samples/gdal_mkdir.py,sha256=vK7aCUYj0hUJjliSg_2pn2O60pr6l_c5bBb_EUic1i8,2403
 osgeo_utils/samples/gdal_remove_towgs84.py,sha256=53yJZJNQnO4vo3OGuyEPK1oBKgIFl5JifPxW4AYMcVo,4426
 osgeo_utils/samples/gdal_rm.py,sha256=eIKWawlsAQx1bnua2NQXUDQJnc99A7iOVgPQnuaz4E4,4035
 osgeo_utils/samples/gdal_rmdir.py,sha256=AI5a7asR9d_XedCxnze3_BORQTM7BzA1Noh1hgj1Sq0,2538
 osgeo_utils/samples/gdal_vrtmerge.py,sha256=DRmOH-adMdQwvCDDowakTcTQj2SlVLCC57BHELODk1E,11900
 osgeo_utils/samples/gdal_zip.py,sha256=nuz4gVAK4IXZPN4zmXawtMIC3_um-oRgzUtdA4x2kTY,4069
 osgeo_utils/samples/gdalchksum.py,sha256=rq_PnqSqPzyRo8Ju77DRxAOP77sAdTgn7GeBzalfm6g,3004
 osgeo_utils/samples/gdalcopyproj.py,sha256=68bcSMpnl-gR6eHHpB_FEDP_6_BPdKqCrd1_hrMkj4o,3004
 osgeo_utils/samples/gdalfilter.py,sha256=JeOcJ-axMYYa2PWbg7G0YY8IQj5ovGWwEsxZqnaoPTM,6067
 osgeo_utils/samples/gdalident.py,sha256=AmFqnwSqO0L6JPLRMVQBLY6354ibe6qCjPs9eyzat74,3021
 osgeo_utils/samples/gdalimport.py,sha256=9sWBl9yBhDPCqgkfowfGjAvprSiJg97zebbnNqWpnBM,3036
-osgeo_utils/samples/gdalinfo.py,sha256=TO_boRa3TIIZxykDhO-k5Gtc4k3muTo0q23QWPRKG78,22185
+osgeo_utils/samples/gdalinfo.py,sha256=qpMdmHZjT6txPuD5BXXSkdyCd7PaaWPUYLMUah1WGWw,22278
 osgeo_utils/samples/gdallocationinfo.py,sha256=psZ8R41xqoLLcabMwM7y50bnCjAh6_Kl69PQ9ABc2Ag,20066
 osgeo_utils/samples/get_soundg.py,sha256=50JNLTm59qQmoBbwxYc1j4-HV52ZVGhmo0wrj-H_TBM,4095
 osgeo_utils/samples/histrep.py,sha256=YJdhx8WWMtqLpBWrbW89h62h2ORPpmpJ_qFieKP8pIQ,3374
 osgeo_utils/samples/hsv_merge.py,sha256=OadljByd6a37NYoLz552QLXz9ohHBNzjgiQQJOa9n4w,8150
 osgeo_utils/samples/jpeg_in_tiff_extract.py,sha256=-y03V1wU3hln2n3s-UJsV-rYHgtyDFQeWYByLqZa-cY,10510
 osgeo_utils/samples/load2odbc.py,sha256=SU1eKup3RfDgH5JwaKIhSTGa66OOXM6OesUUC52ctnw,6440
 osgeo_utils/samples/loslas2ntv2.py,sha256=EblBd0Q20TdBWeV1mObEc2kkLgxRQHo21x4uzfxctjE,8847
 osgeo_utils/samples/magphase.py,sha256=YaXmANGZme5AuedgPgugdVf6dDNrsMeC6mm1aBEc_qc,2739
 osgeo_utils/samples/make_fuzzer_friendly_archive.py,sha256=qa7Yns2VEAZu6uVssznZlRvnSIMz7tKx15tok5rqiYs,2167
 osgeo_utils/samples/mkgraticule.py,sha256=_GHqY-yqx9hOK-OJ0MP0ei48388Eg__54dmwxtKFGNk,7547
-osgeo_utils/samples/ogr2ogr.py,sha256=I_GK4QMrUoaB9VPHSVboolznI0JwDowVFCJ-pKx3L5s,70278
-osgeo_utils/samples/ogr2vrt.py,sha256=COU8ycoXJoFi6U_1k7UqmAvt_CSpErNwblDY33P-qog,12582
+osgeo_utils/samples/ogr2ogr.py,sha256=7VBOxb35rYzOHmAtIkTqABUT4Xgx5aACd2wWTBTeaw4,70440
+osgeo_utils/samples/ogr2vrt.py,sha256=8mVhAnbHFh5S0B3vCEkSOfHzEDzZRQX7xj1RgVi3nFg,12810
 osgeo_utils/samples/ogr_build_junction_table.py,sha256=jkXDmQRXHWPNjdngoLHTjNpLG3rh_CH7cRo_wZBJ4w0,7567
 osgeo_utils/samples/ogr_dispatch.py,sha256=od7zpznEL-3fYheKfXA4LnWDdgPGIKlkYarK54pdAXQ,14345
 osgeo_utils/samples/ogrinfo.py,sha256=9YBv6zA9PQPuA2GLa3IN2gYSZblQVZHLgMbeJoHwuNo,21229
 osgeo_utils/samples/ogrupdate.py,sha256=dsg3jwqghuQp9eyCq2Uwb5yW9cRzkdoBpQy-W3xjQOg,19843
 osgeo_utils/samples/rel.py,sha256=lbTnJ_o-HsrGsPTyQK36ZIHMUMjXWO0as1lpvvXpQ14,7724
 osgeo_utils/samples/tigerpoly.py,sha256=9vScW-3dZ4FMR25PoZti7IwpjvMNhBnqYHbzi0WoY4E,7578
 osgeo_utils/samples/tile_extent_from_raster.py,sha256=bHstiiXccWDQ9FBZCEVNDJk9JhDDAG_3fPKxqGbMeOA,4368
 osgeo_utils/samples/tolatlong.py,sha256=Ypfr_Yy62AjbzYKrcwItyRqy1l7hRGHWEIgdqWlkrGk,4055
 osgeo_utils/samples/val_repl.py,sha256=k7uFjiXhaYO6bGs0_C2GVJHEz8xnESPqyQ6WViY55bE,4344
 osgeo_utils/samples/validate_cloud_optimized_geotiff.py,sha256=2OZDoyjs_vPo8abwNd15Ex2g-u3HBQPJCgZH-jJ2E14,18476
-osgeo_utils/samples/validate_gpkg.py,sha256=bvC4Z49LXIHCdNCXEcCi2ur9ex3A22SnlcNEj7KKL5I,108556
+osgeo_utils/samples/validate_gpkg.py,sha256=tMl8c_vRsIN1fvmFI7NY5rFJTK3SRwot4evxrKU-sWo,109775
 osgeo_utils/samples/validate_jp2.py,sha256=RYMn5m_WWoySaOvHzzB2cr6IrR9YVUKYRbaSzzSh4yY,70659
 osgeo_utils/samples/vec_tr.py,sha256=CzwiIcbOBb78JHAV5rlOJ5Jn_g_EkvlGjYHdhs4dXhw,4768
 osgeo_utils/samples/vec_tr_spat.py,sha256=M380f8P1TDa3p_1CBicXx_gk9J7FKtFYi6v_jQ0kRCs,4843
 osgeo_utils/samples/wcs_virtds_params.py,sha256=bo-5FtBCk97DwaNF1GxkfHNCe9xLOCt1oR4PsEGpU38,7103
-gdal_utils-3.6.4.0.dist-info/METADATA,sha256=JE4zdUGdGRNt8AeGIxWNDDjOtPasJLAGhXPhQE0Ei5Y,3882
-gdal_utils-3.6.4.0.dist-info/WHEEL,sha256=g4nMs7d-Xl9-xC9XovUrsDHGXt-FT0E17Yqo92DEfvY,92
-gdal_utils-3.6.4.0.dist-info/entry_points.txt,sha256=64fFaWlzSWRY4LAVNTheYcIR7xJlvNznOwdtS8HgzLc,828
-gdal_utils-3.6.4.0.dist-info/top_level.txt,sha256=S2PDWMyA5xqC4JEsxOsQN222-k98sNYTODfMO7B1_NU,12
-gdal_utils-3.6.4.0.dist-info/RECORD,,
+gdal_utils-3.7.0.0.dist-info/METADATA,sha256=bjk-wqxRcqP-QEcd1s44cMZSZjQiMM1yM8zeTWy4Vu4,3878
+gdal_utils-3.7.0.0.dist-info/WHEEL,sha256=g4nMs7d-Xl9-xC9XovUrsDHGXt-FT0E17Yqo92DEfvY,92
+gdal_utils-3.7.0.0.dist-info/entry_points.txt,sha256=64fFaWlzSWRY4LAVNTheYcIR7xJlvNznOwdtS8HgzLc,828
+gdal_utils-3.7.0.0.dist-info/top_level.txt,sha256=S2PDWMyA5xqC4JEsxOsQN222-k98sNYTODfMO7B1_NU,12
+gdal_utils-3.7.0.0.dist-info/RECORD,,
```

