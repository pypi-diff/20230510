# Comparing `tmp/extract_msg-0.40.0.tar.gz` & `tmp/extract_msg-0.41.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "extract_msg-0.40.0.tar", last modified: Sat Mar 18 23:24:12 2023, max compression
+gzip compressed data, was "extract_msg-0.41.0.tar", last modified: Tue May  9 19:56:22 2023, max compression
```

## Comparing `extract_msg-0.40.0.tar` & `extract_msg-0.41.0.tar`

### file list

```diff
@@ -1,77 +1,71 @@
-drwxrwxrwx   0        0        0        0 2023-03-18 23:24:12.387195 extract_msg-0.40.0/
--rw-rw-rw-   0        0        0    70850 2023-03-18 23:23:44.000000 extract_msg-0.40.0/CHANGELOG.md
--rw-rw-rw-   0        0        0    35821 2022-01-20 06:06:24.000000 extract_msg-0.40.0/LICENSE.txt
--rw-rw-rw-   0        0        0      172 2022-01-20 06:06:24.000000 extract_msg-0.40.0/MANIFEST.in
--rw-rw-rw-   0        0        0    11928 2023-03-18 23:24:12.388474 extract_msg-0.40.0/PKG-INFO
--rw-rw-rw-   0        0        0    11371 2023-03-18 23:23:44.000000 extract_msg-0.40.0/README.rst
-drwxrwxrwx   0        0        0        0 2023-03-18 23:24:12.099882 extract_msg-0.40.0/extract_msg/
--rw-rw-rw-   0        0        0     1916 2023-03-18 23:23:44.000000 extract_msg-0.40.0/extract_msg/__init__.py
--rw-rw-rw-   0        0        0     4562 2022-11-30 07:36:43.000000 extract_msg-0.40.0/extract_msg/__main__.py
-drwxrwxrwx   0        0        0        0 2023-03-18 23:24:12.123819 extract_msg-0.40.0/extract_msg/_rtf/
--rw-rw-rw-   0        0        0      262 2023-03-18 23:23:44.000000 extract_msg-0.40.0/extract_msg/_rtf/__init__.py
--rw-rw-rw-   0        0        0      831 2023-03-18 23:23:44.000000 extract_msg-0.40.0/extract_msg/_rtf/create_doc.py
--rw-rw-rw-   0        0        0     6395 2023-03-18 23:23:44.000000 extract_msg-0.40.0/extract_msg/_rtf/inject_rtf.py
--rw-rw-rw-   0        0        0      839 2023-03-18 23:23:44.000000 extract_msg-0.40.0/extract_msg/_rtf/token.py
--rw-rw-rw-   0        0        0     9186 2023-03-18 23:23:44.000000 extract_msg-0.40.0/extract_msg/_rtf/tokenize_rtf.py
--rw-rw-rw-   0        0        0     7096 2022-07-16 04:11:43.000000 extract_msg-0.40.0/extract_msg/appointment.py
--rw-rw-rw-   0        0        0    13319 2023-02-12 23:16:26.000000 extract_msg-0.40.0/extract_msg/attachment.py
--rw-rw-rw-   0        0        0    16247 2023-02-27 04:34:25.000000 extract_msg-0.40.0/extract_msg/attachment_base.py
--rw-rw-rw-   0        0        0     3223 2022-07-16 04:11:43.000000 extract_msg-0.40.0/extract_msg/calendar.py
--rw-rw-rw-   0        0        0    21539 2022-07-16 04:11:43.000000 extract_msg-0.40.0/extract_msg/calendar_base.py
--rw-rw-rw-   0        0        0    26647 2023-03-18 23:23:44.000000 extract_msg-0.40.0/extract_msg/constants.py
--rw-rw-rw-   0        0        0    51298 2023-01-18 03:33:10.000000 extract_msg-0.40.0/extract_msg/contact.py
--rw-rw-rw-   0        0        0     2388 2022-06-09 01:13:27.000000 extract_msg-0.40.0/extract_msg/dev.py
-drwxrwxrwx   0        0        0        0 2023-03-18 23:24:12.196905 extract_msg-0.40.0/extract_msg/dev_classes/
--rw-rw-rw-   0        0        0       66 2022-01-20 06:06:24.000000 extract_msg-0.40.0/extract_msg/dev_classes/__init__.py
--rw-rw-rw-   0        0        0     2875 2022-06-09 01:13:27.000000 extract_msg-0.40.0/extract_msg/dev_classes/attachment.py
--rw-rw-rw-   0        0        0    10050 2022-07-16 04:11:43.000000 extract_msg-0.40.0/extract_msg/dev_classes/message.py
--rw-rw-rw-   0        0        0    56330 2023-02-12 23:16:26.000000 extract_msg-0.40.0/extract_msg/enums.py
--rw-rw-rw-   0        0        0     2845 2022-07-11 21:25:08.000000 extract_msg-0.40.0/extract_msg/exceptions.py
-drwxrwxrwx   0        0        0        0 2023-03-18 23:24:12.218822 extract_msg-0.40.0/extract_msg/logging-config/
--rw-rw-rw-   0        0        0     2146 2022-01-20 06:06:24.000000 extract_msg-0.40.0/extract_msg/logging-config/logging-nt.json
--rw-rw-rw-   0        0        0     2122 2022-01-20 06:06:24.000000 extract_msg-0.40.0/extract_msg/logging-config/logging-posix.json
--rw-rw-rw-   0        0        0     3632 2022-07-11 21:25:08.000000 extract_msg-0.40.0/extract_msg/meeting_cancellation.py
--rw-rw-rw-   0        0        0     1635 2022-07-16 04:11:43.000000 extract_msg-0.40.0/extract_msg/meeting_exception.py
--rw-rw-rw-   0        0        0     3894 2022-07-16 04:11:43.000000 extract_msg-0.40.0/extract_msg/meeting_forward.py
--rw-rw-rw-   0        0        0     2064 2022-07-16 04:11:43.000000 extract_msg-0.40.0/extract_msg/meeting_related.py
--rw-rw-rw-   0        0        0     6913 2022-07-16 04:11:43.000000 extract_msg-0.40.0/extract_msg/meeting_request.py
--rw-rw-rw-   0        0        0     2444 2022-07-16 04:11:43.000000 extract_msg-0.40.0/extract_msg/meeting_response.py
--rw-rw-rw-   0        0        0      456 2022-07-11 21:25:08.000000 extract_msg-0.40.0/extract_msg/message.py
--rw-rw-rw-   0        0        0    59905 2023-03-18 23:23:44.000000 extract_msg-0.40.0/extract_msg/message_base.py
--rw-rw-rw-   0        0        0      273 2022-07-11 21:25:08.000000 extract_msg-0.40.0/extract_msg/message_signed.py
--rw-rw-rw-   0        0        0     6787 2022-12-03 08:13:23.000000 extract_msg-0.40.0/extract_msg/message_signed_base.py
--rw-rw-rw-   0        0        0    39291 2023-02-27 04:34:25.000000 extract_msg-0.40.0/extract_msg/msg.py
--rw-rw-rw-   0        0        0    12643 2023-01-18 03:33:10.000000 extract_msg-0.40.0/extract_msg/named.py
--rw-rw-rw-   0        0        0    42280 2023-02-12 23:16:26.000000 extract_msg-0.40.0/extract_msg/ole_writer.py
--rw-rw-rw-   0        0        0     2572 2022-07-16 04:11:43.000000 extract_msg-0.40.0/extract_msg/post.py
--rw-rw-rw-   0        0        0     6813 2022-07-16 04:11:43.000000 extract_msg-0.40.0/extract_msg/prop.py
--rw-rw-rw-   0        0        0     7535 2023-01-18 03:33:10.000000 extract_msg-0.40.0/extract_msg/properties.py
--rw-rw-rw-   0        0        0        0 2022-07-20 09:36:46.000000 extract_msg-0.40.0/extract_msg/py.typed
--rw-rw-rw-   0        0        0    12578 2022-07-16 04:11:43.000000 extract_msg-0.40.0/extract_msg/recipient.py
--rw-rw-rw-   0        0        0     6563 2022-07-11 21:25:08.000000 extract_msg-0.40.0/extract_msg/signed_attachment.py
-drwxrwxrwx   0        0        0        0 2023-03-18 23:24:12.386196 extract_msg-0.40.0/extract_msg/structures/
--rw-rw-rw-   0        0        0      195 2022-07-11 21:25:08.000000 extract_msg-0.40.0/extract_msg/structures/__init__.py
--rw-rw-rw-   0        0        0    11979 2022-07-11 21:25:08.000000 extract_msg-0.40.0/extract_msg/structures/_helpers.py
--rw-rw-rw-   0        0        0     6823 2022-07-11 21:25:08.000000 extract_msg-0.40.0/extract_msg/structures/business_card.py
--rw-rw-rw-   0        0        0    19314 2022-07-16 04:11:43.000000 extract_msg-0.40.0/extract_msg/structures/entry_id.py
--rw-rw-rw-   0        0        0     6288 2022-07-11 21:25:08.000000 extract_msg-0.40.0/extract_msg/structures/misc_id.py
--rw-rw-rw-   0        0        0     7467 2022-07-11 21:25:08.000000 extract_msg-0.40.0/extract_msg/structures/recurrence_pattern.py
--rw-rw-rw-   0        0        0     3347 2022-07-16 04:11:43.000000 extract_msg-0.40.0/extract_msg/structures/report_tag.py
--rw-rw-rw-   0        0        0     1405 2022-07-11 21:25:08.000000 extract_msg-0.40.0/extract_msg/structures/system_time.py
--rw-rw-rw-   0        0        0     1658 2022-07-11 21:25:08.000000 extract_msg-0.40.0/extract_msg/structures/time_zone_definition.py
--rw-rw-rw-   0        0        0     2487 2022-07-11 21:25:08.000000 extract_msg-0.40.0/extract_msg/structures/time_zone_struct.py
--rw-rw-rw-   0        0        0     3346 2022-07-11 21:25:08.000000 extract_msg-0.40.0/extract_msg/structures/tz_rule.py
--rw-rw-rw-   0        0        0    13485 2022-07-16 04:11:43.000000 extract_msg-0.40.0/extract_msg/task.py
--rw-rw-rw-   0        0        0     4032 2022-07-16 04:11:43.000000 extract_msg-0.40.0/extract_msg/task_request.py
--rw-rw-rw-   0        0        0    56670 2023-02-12 23:16:26.000000 extract_msg-0.40.0/extract_msg/utils.py
--rw-rw-rw-   0        0        0     3464 2022-07-16 04:11:43.000000 extract_msg-0.40.0/extract_msg/validation.py
-drwxrwxrwx   0        0        0        0 2023-03-18 23:24:12.118863 extract_msg-0.40.0/extract_msg.egg-info/
--rw-rw-rw-   0        0        0    11928 2023-03-18 23:24:07.000000 extract_msg-0.40.0/extract_msg.egg-info/PKG-INFO
--rw-rw-rw-   0        0        0     1981 2023-03-18 23:24:07.000000 extract_msg-0.40.0/extract_msg.egg-info/SOURCES.txt
--rw-rw-rw-   0        0        0        1 2023-03-18 23:24:07.000000 extract_msg-0.40.0/extract_msg.egg-info/dependency_links.txt
--rw-rw-rw-   0        0        0       59 2023-03-18 23:24:07.000000 extract_msg-0.40.0/extract_msg.egg-info/entry_points.txt
--rw-rw-rw-   0        0        0      228 2023-03-18 23:24:07.000000 extract_msg-0.40.0/extract_msg.egg-info/requires.txt
--rw-rw-rw-   0        0        0       12 2023-03-18 23:24:07.000000 extract_msg-0.40.0/extract_msg.egg-info/top_level.txt
--rw-rw-rw-   0        0        0      208 2022-12-03 08:13:23.000000 extract_msg-0.40.0/requirements.txt
--rw-rw-rw-   0        0        0      167 2023-03-18 23:24:12.389846 extract_msg-0.40.0/setup.cfg
--rw-rw-rw-   0        0        0     1707 2023-03-18 23:23:44.000000 extract_msg-0.40.0/setup.py
+drwxrwxrwx   0        0        0        0 2023-05-09 19:56:22.165643 extract_msg-0.41.0/
+-rw-rw-rw-   0        0        0    74794 2023-05-09 19:54:43.000000 extract_msg-0.41.0/CHANGELOG.md
+-rw-rw-rw-   0        0        0    35147 2023-05-09 19:47:37.000000 extract_msg-0.41.0/LICENSE.txt
+-rw-rw-rw-   0        0        0      165 2023-05-09 19:47:37.000000 extract_msg-0.41.0/MANIFEST.in
+-rw-rw-rw-   0        0        0    12267 2023-05-09 19:56:22.166640 extract_msg-0.41.0/PKG-INFO
+-rw-rw-rw-   0        0        0    11460 2023-05-09 19:54:43.000000 extract_msg-0.41.0/README.rst
+drwxrwxrwx   0        0        0        0 2023-05-09 19:56:22.057993 extract_msg-0.41.0/extract_msg/
+-rw-rw-rw-   0        0        0     2254 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/__init__.py
+-rw-rw-rw-   0        0        0     3542 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/__main__.py
+drwxrwxrwx   0        0        0        0 2023-05-09 19:56:22.111441 extract_msg-0.41.0/extract_msg/_rtf/
+-rw-rw-rw-   0        0        0      425 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/_rtf/__init__.py
+-rw-rw-rw-   0        0        0      845 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/_rtf/create_doc.py
+-rw-rw-rw-   0        0        0     6250 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/_rtf/inject_rtf.py
+-rw-rw-rw-   0        0        0      856 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/_rtf/token.py
+-rw-rw-rw-   0        0        0     8932 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/_rtf/tokenize_rtf.py
+-rw-rw-rw-   0        0        0     6954 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/appointment.py
+-rw-rw-rw-   0        0        0    13262 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/attachment.py
+-rw-rw-rw-   0        0        0    16369 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/attachment_base.py
+-rw-rw-rw-   0        0        0     3169 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/calendar.py
+-rw-rw-rw-   0        0        0    21050 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/calendar_base.py
+-rw-rw-rw-   0        0        0    27572 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/constants.py
+-rw-rw-rw-   0        0        0    50103 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/contact.py
+-rw-rw-rw-   0        0        0    58138 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/enums.py
+-rw-rw-rw-   0        0        0     3377 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/exceptions.py
+drwxrwxrwx   0        0        0        0 2023-05-09 19:56:22.121415 extract_msg-0.41.0/extract_msg/logging-config/
+-rw-rw-rw-   0        0        0     2082 2023-05-09 19:47:37.000000 extract_msg-0.41.0/extract_msg/logging-config/logging-nt.json
+-rw-rw-rw-   0        0        0     2058 2023-05-09 19:47:37.000000 extract_msg-0.41.0/extract_msg/logging-config/logging-posix.json
+-rw-rw-rw-   0        0        0     3588 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/meeting_cancellation.py
+-rw-rw-rw-   0        0        0     1628 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/meeting_exception.py
+-rw-rw-rw-   0        0        0     3771 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/meeting_forward.py
+-rw-rw-rw-   0        0        0     2043 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/meeting_related.py
+-rw-rw-rw-   0        0        0     6784 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/meeting_request.py
+-rw-rw-rw-   0        0        0     2415 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/meeting_response.py
+-rw-rw-rw-   0        0        0      375 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/message.py
+-rw-rw-rw-   0        0        0    58493 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/message_base.py
+-rw-rw-rw-   0        0        0      201 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/message_signed.py
+-rw-rw-rw-   0        0        0     7201 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/message_signed_base.py
+-rw-rw-rw-   0        0        0    39208 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/msg.py
+-rw-rw-rw-   0        0        0    12647 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/named.py
+-rw-rw-rw-   0        0        0    41608 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/ole_writer.py
+-rw-rw-rw-   0        0        0     2578 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/post.py
+-rw-rw-rw-   0        0        0     6723 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/prop.py
+-rw-rw-rw-   0        0        0     7602 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/properties.py
+-rw-rw-rw-   0        0        0        0 2023-05-09 19:47:37.000000 extract_msg-0.41.0/extract_msg/py.typed
+-rw-rw-rw-   0        0        0    12677 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/recipient.py
+-rw-rw-rw-   0        0        0     8976 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/signed_attachment.py
+drwxrwxrwx   0        0        0        0 2023-05-09 19:56:22.164646 extract_msg-0.41.0/extract_msg/structures/
+-rw-rw-rw-   0        0        0      336 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/structures/__init__.py
+-rw-rw-rw-   0        0        0    11677 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/structures/_helpers.py
+-rw-rw-rw-   0        0        0     6676 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/structures/business_card.py
+-rw-rw-rw-   0        0        0    19038 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/structures/entry_id.py
+-rw-rw-rw-   0        0        0     6161 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/structures/misc_id.py
+-rw-rw-rw-   0        0        0     7370 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/structures/recurrence_pattern.py
+-rw-rw-rw-   0        0        0     3263 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/structures/report_tag.py
+-rw-rw-rw-   0        0        0     1391 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/structures/system_time.py
+-rw-rw-rw-   0        0        0     1616 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/structures/time_zone_definition.py
+-rw-rw-rw-   0        0        0     2440 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/structures/time_zone_struct.py
+-rw-rw-rw-   0        0        0     3263 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/structures/tz_rule.py
+-rw-rw-rw-   0        0        0    13190 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/task.py
+-rw-rw-rw-   0        0        0     4162 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/task_request.py
+-rw-rw-rw-   0        0        0    55903 2023-05-09 19:54:43.000000 extract_msg-0.41.0/extract_msg/utils.py
+drwxrwxrwx   0        0        0        0 2023-05-09 19:56:22.085510 extract_msg-0.41.0/extract_msg.egg-info/
+-rw-rw-rw-   0        0        0    12267 2023-05-09 19:56:21.000000 extract_msg-0.41.0/extract_msg.egg-info/PKG-INFO
+-rw-rw-rw-   0        0        0     1827 2023-05-09 19:56:21.000000 extract_msg-0.41.0/extract_msg.egg-info/SOURCES.txt
+-rw-rw-rw-   0        0        0        1 2023-05-09 19:56:21.000000 extract_msg-0.41.0/extract_msg.egg-info/dependency_links.txt
+-rw-rw-rw-   0        0        0       58 2023-05-09 19:56:21.000000 extract_msg-0.41.0/extract_msg.egg-info/entry_points.txt
+-rw-rw-rw-   0        0        0      228 2023-05-09 19:56:21.000000 extract_msg-0.41.0/extract_msg.egg-info/requires.txt
+-rw-rw-rw-   0        0        0       12 2023-05-09 19:56:21.000000 extract_msg-0.41.0/extract_msg.egg-info/top_level.txt
+-rw-rw-rw-   0        0        0      197 2023-05-09 19:54:43.000000 extract_msg-0.41.0/requirements.txt
+-rw-rw-rw-   0        0        0      167 2023-05-09 19:56:22.168635 extract_msg-0.41.0/setup.cfg
+-rw-rw-rw-   0        0        0     1657 2023-05-09 19:47:37.000000 extract_msg-0.41.0/setup.py
```

### Comparing `extract_msg-0.40.0/CHANGELOG.md` & `extract_msg-0.41.0/CHANGELOG.md`

 * *Files 10% similar despite different names*

```diff
@@ -1,631 +1,663 @@
-**v0.40.0**
-* [[TeamMsgExtractor #338](https://github.com/TeamMsgExtractor/msg-extractor/issues/338)] Added new code to handle injection of text into the RTF body. For many cases, this will be much more effective as it relies on ensuring that it is in the main group and past the header before injection. It is *not* currently the first choice as it doesn't have proper respect for encapsulated HTML, however it will replace some of the old methods entirely. Solving this issue was done through the use of a few functions and the internal `_rtf` module. This module in it's entirety is considered to be implementation details, and I give no guarantee that it will remain in it's current state even across patch versions. As such, it is not recommended to use it outside of the module.
-* Changed `MessageBase.rtfEncapInjectableHeader` and `MessageBase.rtfPlainInjectableHeader` from `str` to `bytes`. They always get encoded anyways, so I don't know why I had them returning as `str`.
-* Updated minimum Python version to 3.8 as 3.6 has reached end of support and 3.7 will reach end of support within the year.
-* Updated information in `README`.
-
-**v0.39.2**
-* Fixed issues with `AttachmentBase.name` that could cause it to generate wrong.
-* Added convenience function `MSGFile.exportBytes` which returns the exported version from `MSGFile.export` as bytes instead of writing it to a file or file-like object.
-
-**v0.39.1**
-* [[TeamMsgExtractor #333](https://github.com/TeamMsgExtractor/msg-extractor/issues/333)] Fixed typo in a warning.
-* [[TeamMsgExtractor #334](https://github.com/TeamMsgExtractor/msg-extractor/issues/334)] Removed `__del__` method from `MSGFile`. It was there for cleanup, but wasn't planned well enough to stop it from causing issues. It may be reintroduced in the future if I can manage to remove the issues.
-* [[TeamMsgExtractor #335](https://github.com/TeamMsgExtractor/msg-extractor/issues/335)] Fixed some parts of `extract_msg.utils.getCommandArgs` having invalid logic after a previous (rather old) update that caused exceptions when using certain options.
-* Added new property `treePath` to `AttachmentBase` and `MSGFile` (which adds it to nearly every class). This property is the path to the current instance, represented as a tuple of instances that would be used to get to the current instance.
-* Added sphinx documentation.
-* Fixed an issue in `OleWriter` that would produce corrupted OLE files if the DIFAT needed more than the header.
-
-**v0.39.0**
-* [[TeamMsgExtractor #318](https://github.com/TeamMsgExtractor/msg-extractor/issues/318)] Added code to handle a standards violation (from what I can tell, anyways) caused by the attachment not having an `AttachMethod` property. The code will log a warning, attempt to detect the method, and throw a `StandardViolationError` if it fails.
-* [[TeamMsgExtractor #320](https://github.com/TeamMsgExtractor/msg-extractor/issues/320)] Changed the way string named properties are handled to allow for the string stream to have some errors and still be parsed. Warnings about these errors will be logged.
-* [[TeamMsgExtractor #324](https://github.com/TeamMsgExtractor/msg-extractor/issues/324)] Fixed an issues with contact saving when a list property returns `None`.
-* [[TeamMsgExtractor #326](https://github.com/TeamMsgExtractor/msg-extractor/issues/326)] Fixed a bug that could cause some files to error when exporting.
-* Fixed an issue where creation and modification times were not being copied to the new OLE file created by `OleWriter`.
-* Fixed up a few docstrings.
-* Fixed a few issues in `MSGFile` regarding the `filename` keyword argument.
-* Added new argument `rootPath` to `OleWriter.fromOleFile` for saving a specific directory from an OLE file instead of just copying the entire file. That directory will become the root of the new one.
-* Adjusted code for `OleWriter` to generate certain values *only* at save time to make them more dynamic. This allows for existing streams to be properly edited (although has issues with allowing storages to be edited).
-* Added new function `OleWriter.deleteEntry` to remove an entry that was already added. If the entry is a storage, all children will be removed too.
-* Added new function `OleWriter.editEntry` to edit an entry that was already added.
-* Added new function `OleWriter.addEntry` to add a new entry to the writer without an `OleFileIO` instance. Properties of the entry are instead set using the same keyword arguments as described in `OleWriter.editEntry`.
-* Changed `_DirectoryEntry` to `DirectoryEntry` to make the more finalized version public. Access to the originals that the `OleWriter` class creates should never happen, instead copies should be returned to ensure the behavior is as expected.
-* Added new function `OleWriter.getEntry` which returns a copy of the `DirectoryEntry` instance for that stream or storage in the writer. Use this function to see the current internal state of an entry.
-* Added new function `OleWriter.renameEntry` which allows the user to rename a stream or storage (in place). This only changes it's direct name and not it's location in the new OLE file.
-* Added new function `OleWriter.walk` which is similar to `os.walk` but for walking the structure of the new OLE file.
-* Added new function `OleWriter.listItems` which is functionally equivalent to `olefile.OleFileIO.listdir` which returns a list of paths to every item. Optionally a user can get the paths just for streams, just for storages, or both. Requesting neither will simply return an empty list. Default is to just return streams.
-* Added a small amount of path validation to `inputToMsgPath` which is used in a lot of places where user input for a path is accepted. It ensures illegal characters don't exist and that the path segments (each name for a storage or stream) are less than 32 characters. This will be most helpful for `OleWriter`.
-* Added *many* internal helper functions to `OleWriter` to make extensions easier and consolidate common code. Many of these involve direct access to internal data which is why they are private.
-
-**v0.38.4**
-* Fix line in `OleWriter` that was causing exporting to fail.
-* Fixed some issues with the `README`.
-
-**v0.38.3**
-* Fixed issues in HTML generation that caused line breaks to be omitted from large sections of the text.
-* Fixed issues with requirements file.
-
-**v0.38.2**
-* Fixed new `NameError` accidentally introduced in the previous version.
-
-**v0.38.1**
-* Added a `__del__` method to `MSGFile` to ensure a bit of proper cleanup should all references to an `MSGFile` instance be removed before the file is closed. `OleFileIO` doesn't appear to have one, so it's up to us to ensure it is properly closed. Note that the `del` keyword does not guarantee the immediate deletion of the object, and you should take care to close the file yourself. If this is not possible, importing the `gc` module and using it's `collect` method will free the files if your code has no references to them.
-* Fixed an import issue with signed messages.
-
-**v0.38.0**
-* [[TeamMsgExtractor #117](https://github.com/TeamMsgExtractor/msg-extractor/issues/117)] Added class `OleWriter` to allow the writing of OLE files, which allows for embedded MSG files to be extracted.
-* Added function `MSGFile.export` which copies all streams and storages from an MSG file into a new file. This can "clone" an MSG file or be used for extracting an MSG file that is embedded inside of another.
-* Added hidden function to `MSGFile` for getting the `OleDirectoryEntry` for a storage or stream. This is mainly for use by the `OleWriter` class.
-* Added option `extractEmbedded` to `Attachment.save` (`--extract-embedded` on the command line) which causes embedded MSG files to be extracted instead of running their save methods.
-* Fixed minor issues with `utils.inputToMsgPath` (renamed from `utils.inputToMsgPath`).
-* Renamed `utils.msgpathToString` to `utils.msgPathToString`.
-* Made some of the module requirements a little more strict to better version control. I'll be trying to make periodic checks for updates to the dependency packages and make sure that new versions are compatible before changing the allowed versions, while also trying to keep the requirements a bit flexible.
-
-**v0.37.1**
-* Added option to save function (including `MSGFile.saveAttachments`) to skip any attachments marked as hidden. This can also be done from the command line with `--skip-hidden`.
-* Fixed an issue that could cause an `MSGFile` to be included in the attachment names instead of just strings.
-* Fixed up several comments.
-* Fixed bug that would cause spaces at the end of the subject or filename to break the module.
-
-**v0.37.0**
-* [[TeamMsgExtractor #303](https://github.com/TeamMsgExtractor/msg-extractor/issues/303)] Renamed internal variable that wasn't changed when the other instances or it were renamed.
-* [[TeamMsgExtractor #302](https://github.com/TeamMsgExtractor/msg-extractor/issues/302)] Fixed properties missing (a fatal MSG error) raising an unclear exception. It now uses `InvalidFileFormatError`.
-* Updated `README` to contain documentation on command line option added in previous version.
-* Removed `MSGFile.mainProperties` after deprecating it in v0.36.0.
-* Added new `Properties` `Intelligence` type: `ERROR`. This type is used when a properties instance is created but has something wrong with it that is not necessarily fatal. Currently the only thing that will cause it is the properties stream being 0 bytes.
-
-**v0.36.5**
-* Documented and exposed to the command line the ability to save the headers to it's own file when saving the msg file. Thanks to martin-mueller-cemas on GitHub for fixing this (and telling me I can switch the branch a pull request points to). I don't know when I added the code to allow the user to do it, but somehow it was never documented and never exposed to the command line.
-
-**v0.36.4**
-* [[TeamMsgExtractor #291](https://github.com/TeamMsgExtractor/msg-extractor/issues/291)] Fixed typo in `MSGFile.saveRaw` that may have existed for a significant amount of time. It was using the wrong function (same name, but with different capitalization) but was hidden until `MSGFile` stopped being derived from `OleFileIO`.
-* Added logging code to `MessageBase.getSavePdfBody` to log the list that is going to be used to run `wkhtmltopdf`. This is mainly for debugging purposes, to allow users to potentially see why their arguments may be failing.
-* Updating funding information on GitHub and the `README` with more ways to support the module's development.
-* Fixed one of the exceptions in `MessageBase.getSavePdfBody` not using an fstring which caused it to omit information.
-* Changed the way `wkhtmltopdf` is called to patch a possible security vulnerability. This also seems to have fixed [[TeamMsgExtractor #291](https://github.com/TeamMsgExtractor/msg-extractor/issues/291)].
-
-**v0.36.3**
-* Added an option to skip the body if it could not be found, rather than throwing an error. This will cause no file to be made for it in the event no valid body exists. For the save functions, this option is `skipBodyNotFound` and from the command line the option is `--skip-body-not-found`.
-* Fixed a bug that caused contacts to save the business phone with two colons instead of 1.
-
-**v0.36.2**
-* [[TeamMsgExtractor #286](https://github.com/TeamMsgExtractor/msg-extractor/issues/286)] Fix missing import.
-
-**v0.36.1**
-* [[TeamMsgExtractor #283](https://github.com/TeamMsgExtractor/msg-extractor/issues/283)] Added file for typing recognition.
-* Added new option to allow messages with `NotImplementedError` attachments to at least save everything not related to them. From the command line this would be `--skip-not-implemented` or `--skip-ni`. From the save function, this would be the `skipNotImplemented` option.
-
-**v0.36.0**
-* Improved type hints to tell when a function may not return anything.
-* Added support for the `reportTag` property to `MessageBase`. I noticed this was one of the properties for `IPM.Outlook.Recall` so I decided to implement it. I'll work on ensuring all of `[MS-OXOMSG]` and `[MS-OXCMSG]` are implemented at a later date, including splitting off `REPORT` into it's own class, because it is it's own class.
-* Fixed a few minor issues in some properties. Mostly some `bool` returning properties should have been returning False when they were not found instead of None. Ones that may return None are specifically typed as optional in the source code. Unfortunately using the `help` command doesn't seem to show the return type for properties for me at least on Python 3.9 and below.
-* Fixed `Attachment.save` returning a `pathlib.Path` object instead of a `str` after the conversion to `pathlib`.
-* Added code to allow `pathlib` objects in `utils.openMsgBulk`. It uses `glob.glob` which *cannot* take a `pathlib` object.
-* Removed `PermanentEntryID` from `EntryID.autoCreate`. It shares a provider ID with `AddressBookEntryID`, and as such would never generate from it anyways. If you specifically need a `PermanentEntryID` you will have to instantiate it manually. Additionally, the entry has been removed from `enums.EntryIDType`.
-* Fixed the GUIDs for some of the EntryID structures being returned as bytes instead of a standard GUID string. This is considered a breaking change and is the reason for the full version increase.
-* Improved consistency of properties (the Python kind, not the MSG kind) so that properties for the raw data used to create an instance will all use the same name. Not all classes have this, but the ones that do will now all use `rawData` as the property name.
-* Fixed the properties header being read in a way that actually swapped the values in it.
-* Modified `MSGFile` to use the same name for Properties instances as all other classes. `MSGFile.mainProperties` will currently raise a `DeprecationWarning` instead of outright failing to help ease the transition. Use `MSGFile.props` instead.
-
-**v0.35.3**
-* [[TeamMsgExtractor #280](https://github.com/TeamMsgExtractor/msg-extractor/issues/280)] Fix typing issue in `message_base.py`.
-
-**v0.35.2**
-* Made a change to the argument handling for `--no-folders`. Since it requires `--attachmentsOnly` to work, I simply made it error when it's not given to avoid confusion.
-* Updated README.
-* Added `-v` to be used instead of `--verbose`. This allows you to do `-vvv` for verbosity level 3.
-
-**v0.35.1**
-* Fixed a few property conflicts that I missed in the last release (forgot to run the helper script before releasing).
-
-**v0.35.0**
-* [[TeamMsgExtractor #206](https://github.com/TeamMsgExtractor/msg-extractor/issues/206)] Implemented full support for Post objects, including the ability to save them.
-* [[TeamMsgExtractor #212](https://github.com/TeamMsgExtractor/msg-extractor/issues/212)] Implemented full support for Task objects, including the ability to save them. This also includes TaskRequest objects.
-* [[TeamMsgExtractor #110](https://github.com/TeamMsgExtractor/msg-extractor/issues/110)] Implemented full support for Contact objects, including the ability to save them.
-* [[TeamMsgExtractor #143](https://github.com/TeamMsgExtractor/msg-extractor/issues/143)] Rewrote the system used for `Appointment` objects to include all of the objects specified in [MS-OXOCAL]. Name changed to `AppointmentMeeting`. Completed support for Appointment objects, including the ability to save them.
-* [[TeamMsgExtractor #243](https://github.com/TeamMsgExtractor/msg-extractor/issues/256)] Added optional dependency `mimetype-magic` (installable using the `mime` extra) which helps to identify attachments that do not give a mime-type.
-* [[TeamMsgExtractor #274](https://github.com/TeamMsgExtractor/msg-extractor/issues/274)] Apparently the properties stream can have random garbage at the end of it (outlook generate the file that showed this) so code was added to ensure it wouldn't break everything.
-* [[TeamMsgExtractor #274](https://github.com/TeamMsgExtractor/msg-extractor/issues/274)] Made sure that the save function would report if it failed to find or generate a valid body. Specifically, if you were just trying to use the plain text body but it didn't exist (the stream didn't exist, not that the stream was empty) it would silently pass, which was bad behavior. Additionally, `allowFallback` will change the message to specify that current options were not usable for getting a valid body.
-* [[TeamMsgExtractor #207](https://github.com/TeamMsgExtractor/msg-extractor/issues/207)] Changed behavior for max date. Apparently it looks like it is supposed to be August 31, 4500 at 11:59 PM. However, in case this needs to change, we have created a constant called `extract_msg.constants.NULL_DATE` to represent this that you can use in your code to not have to worry about changing your code if we check it.
-* Moved a few more minor constants to `enums`.
-* Added support for many internal data structures, specifically Entry ID structures.
-* Refactored classes from `extract_msg.data` to submodule `extract_msg.structures`.
-* Added `python_requires` to setup.py as I noticed that it was missing.
-* Due to new saving requirements, adjusted the way header injection worked all around. Functions are now built-in to `MessageBase`. `getSaveXBody` functions have also been moved down to be defined in `MessageBase`. If the extension class needs to specify custom behaviors for creating the save bodies, these functions will need to be overridden.
-    * For saving, `MessageBase` (being the lowest one to currently contain bodies) has a few new properties. These properties represent the injection strings that will be injected into the bodies for the header, with an additional property to specify what properties map to what part of the format string. See `MessageBase.headerFormatProperties` for more information and an example of how to implement this in your own class.
-    * Injection strings in constants have been removed in favor of dynamic generation, which only creates what is needed. No you will no longer see an empty Bcc field in your messages when you save them.
-    * Plain text bodies now also use this injection, making it easy to change the header in all bodies by overwriting a single property that tells the program what data to put where.
-* Fixed issue in encapsulated RTF header that caused the "To" field to not be present. I had to write them by hand, so it was bound to happen. They are now dynamically generated by each instance, so these fields should always appear.
-* All save code has been moved down from `Message` into `MessageBase` for convenience. `Message` exists now for specific checking and for future specializations. This also means that anything that is a `MessageBase` now has the entire framework for saving built-in, with easy way to change details.
-* Fixed bad property in `Contact`.
-* Created save function for `Contact`. Saving, though it exists, is rather minimal and is limited to plain text and HTML.
-* Significantly extended the `Contact` class's properties.
-* Adjusted the naming of a few `Contact` properties to better match the microsoft names.
-    * `firstName` -> `givenName`.
-    * `lastName` -> `surname`.
-    * `businessPhone` -> `businessTelephoneNumber`
-    * Etc.
-* Changed existing fax properties to give a dictionary of the properties they actually contain rather than just the number. This makes them behave like the newly added email properties.
-* Fixed issues with `Task` properties being incorrect.
-* Added implementation for PtypErrorCode.
-* Changed behavior of `Properties.date` to *only* return the submit time. This is to ensure messages that were never sent do not have a sent date.
-* Changed behavior of `MessageBase.date` to only return a send date if the message has been sent. For messages with no flags, it assumes `True`.
-* Generally brought saving behavior closer to the way outlook handles it.
-* Made `SignedAttachment` and `BaseAttachment` more similar by adding properties to each that are shared. `BaseAttachment` now have a `name` property and `SignedAttachment` now have `longFilename` and `shortFilename`.
-* Fixed issue in HTML saving that would cause some characters to be dropped when rendering them due to how the header injection worked.
-* Removed `__init__` methods from MSG classes that don't change it. This ensures notes are easily passed down.
-* Correction to last comment, *one* max date was supposed to be at that date, but another max date is at a different date of the same year.
-* Changed the way that `PtypTime` is handled, making it a single function in `utils`.
-* Upgraded dependencies to newer versions (some really need to be newer, like `tzlocal`, for best results). Included dependencies are `beautifulsoup4` and `tzlocal`.
-* Fixed an issue where zip file naming conflicts *always* failed in zip files for attachments. Both the embedded msg and the plain attachments would fail.
-* *Actually* fixed the issue that would break the main loop.
-* MSGFile no longer inherits directly from `OleFileIO`. While I would prefer to do that, the `__init__` method for it is rather expensive, and allowing embedded msg files to directly share each other's instances of `OleFileIO` would improve speed immensely.
-* Fixed attachments not being preemptively loaded when `delayAttachments` was `False`.
-* `utils.openMsg` now delays attachments while loading the file to get the class type. This means all time for attachments is cut in half as they are only ever loaded once. It also means that files that won't open due to attachments will error a little later, but this shouldn't be a problem.
-* Changed named properties `Guid` back to constants. This has to do with the next entry.
-* Fixed a major issue in named properties. Apparently the ID is not enough and you *must* have the GUID as well, as multiple properties can share the exact same ID.
-* Added option `--no-folders` to the command line allowing you to save all attachments from a set of MSG files into a single folder.
-* Added option `--skip-embedded` to the command line to skip saving embedded MSG files.
-* Added option `skipEmbedded` to `Attachment.save` (and all other related save methods that call it) to skip saving an embedded MSG file.
-* Changed `__main__` so that it opens the zip file there instead of relying on everything it calls to do it again and again.
-* Changed the behavior of `--verbose` to allow it to be stacked for more verbosity. Specifying it once turns on warnings, twice for info, and three times for debug. Not specifying it only turns on error logging.
-
-**v0.34.3**
-* Fixed issue that may have caused other olefile types to raise the wrong type of error when passed to `openMsg`.
-* Fixed issues with changelog format.
-* Fixed issue that caused progress to sometimes break the main loop when a file had Unicode characters if the console it was writing to didn't support them.
-* Added option to `MessageBase` (and subsequently `openMsg`) that allows you to override the code being used for deencapsulation. See `MessageBase.__init__` for details on how to create an override function.
-* Added additional msg class types that I found to the list of known class types.
-
-**v0.34.2**
-* [[TeamMsgExtractor #267](https://github.com/TeamMsgExtractor/msg-extractor/issues/267)] Fixed issue that caused signed messages that were .eml files to have their data field *not* be a bytes instance. This field will now *always* be bytes. If a problem making it bytes occurs, an exception will be raised to give you brief details.
-* Added function `utils.unwrapMultipart` that takes a multipart message and acquires a plain text body, an HTML body, and a list of attachments from it. These attachments are returned as `dict`s that can easily be converted to `SignedAttachment`s. It replaces the logic `mailbits` was being used for, and as such `mailbits` is no longer required. The module may be reintroduced in the future.
-* Added new property `emailMessage` to `SignedAttachment`, which returns the email `Message` instance used to get data for the attachment.
-
-**v0.34.1**
-* Added convenience function `utils.openMsgBulk` (imported to `extract_msg` namespace) for opening message paths with wildcards. Allows you to open several messages with one function, returning a list of the opened messages.
-* Added convenience function `utils.unwrapMsg` which recurses through an `MSGFile` and it's attachments, creating a series of linear structures stored in a dictionary. Useful for analyzing, saving, etc. all messages and attachments down through the structure without having to recurse yourself.
-* Fixed an issue that would cause signed attachments to not properly generate.
-
-**v0.34.0**
-* [[TeamMsgExtractor #102](https://github.com/TeamMsgExtractor/msg-extractor/issues/102)] Added the option to directly save body to pdf. This requires that you either have wkhtmltopdf on your path or that you provide a path directly to it in order to work. Simply pass `pdf = True` to save to turn it on. More details in the doc for the save function. You can also do this from the command line using the `--pdf` option, incompatible with other body types.
-* Added `--glob` option for allowing you to provide an msg path that will evaluate wildcards.
-* Removed per-file output names as they weren't actually functional and currently add too much complexity. If anyone knows a way to handle it directly with `argparse` let me know.
-* Added `chardet` as a requirement to help work around an error in `RTFDE`.
-* Looking into some of the unsupported encodings revealed at least one to be supported, but was missed due to the name not being registered as an alias.
-* Fixed a bug that prevented an HTML body from the plain text body when it couldn't be generated any other way. This happened when the RTF body existed and the plain text body existed, but the RTF body was not encapsulated HTML.
-* Due to several of the issues with RTFDE preventing saving due to exceptions, the option `ignoreRtfDeErrors` has been added to the `MessageBase` class and `openMsg`. It can also be enabled from the command line with `--ignore-rtfde`. This option will make it so all exceptions will be silenced from the module.
-
-**v0.33.0**
-* [[TeamMsgExtractor #212](https://github.com/TeamMsgExtractor/msg-extractor/issues/212)] Added support for Task objects.
-* Added additional parameter `overrideClass` to all `_ensureSetX` type functions. This parameter is a class to initialize using the data, if provided. The data will be provided as the first argument to the `__init__` function of the class *if* the data is not `None`. If the data is done, the value set and returned from `_ensureSetX` will be `None`. This can be overridden using the second added parameter, which defaults to this behavior. Simply set `preserveNone` to `False` to force the data to be passed to the class. Keep in mind that this means the class will receive `None` as it's first parameter.
-* Updated `Named` class to make it more like the dictionary it is build on top of. Specifically, added `keys`, `values`, and `items` as functions.
-* Fixed issue in `Named` where old code wasn't deleted, causing some named properties to be completely omitted.
-* Improved efficiency of `Named` by making it so `get` no longer copied the entire dictionary repeatedly while looking for the property.
-* Fixed typo in `Attachment` that caused embedded msg files to still regenerate the `Named` instance even though they should have been using the parent's.
-* Updated fields in `MSGFile` to use enums.
-* Added additional properties to `MSGFile`.
-* Significant cleanup.
-
-**v0.32.0**
-* [[TeamMsgExtractor #217](https://github.com/TeamMsgExtractor/msg-extractor/issues/217)] Redesigned named properties to be much more efficient. All in all, load times for MSG files are significantly improved all around.
-    * Named properties load dynamically.
-    * Named properties use a single shared instance for embedded msg files to contain all of the entries, and tiny individual instances for actually accessing based on what is accessing.
-    * `Named` has been updated so it's methods are more standardized.
-    * `Named` is no longer usable to directly access property values. Instead,
-    access to them is done through `NamedProperties`.
-    * `_registerNamedProperty` has been removed due to no longer being part of the named properties framework.
-* Actually removed the exception I meant to remove in 0.31.0.
-* Changed `Attachment.type` to an enum instead of a string. This makes it easier to see all of the possible values.
-* Added option to allow attachment saving to be skipped when calling `Message.save`.
-* Added `type` property to all attachment types. `AttachmentBase` uses `AttachmentType.UNKNOWN`, `BrokenAttachment` uses `AttachmentType.BROKEN`, and `UnsupportedAttachment` uses `AttachmentType.UNSUPPORTED`.
-
-**v0.31.1**
-* Updated signed attachment mimetype property from `mime` to `mimetype` to match with the regular attachment property.
-
-**v0.31.0**
-* [[TeamMsgExtractor #223](https://github.com/TeamMsgExtractor/msg-extractor/issues/223)] First implementation of support for signed messages.
-* [[TeamMsgExtractor #256](https://github.com/TeamMsgExtractor/msg-extractor/issues/256)] Extended the properties of the attachment class to allow for access to more data.
-* Fixed some issues with the contact class (some of the code was left unfinished).
-* Converted many arguments for msg files to keyword arguments (`**kwargs`). This is a breaking change if your code provides anything except the path to the msg file. This will, however, make it easier to add arguments without the function signature being polluted with numerous arguments.
-* Updated exception blocks to ensure they would only catch exceptions that are instances of Exception or a child of Exception. A few were missing this check and so might have caught unwanted exceptions.
-* Shifted some minor parts down towards the `AttachmentBase` class where possible to allow more usability with broken and unsupported attachments. Nothing about these properties required the attachment to be fully processed, which is why they were moved down. From the perspective of using the `Attachment` class nothing has changed. The following properties have been moved: `attachmentEncoding`, `additionalInformation`, `cid`/`contentId`, `longFilename`, `renderingPosition`, and `shortFilename`.
-* Added link to readme for supporting development.
-* Finally found the behavior to use for missing encoding. As such, `MissingEncodingError` is being removed from the module entirely, as it is no longer a thing.
-* Moved many constant sets to enums. This makes things a lot more organized.
-
-**v0.30.14**
-* Fixed major bug in `MSGFile.listDir` that would cause it to give the wrong data due to caching. I forgot to have it cache a different result for each set of options, so it would always give the same result regardless of options after the first access.
-* Minor updates to `setup.py`.
-* Fixed URLs in `README`.
-
-**v0.30.13**
-* [[TeamMsgExtractor #257](https://github.com/TeamMsgExtractor/msg-extractor/issues/257)] Fixed missing documentation for `customPath` keyword argument to `Attachment.save`.
-
-**v0.30.12**
-* [[TeamMsgExtractor #253](https://github.com/TeamMsgExtractor/msg-extractor/issues/253)] Fixed various docstring issues.
-
-**v0.30.11**
-* [[TeamMsgExtractor #249](https://github.com/TeamMsgExtractor/msg-extractor/issues/249)] Fixed an error with opening the body causing the file to throw an uncaught exception in the `__init__` function of `MessageBase`. The error may still come up later, but you will still have general access to the instance.
-* Fixed an issue with part of the command line documentation.
-
-**v0.30.10**
-* [[TeamMsgExtractor #249](https://github.com/TeamMsgExtractor/msg-extractor/issues/249)] Fixed exception catching not properly accessing the exception (forgot to go through one of the submodules to access exception).
-* Updated docstring for `MessageBase.deencapsulatedRtf`.
-
-**v0.30.9**
-* Fixed the behavior of `Properties.get` so it actually behaves like a dict (that was the intent of it, but I did it the wrong way for some reason).
-* Fixed a type that caused an exception when no HTML body could be found nor generated.
-
-**v0.30.8**
-* Update `imapclient` requirement to `>=2.1.0` instead of `==2.1.0`. Currently there are no changes that would prevent current future versions from working.
-
-**v0.30.7**
-* [[TeamMsgExtractor #239](https://github.com/TeamMsgExtractor/msg-extractor/issues/239)] Fixed msg.py not having `import pathlib`.
-* After going through the details of the example MSG files provided with the module, specifically unicode.msg, I now am glad I decided to put in some fail-safes in the HTML body processing. One of them does not have an `<html>`, `<head>`, nor `<body>` tag, and so would have had an error. This will actually prevent the header from injecting properly as well, so a bit of validation before was made necessary to ensure the HTML saving would still work.
-* Added new exception `BadHtmlError`.
-* Added new function `utils.validateHtml`.
-* Updated README credits.
-* Changed header logic to generate manually if the header data has been stripped (filled with null bytes) and not just if the stream does not exist.
-
-**v0.30.6**
-* Small adjustments to internal code to make it a bit better.
-* Added `Message.getSaveBody`, `Message.getSaveHtmlBody`, and `Message.getSaveRtfBody`. These three functions generate their respective bodies that will be used when saving the file, allowing you to retrieve the final products without having to write them to the disk first. All arguments that are passed to `Message.save` that would influence the respective bodies are passed to their respective functions.
-* I thought I added the documentation for `attachmentsOnly` to `Message.save` but apparently it was missing. Not sure what happened there but I made sure it was added this time.
-* Added new option to `Message.save` called `charset`. This is used in the preparation of the HTML body when using `preparedHtml`. This is also usable with `--charset CHARSET` from the command line.
-
-**v0.30.5**
-* [[TeamMsgExtractor #225](https://github.com/TeamMsgExtractor/msg-extractor/issues/225)] Added the ability to generate the HTML body from the RTF body if it is encapsulated HTML. If there is no RTF body, then it will do a very basic generation from the plain text body. This process is automatically performed if the HTML body is missing.
-* Added the ability for the plain text body to sometimes generate from the RTF body if the plain text body does not exist.
-* Added documentation to `Message.save` for the `attachmentsOnly` option.
-
-**v0.30.4**
-* [[TeamMsgExtractor #233](https://github.com/TeamMsgExtractor/msg-extractor/issues/233)] Added option to `Message.save` to only save the attachments (`attachmentsOnly`). This can also be used from the command line with the option `--attachments-only`.
-* Corrected error string for incompatible options in `Message.save`.
-* Fixed if blocks being nested weirdly in `Message.save` instead of being chained with `elif`. Probably an artifact left from adding support for HTML and RTF.
-
-**v0.30.3**
-* [[TeamMsgExtractor #232](https://github.com/TeamMsgExtractor/msg-extractor/issues/232)] Updated list of known MSG class types so the module would correctly give `UnsupportedMSGTypeError` instead of `UnrecognizedMSGTypeError`.
-
-**v0.30.2**
-* Fixed typo in `utils.knownMsgClass`.
-* Updated contributing guidelines and pull request template. Pull requests were updated to match the new structure of the module while the guidelines were updated for clarity.
-
-**v0.30.1**
-* [[TeamMsgExtractor #102](https://github.com/TeamMsgExtractor/msg-extractor/issues/102)] Added property `MessageBase.htmlBodyPrepared` which provides the HTML body that has been prepared for actual use or conversion to PDF. All attachments that can be injected into the body directly will be injected.
-* Corrected a mistake in the documentation of `Message.save`.
-* Fixed issue where the command line parser was not checking for raw in conjunction with other saving options.
-* Changed `utils.setupLogging` to use `pathlib`.
-* Improved reliability of the logic in `utils.setupLogging`.
-* Removed function `utils.getContFileDir`.
-* Cleaned up plain `Exception` being raised at the end of `utils.injectRtfHeader` if the injection failed. This now raises `RuntimeError`, an error that should be reported so the injection system can be improved.
-* Added parsing for PtypServerId to `utils.parseType`.
-* Added `FolderID`, `MessageID`, and `ServerID` to `data`.
-* Added zip output to the command line.
-* Added support for PtypMultipleFloatingTime to `utils.parseType`.
-* Improved documentation of many functions with the exceptions they may raise.
-* Changed the way zip files are handled so that files written to them actually have a modification date now.
-
-**v0.30.0**
-* Removed all support for Python 2. This caused a lot of things to be moved around and changed from indirect references to direct references, so it's possible something fell through the cracks. I'm doing my best to test it, but let me know if you have an issue.
-* Changed classes to now prefer `super()` over direct superclass initialization.
-* Removed explicit object subclassing (it's implicit in Python 3 so we don't need it anymore).
-* Converted most `.format`s into f strings.
-* Improved consistency of docstrings. It's not perfect, but it should at least be better.
-* Started the addition of type hints to functions and methods.
-* Updated `utils.bytesToGuid` to make it faster and more efficient.
-* Renamed `utils.msgEpoch` to `utils.filetimeToUtc` to be more descriptive.
-* Updated internal variable names to be more consistent.
-* Improvements to the way `__main__` works. This does not affect the output it will generate, only the efficiency and readability.
-
-**v0.29.3**
-* [[TeamMsgExtractor #226](https://github.com/TeamMsgExtractor/msg-extractor/issues/198)] Fix typo in command parsing that prevented the usage of `allowFallback`.
-* Fixed main still manually navigating to a new directory with os.chdir instead of using `customPath`.
-* Fixed issue in main where the `--html` option was being using for both html *and* rtf. This meant if you wanted rtf it would not have used it, and if you wanted html it would have thrown an error.
-* Fixed `--out-name` having no effect.
-* Fixed `--out` having no effect.
-
-**v0.29.2**
-* Fixed issue where the RTF injection was accidentally doing HTML escapes for non-encapsulated streams and *not* doing escapes for encapsulated streams.
-* Fixed name error in `Message.save` causing bad logic. For context, the internal variable `zip` was renamed to `_zip` to avoid a name conflict with the built-in function. Some instances of it were missed.
-
-**v0.29.1**
-* [[TeamMsgExtractor #198](https://github.com/TeamMsgExtractor/msg-extractor/issues/198)] Added a feature to save the header in it's own file (prefers the full raw header if it can find it, otherwise puts in a generated one) that was actually supposed to be in v0.29.0 but I forgot, lol.
-
-**v0.29.0**
-* [[TeamMsgExtractor #207](https://github.com/TeamMsgExtractor/msg-extractor/issues/207)] Made it so that unspecified dates are handled properly. For clarification, an unspecified date is a custom value in MSG files for dates that means that the date is unspecified. It is distinctly different from a property not existing, which will still return None. For unspecified dates, `datetime.datetime.max` is returned. While perhaps not the best solution, it will have to do for now.
-* Fixed an issue where `utils.parseType` was returning a string for the date when it makes more sense to return an actual datetime instance.
-* [[TeamMsgExtractor #165](https://github.com/TeamMsgExtractor/msg-extractor/issues/165)] [[TeamMsgExtractor #191](https://github.com/TeamMsgExtractor/msg-extractor/issues/191)] Completely redesigned all existing save functions. You can now properly save to custom locations under custom file names. This change may break existing code for several reasons. First, all arguments have been changed to keyword arguments. Second, a few keyword arguments have been renamed to better fit the naming conventions.
-* [[TeamMsgExtractor #200](https://github.com/TeamMsgExtractor/msg-extractor/issues/200)] Changed imports to use relative imports instead of hard imports where applicable.
-* Updated the save functions to no longer rely on the current working directory to save things. The module now does what it can to use hard pathing so that if you spontaneously change working directory it will not cause problems. This should also allow for saving to be threaded, if I am correct.
-* [[TeamMsgExtractor #197](https://github.com/TeamMsgExtractor/msg-extractor/issues/197)] Added new property `Message.defaultFolderName`. This property returns the default name to be used for a Message if none of the options change the name.
-* [[TeamMsgExtractor #201](https://github.com/TeamMsgExtractor/msg-extractor/issues/201)] Fixed an issue where if the class type was all caps it would not be recognized. According to the documentation the comparisons should have been case insensitive, but I must have misread it at some point.
-* [[TeamMsgExtractor #202](https://github.com/TeamMsgExtractor/msg-extractor/issues/202)] Module will now handle path lengths in a semi-intelligent way to determine how best to save the MSG files. Default path length max is 255.
-* [[TeamMsgExtractor #203](https://github.com/TeamMsgExtractor/msg-extractor/issues/203)] Fixed an issue where having multiple "." characters in your file name would cause the directories to be incorrectly named when using the `useFileName` (now `useMsgFilename`) argument in the save function.
-* [[TeamMsgExtractor #204](https://github.com/TeamMsgExtractor/msg-extractor/issues/204)] Fixed an issue where the failsafe name used by attachments wasn't being encoded before hand causing encoding errors.
-* MSG files with a type of simply `IPM` will now be returned as `MSGFile` by `openMsg`, as this specifies that no format has been specified.
-* [[TeamMsgExtractor #214](https://github.com/TeamMsgExtractor/msg-extractor/issues/214)] Attachments that error because the MSG class type wasn't recognized or isn't supported will now correctly be `UnsupportedAttachment` instead of `BrokenAttachment`.
-* Improved internal code in many functions to make them faster and more efficient.
-* `openMsg` will now tell you if a class type is simply unsupported rather than unrecognized. If it is found in the list, the function will raise `UnsupportedMSGTypeError`.
-* Added caching to `MSGFile.listDir`. I found that if you have larger files this single function might be taking up over half of the processing time because of how many times it is used in the module.
-* Fully implemented raw saving.
-* Extended the `Contact` class to have more properties.
-* Added new function `MSGFile._ensureSetTyped` which acts like the other ensure set functions but doesn't require you to know the type. Prefer to use other ensure set function when you know exactly what type it will be.
-* Changed `Message.saveRaw` to `MSGFile.saveRaw`.
-* Changed `MSGFile.saveRaw` to take a path and save the contents to a zip file.
-* Corrected the help doc to reflect the current repository (was still on mattgwwalker).
-* Fixed a bug that would cause an exception on trying to access the RTF body on a file that didn't have one. This is now correctly returning `None`.
-* The `raw` keyword of `Message.save` now actually works.
-* Added property `Attachment.randomFilename` which allows you to get the randomly generated name for attachments that don't have a usable one otherwise.
-* Added function `Attachment.regenerateRandomName` for creating a new random name if necessary.
-* Added function `Attachment.getFilename`. This function is used to get the name an attachment will be saved with given the specified arguments. Arguments are identical to `Attachment.save`.
-* Changed pull requests to reflect new style.
-* Added additional properties for defined MSG file fields.
-* Added zip file support for the `Attachment.save` and `Message.save`. Simply pass a path for the `zip` keyword argument and it will create a new `ZipFile` instance and save all of it's data inside there. Alternatively, you can pass an instance of a class that is either a `ZipFile` or `ZipFile`-like and it will simply use that. When this argument is defined, the `customPath` argument refers to the path inside the zip file.
-* Added the `html` and `rtf` keywords to `Message.save`. These will attempt to save the body in the html or rtf format, respectively. If the program cannot save in those formats, it will raise an exception unless the `allowFallback` keyword argument is `True`.
-* Changed `utils.hasLen` to use `hasattr` instead of the try-except method it was using.
-* Added new option `recipientSeparator` to `MessageBase` allowing you to specify a custom recipient separator (default is ";" to match Microsoft Outlook).
-* Changed the `openMsg` function in `Attachment` to not be strict. This allows you to actually open the MSG file even if we don't recognize the type of embedded MSG that is being used.
-* Attempted to normalize encoding names throughout the module so that a certain encoding will only show up using one name and not multiple.
-* Finally figured out what CRC32 algorithm is used in named properties after directly asking in a Microsoft forum (see the thread [here](https://docs.microsoft.com/en-us/answers/questions/574894/ms-oxmsg-specifies-the-use-of-crc-32-checksums-wit.html)). Fortunately the is already defined in the `compressed-rtf` module so we can take advantage of that.
-* Reworked `MessageBase._genRecipient` to improve it (because what on earth was that code it was using before?). Variables in the function are now more descriptive. Added comments in several places.
-* Many renames to better fit naming convention:
-    * `dev.setup_dev_logger` to `dev.setupDevLogger`.
-    * `MSGFile.fix_path` to `MSGFile.fixPath`.
-    * `MessageBase.save_attachments` to `MessageBase.saveAttachments`.
-    * `*.Exists` to `exists`.
-    * `*.ExistsTypedProperty` to `*.existsTypedProperty`.
-    * `prop.create_prop` to `prop.createProp`.
-    * `Properties.attachment_count` to `Properties.attachmentCount`.
-    * `Properties.next_attachment_id` to `Properties.nextAttachmentId`.
-    * `Properties.next_recipient_id` to `Properties.nextRecipientId`.
-    * `Properties.recipient_count` to `Properties.recipientCount`.
-    * `utils.get_command_args` to `utils.getCommandArgs`.
-    * `utils.get_full_class_name` to `utils.getFullClassName`.
-    * `utils.get_input` to `utils.getInput`.
-    * `utils.has_len` to `utils.hasLen`.
-    * `utils.setup_logging` to `utils.setupLogging`.
-    * `constants.int_to_data_type` to `constants.intToDataType`.
-    * `constants.int_to_intelligence` to `constants.intToIntelligence`.
-    * `constants.int_to_recipient_type` to `constants.intToRecipientType`.
-    * Misc internal function variables.
-
-**v0.28.7**
-* Added hex versions of the `MULTIPLE_X_BYTES` constants.
-* Added `1048` to `constants.MULTIPLE_16_BYTES`
-* [[TeamMsgExtractor #173](https://github.com/TeamMsgExtractor/msg-extractor/issues/173)] rewrote the parsing of the length in `VariableLengthProp.__init__` to use constants rather than values coded directly into the function. This should fix this issue.
-
-**v0.28.6**
-* [[TeamMsgExtractor #191](https://github.com/TeamMsgExtractor/msg-extractor/issues/191)] This feature was never properly implemented, so it's not officially supported. However, this specific issue should be fixed. This is a temporary patch until I can get around to rewriting the way the module saves files in general.
-* Added `venv` to the .gitignore list.
-* Added information to the readme.
-
-**v0.28.5**
-* [[TeamMsgExtractor #189](https://github.com/TeamMsgExtractor/msg-extractor/issues/189)] Forgot to import `prepareFilename` in `attachment.py`.
-* Fixed bad link in the changelog.
-
-**v0.28.4**
-* [[TeamMsgExtractor #184](https://github.com/TeamMsgExtractor/msg-extractor/issues/184)] Added code to `Message` to ensure subjects with null characters get stripped of them.
-* Moved code for stripping subjects of bad characters to `prepareFilename` in `utils`.
-
-**v0.28.3**
-* Fixed minor typo in an exception description.
-* Updated the README this time. Forgot to do it for at least 1 update.
-
-**v0.28.2**
-* Started preparing more of the code for when HTML and RTF saving are fully implemented. Please note that they do not work at all right now. Commented out the code for this because it wasn't meant to be uncommented.
-* [[TeamMsgExtractor #184](https://github.com/TeamMsgExtractor/msg-extractor/issues/184)] Added code to ensure file names don't have null characters when saving an attachment.
-* Minor improvement to the section of the save code that checks if you have provided incompatible options.
-* [[TeamMsgExtractor #185](https://github.com/TeamMsgExtractor/msg-extractor/issues/185)] Added the `IncompatibleOptionsError`. It was supposed to be added a few updates ago, but was accidentally left out.
-* Modified `Message.save` to return the current `Message` instance to allow for chained commands. This allows you to do something like `extract_msg.openMsg("path/to/message.msg").save().close()` where you could not before.
-
-**v0.28.1**
-* [[TeamMsgExtractor #181](https://github.com/TeamMsgExtractor/msg-extractor/issues/181)] Fixed issue in `Attachment` that arose when moving some of the code to a base class.
-* Fixed small error in `utils.parse_type` that caused it to incorrectly compare expected and actual length. Fortunately, this had no actual effect aside from a warning.
-* Added the `ebcdic` module to the requirements to add more supported encodings.
-
-**v0.28.0**
-* [[TeamMsgExtractor #87](https://github.com/TeamMsgExtractor/msg-extractor/issues/87)] Added a new system to handle `NotImplementedError` and other exceptions. All msg classes now have an option called `attachmentErrorBehavior` that tells the class what to do if it has an error. The value should be one of three constants: `ATTACHMENT_ERROR_THROW`, `ATTACHMENT_ERROR_NOT_IMPLEMENTED`, or `ATTACHMENT_ERROR_BROKEN`. `ATTACHMENT_ERROR_THROW` tells the class to not catch and exceptions and just let the user handle them. `ATTACHMENT_ERROR_NOT_IMPLEMENTED` tells the class to catch `NotImplementedError` exceptions and put an instance of `UnsupportedAttachment` in place of a regular attachment. `ATTACHMENT_ERROR_BROKEN` tells the class to catch *all* exceptions and either replace the attachment with `UnsupportedAttachment` if it is a `NotImplementedError` or `BrokenAttachment` for all other exceptions. With both of those options, caught exceptions will be logged.
-* In making the previous point work, much code from `Attachment` has been moved to a new class called `AttachmentBase`. Both `BrokenAttachment` and `UnsupportedAttachment` are subclasses of `AttachmentBase` meaning data can be extracted from their streams in the same way as a functioning attachment.
-* [[TeamMsgExtractor #162](https://github.com/TeamMsgExtractor/msg-extractor/issues/162)] Pretty sure I actually got it this time. The execution flag should be applied by pip now.
-* Fixed typos in some exceptions
-
-**v0.27.16**
-* [[TeamMsgExtractor #177](https://github.com/TeamMsgExtractor/msg-extractor/issues/177)] Fixed incorrect struct being used. It should be the correct one now, but further testing will be required to confirm this.
-* Fixed log error message in `extract_msg.prop` to actually format a value into the message.
-
-**v0.27.15**
-* [[TeamMsgExtractor #177](https://github.com/TeamMsgExtractor/msg-extractor/issues/177)] Fixed missing import.
-
-**v0.27.14**
-* [[TeamMsgExtractor #173](https://github.com/TeamMsgExtractor/msg-extractor/issues/173)] Fixed typo that I made in the last version that broke things. I didn't have the resources to test this one myself, unfortunately.
-* Fixed a typo in an exception message.
-
-**v0.27.13**
-* [[TeamMsgExtractor #173](https://github.com/TeamMsgExtractor/msg-extractor/issues/173)] Moved some data used in checks into constants so that I can make sure they get changed every where that they are used. Hopefully I can close this issue.
-
-**v0.27.12**
-* [[TeamMsgExtractor #173](https://github.com/TeamMsgExtractor/msg-extractor/issues/173)] Made an assumption about where an exception was thrown from and was wrong. While that location would have throw an exception, the function that called that code was the one to actually throw the exception in question. This issue *should* be fixed...
-* [[TeamMsgExtractor #162](https://github.com/TeamMsgExtractor/msg-extractor/issues/162)] Made another attempt to fix the execution flag on the wrapper script.
-
-**v0.27.11**
-* [[TeamMsgExtractor #173](https://github.com/TeamMsgExtractor/msg-extractor/issues/173)] Tentatively implemented type 0x1014 (PtypMultipleInteger64). Apparently I forgot to do it earlier.
-
-**v0.27.10**
-* [[TeamMsgExtractor #162](https://github.com/TeamMsgExtractor/msg-extractor/issues/162)] Fixed line endings in the wrapper script to be UNIX line endings rather than Windows line endings. Attempted to add the execution flag to the runnable script.
-
-**v0.27.9**
-* [[TeamMsgExtractor #161](https://github.com/TeamMsgExtractor/msg-extractor/issues/161)] Added commands to the command line that will allow the user to specify that they want the message data to be output to stdout rather than to a file.
-* [[TeamMsgExtractor #162](https://github.com/TeamMsgExtractor/msg-extractor/issues/162)] Added a wrapper for extract_msg that will be installed.
-* Fixed some of the encoding names to allow them to actually be used in Python. The names they previously held were not aliases that currently exist.
-* Added more documentation to `constants.CODE_PAGES` to give more information about what it is. As it is a list of the possible encodings an msg file can use, I also specified which ones were supported by Python 3.
-* Moved the main code into a function so it is now callable from outside of the file.
-
-**v0.27.8**
-* [[TeamMsgExtractor #158](https://github.com/TeamMsgExtractor/msg-extractor/issues/158)] Fixed a spelling error in a function name that was causing it to not be seen. The function was called `ceilDiv` but was accidentally called as `cielDiv`.
-
-**v0.27.7**
-* Fixed an issue in the new bitwise adjustment functions. One of the variable names was incorrect.
-
-**v0.27.6**
-* Fixed a few lines in `data.py`.
-
-**v0.27.5**
-* Fixed an error in `utils.divide` that would cause it to drop the extra data if there was not enough to create a full division. For example, if you had a string that was 10 characters, and divided by 3, you would only receive a total of 9 characters back.
-* Added some useful functions that will be used in the future.
-* [[TeamMsgExtractor #155](https://github.com/TeamMsgExtractor/msg-extractor/issues/155)] Updated to use new version of tzlocal.
-* Updated changelog to fit new repository.
-
-**v0.27.4**
-* [[TeamMsgExtractor #152](https://github.com/TeamMsgExtractor/msg-extractor/issues/152)] Fixed an issue where the name of an exception was put as the wrong thing.
-
-**v0.27.3**
-* [[TeamMsgExtractor #105](https://github.com/TeamMsgExtractor/msg-extractor/issues/105)] Added code to fix an internal msg issue that had recipient lists being split up in the header after a certain amount of characters. This was now a bug on our part, but an issue with the generation of the msg file itself.
-* Exposed the `MessageBase` class directly from `extract_msg`. I forgot to do this when I created it.
-* Added `MessageBase.bcc`. I think it used to exist but got erased somehow on accident. Either way, it exists now.
-
-**v0.27.2**
-* After much debate, I have finally decided to allow an option to override the string encoding in message files. This Was something I reserved solely for `dev_classes.Message` because it felt like it didn't fit with how msg files were supposed to work. I also didn't want messages from people about them running into errors after they overrode the encoding. You can now do this by providing the `overrideEncoding` option on any `MSGFile` class as well as the `openMsg` function.
-* [[TeamMsgExtractor #103](https://github.com/TeamMsgExtractor/msg-extractor/issues/103)] Implemented correct detection of encodings. If you have any more issues with "'X' codec can't decode bytes" it is likely because the encoding specified inside the msg file is wrong.
-
-**v0.27.1**
-* [[TeamMsgExtractor #147](https://github.com/TeamMsgExtractor/msg-extractor/issues/147)] Fixed an issue in `Message.save` caused by it attempting to directly access a private variable that was moved to the base class `MessageBase`.
-
-**v0.27.0**
-* [[TeamMsgExtractor #143](https://github.com/TeamMsgExtractor/msg-extractor/issues/143)] Added new class `Appointment` that can handle outlook appointments or meetings.
-* [[TeamMsgExtractor #143](https://github.com/TeamMsgExtractor/msg-extractor/issues/143)] Added new class `MessageBase` for classes that end up being mostly like the `Message` class. Currently subclassed by `Message` and `Appointment`. This should not have a direct effect on any code that uses this module.
-* Added support for `PtypFloatingTime` in `utils.parseType`.
-* Added proper support for `PtypTime` in `FixedLengthProp.parseType`
-* Added pretty print functions to the `Properties` class and the `Named` class.
-* Added new function `MSGFile._ensureSetProperty` that acts like `MSGFile._ensureSet` except that it works with properties from the `Properties` instance.
-* Added equivalent of the previously mentioned function to the `Attachment` class and the `Recipient` class.
-
-**v0.26.4**
-* Added new function `MSGFile._ensureSetNamed` which acts like `MSGFile._ensureSet` except that it works with named properties.
-* Added a version of the previous function to the `Attachment` and `Recipient` classes.
-* Added new file `data.py` that contains various data structures that are used for specific properties.
-* Expanded the functionality of the `Recipient` class by adding more properties.
-* Added new functions `Named.getNamed` and `Named.getNamedValue` which retrieves a named property or the value of a named property, respectively, based on its name.
-
-**v0.26.3**
-* Added new function `MSGFile.save` that causes it and subclasses to raise a `NotImplementedError` if they do not override it.
-* Fixed some issues in the changelog.
-* Added some additional constants for future use.
-
-**v0.26.2**
-* Fixed error in `Message._registerNamedProperty` where I put the exception `KeyError` instead of `AttributeError`.
-
-**v0.26.1**
-* Fixed an issue in `openMsg` that would leave the basic `MSGFile` instance open with the function returned, even if the function was returning a specific msg instance.
-
-**v0.26.0**
-* [[TheElementalOfDestruction #3](https://github.com/TheElementalOfDestruction/msg-extractor/issues/3)] Implementation of Named properties has finally been added. This allows us to access certain data that was not available to us before through regular methods.
-* Added new function `MSGFile.slistDir` that acts like `MSGFile.listDir`, except that it returns a list of strings rather than a list of lists.
-* [[TheElementalOfDestruction #6](https://github.com/TheElementalOfDestruction/msg-extractor/issues/6)] Added new function `MSGFile._getTypedStream` which, based on a path formatted in the same way as you would give to `MSGFile._getStringStream`, will return the data in the specified stream without the user needing to know the type before hand. However, if you DO know the type before hand, you can provide this function with one of the values in `constants.FIXED_LENGTH_PROPS_STRING` or `constants.VARIABLE_LENGTH_PROPS_STRING`.
-* [[TheElementalOfDestruction #6](https://github.com/TheElementalOfDestruction/msg-extractor/issues/6)] Added new function `MSGFile._getTypedProperty` which, based on a 4 digit hexadecimal string, will return the property in the properties file that matches that string without the type needing to be specified. However, if you DO know the type before hand, you can provide this function with one of the values in `constants.FIXED_LENGTH_PROPS_STRING` or `constants.VARIABLE_LENGTH_PROPS_STRING`.
-* [[TheElementalOfDestruction #6](https://github.com/TheElementalOfDestruction/msg-extractor/issues/6)] Added new function `MSGFile._getTypedData` which is a combination of the two previously stated functions.
-* Added new function `MSGFile.ExistsTypedProperty` which determines if a property with the specified id exists in the specified location. If you are looking for a property that may be in the properties file of an attachment or a recipient, please use the corresponding function from that class.
-* Added an equivalent of the previous 4 functions for the `Recipient` and `Attachment` classes.
-* [[TheElementalOfDestruction #2](https://github.com/TheElementalOfDestruction/msg-extractor/issues/2)] Finished partial implementation of `utils.parseType` which was necessary for the proper implementation of named properties. This function is not fully implemented because there are some types we do not fully understand.
-
-**v0.25.3**
-* [[TeamMsgExtractor #138](https://github.com/TeamMsgExtractor/msg-extractor/issues/138)] Fixed missing import in `extract_msg/utils.py`.
-
-**v0.25.2**
-* [[TeamMsgExtractor #134](https://github.com/TeamMsgExtractor/msg-extractor/issues/134)] Fixed a typo that caused `Message.headerDict` to raise an exception.
-* Upgraded code for `Message.headerDict` to avoid accidentally raising a key error if the header is ever missing the "Received" property.
-* Fixed an error in the changelog that caused some issue links to link to the wrong place.
-
-**v0.25.1**
-* [[TeamMsgExtractor #132](https://github.com/TeamMsgExtractor/msg-extractor/issues/132)] Fixed an issue caused by unfinished code being left in the \_\_main\_\_ file.
-* Cleaned up the imports to only be what is needed.
-
-**v0.25.0**
-* Added new class `MSGFile`. The `Message` class now inherits from this. This class is the base for all MSG files, not just `Message`s. It somewhat recently came to our attention that MSG files are used for a variety of things, including the storage of contacts, leading us to the next part of the changelog.
-* [[TeamMsgExtractor #110](https://github.com/TeamMsgExtractor/msg-extractor/issues/110)] Added new class `Contact` for extracting the data from MSG files storing contacts.
-* Added new function `openMsg` to the module to be used to open MSG files in which it is not certain what type of MSG is being opened.
-* Modified the `Attachment` class to use the `openMsg` function to open embedded MSG files.
-* Added option `delayAttachments` to the `Message` class that will stop it from initializing attachments until the user is ready. This allows users to open `Message`s that have unimplemented attachment types without having to worry about the exception stopping them. This is also an option in the new `openMsg` function.
-
-**v0.24.4**
-* Added new property `Message.isRead` to show whether the email has been marked as read.
-* Renamed `Message.header_dict` to `Message.headerDict` to better match naming conventions.
-* Renamed `Message.message_id` to `Message.messageId` to better match naming conventions.
-
-**v0.24.3**
-* Added new close function to the `Message` class to ensure that all embedded `Message` instances get closed as well. Not having this was causing issues with trying to modify the msg file after the user thought that it had been closed.
-
-**v0.24.2**
-* Fixed bug that somehow escaped detection that caused certain properties to not work.
-* Fixed bug with embedded msg files introduced in v0.24.0
-
-**v0.24.0**
-* [[TeamMsgExtractor #107](https://github.com/TeamMsgExtractor/msg-extractor/issues/107)] Rewrote the `Messsage.save` function to fix many errors arising from it and to extend its functionality.
-* Added new function `isEmptyString` to check if a string passed to it is `None` or is empty.
-
-**v0.23.4**
-* [[TeamMsgExtractor #112](https://github.com/TeamMsgExtractor/msg-extractor/issues/112)] Changed method used to get the message from an exception to make it compatible with Python 2 and 3.
-* [[TheElementalOfDestruction #23](https://github.com/TheElementalOfDestruction/msg-extractor/issues/23)] General cleanup and all around improvements of the code.
-
-**v0.23.3**
-* Fixed issues in readme.
-* [[TheElementalOfDestruction #22](https://github.com/TheElementalOfDestruction/msg-extractor/issues/22)] Updated `dev_classes.Message` to better match the current `Message` class.
-* Fixed bad links in changelog.
-* [[TeamMsgExtractor #95](https://github.com/TeamMsgExtractor/msg-extractor/issues/95)] Added fallback encoding as well as manual encoding change to `dev_classes.Message`.
-
-**v0.23.1**
-* Fixed issue with embedded msg files caused by the changes in v0.23.0.
-
-**v0.23.0**
-* [[TeamMsgExtractor #75](https://github.com/TeamMsgExtractor/msg-extractor/issues/75)] & [[TheElementalOfDestruction #19](https://github.com/TheElementalOfDestruction/msg-extractor/issues/19)] Completely rewrote the function `Message._getStringStream`. This was done for two reasons. The first was to make it actually work with msg files that have their strings encoded in a non-Unicode encoding. The second reason was to make it so that it better reflected msg specification which says that ALL strings in a file will be either Unicode or non-Unicode, but not both. Because of the second part, the `prefer` option has been removed.
-* As part of fixing the two issues in the previous change, we have added two new properties:
-    1. a boolean `Message.areStringsUnicode` which tells if the strings are Unicode encoded.
-    2. A string `Message.stringEncoding` which tells what the encoding is. This is used by the `Message._getStringStream` to determine how to decode the data into a string.
-
-**v0.22.1**
-* [[TeamMsgExtractor #69](https://github.com/TeamMsgExtractor/msg-extractor/issues/69)] Fixed date format not being up to standard.
-* Fixed a minor spelling error in the code.
-
-**v0.22.0**
-* [[TheElementalOfDestruction #18](https://github.com/TheElementalOfDestruction/msg-extractor/issues/18)] Added `--validate` option.
-* [[TheElementalOfDestruction #16](https://github.com/TheElementalOfDestruction/msg-extractor/issues/16)] Moved all dev code into its own scripts. Use `--dev` to use from the command line.
-* [[TeamMsgExtractor #67](https://github.com/TeamMsgExtractor/msg-extractor/issues/67)] Added compatibility module to enforce Unicode os functions.
-* Added new function to `Message` class: `Message.sExists`. This function checks if a string stream exists. It's input should be formatted identically to that of `Message._getStringStream`.
-* Added new function to `Message` class: `Message.fix_path`. This function will add the proper prefix to the path (if the `prefix` parameter is true) and adjust the path to be a string rather than a list or tuple.
-* Added new function to `utils.py`: `get_full_class_name`. This function returns a string containing the module name and the class name of any instance of any class. It is returned in the format of `{module}.{class}`.
-* Added a sort of alias of `Message._getStream`, `Message._getStringStream`, `Message.Exists`, and `Message.sExists` to `Attachment` and `Recipient`. These functions run inside the associated attachment directory or recipient directory, respectively.
-* Added a fix to an issue introduced in an earlier version caused by accidentally deleting a letter in the code.
-
-**v0.21.0**
-* [[TheElementalOfDestruction #12](https://github.com/TheElementalOfDestruction/msg-extractor/issues/12)] Changed debug code to use logging module.
-* [[TheElementalOfDestruction #17](https://github.com/TheElementalOfDestruction/msg-extractor/issues/17)] Fixed Attachment class using wrong properties file location in embedded msg files.
-* [[TheElementalOfDestruction #11](https://github.com/TheElementalOfDestruction/msg-extractor/issues/11)] Improved handling of command line arguments using argparse module.
-* [[TheElementalOfDestruction #16](https://github.com/TheElementalOfDestruction/msg-extractor/issues/16)] Started work on moving developer code into its own script.
-* [[TeamMsgExtractor #63](https://github.com/TeamMsgExtractor/msg-extractor/issues/63)] Fixed JSON saving not applying to embedded msg files.
-* [[TeamMsgExtractor #55](https://github.com/TeamMsgExtractor/msg-extractor/issues/55)] Added fix for recipient sometimes missing email address.
-* [[TeamMsgExtractor #65](https://github.com/TeamMsgExtractor/msg-extractor/issues/65)] Added fix for special characters in recipient names.
-* Module now raises a custom exception (instead of just `IOError`) if the input is not a valid OLE file.
-* Added `header_dict` property to the `Message` class.
-* General minor bug fixes.
-* Fixed a section in the `Recipient` class that I have no idea why I did it that way. If errors start randomly occurring with it, this fix is why.
-
-**v0.20.8**
-* Fixed a tab issue and parameter type in `message.py`.
-
-
-**v0.20.7**
-
-* Separated classes into their own files to make things more manageable.
-* Placed `__doc__` back inside of `__init__.py`.
-* Rewrote the `Prop` class to be two different classes that extend from a base class.
-* Made decent progress on completing the `parse_type` function of the `FixedLengthProp` class (formerly a function of the `Prop` class).
-* Improved exception handling code throughout most of the module.
-* Updated the `.gitignore`.
-* Updated README.
-* Added `# DEBUG` comments before debugging lines to make them easier to find in the future.
-* Added function `create_prop` in `prop.py` which should be used for creating what used to be an instance of the `Prop` class.
-* Added more constants to reflect some of the changes made.
-* Fixed a major bug that was causing the header to generate after things like "to" and "cc" which would force those fields to not use the header.
-* Fixed the debug variable.
-* Fixed many small bugs in many of the classes.
-* [[TheElementalOfDestruction #13](https://github.com/TheElementalOfDestruction/msg-extractor/issues/13)] Various loose ends to enhance the workflow in the repo.
+**v0.41.0**
+* [[TeamMsgExtractor #357](https://github.com/TeamMsgExtractor/msg-extractor/issues/357)] Fixed an issue where the properties stream being absent would raise an error message that was not clear.
+* [[TeamMsgExtractor #357](https://github.com/TeamMsgExtractor/msg-extractor/issues/357)] Added a way to suppress `StandardViolationError` for poorly created files. This may cause issues you might not expect since this exception is meant to stop the processing for a reason.
+* [[TeamMsgExtractor #223](https://github.com/TeamMsgExtractor/msg-extractor/issues/223)] Finally got around to dealing with signed attachments that are embedded MSG files. `SignedAttachment.data` now returns either `bytes` or `MSGFile`. `SignedAttachment` also now has a `asBytes` property that will return the bytes that created the signed attachment, regardless of if it is an MSG or not, making it unnecessary to call `MSGFile.exportBytes` to get the bytes of the embedded MSG file, which can add a small delay to your code. As `Attachment` is a much more complex class, it does *not* (at least yet) have this property. Also unlike `Attachment`, `SignedAttachment` *will not* throw an exception if the data is an MSG file but is not supported. Instead, it will simply be logged as a exception, but the code will continue. If the data is successfully read as an embedded MSG file, the `AttachmentType` will be `AttachmentType.SIGNED_EMBEDDED`.
+* Deprecated `AttachErrorBehavior` in favor of the new `ErrorBehavior` enum which controls the error behavior for the various parts of the MSG file. Uses of the former will work until the next major version.
+* Deprecated the `attachmentErrorBehavior` parameter of `MSGFile` in favor of `errorBehavior`. Uses of the previous will work until the next major version.
+* Added `treePath` property to `SignedAttachment` to bring it more in line with `AttachmentBase`.
+* Fixed bug in rare logging message caused by incorrect type name.
+* Removed the `dev` and `dev_classes` submodules, as most of their features are possible using the base code. Additionally, the classes involved because significantly outdated over time.
+* Removed the `--dev` argument from the command line.
+* Changed the message for the standards violation error when an attachment has no specified attachment type and it could not be determined automatically. The error now specifies the path of the attachment that had an issue for easier debugging. Additionally, the log message for it simply not being present has also been changed to show this information.
+* Added a dev level log that will output the entire properties mapping if the attachment type is not set. Dev level is 5.
+* Fixed a critical error in `Properties` that caused the `__contains__` method to *always* be `False`. This occurred because it was missing a `return` statement. Fortunately, it looks like only one part of the module was affected due to other parts using a properly written function.
+* Removed some debug prints that slipped through.
+* Changed some parts to use `in` for checking that a property exists as opposed to `has_key`. The function was there to act more like Python 2.
+* Deprecated `Properties.has_key`.
+* Removed the `validation` submodule and all related references. It was pretty outdated and has minimal usage at this point in time. It may come back at some later point.
+* Changed behavior of `MessageBase.save` so it doesn't save raw when an exception occurs. This behavior may have ended up creating unexpected output which is why it was removed. It was mainly there for debugging in the first place, but is no longer necessary.
+* Added `__contains__` function to `Named` class.
+* Fixed missing import in `message_base.py` that would only cause problems if something was wrong with the HTML.
+* Fixed a bad error message appearing when trying to add or use an entry in `OleWriter` using an empty path.
+* Changed the `InvalidFileFormatError` for a missing property stream to a `StandardViolationError`.
+* Changed the exception messages for a few exceptions to fix typos and clarify.
+* Fixed issues in `_rtf.tokenize_rtf` which would cause an exception to handle incorrectly and throw an unclear error.
+* Fixed various small bugs caused by typos.
+* Clean up unneeded imports.
+* Improved existing `__all__` entries and added some where they should be.
+* Removed default export of the `UnrecognizedMSGTypeError` exception in favor of exporting the exceptions module.
+* Removed default export of `properHex`.
+* Improved type checking in many places.
+* Fixed issues in `RecurrencePattern`.
+
+**v0.40.0**
+* [[TeamMsgExtractor #338](https://github.com/TeamMsgExtractor/msg-extractor/issues/338)] Added new code to handle injection of text into the RTF body. For many cases, this will be much more effective as it relies on ensuring that it is in the main group and past the header before injection. It is *not* currently the first choice as it doesn't have proper respect for encapsulated HTML, however it will replace some of the old methods entirely. Solving this issue was done through the use of a few functions and the internal `_rtf` module. This module in it's entirety is considered to be implementation details, and I give no guarantee that it will remain in it's current state even across patch versions. As such, it is not recommended to use it outside of the module.
+* Changed `MessageBase.rtfEncapInjectableHeader` and `MessageBase.rtfPlainInjectableHeader` from `str` to `bytes`. They always get encoded anyways, so I don't know why I had them returning as `str`.
+* Updated minimum Python version to 3.8 as 3.6 has reached end of support and 3.7 will reach end of support within the year.
+* Updated information in `README`.
+
+**v0.39.2**
+* Fixed issues with `AttachmentBase.name` that could cause it to generate wrong.
+* Added convenience function `MSGFile.exportBytes` which returns the exported version from `MSGFile.export` as bytes instead of writing it to a file or file-like object.
+
+**v0.39.1**
+* [[TeamMsgExtractor #333](https://github.com/TeamMsgExtractor/msg-extractor/issues/333)] Fixed typo in a warning.
+* [[TeamMsgExtractor #334](https://github.com/TeamMsgExtractor/msg-extractor/issues/334)] Removed `__del__` method from `MSGFile`. It was there for cleanup, but wasn't planned well enough to stop it from causing issues. It may be reintroduced in the future if I can manage to remove the issues.
+* [[TeamMsgExtractor #335](https://github.com/TeamMsgExtractor/msg-extractor/issues/335)] Fixed some parts of `extract_msg.utils.getCommandArgs` having invalid logic after a previous (rather old) update that caused exceptions when using certain options.
+* Added new property `treePath` to `AttachmentBase` and `MSGFile` (which adds it to nearly every class). This property is the path to the current instance, represented as a tuple of instances that would be used to get to the current instance.
+* Added sphinx documentation.
+* Fixed an issue in `OleWriter` that would produce corrupted OLE files if the DIFAT needed more than the header.
+
+**v0.39.0**
+* [[TeamMsgExtractor #318](https://github.com/TeamMsgExtractor/msg-extractor/issues/318)] Added code to handle a standards violation (from what I can tell, anyways) caused by the attachment not having an `AttachMethod` property. The code will log a warning, attempt to detect the method, and throw a `StandardViolationError` if it fails.
+* [[TeamMsgExtractor #320](https://github.com/TeamMsgExtractor/msg-extractor/issues/320)] Changed the way string named properties are handled to allow for the string stream to have some errors and still be parsed. Warnings about these errors will be logged.
+* [[TeamMsgExtractor #324](https://github.com/TeamMsgExtractor/msg-extractor/issues/324)] Fixed an issues with contact saving when a list property returns `None`.
+* [[TeamMsgExtractor #326](https://github.com/TeamMsgExtractor/msg-extractor/issues/326)] Fixed a bug that could cause some files to error when exporting.
+* Fixed an issue where creation and modification times were not being copied to the new OLE file created by `OleWriter`.
+* Fixed up a few docstrings.
+* Fixed a few issues in `MSGFile` regarding the `filename` keyword argument.
+* Added new argument `rootPath` to `OleWriter.fromOleFile` for saving a specific directory from an OLE file instead of just copying the entire file. That directory will become the root of the new one.
+* Adjusted code for `OleWriter` to generate certain values *only* at save time to make them more dynamic. This allows for existing streams to be properly edited (although has issues with allowing storages to be edited).
+* Added new function `OleWriter.deleteEntry` to remove an entry that was already added. If the entry is a storage, all children will be removed too.
+* Added new function `OleWriter.editEntry` to edit an entry that was already added.
+* Added new function `OleWriter.addEntry` to add a new entry to the writer without an `OleFileIO` instance. Properties of the entry are instead set using the same keyword arguments as described in `OleWriter.editEntry`.
+* Changed `_DirectoryEntry` to `DirectoryEntry` to make the more finalized version public. Access to the originals that the `OleWriter` class creates should never happen, instead copies should be returned to ensure the behavior is as expected.
+* Added new function `OleWriter.getEntry` which returns a copy of the `DirectoryEntry` instance for that stream or storage in the writer. Use this function to see the current internal state of an entry.
+* Added new function `OleWriter.renameEntry` which allows the user to rename a stream or storage (in place). This only changes it's direct name and not it's location in the new OLE file.
+* Added new function `OleWriter.walk` which is similar to `os.walk` but for walking the structure of the new OLE file.
+* Added new function `OleWriter.listItems` which is functionally equivalent to `olefile.OleFileIO.listdir` which returns a list of paths to every item. Optionally a user can get the paths just for streams, just for storages, or both. Requesting neither will simply return an empty list. Default is to just return streams.
+* Added a small amount of path validation to `inputToMsgPath` which is used in a lot of places where user input for a path is accepted. It ensures illegal characters don't exist and that the path segments (each name for a storage or stream) are less than 32 characters. This will be most helpful for `OleWriter`.
+* Added *many* internal helper functions to `OleWriter` to make extensions easier and consolidate common code. Many of these involve direct access to internal data which is why they are private.
+
+**v0.38.4**
+* Fix line in `OleWriter` that was causing exporting to fail.
+* Fixed some issues with the `README`.
+
+**v0.38.3**
+* Fixed issues in HTML generation that caused line breaks to be omitted from large sections of the text.
+* Fixed issues with requirements file.
+
+**v0.38.2**
+* Fixed new `NameError` accidentally introduced in the previous version.
+
+**v0.38.1**
+* Added a `__del__` method to `MSGFile` to ensure a bit of proper cleanup should all references to an `MSGFile` instance be removed before the file is closed. `OleFileIO` doesn't appear to have one, so it's up to us to ensure it is properly closed. Note that the `del` keyword does not guarantee the immediate deletion of the object, and you should take care to close the file yourself. If this is not possible, importing the `gc` module and using it's `collect` method will free the files if your code has no references to them.
+* Fixed an import issue with signed messages.
+
+**v0.38.0**
+* [[TeamMsgExtractor #117](https://github.com/TeamMsgExtractor/msg-extractor/issues/117)] Added class `OleWriter` to allow the writing of OLE files, which allows for embedded MSG files to be extracted.
+* Added function `MSGFile.export` which copies all streams and storages from an MSG file into a new file. This can "clone" an MSG file or be used for extracting an MSG file that is embedded inside of another.
+* Added hidden function to `MSGFile` for getting the `OleDirectoryEntry` for a storage or stream. This is mainly for use by the `OleWriter` class.
+* Added option `extractEmbedded` to `Attachment.save` (`--extract-embedded` on the command line) which causes embedded MSG files to be extracted instead of running their save methods.
+* Fixed minor issues with `utils.inputToMsgPath` (renamed from `utils.inputToMsgPath`).
+* Renamed `utils.msgpathToString` to `utils.msgPathToString`.
+* Made some of the module requirements a little more strict to better version control. I'll be trying to make periodic checks for updates to the dependency packages and make sure that new versions are compatible before changing the allowed versions, while also trying to keep the requirements a bit flexible.
+
+**v0.37.1**
+* Added option to save function (including `MSGFile.saveAttachments`) to skip any attachments marked as hidden. This can also be done from the command line with `--skip-hidden`.
+* Fixed an issue that could cause an `MSGFile` to be included in the attachment names instead of just strings.
+* Fixed up several comments.
+* Fixed bug that would cause spaces at the end of the subject or filename to break the module.
+
+**v0.37.0**
+* [[TeamMsgExtractor #303](https://github.com/TeamMsgExtractor/msg-extractor/issues/303)] Renamed internal variable that wasn't changed when the other instances or it were renamed.
+* [[TeamMsgExtractor #302](https://github.com/TeamMsgExtractor/msg-extractor/issues/302)] Fixed properties missing (a fatal MSG error) raising an unclear exception. It now uses `InvalidFileFormatError`.
+* Updated `README` to contain documentation on command line option added in previous version.
+* Removed `MSGFile.mainProperties` after deprecating it in v0.36.0.
+* Added new `Properties` `Intelligence` type: `ERROR`. This type is used when a properties instance is created but has something wrong with it that is not necessarily fatal. Currently the only thing that will cause it is the properties stream being 0 bytes.
+
+**v0.36.5**
+* Documented and exposed to the command line the ability to save the headers to it's own file when saving the msg file. Thanks to martin-mueller-cemas on GitHub for fixing this (and telling me I can switch the branch a pull request points to). I don't know when I added the code to allow the user to do it, but somehow it was never documented and never exposed to the command line.
+
+**v0.36.4**
+* [[TeamMsgExtractor #291](https://github.com/TeamMsgExtractor/msg-extractor/issues/291)] Fixed typo in `MSGFile.saveRaw` that may have existed for a significant amount of time. It was using the wrong function (same name, but with different capitalization) but was hidden until `MSGFile` stopped being derived from `OleFileIO`.
+* Added logging code to `MessageBase.getSavePdfBody` to log the list that is going to be used to run `wkhtmltopdf`. This is mainly for debugging purposes, to allow users to potentially see why their arguments may be failing.
+* Updating funding information on GitHub and the `README` with more ways to support the module's development.
+* Fixed one of the exceptions in `MessageBase.getSavePdfBody` not using an fstring which caused it to omit information.
+* Changed the way `wkhtmltopdf` is called to patch a possible security vulnerability. This also seems to have fixed [[TeamMsgExtractor #291](https://github.com/TeamMsgExtractor/msg-extractor/issues/291)].
+
+**v0.36.3**
+* Added an option to skip the body if it could not be found, rather than throwing an error. This will cause no file to be made for it in the event no valid body exists. For the save functions, this option is `skipBodyNotFound` and from the command line the option is `--skip-body-not-found`.
+* Fixed a bug that caused contacts to save the business phone with two colons instead of 1.
+
+**v0.36.2**
+* [[TeamMsgExtractor #286](https://github.com/TeamMsgExtractor/msg-extractor/issues/286)] Fix missing import.
+
+**v0.36.1**
+* [[TeamMsgExtractor #283](https://github.com/TeamMsgExtractor/msg-extractor/issues/283)] Added file for typing recognition.
+* Added new option to allow messages with `NotImplementedError` attachments to at least save everything not related to them. From the command line this would be `--skip-not-implemented` or `--skip-ni`. From the save function, this would be the `skipNotImplemented` option.
+
+**v0.36.0**
+* Improved type hints to tell when a function may not return anything.
+* Added support for the `reportTag` property to `MessageBase`. I noticed this was one of the properties for `IPM.Outlook.Recall` so I decided to implement it. I'll work on ensuring all of `[MS-OXOMSG]` and `[MS-OXCMSG]` are implemented at a later date, including splitting off `REPORT` into it's own class, because it is it's own class.
+* Fixed a few minor issues in some properties. Mostly some `bool` returning properties should have been returning False when they were not found instead of None. Ones that may return None are specifically typed as optional in the source code. Unfortunately using the `help` command doesn't seem to show the return type for properties for me at least on Python 3.9 and below.
+* Fixed `Attachment.save` returning a `pathlib.Path` object instead of a `str` after the conversion to `pathlib`.
+* Added code to allow `pathlib` objects in `utils.openMsgBulk`. It uses `glob.glob` which *cannot* take a `pathlib` object.
+* Removed `PermanentEntryID` from `EntryID.autoCreate`. It shares a provider ID with `AddressBookEntryID`, and as such would never generate from it anyways. If you specifically need a `PermanentEntryID` you will have to instantiate it manually. Additionally, the entry has been removed from `enums.EntryIDType`.
+* Fixed the GUIDs for some of the EntryID structures being returned as bytes instead of a standard GUID string. This is considered a breaking change and is the reason for the full version increase.
+* Improved consistency of properties (the Python kind, not the MSG kind) so that properties for the raw data used to create an instance will all use the same name. Not all classes have this, but the ones that do will now all use `rawData` as the property name.
+* Fixed the properties header being read in a way that actually swapped the values in it.
+* Modified `MSGFile` to use the same name for Properties instances as all other classes. `MSGFile.mainProperties` will currently raise a `DeprecationWarning` instead of outright failing to help ease the transition. Use `MSGFile.props` instead.
+
+**v0.35.3**
+* [[TeamMsgExtractor #280](https://github.com/TeamMsgExtractor/msg-extractor/issues/280)] Fix typing issue in `message_base.py`.
+
+**v0.35.2**
+* Made a change to the argument handling for `--no-folders`. Since it requires `--attachmentsOnly` to work, I simply made it error when it's not given to avoid confusion.
+* Updated README.
+* Added `-v` to be used instead of `--verbose`. This allows you to do `-vvv` for verbosity level 3.
+
+**v0.35.1**
+* Fixed a few property conflicts that I missed in the last release (forgot to run the helper script before releasing).
+
+**v0.35.0**
+* [[TeamMsgExtractor #206](https://github.com/TeamMsgExtractor/msg-extractor/issues/206)] Implemented full support for Post objects, including the ability to save them.
+* [[TeamMsgExtractor #212](https://github.com/TeamMsgExtractor/msg-extractor/issues/212)] Implemented full support for Task objects, including the ability to save them. This also includes TaskRequest objects.
+* [[TeamMsgExtractor #110](https://github.com/TeamMsgExtractor/msg-extractor/issues/110)] Implemented full support for Contact objects, including the ability to save them.
+* [[TeamMsgExtractor #143](https://github.com/TeamMsgExtractor/msg-extractor/issues/143)] Rewrote the system used for `Appointment` objects to include all of the objects specified in [MS-OXOCAL]. Name changed to `AppointmentMeeting`. Completed support for Appointment objects, including the ability to save them.
+* [[TeamMsgExtractor #243](https://github.com/TeamMsgExtractor/msg-extractor/issues/256)] Added optional dependency `mimetype-magic` (installable using the `mime` extra) which helps to identify attachments that do not give a mime-type.
+* [[TeamMsgExtractor #274](https://github.com/TeamMsgExtractor/msg-extractor/issues/274)] Apparently the properties stream can have random garbage at the end of it (outlook generate the file that showed this) so code was added to ensure it wouldn't break everything.
+* [[TeamMsgExtractor #274](https://github.com/TeamMsgExtractor/msg-extractor/issues/274)] Made sure that the save function would report if it failed to find or generate a valid body. Specifically, if you were just trying to use the plain text body but it didn't exist (the stream didn't exist, not that the stream was empty) it would silently pass, which was bad behavior. Additionally, `allowFallback` will change the message to specify that current options were not usable for getting a valid body.
+* [[TeamMsgExtractor #207](https://github.com/TeamMsgExtractor/msg-extractor/issues/207)] Changed behavior for max date. Apparently it looks like it is supposed to be August 31, 4500 at 11:59 PM. However, in case this needs to change, we have created a constant called `extract_msg.constants.NULL_DATE` to represent this that you can use in your code to not have to worry about changing your code if we check it.
+* Moved a few more minor constants to `enums`.
+* Added support for many internal data structures, specifically Entry ID structures.
+* Refactored classes from `extract_msg.data` to submodule `extract_msg.structures`.
+* Added `python_requires` to setup.py as I noticed that it was missing.
+* Due to new saving requirements, adjusted the way header injection worked all around. Functions are now built-in to `MessageBase`. `getSaveXBody` functions have also been moved down to be defined in `MessageBase`. If the extension class needs to specify custom behaviors for creating the save bodies, these functions will need to be overridden.
+    * For saving, `MessageBase` (being the lowest one to currently contain bodies) has a few new properties. These properties represent the injection strings that will be injected into the bodies for the header, with an additional property to specify what properties map to what part of the format string. See `MessageBase.headerFormatProperties` for more information and an example of how to implement this in your own class.
+    * Injection strings in constants have been removed in favor of dynamic generation, which only creates what is needed. No you will no longer see an empty Bcc field in your messages when you save them.
+    * Plain text bodies now also use this injection, making it easy to change the header in all bodies by overwriting a single property that tells the program what data to put where.
+* Fixed issue in encapsulated RTF header that caused the "To" field to not be present. I had to write them by hand, so it was bound to happen. They are now dynamically generated by each instance, so these fields should always appear.
+* All save code has been moved down from `Message` into `MessageBase` for convenience. `Message` exists now for specific checking and for future specializations. This also means that anything that is a `MessageBase` now has the entire framework for saving built-in, with easy way to change details.
+* Fixed bad property in `Contact`.
+* Created save function for `Contact`. Saving, though it exists, is rather minimal and is limited to plain text and HTML.
+* Significantly extended the `Contact` class's properties.
+* Adjusted the naming of a few `Contact` properties to better match the microsoft names.
+    * `firstName` -> `givenName`.
+    * `lastName` -> `surname`.
+    * `businessPhone` -> `businessTelephoneNumber`
+    * Etc.
+* Changed existing fax properties to give a dictionary of the properties they actually contain rather than just the number. This makes them behave like the newly added email properties.
+* Fixed issues with `Task` properties being incorrect.
+* Added implementation for PtypErrorCode.
+* Changed behavior of `Properties.date` to *only* return the submit time. This is to ensure messages that were never sent do not have a sent date.
+* Changed behavior of `MessageBase.date` to only return a send date if the message has been sent. For messages with no flags, it assumes `True`.
+* Generally brought saving behavior closer to the way outlook handles it.
+* Made `SignedAttachment` and `BaseAttachment` more similar by adding properties to each that are shared. `BaseAttachment` now have a `name` property and `SignedAttachment` now have `longFilename` and `shortFilename`.
+* Fixed issue in HTML saving that would cause some characters to be dropped when rendering them due to how the header injection worked.
+* Removed `__init__` methods from MSG classes that don't change it. This ensures notes are easily passed down.
+* Correction to last comment, *one* max date was supposed to be at that date, but another max date is at a different date of the same year.
+* Changed the way that `PtypTime` is handled, making it a single function in `utils`.
+* Upgraded dependencies to newer versions (some really need to be newer, like `tzlocal`, for best results). Included dependencies are `beautifulsoup4` and `tzlocal`.
+* Fixed an issue where zip file naming conflicts *always* failed in zip files for attachments. Both the embedded msg and the plain attachments would fail.
+* *Actually* fixed the issue that would break the main loop.
+* MSGFile no longer inherits directly from `OleFileIO`. While I would prefer to do that, the `__init__` method for it is rather expensive, and allowing embedded msg files to directly share each other's instances of `OleFileIO` would improve speed immensely.
+* Fixed attachments not being preemptively loaded when `delayAttachments` was `False`.
+* `utils.openMsg` now delays attachments while loading the file to get the class type. This means all time for attachments is cut in half as they are only ever loaded once. It also means that files that won't open due to attachments will error a little later, but this shouldn't be a problem.
+* Changed named properties `Guid` back to constants. This has to do with the next entry.
+* Fixed a major issue in named properties. Apparently the ID is not enough and you *must* have the GUID as well, as multiple properties can share the exact same ID.
+* Added option `--no-folders` to the command line allowing you to save all attachments from a set of MSG files into a single folder.
+* Added option `--skip-embedded` to the command line to skip saving embedded MSG files.
+* Added option `skipEmbedded` to `Attachment.save` (and all other related save methods that call it) to skip saving an embedded MSG file.
+* Changed `__main__` so that it opens the zip file there instead of relying on everything it calls to do it again and again.
+* Changed the behavior of `--verbose` to allow it to be stacked for more verbosity. Specifying it once turns on warnings, twice for info, and three times for debug. Not specifying it only turns on error logging.
+
+**v0.34.3**
+* Fixed issue that may have caused other olefile types to raise the wrong type of error when passed to `openMsg`.
+* Fixed issues with changelog format.
+* Fixed issue that caused progress to sometimes break the main loop when a file had Unicode characters if the console it was writing to didn't support them.
+* Added option to `MessageBase` (and subsequently `openMsg`) that allows you to override the code being used for deencapsulation. See `MessageBase.__init__` for details on how to create an override function.
+* Added additional msg class types that I found to the list of known class types.
+
+**v0.34.2**
+* [[TeamMsgExtractor #267](https://github.com/TeamMsgExtractor/msg-extractor/issues/267)] Fixed issue that caused signed messages that were .eml files to have their data field *not* be a bytes instance. This field will now *always* be bytes. If a problem making it bytes occurs, an exception will be raised to give you brief details.
+* Added function `utils.unwrapMultipart` that takes a multipart message and acquires a plain text body, an HTML body, and a list of attachments from it. These attachments are returned as `dict`s that can easily be converted to `SignedAttachment`s. It replaces the logic `mailbits` was being used for, and as such `mailbits` is no longer required. The module may be reintroduced in the future.
+* Added new property `emailMessage` to `SignedAttachment`, which returns the email `Message` instance used to get data for the attachment.
+
+**v0.34.1**
+* Added convenience function `utils.openMsgBulk` (imported to `extract_msg` namespace) for opening message paths with wildcards. Allows you to open several messages with one function, returning a list of the opened messages.
+* Added convenience function `utils.unwrapMsg` which recurses through an `MSGFile` and it's attachments, creating a series of linear structures stored in a dictionary. Useful for analyzing, saving, etc. all messages and attachments down through the structure without having to recurse yourself.
+* Fixed an issue that would cause signed attachments to not properly generate.
+
+**v0.34.0**
+* [[TeamMsgExtractor #102](https://github.com/TeamMsgExtractor/msg-extractor/issues/102)] Added the option to directly save body to pdf. This requires that you either have wkhtmltopdf on your path or that you provide a path directly to it in order to work. Simply pass `pdf = True` to save to turn it on. More details in the doc for the save function. You can also do this from the command line using the `--pdf` option, incompatible with other body types.
+* Added `--glob` option for allowing you to provide an msg path that will evaluate wildcards.
+* Removed per-file output names as they weren't actually functional and currently add too much complexity. If anyone knows a way to handle it directly with `argparse` let me know.
+* Added `chardet` as a requirement to help work around an error in `RTFDE`.
+* Looking into some of the unsupported encodings revealed at least one to be supported, but was missed due to the name not being registered as an alias.
+* Fixed a bug that prevented an HTML body from the plain text body when it couldn't be generated any other way. This happened when the RTF body existed and the plain text body existed, but the RTF body was not encapsulated HTML.
+* Due to several of the issues with RTFDE preventing saving due to exceptions, the option `ignoreRtfDeErrors` has been added to the `MessageBase` class and `openMsg`. It can also be enabled from the command line with `--ignore-rtfde`. This option will make it so all exceptions will be silenced from the module.
+
+**v0.33.0**
+* [[TeamMsgExtractor #212](https://github.com/TeamMsgExtractor/msg-extractor/issues/212)] Added support for Task objects.
+* Added additional parameter `overrideClass` to all `_ensureSetX` type functions. This parameter is a class to initialize using the data, if provided. The data will be provided as the first argument to the `__init__` function of the class *if* the data is not `None`. If the data is done, the value set and returned from `_ensureSetX` will be `None`. This can be overridden using the second added parameter, which defaults to this behavior. Simply set `preserveNone` to `False` to force the data to be passed to the class. Keep in mind that this means the class will receive `None` as it's first parameter.
+* Updated `Named` class to make it more like the dictionary it is build on top of. Specifically, added `keys`, `values`, and `items` as functions.
+* Fixed issue in `Named` where old code wasn't deleted, causing some named properties to be completely omitted.
+* Improved efficiency of `Named` by making it so `get` no longer copied the entire dictionary repeatedly while looking for the property.
+* Fixed typo in `Attachment` that caused embedded msg files to still regenerate the `Named` instance even though they should have been using the parent's.
+* Updated fields in `MSGFile` to use enums.
+* Added additional properties to `MSGFile`.
+* Significant cleanup.
+
+**v0.32.0**
+* [[TeamMsgExtractor #217](https://github.com/TeamMsgExtractor/msg-extractor/issues/217)] Redesigned named properties to be much more efficient. All in all, load times for MSG files are significantly improved all around.
+    * Named properties load dynamically.
+    * Named properties use a single shared instance for embedded msg files to contain all of the entries, and tiny individual instances for actually accessing based on what is accessing.
+    * `Named` has been updated so it's methods are more standardized.
+    * `Named` is no longer usable to directly access property values. Instead,
+    access to them is done through `NamedProperties`.
+    * `_registerNamedProperty` has been removed due to no longer being part of the named properties framework.
+* Actually removed the exception I meant to remove in 0.31.0.
+* Changed `Attachment.type` to an enum instead of a string. This makes it easier to see all of the possible values.
+* Added option to allow attachment saving to be skipped when calling `Message.save`.
+* Added `type` property to all attachment types. `AttachmentBase` uses `AttachmentType.UNKNOWN`, `BrokenAttachment` uses `AttachmentType.BROKEN`, and `UnsupportedAttachment` uses `AttachmentType.UNSUPPORTED`.
+
+**v0.31.1**
+* Updated signed attachment mimetype property from `mime` to `mimetype` to match with the regular attachment property.
+
+**v0.31.0**
+* [[TeamMsgExtractor #223](https://github.com/TeamMsgExtractor/msg-extractor/issues/223)] First implementation of support for signed messages.
+* [[TeamMsgExtractor #256](https://github.com/TeamMsgExtractor/msg-extractor/issues/256)] Extended the properties of the attachment class to allow for access to more data.
+* Fixed some issues with the contact class (some of the code was left unfinished).
+* Converted many arguments for msg files to keyword arguments (`**kwargs`). This is a breaking change if your code provides anything except the path to the msg file. This will, however, make it easier to add arguments without the function signature being polluted with numerous arguments.
+* Updated exception blocks to ensure they would only catch exceptions that are instances of Exception or a child of Exception. A few were missing this check and so might have caught unwanted exceptions.
+* Shifted some minor parts down towards the `AttachmentBase` class where possible to allow more usability with broken and unsupported attachments. Nothing about these properties required the attachment to be fully processed, which is why they were moved down. From the perspective of using the `Attachment` class nothing has changed. The following properties have been moved: `attachmentEncoding`, `additionalInformation`, `cid`/`contentId`, `longFilename`, `renderingPosition`, and `shortFilename`.
+* Added link to readme for supporting development.
+* Finally found the behavior to use for missing encoding. As such, `MissingEncodingError` is being removed from the module entirely, as it is no longer a thing.
+* Moved many constant sets to enums. This makes things a lot more organized.
+
+**v0.30.14**
+* Fixed major bug in `MSGFile.listDir` that would cause it to give the wrong data due to caching. I forgot to have it cache a different result for each set of options, so it would always give the same result regardless of options after the first access.
+* Minor updates to `setup.py`.
+* Fixed URLs in `README`.
+
+**v0.30.13**
+* [[TeamMsgExtractor #257](https://github.com/TeamMsgExtractor/msg-extractor/issues/257)] Fixed missing documentation for `customPath` keyword argument to `Attachment.save`.
+
+**v0.30.12**
+* [[TeamMsgExtractor #253](https://github.com/TeamMsgExtractor/msg-extractor/issues/253)] Fixed various docstring issues.
+
+**v0.30.11**
+* [[TeamMsgExtractor #249](https://github.com/TeamMsgExtractor/msg-extractor/issues/249)] Fixed an error with opening the body causing the file to throw an uncaught exception in the `__init__` function of `MessageBase`. The error may still come up later, but you will still have general access to the instance.
+* Fixed an issue with part of the command line documentation.
+
+**v0.30.10**
+* [[TeamMsgExtractor #249](https://github.com/TeamMsgExtractor/msg-extractor/issues/249)] Fixed exception catching not properly accessing the exception (forgot to go through one of the submodules to access exception).
+* Updated docstring for `MessageBase.deencapsulatedRtf`.
+
+**v0.30.9**
+* Fixed the behavior of `Properties.get` so it actually behaves like a dict (that was the intent of it, but I did it the wrong way for some reason).
+* Fixed a type that caused an exception when no HTML body could be found nor generated.
+
+**v0.30.8**
+* Update `imapclient` requirement to `>=2.1.0` instead of `==2.1.0`. Currently there are no changes that would prevent current future versions from working.
+
+**v0.30.7**
+* [[TeamMsgExtractor #239](https://github.com/TeamMsgExtractor/msg-extractor/issues/239)] Fixed msg.py not having `import pathlib`.
+* After going through the details of the example MSG files provided with the module, specifically unicode.msg, I now am glad I decided to put in some fail-safes in the HTML body processing. One of them does not have an `<html>`, `<head>`, nor `<body>` tag, and so would have had an error. This will actually prevent the header from injecting properly as well, so a bit of validation before was made necessary to ensure the HTML saving would still work.
+* Added new exception `BadHtmlError`.
+* Added new function `utils.validateHtml`.
+* Updated README credits.
+* Changed header logic to generate manually if the header data has been stripped (filled with null bytes) and not just if the stream does not exist.
+
+**v0.30.6**
+* Small adjustments to internal code to make it a bit better.
+* Added `Message.getSaveBody`, `Message.getSaveHtmlBody`, and `Message.getSaveRtfBody`. These three functions generate their respective bodies that will be used when saving the file, allowing you to retrieve the final products without having to write them to the disk first. All arguments that are passed to `Message.save` that would influence the respective bodies are passed to their respective functions.
+* I thought I added the documentation for `attachmentsOnly` to `Message.save` but apparently it was missing. Not sure what happened there but I made sure it was added this time.
+* Added new option to `Message.save` called `charset`. This is used in the preparation of the HTML body when using `preparedHtml`. This is also usable with `--charset CHARSET` from the command line.
+
+**v0.30.5**
+* [[TeamMsgExtractor #225](https://github.com/TeamMsgExtractor/msg-extractor/issues/225)] Added the ability to generate the HTML body from the RTF body if it is encapsulated HTML. If there is no RTF body, then it will do a very basic generation from the plain text body. This process is automatically performed if the HTML body is missing.
+* Added the ability for the plain text body to sometimes generate from the RTF body if the plain text body does not exist.
+* Added documentation to `Message.save` for the `attachmentsOnly` option.
+
+**v0.30.4**
+* [[TeamMsgExtractor #233](https://github.com/TeamMsgExtractor/msg-extractor/issues/233)] Added option to `Message.save` to only save the attachments (`attachmentsOnly`). This can also be used from the command line with the option `--attachments-only`.
+* Corrected error string for incompatible options in `Message.save`.
+* Fixed if blocks being nested weirdly in `Message.save` instead of being chained with `elif`. Probably an artifact left from adding support for HTML and RTF.
+
+**v0.30.3**
+* [[TeamMsgExtractor #232](https://github.com/TeamMsgExtractor/msg-extractor/issues/232)] Updated list of known MSG class types so the module would correctly give `UnsupportedMSGTypeError` instead of `UnrecognizedMSGTypeError`.
+
+**v0.30.2**
+* Fixed typo in `utils.knownMsgClass`.
+* Updated contributing guidelines and pull request template. Pull requests were updated to match the new structure of the module while the guidelines were updated for clarity.
+
+**v0.30.1**
+* [[TeamMsgExtractor #102](https://github.com/TeamMsgExtractor/msg-extractor/issues/102)] Added property `MessageBase.htmlBodyPrepared` which provides the HTML body that has been prepared for actual use or conversion to PDF. All attachments that can be injected into the body directly will be injected.
+* Corrected a mistake in the documentation of `Message.save`.
+* Fixed issue where the command line parser was not checking for raw in conjunction with other saving options.
+* Changed `utils.setupLogging` to use `pathlib`.
+* Improved reliability of the logic in `utils.setupLogging`.
+* Removed function `utils.getContFileDir`.
+* Cleaned up plain `Exception` being raised at the end of `utils.injectRtfHeader` if the injection failed. This now raises `RuntimeError`, an error that should be reported so the injection system can be improved.
+* Added parsing for PtypServerId to `utils.parseType`.
+* Added `FolderID`, `MessageID`, and `ServerID` to `data`.
+* Added zip output to the command line.
+* Added support for PtypMultipleFloatingTime to `utils.parseType`.
+* Improved documentation of many functions with the exceptions they may raise.
+* Changed the way zip files are handled so that files written to them actually have a modification date now.
+
+**v0.30.0**
+* Removed all support for Python 2. This caused a lot of things to be moved around and changed from indirect references to direct references, so it's possible something fell through the cracks. I'm doing my best to test it, but let me know if you have an issue.
+* Changed classes to now prefer `super()` over direct superclass initialization.
+* Removed explicit object subclassing (it's implicit in Python 3 so we don't need it anymore).
+* Converted most `.format`s into f strings.
+* Improved consistency of docstrings. It's not perfect, but it should at least be better.
+* Started the addition of type hints to functions and methods.
+* Updated `utils.bytesToGuid` to make it faster and more efficient.
+* Renamed `utils.msgEpoch` to `utils.filetimeToUtc` to be more descriptive.
+* Updated internal variable names to be more consistent.
+* Improvements to the way `__main__` works. This does not affect the output it will generate, only the efficiency and readability.
+
+**v0.29.3**
+* [[TeamMsgExtractor #226](https://github.com/TeamMsgExtractor/msg-extractor/issues/198)] Fix typo in command parsing that prevented the usage of `allowFallback`.
+* Fixed main still manually navigating to a new directory with os.chdir instead of using `customPath`.
+* Fixed issue in main where the `--html` option was being using for both html *and* rtf. This meant if you wanted rtf it would not have used it, and if you wanted html it would have thrown an error.
+* Fixed `--out-name` having no effect.
+* Fixed `--out` having no effect.
+
+**v0.29.2**
+* Fixed issue where the RTF injection was accidentally doing HTML escapes for non-encapsulated streams and *not* doing escapes for encapsulated streams.
+* Fixed name error in `Message.save` causing bad logic. For context, the internal variable `zip` was renamed to `_zip` to avoid a name conflict with the built-in function. Some instances of it were missed.
+
+**v0.29.1**
+* [[TeamMsgExtractor #198](https://github.com/TeamMsgExtractor/msg-extractor/issues/198)] Added a feature to save the header in it's own file (prefers the full raw header if it can find it, otherwise puts in a generated one) that was actually supposed to be in v0.29.0 but I forgot, lol.
+
+**v0.29.0**
+* [[TeamMsgExtractor #207](https://github.com/TeamMsgExtractor/msg-extractor/issues/207)] Made it so that unspecified dates are handled properly. For clarification, an unspecified date is a custom value in MSG files for dates that means that the date is unspecified. It is distinctly different from a property not existing, which will still return None. For unspecified dates, `datetime.datetime.max` is returned. While perhaps not the best solution, it will have to do for now.
+* Fixed an issue where `utils.parseType` was returning a string for the date when it makes more sense to return an actual datetime instance.
+* [[TeamMsgExtractor #165](https://github.com/TeamMsgExtractor/msg-extractor/issues/165)] [[TeamMsgExtractor #191](https://github.com/TeamMsgExtractor/msg-extractor/issues/191)] Completely redesigned all existing save functions. You can now properly save to custom locations under custom file names. This change may break existing code for several reasons. First, all arguments have been changed to keyword arguments. Second, a few keyword arguments have been renamed to better fit the naming conventions.
+* [[TeamMsgExtractor #200](https://github.com/TeamMsgExtractor/msg-extractor/issues/200)] Changed imports to use relative imports instead of hard imports where applicable.
+* Updated the save functions to no longer rely on the current working directory to save things. The module now does what it can to use hard pathing so that if you spontaneously change working directory it will not cause problems. This should also allow for saving to be threaded, if I am correct.
+* [[TeamMsgExtractor #197](https://github.com/TeamMsgExtractor/msg-extractor/issues/197)] Added new property `Message.defaultFolderName`. This property returns the default name to be used for a Message if none of the options change the name.
+* [[TeamMsgExtractor #201](https://github.com/TeamMsgExtractor/msg-extractor/issues/201)] Fixed an issue where if the class type was all caps it would not be recognized. According to the documentation the comparisons should have been case insensitive, but I must have misread it at some point.
+* [[TeamMsgExtractor #202](https://github.com/TeamMsgExtractor/msg-extractor/issues/202)] Module will now handle path lengths in a semi-intelligent way to determine how best to save the MSG files. Default path length max is 255.
+* [[TeamMsgExtractor #203](https://github.com/TeamMsgExtractor/msg-extractor/issues/203)] Fixed an issue where having multiple "." characters in your file name would cause the directories to be incorrectly named when using the `useFileName` (now `useMsgFilename`) argument in the save function.
+* [[TeamMsgExtractor #204](https://github.com/TeamMsgExtractor/msg-extractor/issues/204)] Fixed an issue where the failsafe name used by attachments wasn't being encoded before hand causing encoding errors.
+* MSG files with a type of simply `IPM` will now be returned as `MSGFile` by `openMsg`, as this specifies that no format has been specified.
+* [[TeamMsgExtractor #214](https://github.com/TeamMsgExtractor/msg-extractor/issues/214)] Attachments that error because the MSG class type wasn't recognized or isn't supported will now correctly be `UnsupportedAttachment` instead of `BrokenAttachment`.
+* Improved internal code in many functions to make them faster and more efficient.
+* `openMsg` will now tell you if a class type is simply unsupported rather than unrecognized. If it is found in the list, the function will raise `UnsupportedMSGTypeError`.
+* Added caching to `MSGFile.listDir`. I found that if you have larger files this single function might be taking up over half of the processing time because of how many times it is used in the module.
+* Fully implemented raw saving.
+* Extended the `Contact` class to have more properties.
+* Added new function `MSGFile._ensureSetTyped` which acts like the other ensure set functions but doesn't require you to know the type. Prefer to use other ensure set function when you know exactly what type it will be.
+* Changed `Message.saveRaw` to `MSGFile.saveRaw`.
+* Changed `MSGFile.saveRaw` to take a path and save the contents to a zip file.
+* Corrected the help doc to reflect the current repository (was still on mattgwwalker).
+* Fixed a bug that would cause an exception on trying to access the RTF body on a file that didn't have one. This is now correctly returning `None`.
+* The `raw` keyword of `Message.save` now actually works.
+* Added property `Attachment.randomFilename` which allows you to get the randomly generated name for attachments that don't have a usable one otherwise.
+* Added function `Attachment.regenerateRandomName` for creating a new random name if necessary.
+* Added function `Attachment.getFilename`. This function is used to get the name an attachment will be saved with given the specified arguments. Arguments are identical to `Attachment.save`.
+* Changed pull requests to reflect new style.
+* Added additional properties for defined MSG file fields.
+* Added zip file support for the `Attachment.save` and `Message.save`. Simply pass a path for the `zip` keyword argument and it will create a new `ZipFile` instance and save all of it's data inside there. Alternatively, you can pass an instance of a class that is either a `ZipFile` or `ZipFile`-like and it will simply use that. When this argument is defined, the `customPath` argument refers to the path inside the zip file.
+* Added the `html` and `rtf` keywords to `Message.save`. These will attempt to save the body in the html or rtf format, respectively. If the program cannot save in those formats, it will raise an exception unless the `allowFallback` keyword argument is `True`.
+* Changed `utils.hasLen` to use `hasattr` instead of the try-except method it was using.
+* Added new option `recipientSeparator` to `MessageBase` allowing you to specify a custom recipient separator (default is ";" to match Microsoft Outlook).
+* Changed the `openMsg` function in `Attachment` to not be strict. This allows you to actually open the MSG file even if we don't recognize the type of embedded MSG that is being used.
+* Attempted to normalize encoding names throughout the module so that a certain encoding will only show up using one name and not multiple.
+* Finally figured out what CRC32 algorithm is used in named properties after directly asking in a Microsoft forum (see the thread [here](https://docs.microsoft.com/en-us/answers/questions/574894/ms-oxmsg-specifies-the-use-of-crc-32-checksums-wit.html)). Fortunately the is already defined in the `compressed-rtf` module so we can take advantage of that.
+* Reworked `MessageBase._genRecipient` to improve it (because what on earth was that code it was using before?). Variables in the function are now more descriptive. Added comments in several places.
+* Many renames to better fit naming convention:
+    * `dev.setup_dev_logger` to `dev.setupDevLogger`.
+    * `MSGFile.fix_path` to `MSGFile.fixPath`.
+    * `MessageBase.save_attachments` to `MessageBase.saveAttachments`.
+    * `*.Exists` to `exists`.
+    * `*.ExistsTypedProperty` to `*.existsTypedProperty`.
+    * `prop.create_prop` to `prop.createProp`.
+    * `Properties.attachment_count` to `Properties.attachmentCount`.
+    * `Properties.next_attachment_id` to `Properties.nextAttachmentId`.
+    * `Properties.next_recipient_id` to `Properties.nextRecipientId`.
+    * `Properties.recipient_count` to `Properties.recipientCount`.
+    * `utils.get_command_args` to `utils.getCommandArgs`.
+    * `utils.get_full_class_name` to `utils.getFullClassName`.
+    * `utils.get_input` to `utils.getInput`.
+    * `utils.has_len` to `utils.hasLen`.
+    * `utils.setup_logging` to `utils.setupLogging`.
+    * `constants.int_to_data_type` to `constants.intToDataType`.
+    * `constants.int_to_intelligence` to `constants.intToIntelligence`.
+    * `constants.int_to_recipient_type` to `constants.intToRecipientType`.
+    * Misc internal function variables.
+
+**v0.28.7**
+* Added hex versions of the `MULTIPLE_X_BYTES` constants.
+* Added `1048` to `constants.MULTIPLE_16_BYTES`
+* [[TeamMsgExtractor #173](https://github.com/TeamMsgExtractor/msg-extractor/issues/173)] rewrote the parsing of the length in `VariableLengthProp.__init__` to use constants rather than values coded directly into the function. This should fix this issue.
+
+**v0.28.6**
+* [[TeamMsgExtractor #191](https://github.com/TeamMsgExtractor/msg-extractor/issues/191)] This feature was never properly implemented, so it's not officially supported. However, this specific issue should be fixed. This is a temporary patch until I can get around to rewriting the way the module saves files in general.
+* Added `venv` to the .gitignore list.
+* Added information to the readme.
+
+**v0.28.5**
+* [[TeamMsgExtractor #189](https://github.com/TeamMsgExtractor/msg-extractor/issues/189)] Forgot to import `prepareFilename` in `attachment.py`.
+* Fixed bad link in the changelog.
+
+**v0.28.4**
+* [[TeamMsgExtractor #184](https://github.com/TeamMsgExtractor/msg-extractor/issues/184)] Added code to `Message` to ensure subjects with null characters get stripped of them.
+* Moved code for stripping subjects of bad characters to `prepareFilename` in `utils`.
+
+**v0.28.3**
+* Fixed minor typo in an exception description.
+* Updated the README this time. Forgot to do it for at least 1 update.
+
+**v0.28.2**
+* Started preparing more of the code for when HTML and RTF saving are fully implemented. Please note that they do not work at all right now. Commented out the code for this because it wasn't meant to be uncommented.
+* [[TeamMsgExtractor #184](https://github.com/TeamMsgExtractor/msg-extractor/issues/184)] Added code to ensure file names don't have null characters when saving an attachment.
+* Minor improvement to the section of the save code that checks if you have provided incompatible options.
+* [[TeamMsgExtractor #185](https://github.com/TeamMsgExtractor/msg-extractor/issues/185)] Added the `IncompatibleOptionsError`. It was supposed to be added a few updates ago, but was accidentally left out.
+* Modified `Message.save` to return the current `Message` instance to allow for chained commands. This allows you to do something like `extract_msg.openMsg("path/to/message.msg").save().close()` where you could not before.
+
+**v0.28.1**
+* [[TeamMsgExtractor #181](https://github.com/TeamMsgExtractor/msg-extractor/issues/181)] Fixed issue in `Attachment` that arose when moving some of the code to a base class.
+* Fixed small error in `utils.parse_type` that caused it to incorrectly compare expected and actual length. Fortunately, this had no actual effect aside from a warning.
+* Added the `ebcdic` module to the requirements to add more supported encodings.
+
+**v0.28.0**
+* [[TeamMsgExtractor #87](https://github.com/TeamMsgExtractor/msg-extractor/issues/87)] Added a new system to handle `NotImplementedError` and other exceptions. All msg classes now have an option called `attachmentErrorBehavior` that tells the class what to do if it has an error. The value should be one of three constants: `ATTACHMENT_ERROR_THROW`, `ATTACHMENT_ERROR_NOT_IMPLEMENTED`, or `ATTACHMENT_ERROR_BROKEN`. `ATTACHMENT_ERROR_THROW` tells the class to not catch and exceptions and just let the user handle them. `ATTACHMENT_ERROR_NOT_IMPLEMENTED` tells the class to catch `NotImplementedError` exceptions and put an instance of `UnsupportedAttachment` in place of a regular attachment. `ATTACHMENT_ERROR_BROKEN` tells the class to catch *all* exceptions and either replace the attachment with `UnsupportedAttachment` if it is a `NotImplementedError` or `BrokenAttachment` for all other exceptions. With both of those options, caught exceptions will be logged.
+* In making the previous point work, much code from `Attachment` has been moved to a new class called `AttachmentBase`. Both `BrokenAttachment` and `UnsupportedAttachment` are subclasses of `AttachmentBase` meaning data can be extracted from their streams in the same way as a functioning attachment.
+* [[TeamMsgExtractor #162](https://github.com/TeamMsgExtractor/msg-extractor/issues/162)] Pretty sure I actually got it this time. The execution flag should be applied by pip now.
+* Fixed typos in some exceptions
+
+**v0.27.16**
+* [[TeamMsgExtractor #177](https://github.com/TeamMsgExtractor/msg-extractor/issues/177)] Fixed incorrect struct being used. It should be the correct one now, but further testing will be required to confirm this.
+* Fixed log error message in `extract_msg.prop` to actually format a value into the message.
+
+**v0.27.15**
+* [[TeamMsgExtractor #177](https://github.com/TeamMsgExtractor/msg-extractor/issues/177)] Fixed missing import.
+
+**v0.27.14**
+* [[TeamMsgExtractor #173](https://github.com/TeamMsgExtractor/msg-extractor/issues/173)] Fixed typo that I made in the last version that broke things. I didn't have the resources to test this one myself, unfortunately.
+* Fixed a typo in an exception message.
+
+**v0.27.13**
+* [[TeamMsgExtractor #173](https://github.com/TeamMsgExtractor/msg-extractor/issues/173)] Moved some data used in checks into constants so that I can make sure they get changed every where that they are used. Hopefully I can close this issue.
+
+**v0.27.12**
+* [[TeamMsgExtractor #173](https://github.com/TeamMsgExtractor/msg-extractor/issues/173)] Made an assumption about where an exception was thrown from and was wrong. While that location would have throw an exception, the function that called that code was the one to actually throw the exception in question. This issue *should* be fixed...
+* [[TeamMsgExtractor #162](https://github.com/TeamMsgExtractor/msg-extractor/issues/162)] Made another attempt to fix the execution flag on the wrapper script.
+
+**v0.27.11**
+* [[TeamMsgExtractor #173](https://github.com/TeamMsgExtractor/msg-extractor/issues/173)] Tentatively implemented type 0x1014 (PtypMultipleInteger64). Apparently I forgot to do it earlier.
+
+**v0.27.10**
+* [[TeamMsgExtractor #162](https://github.com/TeamMsgExtractor/msg-extractor/issues/162)] Fixed line endings in the wrapper script to be UNIX line endings rather than Windows line endings. Attempted to add the execution flag to the runnable script.
+
+**v0.27.9**
+* [[TeamMsgExtractor #161](https://github.com/TeamMsgExtractor/msg-extractor/issues/161)] Added commands to the command line that will allow the user to specify that they want the message data to be output to stdout rather than to a file.
+* [[TeamMsgExtractor #162](https://github.com/TeamMsgExtractor/msg-extractor/issues/162)] Added a wrapper for extract_msg that will be installed.
+* Fixed some of the encoding names to allow them to actually be used in Python. The names they previously held were not aliases that currently exist.
+* Added more documentation to `constants.CODE_PAGES` to give more information about what it is. As it is a list of the possible encodings an msg file can use, I also specified which ones were supported by Python 3.
+* Moved the main code into a function so it is now callable from outside of the file.
+
+**v0.27.8**
+* [[TeamMsgExtractor #158](https://github.com/TeamMsgExtractor/msg-extractor/issues/158)] Fixed a spelling error in a function name that was causing it to not be seen. The function was called `ceilDiv` but was accidentally called as `cielDiv`.
+
+**v0.27.7**
+* Fixed an issue in the new bitwise adjustment functions. One of the variable names was incorrect.
+
+**v0.27.6**
+* Fixed a few lines in `data.py`.
+
+**v0.27.5**
+* Fixed an error in `utils.divide` that would cause it to drop the extra data if there was not enough to create a full division. For example, if you had a string that was 10 characters, and divided by 3, you would only receive a total of 9 characters back.
+* Added some useful functions that will be used in the future.
+* [[TeamMsgExtractor #155](https://github.com/TeamMsgExtractor/msg-extractor/issues/155)] Updated to use new version of tzlocal.
+* Updated changelog to fit new repository.
+
+**v0.27.4**
+* [[TeamMsgExtractor #152](https://github.com/TeamMsgExtractor/msg-extractor/issues/152)] Fixed an issue where the name of an exception was put as the wrong thing.
+
+**v0.27.3**
+* [[TeamMsgExtractor #105](https://github.com/TeamMsgExtractor/msg-extractor/issues/105)] Added code to fix an internal msg issue that had recipient lists being split up in the header after a certain amount of characters. This was now a bug on our part, but an issue with the generation of the msg file itself.
+* Exposed the `MessageBase` class directly from `extract_msg`. I forgot to do this when I created it.
+* Added `MessageBase.bcc`. I think it used to exist but got erased somehow on accident. Either way, it exists now.
+
+**v0.27.2**
+* After much debate, I have finally decided to allow an option to override the string encoding in message files. This Was something I reserved solely for `dev_classes.Message` because it felt like it didn't fit with how msg files were supposed to work. I also didn't want messages from people about them running into errors after they overrode the encoding. You can now do this by providing the `overrideEncoding` option on any `MSGFile` class as well as the `openMsg` function.
+* [[TeamMsgExtractor #103](https://github.com/TeamMsgExtractor/msg-extractor/issues/103)] Implemented correct detection of encodings. If you have any more issues with "'X' codec can't decode bytes" it is likely because the encoding specified inside the msg file is wrong.
+
+**v0.27.1**
+* [[TeamMsgExtractor #147](https://github.com/TeamMsgExtractor/msg-extractor/issues/147)] Fixed an issue in `Message.save` caused by it attempting to directly access a private variable that was moved to the base class `MessageBase`.
+
+**v0.27.0**
+* [[TeamMsgExtractor #143](https://github.com/TeamMsgExtractor/msg-extractor/issues/143)] Added new class `Appointment` that can handle outlook appointments or meetings.
+* [[TeamMsgExtractor #143](https://github.com/TeamMsgExtractor/msg-extractor/issues/143)] Added new class `MessageBase` for classes that end up being mostly like the `Message` class. Currently subclassed by `Message` and `Appointment`. This should not have a direct effect on any code that uses this module.
+* Added support for `PtypFloatingTime` in `utils.parseType`.
+* Added proper support for `PtypTime` in `FixedLengthProp.parseType`
+* Added pretty print functions to the `Properties` class and the `Named` class.
+* Added new function `MSGFile._ensureSetProperty` that acts like `MSGFile._ensureSet` except that it works with properties from the `Properties` instance.
+* Added equivalent of the previously mentioned function to the `Attachment` class and the `Recipient` class.
+
+**v0.26.4**
+* Added new function `MSGFile._ensureSetNamed` which acts like `MSGFile._ensureSet` except that it works with named properties.
+* Added a version of the previous function to the `Attachment` and `Recipient` classes.
+* Added new file `data.py` that contains various data structures that are used for specific properties.
+* Expanded the functionality of the `Recipient` class by adding more properties.
+* Added new functions `Named.getNamed` and `Named.getNamedValue` which retrieves a named property or the value of a named property, respectively, based on its name.
+
+**v0.26.3**
+* Added new function `MSGFile.save` that causes it and subclasses to raise a `NotImplementedError` if they do not override it.
+* Fixed some issues in the changelog.
+* Added some additional constants for future use.
+
+**v0.26.2**
+* Fixed error in `Message._registerNamedProperty` where I put the exception `KeyError` instead of `AttributeError`.
+
+**v0.26.1**
+* Fixed an issue in `openMsg` that would leave the basic `MSGFile` instance open with the function returned, even if the function was returning a specific msg instance.
+
+**v0.26.0**
+* [[TheElementalOfDestruction #3](https://github.com/TheElementalOfDestruction/msg-extractor/issues/3)] Implementation of Named properties has finally been added. This allows us to access certain data that was not available to us before through regular methods.
+* Added new function `MSGFile.slistDir` that acts like `MSGFile.listDir`, except that it returns a list of strings rather than a list of lists.
+* [[TheElementalOfDestruction #6](https://github.com/TheElementalOfDestruction/msg-extractor/issues/6)] Added new function `MSGFile._getTypedStream` which, based on a path formatted in the same way as you would give to `MSGFile._getStringStream`, will return the data in the specified stream without the user needing to know the type before hand. However, if you DO know the type before hand, you can provide this function with one of the values in `constants.FIXED_LENGTH_PROPS_STRING` or `constants.VARIABLE_LENGTH_PROPS_STRING`.
+* [[TheElementalOfDestruction #6](https://github.com/TheElementalOfDestruction/msg-extractor/issues/6)] Added new function `MSGFile._getTypedProperty` which, based on a 4 digit hexadecimal string, will return the property in the properties file that matches that string without the type needing to be specified. However, if you DO know the type before hand, you can provide this function with one of the values in `constants.FIXED_LENGTH_PROPS_STRING` or `constants.VARIABLE_LENGTH_PROPS_STRING`.
+* [[TheElementalOfDestruction #6](https://github.com/TheElementalOfDestruction/msg-extractor/issues/6)] Added new function `MSGFile._getTypedData` which is a combination of the two previously stated functions.
+* Added new function `MSGFile.ExistsTypedProperty` which determines if a property with the specified id exists in the specified location. If you are looking for a property that may be in the properties file of an attachment or a recipient, please use the corresponding function from that class.
+* Added an equivalent of the previous 4 functions for the `Recipient` and `Attachment` classes.
+* [[TheElementalOfDestruction #2](https://github.com/TheElementalOfDestruction/msg-extractor/issues/2)] Finished partial implementation of `utils.parseType` which was necessary for the proper implementation of named properties. This function is not fully implemented because there are some types we do not fully understand.
+
+**v0.25.3**
+* [[TeamMsgExtractor #138](https://github.com/TeamMsgExtractor/msg-extractor/issues/138)] Fixed missing import in `extract_msg/utils.py`.
+
+**v0.25.2**
+* [[TeamMsgExtractor #134](https://github.com/TeamMsgExtractor/msg-extractor/issues/134)] Fixed a typo that caused `Message.headerDict` to raise an exception.
+* Upgraded code for `Message.headerDict` to avoid accidentally raising a key error if the header is ever missing the "Received" property.
+* Fixed an error in the changelog that caused some issue links to link to the wrong place.
+
+**v0.25.1**
+* [[TeamMsgExtractor #132](https://github.com/TeamMsgExtractor/msg-extractor/issues/132)] Fixed an issue caused by unfinished code being left in the \_\_main\_\_ file.
+* Cleaned up the imports to only be what is needed.
+
+**v0.25.0**
+* Added new class `MSGFile`. The `Message` class now inherits from this. This class is the base for all MSG files, not just `Message`s. It somewhat recently came to our attention that MSG files are used for a variety of things, including the storage of contacts, leading us to the next part of the changelog.
+* [[TeamMsgExtractor #110](https://github.com/TeamMsgExtractor/msg-extractor/issues/110)] Added new class `Contact` for extracting the data from MSG files storing contacts.
+* Added new function `openMsg` to the module to be used to open MSG files in which it is not certain what type of MSG is being opened.
+* Modified the `Attachment` class to use the `openMsg` function to open embedded MSG files.
+* Added option `delayAttachments` to the `Message` class that will stop it from initializing attachments until the user is ready. This allows users to open `Message`s that have unimplemented attachment types without having to worry about the exception stopping them. This is also an option in the new `openMsg` function.
+
+**v0.24.4**
+* Added new property `Message.isRead` to show whether the email has been marked as read.
+* Renamed `Message.header_dict` to `Message.headerDict` to better match naming conventions.
+* Renamed `Message.message_id` to `Message.messageId` to better match naming conventions.
+
+**v0.24.3**
+* Added new close function to the `Message` class to ensure that all embedded `Message` instances get closed as well. Not having this was causing issues with trying to modify the msg file after the user thought that it had been closed.
+
+**v0.24.2**
+* Fixed bug that somehow escaped detection that caused certain properties to not work.
+* Fixed bug with embedded msg files introduced in v0.24.0
+
+**v0.24.0**
+* [[TeamMsgExtractor #107](https://github.com/TeamMsgExtractor/msg-extractor/issues/107)] Rewrote the `Messsage.save` function to fix many errors arising from it and to extend its functionality.
+* Added new function `isEmptyString` to check if a string passed to it is `None` or is empty.
+
+**v0.23.4**
+* [[TeamMsgExtractor #112](https://github.com/TeamMsgExtractor/msg-extractor/issues/112)] Changed method used to get the message from an exception to make it compatible with Python 2 and 3.
+* [[TheElementalOfDestruction #23](https://github.com/TheElementalOfDestruction/msg-extractor/issues/23)] General cleanup and all around improvements of the code.
+
+**v0.23.3**
+* Fixed issues in readme.
+* [[TheElementalOfDestruction #22](https://github.com/TheElementalOfDestruction/msg-extractor/issues/22)] Updated `dev_classes.Message` to better match the current `Message` class.
+* Fixed bad links in changelog.
+* [[TeamMsgExtractor #95](https://github.com/TeamMsgExtractor/msg-extractor/issues/95)] Added fallback encoding as well as manual encoding change to `dev_classes.Message`.
+
+**v0.23.1**
+* Fixed issue with embedded msg files caused by the changes in v0.23.0.
+
+**v0.23.0**
+* [[TeamMsgExtractor #75](https://github.com/TeamMsgExtractor/msg-extractor/issues/75)] & [[TheElementalOfDestruction #19](https://github.com/TheElementalOfDestruction/msg-extractor/issues/19)] Completely rewrote the function `Message._getStringStream`. This was done for two reasons. The first was to make it actually work with msg files that have their strings encoded in a non-Unicode encoding. The second reason was to make it so that it better reflected msg specification which says that ALL strings in a file will be either Unicode or non-Unicode, but not both. Because of the second part, the `prefer` option has been removed.
+* As part of fixing the two issues in the previous change, we have added two new properties:
+    1. a boolean `Message.areStringsUnicode` which tells if the strings are Unicode encoded.
+    2. A string `Message.stringEncoding` which tells what the encoding is. This is used by the `Message._getStringStream` to determine how to decode the data into a string.
+
+**v0.22.1**
+* [[TeamMsgExtractor #69](https://github.com/TeamMsgExtractor/msg-extractor/issues/69)] Fixed date format not being up to standard.
+* Fixed a minor spelling error in the code.
+
+**v0.22.0**
+* [[TheElementalOfDestruction #18](https://github.com/TheElementalOfDestruction/msg-extractor/issues/18)] Added `--validate` option.
+* [[TheElementalOfDestruction #16](https://github.com/TheElementalOfDestruction/msg-extractor/issues/16)] Moved all dev code into its own scripts. Use `--dev` to use from the command line.
+* [[TeamMsgExtractor #67](https://github.com/TeamMsgExtractor/msg-extractor/issues/67)] Added compatibility module to enforce Unicode os functions.
+* Added new function to `Message` class: `Message.sExists`. This function checks if a string stream exists. It's input should be formatted identically to that of `Message._getStringStream`.
+* Added new function to `Message` class: `Message.fix_path`. This function will add the proper prefix to the path (if the `prefix` parameter is true) and adjust the path to be a string rather than a list or tuple.
+* Added new function to `utils.py`: `get_full_class_name`. This function returns a string containing the module name and the class name of any instance of any class. It is returned in the format of `{module}.{class}`.
+* Added a sort of alias of `Message._getStream`, `Message._getStringStream`, `Message.Exists`, and `Message.sExists` to `Attachment` and `Recipient`. These functions run inside the associated attachment directory or recipient directory, respectively.
+* Added a fix to an issue introduced in an earlier version caused by accidentally deleting a letter in the code.
+
+**v0.21.0**
+* [[TheElementalOfDestruction #12](https://github.com/TheElementalOfDestruction/msg-extractor/issues/12)] Changed debug code to use logging module.
+* [[TheElementalOfDestruction #17](https://github.com/TheElementalOfDestruction/msg-extractor/issues/17)] Fixed Attachment class using wrong properties file location in embedded msg files.
+* [[TheElementalOfDestruction #11](https://github.com/TheElementalOfDestruction/msg-extractor/issues/11)] Improved handling of command line arguments using argparse module.
+* [[TheElementalOfDestruction #16](https://github.com/TheElementalOfDestruction/msg-extractor/issues/16)] Started work on moving developer code into its own script.
+* [[TeamMsgExtractor #63](https://github.com/TeamMsgExtractor/msg-extractor/issues/63)] Fixed JSON saving not applying to embedded msg files.
+* [[TeamMsgExtractor #55](https://github.com/TeamMsgExtractor/msg-extractor/issues/55)] Added fix for recipient sometimes missing email address.
+* [[TeamMsgExtractor #65](https://github.com/TeamMsgExtractor/msg-extractor/issues/65)] Added fix for special characters in recipient names.
+* Module now raises a custom exception (instead of just `IOError`) if the input is not a valid OLE file.
+* Added `header_dict` property to the `Message` class.
+* General minor bug fixes.
+* Fixed a section in the `Recipient` class that I have no idea why I did it that way. If errors start randomly occurring with it, this fix is why.
+
+**v0.20.8**
+* Fixed a tab issue and parameter type in `message.py`.
+
+
+**v0.20.7**
+
+* Separated classes into their own files to make things more manageable.
+* Placed `__doc__` back inside of `__init__.py`.
+* Rewrote the `Prop` class to be two different classes that extend from a base class.
+* Made decent progress on completing the `parse_type` function of the `FixedLengthProp` class (formerly a function of the `Prop` class).
+* Improved exception handling code throughout most of the module.
+* Updated the `.gitignore`.
+* Updated README.
+* Added `# DEBUG` comments before debugging lines to make them easier to find in the future.
+* Added function `create_prop` in `prop.py` which should be used for creating what used to be an instance of the `Prop` class.
+* Added more constants to reflect some of the changes made.
+* Fixed a major bug that was causing the header to generate after things like "to" and "cc" which would force those fields to not use the header.
+* Fixed the debug variable.
+* Fixed many small bugs in many of the classes.
+* [[TheElementalOfDestruction #13](https://github.com/TheElementalOfDestruction/msg-extractor/issues/13)] Various loose ends to enhance the workflow in the repo.
```

### Comparing `extract_msg-0.40.0/LICENSE.txt` & `extract_msg-0.41.0/LICENSE.txt`

 * *Ordering differences only*

 * *Files 7% similar despite different names*

```diff
@@ -1,674 +1,674 @@
-                    GNU GENERAL PUBLIC LICENSE
-                       Version 3, 29 June 2007
-
- Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>
- Everyone is permitted to copy and distribute verbatim copies
- of this license document, but changing it is not allowed.
-
-                            Preamble
-
-  The GNU General Public License is a free, copyleft license for
-software and other kinds of works.
-
-  The licenses for most software and other practical works are designed
-to take away your freedom to share and change the works.  By contrast,
-the GNU General Public License is intended to guarantee your freedom to
-share and change all versions of a program--to make sure it remains free
-software for all its users.  We, the Free Software Foundation, use the
-GNU General Public License for most of our software; it applies also to
-any other work released this way by its authors.  You can apply it to
-your programs, too.
-
-  When we speak of free software, we are referring to freedom, not
-price.  Our General Public Licenses are designed to make sure that you
-have the freedom to distribute copies of free software (and charge for
-them if you wish), that you receive source code or can get it if you
-want it, that you can change the software or use pieces of it in new
-free programs, and that you know you can do these things.
-
-  To protect your rights, we need to prevent others from denying you
-these rights or asking you to surrender the rights.  Therefore, you have
-certain responsibilities if you distribute copies of the software, or if
-you modify it: responsibilities to respect the freedom of others.
-
-  For example, if you distribute copies of such a program, whether
-gratis or for a fee, you must pass on to the recipients the same
-freedoms that you received.  You must make sure that they, too, receive
-or can get the source code.  And you must show them these terms so they
-know their rights.
-
-  Developers that use the GNU GPL protect your rights with two steps:
-(1) assert copyright on the software, and (2) offer you this License
-giving you legal permission to copy, distribute and/or modify it.
-
-  For the developers' and authors' protection, the GPL clearly explains
-that there is no warranty for this free software.  For both users' and
-authors' sake, the GPL requires that modified versions be marked as
-changed, so that their problems will not be attributed erroneously to
-authors of previous versions.
-
-  Some devices are designed to deny users access to install or run
-modified versions of the software inside them, although the manufacturer
-can do so.  This is fundamentally incompatible with the aim of
-protecting users' freedom to change the software.  The systematic
-pattern of such abuse occurs in the area of products for individuals to
-use, which is precisely where it is most unacceptable.  Therefore, we
-have designed this version of the GPL to prohibit the practice for those
-products.  If such problems arise substantially in other domains, we
-stand ready to extend this provision to those domains in future versions
-of the GPL, as needed to protect the freedom of users.
-
-  Finally, every program is threatened constantly by software patents.
-States should not allow patents to restrict development and use of
-software on general-purpose computers, but in those that do, we wish to
-avoid the special danger that patents applied to a free program could
-make it effectively proprietary.  To prevent this, the GPL assures that
-patents cannot be used to render the program non-free.
-
-  The precise terms and conditions for copying, distribution and
-modification follow.
-
-                       TERMS AND CONDITIONS
-
-  0. Definitions.
-
-  "This License" refers to version 3 of the GNU General Public License.
-
-  "Copyright" also means copyright-like laws that apply to other kinds of
-works, such as semiconductor masks.
-
-  "The Program" refers to any copyrightable work licensed under this
-License.  Each licensee is addressed as "you".  "Licensees" and
-"recipients" may be individuals or organizations.
-
-  To "modify" a work means to copy from or adapt all or part of the work
-in a fashion requiring copyright permission, other than the making of an
-exact copy.  The resulting work is called a "modified version" of the
-earlier work or a work "based on" the earlier work.
-
-  A "covered work" means either the unmodified Program or a work based
-on the Program.
-
-  To "propagate" a work means to do anything with it that, without
-permission, would make you directly or secondarily liable for
-infringement under applicable copyright law, except executing it on a
-computer or modifying a private copy.  Propagation includes copying,
-distribution (with or without modification), making available to the
-public, and in some countries other activities as well.
-
-  To "convey" a work means any kind of propagation that enables other
-parties to make or receive copies.  Mere interaction with a user through
-a computer network, with no transfer of a copy, is not conveying.
-
-  An interactive user interface displays "Appropriate Legal Notices"
-to the extent that it includes a convenient and prominently visible
-feature that (1) displays an appropriate copyright notice, and (2)
-tells the user that there is no warranty for the work (except to the
-extent that warranties are provided), that licensees may convey the
-work under this License, and how to view a copy of this License.  If
-the interface presents a list of user commands or options, such as a
-menu, a prominent item in the list meets this criterion.
-
-  1. Source Code.
-
-  The "source code" for a work means the preferred form of the work
-for making modifications to it.  "Object code" means any non-source
-form of a work.
-
-  A "Standard Interface" means an interface that either is an official
-standard defined by a recognized standards body, or, in the case of
-interfaces specified for a particular programming language, one that
-is widely used among developers working in that language.
-
-  The "System Libraries" of an executable work include anything, other
-than the work as a whole, that (a) is included in the normal form of
-packaging a Major Component, but which is not part of that Major
-Component, and (b) serves only to enable use of the work with that
-Major Component, or to implement a Standard Interface for which an
-implementation is available to the public in source code form.  A
-"Major Component", in this context, means a major essential component
-(kernel, window system, and so on) of the specific operating system
-(if any) on which the executable work runs, or a compiler used to
-produce the work, or an object code interpreter used to run it.
-
-  The "Corresponding Source" for a work in object code form means all
-the source code needed to generate, install, and (for an executable
-work) run the object code and to modify the work, including scripts to
-control those activities.  However, it does not include the work's
-System Libraries, or general-purpose tools or generally available free
-programs which are used unmodified in performing those activities but
-which are not part of the work.  For example, Corresponding Source
-includes interface definition files associated with source files for
-the work, and the source code for shared libraries and dynamically
-linked subprograms that the work is specifically designed to require,
-such as by intimate data communication or control flow between those
-subprograms and other parts of the work.
-
-  The Corresponding Source need not include anything that users
-can regenerate automatically from other parts of the Corresponding
-Source.
-
-  The Corresponding Source for a work in source code form is that
-same work.
-
-  2. Basic Permissions.
-
-  All rights granted under this License are granted for the term of
-copyright on the Program, and are irrevocable provided the stated
-conditions are met.  This License explicitly affirms your unlimited
-permission to run the unmodified Program.  The output from running a
-covered work is covered by this License only if the output, given its
-content, constitutes a covered work.  This License acknowledges your
-rights of fair use or other equivalent, as provided by copyright law.
-
-  You may make, run and propagate covered works that you do not
-convey, without conditions so long as your license otherwise remains
-in force.  You may convey covered works to others for the sole purpose
-of having them make modifications exclusively for you, or provide you
-with facilities for running those works, provided that you comply with
-the terms of this License in conveying all material for which you do
-not control copyright.  Those thus making or running the covered works
-for you must do so exclusively on your behalf, under your direction
-and control, on terms that prohibit them from making any copies of
-your copyrighted material outside their relationship with you.
-
-  Conveying under any other circumstances is permitted solely under
-the conditions stated below.  Sublicensing is not allowed; section 10
-makes it unnecessary.
-
-  3. Protecting Users' Legal Rights From Anti-Circumvention Law.
-
-  No covered work shall be deemed part of an effective technological
-measure under any applicable law fulfilling obligations under article
-11 of the WIPO copyright treaty adopted on 20 December 1996, or
-similar laws prohibiting or restricting circumvention of such
-measures.
-
-  When you convey a covered work, you waive any legal power to forbid
-circumvention of technological measures to the extent such circumvention
-is effected by exercising rights under this License with respect to
-the covered work, and you disclaim any intention to limit operation or
-modification of the work as a means of enforcing, against the work's
-users, your or third parties' legal rights to forbid circumvention of
-technological measures.
-
-  4. Conveying Verbatim Copies.
-
-  You may convey verbatim copies of the Program's source code as you
-receive it, in any medium, provided that you conspicuously and
-appropriately publish on each copy an appropriate copyright notice;
-keep intact all notices stating that this License and any
-non-permissive terms added in accord with section 7 apply to the code;
-keep intact all notices of the absence of any warranty; and give all
-recipients a copy of this License along with the Program.
-
-  You may charge any price or no price for each copy that you convey,
-and you may offer support or warranty protection for a fee.
-
-  5. Conveying Modified Source Versions.
-
-  You may convey a work based on the Program, or the modifications to
-produce it from the Program, in the form of source code under the
-terms of section 4, provided that you also meet all of these conditions:
-
-    a) The work must carry prominent notices stating that you modified
-    it, and giving a relevant date.
-
-    b) The work must carry prominent notices stating that it is
-    released under this License and any conditions added under section
-    7.  This requirement modifies the requirement in section 4 to
-    "keep intact all notices".
-
-    c) You must license the entire work, as a whole, under this
-    License to anyone who comes into possession of a copy.  This
-    License will therefore apply, along with any applicable section 7
-    additional terms, to the whole of the work, and all its parts,
-    regardless of how they are packaged.  This License gives no
-    permission to license the work in any other way, but it does not
-    invalidate such permission if you have separately received it.
-
-    d) If the work has interactive user interfaces, each must display
-    Appropriate Legal Notices; however, if the Program has interactive
-    interfaces that do not display Appropriate Legal Notices, your
-    work need not make them do so.
-
-  A compilation of a covered work with other separate and independent
-works, which are not by their nature extensions of the covered work,
-and which are not combined with it such as to form a larger program,
-in or on a volume of a storage or distribution medium, is called an
-"aggregate" if the compilation and its resulting copyright are not
-used to limit the access or legal rights of the compilation's users
-beyond what the individual works permit.  Inclusion of a covered work
-in an aggregate does not cause this License to apply to the other
-parts of the aggregate.
-
-  6. Conveying Non-Source Forms.
-
-  You may convey a covered work in object code form under the terms
-of sections 4 and 5, provided that you also convey the
-machine-readable Corresponding Source under the terms of this License,
-in one of these ways:
-
-    a) Convey the object code in, or embodied in, a physical product
-    (including a physical distribution medium), accompanied by the
-    Corresponding Source fixed on a durable physical medium
-    customarily used for software interchange.
-
-    b) Convey the object code in, or embodied in, a physical product
-    (including a physical distribution medium), accompanied by a
-    written offer, valid for at least three years and valid for as
-    long as you offer spare parts or customer support for that product
-    model, to give anyone who possesses the object code either (1) a
-    copy of the Corresponding Source for all the software in the
-    product that is covered by this License, on a durable physical
-    medium customarily used for software interchange, for a price no
-    more than your reasonable cost of physically performing this
-    conveying of source, or (2) access to copy the
-    Corresponding Source from a network server at no charge.
-
-    c) Convey individual copies of the object code with a copy of the
-    written offer to provide the Corresponding Source.  This
-    alternative is allowed only occasionally and noncommercially, and
-    only if you received the object code with such an offer, in accord
-    with subsection 6b.
-
-    d) Convey the object code by offering access from a designated
-    place (gratis or for a charge), and offer equivalent access to the
-    Corresponding Source in the same way through the same place at no
-    further charge.  You need not require recipients to copy the
-    Corresponding Source along with the object code.  If the place to
-    copy the object code is a network server, the Corresponding Source
-    may be on a different server (operated by you or a third party)
-    that supports equivalent copying facilities, provided you maintain
-    clear directions next to the object code saying where to find the
-    Corresponding Source.  Regardless of what server hosts the
-    Corresponding Source, you remain obligated to ensure that it is
-    available for as long as needed to satisfy these requirements.
-
-    e) Convey the object code using peer-to-peer transmission, provided
-    you inform other peers where the object code and Corresponding
-    Source of the work are being offered to the general public at no
-    charge under subsection 6d.
-
-  A separable portion of the object code, whose source code is excluded
-from the Corresponding Source as a System Library, need not be
-included in conveying the object code work.
-
-  A "User Product" is either (1) a "consumer product", which means any
-tangible personal property which is normally used for personal, family,
-or household purposes, or (2) anything designed or sold for incorporation
-into a dwelling.  In determining whether a product is a consumer product,
-doubtful cases shall be resolved in favor of coverage.  For a particular
-product received by a particular user, "normally used" refers to a
-typical or common use of that class of product, regardless of the status
-of the particular user or of the way in which the particular user
-actually uses, or expects or is expected to use, the product.  A product
-is a consumer product regardless of whether the product has substantial
-commercial, industrial or non-consumer uses, unless such uses represent
-the only significant mode of use of the product.
-
-  "Installation Information" for a User Product means any methods,
-procedures, authorization keys, or other information required to install
-and execute modified versions of a covered work in that User Product from
-a modified version of its Corresponding Source.  The information must
-suffice to ensure that the continued functioning of the modified object
-code is in no case prevented or interfered with solely because
-modification has been made.
-
-  If you convey an object code work under this section in, or with, or
-specifically for use in, a User Product, and the conveying occurs as
-part of a transaction in which the right of possession and use of the
-User Product is transferred to the recipient in perpetuity or for a
-fixed term (regardless of how the transaction is characterized), the
-Corresponding Source conveyed under this section must be accompanied
-by the Installation Information.  But this requirement does not apply
-if neither you nor any third party retains the ability to install
-modified object code on the User Product (for example, the work has
-been installed in ROM).
-
-  The requirement to provide Installation Information does not include a
-requirement to continue to provide support service, warranty, or updates
-for a work that has been modified or installed by the recipient, or for
-the User Product in which it has been modified or installed.  Access to a
-network may be denied when the modification itself materially and
-adversely affects the operation of the network or violates the rules and
-protocols for communication across the network.
-
-  Corresponding Source conveyed, and Installation Information provided,
-in accord with this section must be in a format that is publicly
-documented (and with an implementation available to the public in
-source code form), and must require no special password or key for
-unpacking, reading or copying.
-
-  7. Additional Terms.
-
-  "Additional permissions" are terms that supplement the terms of this
-License by making exceptions from one or more of its conditions.
-Additional permissions that are applicable to the entire Program shall
-be treated as though they were included in this License, to the extent
-that they are valid under applicable law.  If additional permissions
-apply only to part of the Program, that part may be used separately
-under those permissions, but the entire Program remains governed by
-this License without regard to the additional permissions.
-
-  When you convey a copy of a covered work, you may at your option
-remove any additional permissions from that copy, or from any part of
-it.  (Additional permissions may be written to require their own
-removal in certain cases when you modify the work.)  You may place
-additional permissions on material, added by you to a covered work,
-for which you have or can give appropriate copyright permission.
-
-  Notwithstanding any other provision of this License, for material you
-add to a covered work, you may (if authorized by the copyright holders of
-that material) supplement the terms of this License with terms:
-
-    a) Disclaiming warranty or limiting liability differently from the
-    terms of sections 15 and 16 of this License; or
-
-    b) Requiring preservation of specified reasonable legal notices or
-    author attributions in that material or in the Appropriate Legal
-    Notices displayed by works containing it; or
-
-    c) Prohibiting misrepresentation of the origin of that material, or
-    requiring that modified versions of such material be marked in
-    reasonable ways as different from the original version; or
-
-    d) Limiting the use for publicity purposes of names of licensors or
-    authors of the material; or
-
-    e) Declining to grant rights under trademark law for use of some
-    trade names, trademarks, or service marks; or
-
-    f) Requiring indemnification of licensors and authors of that
-    material by anyone who conveys the material (or modified versions of
-    it) with contractual assumptions of liability to the recipient, for
-    any liability that these contractual assumptions directly impose on
-    those licensors and authors.
-
-  All other non-permissive additional terms are considered "further
-restrictions" within the meaning of section 10.  If the Program as you
-received it, or any part of it, contains a notice stating that it is
-governed by this License along with a term that is a further
-restriction, you may remove that term.  If a license document contains
-a further restriction but permits relicensing or conveying under this
-License, you may add to a covered work material governed by the terms
-of that license document, provided that the further restriction does
-not survive such relicensing or conveying.
-
-  If you add terms to a covered work in accord with this section, you
-must place, in the relevant source files, a statement of the
-additional terms that apply to those files, or a notice indicating
-where to find the applicable terms.
-
-  Additional terms, permissive or non-permissive, may be stated in the
-form of a separately written license, or stated as exceptions;
-the above requirements apply either way.
-
-  8. Termination.
-
-  You may not propagate or modify a covered work except as expressly
-provided under this License.  Any attempt otherwise to propagate or
-modify it is void, and will automatically terminate your rights under
-this License (including any patent licenses granted under the third
-paragraph of section 11).
-
-  However, if you cease all violation of this License, then your
-license from a particular copyright holder is reinstated (a)
-provisionally, unless and until the copyright holder explicitly and
-finally terminates your license, and (b) permanently, if the copyright
-holder fails to notify you of the violation by some reasonable means
-prior to 60 days after the cessation.
-
-  Moreover, your license from a particular copyright holder is
-reinstated permanently if the copyright holder notifies you of the
-violation by some reasonable means, this is the first time you have
-received notice of violation of this License (for any work) from that
-copyright holder, and you cure the violation prior to 30 days after
-your receipt of the notice.
-
-  Termination of your rights under this section does not terminate the
-licenses of parties who have received copies or rights from you under
-this License.  If your rights have been terminated and not permanently
-reinstated, you do not qualify to receive new licenses for the same
-material under section 10.
-
-  9. Acceptance Not Required for Having Copies.
-
-  You are not required to accept this License in order to receive or
-run a copy of the Program.  Ancillary propagation of a covered work
-occurring solely as a consequence of using peer-to-peer transmission
-to receive a copy likewise does not require acceptance.  However,
-nothing other than this License grants you permission to propagate or
-modify any covered work.  These actions infringe copyright if you do
-not accept this License.  Therefore, by modifying or propagating a
-covered work, you indicate your acceptance of this License to do so.
-
-  10. Automatic Licensing of Downstream Recipients.
-
-  Each time you convey a covered work, the recipient automatically
-receives a license from the original licensors, to run, modify and
-propagate that work, subject to this License.  You are not responsible
-for enforcing compliance by third parties with this License.
-
-  An "entity transaction" is a transaction transferring control of an
-organization, or substantially all assets of one, or subdividing an
-organization, or merging organizations.  If propagation of a covered
-work results from an entity transaction, each party to that
-transaction who receives a copy of the work also receives whatever
-licenses to the work the party's predecessor in interest had or could
-give under the previous paragraph, plus a right to possession of the
-Corresponding Source of the work from the predecessor in interest, if
-the predecessor has it or can get it with reasonable efforts.
-
-  You may not impose any further restrictions on the exercise of the
-rights granted or affirmed under this License.  For example, you may
-not impose a license fee, royalty, or other charge for exercise of
-rights granted under this License, and you may not initiate litigation
-(including a cross-claim or counterclaim in a lawsuit) alleging that
-any patent claim is infringed by making, using, selling, offering for
-sale, or importing the Program or any portion of it.
-
-  11. Patents.
-
-  A "contributor" is a copyright holder who authorizes use under this
-License of the Program or a work on which the Program is based.  The
-work thus licensed is called the contributor's "contributor version".
-
-  A contributor's "essential patent claims" are all patent claims
-owned or controlled by the contributor, whether already acquired or
-hereafter acquired, that would be infringed by some manner, permitted
-by this License, of making, using, or selling its contributor version,
-but do not include claims that would be infringed only as a
-consequence of further modification of the contributor version.  For
-purposes of this definition, "control" includes the right to grant
-patent sublicenses in a manner consistent with the requirements of
-this License.
-
-  Each contributor grants you a non-exclusive, worldwide, royalty-free
-patent license under the contributor's essential patent claims, to
-make, use, sell, offer for sale, import and otherwise run, modify and
-propagate the contents of its contributor version.
-
-  In the following three paragraphs, a "patent license" is any express
-agreement or commitment, however denominated, not to enforce a patent
-(such as an express permission to practice a patent or covenant not to
-sue for patent infringement).  To "grant" such a patent license to a
-party means to make such an agreement or commitment not to enforce a
-patent against the party.
-
-  If you convey a covered work, knowingly relying on a patent license,
-and the Corresponding Source of the work is not available for anyone
-to copy, free of charge and under the terms of this License, through a
-publicly available network server or other readily accessible means,
-then you must either (1) cause the Corresponding Source to be so
-available, or (2) arrange to deprive yourself of the benefit of the
-patent license for this particular work, or (3) arrange, in a manner
-consistent with the requirements of this License, to extend the patent
-license to downstream recipients.  "Knowingly relying" means you have
-actual knowledge that, but for the patent license, your conveying the
-covered work in a country, or your recipient's use of the covered work
-in a country, would infringe one or more identifiable patents in that
-country that you have reason to believe are valid.
-
-  If, pursuant to or in connection with a single transaction or
-arrangement, you convey, or propagate by procuring conveyance of, a
-covered work, and grant a patent license to some of the parties
-receiving the covered work authorizing them to use, propagate, modify
-or convey a specific copy of the covered work, then the patent license
-you grant is automatically extended to all recipients of the covered
-work and works based on it.
-
-  A patent license is "discriminatory" if it does not include within
-the scope of its coverage, prohibits the exercise of, or is
-conditioned on the non-exercise of one or more of the rights that are
-specifically granted under this License.  You may not convey a covered
-work if you are a party to an arrangement with a third party that is
-in the business of distributing software, under which you make payment
-to the third party based on the extent of your activity of conveying
-the work, and under which the third party grants, to any of the
-parties who would receive the covered work from you, a discriminatory
-patent license (a) in connection with copies of the covered work
-conveyed by you (or copies made from those copies), or (b) primarily
-for and in connection with specific products or compilations that
-contain the covered work, unless you entered into that arrangement,
-or that patent license was granted, prior to 28 March 2007.
-
-  Nothing in this License shall be construed as excluding or limiting
-any implied license or other defenses to infringement that may
-otherwise be available to you under applicable patent law.
-
-  12. No Surrender of Others' Freedom.
-
-  If conditions are imposed on you (whether by court order, agreement or
-otherwise) that contradict the conditions of this License, they do not
-excuse you from the conditions of this License.  If you cannot convey a
-covered work so as to satisfy simultaneously your obligations under this
-License and any other pertinent obligations, then as a consequence you may
-not convey it at all.  For example, if you agree to terms that obligate you
-to collect a royalty for further conveying from those to whom you convey
-the Program, the only way you could satisfy both those terms and this
-License would be to refrain entirely from conveying the Program.
-
-  13. Use with the GNU Affero General Public License.
-
-  Notwithstanding any other provision of this License, you have
-permission to link or combine any covered work with a work licensed
-under version 3 of the GNU Affero General Public License into a single
-combined work, and to convey the resulting work.  The terms of this
-License will continue to apply to the part which is the covered work,
-but the special requirements of the GNU Affero General Public License,
-section 13, concerning interaction through a network will apply to the
-combination as such.
-
-  14. Revised Versions of this License.
-
-  The Free Software Foundation may publish revised and/or new versions of
-the GNU General Public License from time to time.  Such new versions will
-be similar in spirit to the present version, but may differ in detail to
-address new problems or concerns.
-
-  Each version is given a distinguishing version number.  If the
-Program specifies that a certain numbered version of the GNU General
-Public License "or any later version" applies to it, you have the
-option of following the terms and conditions either of that numbered
-version or of any later version published by the Free Software
-Foundation.  If the Program does not specify a version number of the
-GNU General Public License, you may choose any version ever published
-by the Free Software Foundation.
-
-  If the Program specifies that a proxy can decide which future
-versions of the GNU General Public License can be used, that proxy's
-public statement of acceptance of a version permanently authorizes you
-to choose that version for the Program.
-
-  Later license versions may give you additional or different
-permissions.  However, no additional obligations are imposed on any
-author or copyright holder as a result of your choosing to follow a
-later version.
-
-  15. Disclaimer of Warranty.
-
-  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
-APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
-HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
-OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
-THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
-PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
-IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
-ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
-
-  16. Limitation of Liability.
-
-  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
-WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
-THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
-GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
-USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
-DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
-PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
-EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
-SUCH DAMAGES.
-
-  17. Interpretation of Sections 15 and 16.
-
-  If the disclaimer of warranty and limitation of liability provided
-above cannot be given local legal effect according to their terms,
-reviewing courts shall apply local law that most closely approximates
-an absolute waiver of all civil liability in connection with the
-Program, unless a warranty or assumption of liability accompanies a
-copy of the Program in return for a fee.
-
-                     END OF TERMS AND CONDITIONS
-
-            How to Apply These Terms to Your New Programs
-
-  If you develop a new program, and you want it to be of the greatest
-possible use to the public, the best way to achieve this is to make it
-free software which everyone can redistribute and change under these terms.
-
-  To do so, attach the following notices to the program.  It is safest
-to attach them to the start of each source file to most effectively
-state the exclusion of warranty; and each file should have at least
-the "copyright" line and a pointer to where the full notice is found.
-
-    <one line to give the program's name and a brief idea of what it does.>
-    Copyright (C) <year>  <name of author>
-
-    This program is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 3 of the License, or
-    (at your option) any later version.
-
-    This program is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-Also add information on how to contact you by electronic and paper mail.
-
-  If the program does terminal interaction, make it output a short
-notice like this when it starts in an interactive mode:
-
-    <program>  Copyright (C) <year>  <name of author>
-    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
-    This is free software, and you are welcome to redistribute it
-    under certain conditions; type `show c' for details.
-
-The hypothetical commands `show w' and `show c' should show the appropriate
-parts of the General Public License.  Of course, your program's commands
-might be different; for a GUI interface, you would use an "about box".
-
-  You should also get your employer (if you work as a programmer) or school,
-if any, to sign a "copyright disclaimer" for the program, if necessary.
-For more information on this, and how to apply and follow the GNU GPL, see
-<http://www.gnu.org/licenses/>.
-
-  The GNU General Public License does not permit incorporating your program
-into proprietary programs.  If your program is a subroutine library, you
-may consider it more useful to permit linking proprietary applications with
-the library.  If this is what you want to do, use the GNU Lesser General
-Public License instead of this License.  But first, please read
-<http://www.gnu.org/philosophy/why-not-lgpl.html>.
+                    GNU GENERAL PUBLIC LICENSE
+                       Version 3, 29 June 2007
+
+ Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>
+ Everyone is permitted to copy and distribute verbatim copies
+ of this license document, but changing it is not allowed.
+
+                            Preamble
+
+  The GNU General Public License is a free, copyleft license for
+software and other kinds of works.
+
+  The licenses for most software and other practical works are designed
+to take away your freedom to share and change the works.  By contrast,
+the GNU General Public License is intended to guarantee your freedom to
+share and change all versions of a program--to make sure it remains free
+software for all its users.  We, the Free Software Foundation, use the
+GNU General Public License for most of our software; it applies also to
+any other work released this way by its authors.  You can apply it to
+your programs, too.
+
+  When we speak of free software, we are referring to freedom, not
+price.  Our General Public Licenses are designed to make sure that you
+have the freedom to distribute copies of free software (and charge for
+them if you wish), that you receive source code or can get it if you
+want it, that you can change the software or use pieces of it in new
+free programs, and that you know you can do these things.
+
+  To protect your rights, we need to prevent others from denying you
+these rights or asking you to surrender the rights.  Therefore, you have
+certain responsibilities if you distribute copies of the software, or if
+you modify it: responsibilities to respect the freedom of others.
+
+  For example, if you distribute copies of such a program, whether
+gratis or for a fee, you must pass on to the recipients the same
+freedoms that you received.  You must make sure that they, too, receive
+or can get the source code.  And you must show them these terms so they
+know their rights.
+
+  Developers that use the GNU GPL protect your rights with two steps:
+(1) assert copyright on the software, and (2) offer you this License
+giving you legal permission to copy, distribute and/or modify it.
+
+  For the developers' and authors' protection, the GPL clearly explains
+that there is no warranty for this free software.  For both users' and
+authors' sake, the GPL requires that modified versions be marked as
+changed, so that their problems will not be attributed erroneously to
+authors of previous versions.
+
+  Some devices are designed to deny users access to install or run
+modified versions of the software inside them, although the manufacturer
+can do so.  This is fundamentally incompatible with the aim of
+protecting users' freedom to change the software.  The systematic
+pattern of such abuse occurs in the area of products for individuals to
+use, which is precisely where it is most unacceptable.  Therefore, we
+have designed this version of the GPL to prohibit the practice for those
+products.  If such problems arise substantially in other domains, we
+stand ready to extend this provision to those domains in future versions
+of the GPL, as needed to protect the freedom of users.
+
+  Finally, every program is threatened constantly by software patents.
+States should not allow patents to restrict development and use of
+software on general-purpose computers, but in those that do, we wish to
+avoid the special danger that patents applied to a free program could
+make it effectively proprietary.  To prevent this, the GPL assures that
+patents cannot be used to render the program non-free.
+
+  The precise terms and conditions for copying, distribution and
+modification follow.
+
+                       TERMS AND CONDITIONS
+
+  0. Definitions.
+
+  "This License" refers to version 3 of the GNU General Public License.
+
+  "Copyright" also means copyright-like laws that apply to other kinds of
+works, such as semiconductor masks.
+
+  "The Program" refers to any copyrightable work licensed under this
+License.  Each licensee is addressed as "you".  "Licensees" and
+"recipients" may be individuals or organizations.
+
+  To "modify" a work means to copy from or adapt all or part of the work
+in a fashion requiring copyright permission, other than the making of an
+exact copy.  The resulting work is called a "modified version" of the
+earlier work or a work "based on" the earlier work.
+
+  A "covered work" means either the unmodified Program or a work based
+on the Program.
+
+  To "propagate" a work means to do anything with it that, without
+permission, would make you directly or secondarily liable for
+infringement under applicable copyright law, except executing it on a
+computer or modifying a private copy.  Propagation includes copying,
+distribution (with or without modification), making available to the
+public, and in some countries other activities as well.
+
+  To "convey" a work means any kind of propagation that enables other
+parties to make or receive copies.  Mere interaction with a user through
+a computer network, with no transfer of a copy, is not conveying.
+
+  An interactive user interface displays "Appropriate Legal Notices"
+to the extent that it includes a convenient and prominently visible
+feature that (1) displays an appropriate copyright notice, and (2)
+tells the user that there is no warranty for the work (except to the
+extent that warranties are provided), that licensees may convey the
+work under this License, and how to view a copy of this License.  If
+the interface presents a list of user commands or options, such as a
+menu, a prominent item in the list meets this criterion.
+
+  1. Source Code.
+
+  The "source code" for a work means the preferred form of the work
+for making modifications to it.  "Object code" means any non-source
+form of a work.
+
+  A "Standard Interface" means an interface that either is an official
+standard defined by a recognized standards body, or, in the case of
+interfaces specified for a particular programming language, one that
+is widely used among developers working in that language.
+
+  The "System Libraries" of an executable work include anything, other
+than the work as a whole, that (a) is included in the normal form of
+packaging a Major Component, but which is not part of that Major
+Component, and (b) serves only to enable use of the work with that
+Major Component, or to implement a Standard Interface for which an
+implementation is available to the public in source code form.  A
+"Major Component", in this context, means a major essential component
+(kernel, window system, and so on) of the specific operating system
+(if any) on which the executable work runs, or a compiler used to
+produce the work, or an object code interpreter used to run it.
+
+  The "Corresponding Source" for a work in object code form means all
+the source code needed to generate, install, and (for an executable
+work) run the object code and to modify the work, including scripts to
+control those activities.  However, it does not include the work's
+System Libraries, or general-purpose tools or generally available free
+programs which are used unmodified in performing those activities but
+which are not part of the work.  For example, Corresponding Source
+includes interface definition files associated with source files for
+the work, and the source code for shared libraries and dynamically
+linked subprograms that the work is specifically designed to require,
+such as by intimate data communication or control flow between those
+subprograms and other parts of the work.
+
+  The Corresponding Source need not include anything that users
+can regenerate automatically from other parts of the Corresponding
+Source.
+
+  The Corresponding Source for a work in source code form is that
+same work.
+
+  2. Basic Permissions.
+
+  All rights granted under this License are granted for the term of
+copyright on the Program, and are irrevocable provided the stated
+conditions are met.  This License explicitly affirms your unlimited
+permission to run the unmodified Program.  The output from running a
+covered work is covered by this License only if the output, given its
+content, constitutes a covered work.  This License acknowledges your
+rights of fair use or other equivalent, as provided by copyright law.
+
+  You may make, run and propagate covered works that you do not
+convey, without conditions so long as your license otherwise remains
+in force.  You may convey covered works to others for the sole purpose
+of having them make modifications exclusively for you, or provide you
+with facilities for running those works, provided that you comply with
+the terms of this License in conveying all material for which you do
+not control copyright.  Those thus making or running the covered works
+for you must do so exclusively on your behalf, under your direction
+and control, on terms that prohibit them from making any copies of
+your copyrighted material outside their relationship with you.
+
+  Conveying under any other circumstances is permitted solely under
+the conditions stated below.  Sublicensing is not allowed; section 10
+makes it unnecessary.
+
+  3. Protecting Users' Legal Rights From Anti-Circumvention Law.
+
+  No covered work shall be deemed part of an effective technological
+measure under any applicable law fulfilling obligations under article
+11 of the WIPO copyright treaty adopted on 20 December 1996, or
+similar laws prohibiting or restricting circumvention of such
+measures.
+
+  When you convey a covered work, you waive any legal power to forbid
+circumvention of technological measures to the extent such circumvention
+is effected by exercising rights under this License with respect to
+the covered work, and you disclaim any intention to limit operation or
+modification of the work as a means of enforcing, against the work's
+users, your or third parties' legal rights to forbid circumvention of
+technological measures.
+
+  4. Conveying Verbatim Copies.
+
+  You may convey verbatim copies of the Program's source code as you
+receive it, in any medium, provided that you conspicuously and
+appropriately publish on each copy an appropriate copyright notice;
+keep intact all notices stating that this License and any
+non-permissive terms added in accord with section 7 apply to the code;
+keep intact all notices of the absence of any warranty; and give all
+recipients a copy of this License along with the Program.
+
+  You may charge any price or no price for each copy that you convey,
+and you may offer support or warranty protection for a fee.
+
+  5. Conveying Modified Source Versions.
+
+  You may convey a work based on the Program, or the modifications to
+produce it from the Program, in the form of source code under the
+terms of section 4, provided that you also meet all of these conditions:
+
+    a) The work must carry prominent notices stating that you modified
+    it, and giving a relevant date.
+
+    b) The work must carry prominent notices stating that it is
+    released under this License and any conditions added under section
+    7.  This requirement modifies the requirement in section 4 to
+    "keep intact all notices".
+
+    c) You must license the entire work, as a whole, under this
+    License to anyone who comes into possession of a copy.  This
+    License will therefore apply, along with any applicable section 7
+    additional terms, to the whole of the work, and all its parts,
+    regardless of how they are packaged.  This License gives no
+    permission to license the work in any other way, but it does not
+    invalidate such permission if you have separately received it.
+
+    d) If the work has interactive user interfaces, each must display
+    Appropriate Legal Notices; however, if the Program has interactive
+    interfaces that do not display Appropriate Legal Notices, your
+    work need not make them do so.
+
+  A compilation of a covered work with other separate and independent
+works, which are not by their nature extensions of the covered work,
+and which are not combined with it such as to form a larger program,
+in or on a volume of a storage or distribution medium, is called an
+"aggregate" if the compilation and its resulting copyright are not
+used to limit the access or legal rights of the compilation's users
+beyond what the individual works permit.  Inclusion of a covered work
+in an aggregate does not cause this License to apply to the other
+parts of the aggregate.
+
+  6. Conveying Non-Source Forms.
+
+  You may convey a covered work in object code form under the terms
+of sections 4 and 5, provided that you also convey the
+machine-readable Corresponding Source under the terms of this License,
+in one of these ways:
+
+    a) Convey the object code in, or embodied in, a physical product
+    (including a physical distribution medium), accompanied by the
+    Corresponding Source fixed on a durable physical medium
+    customarily used for software interchange.
+
+    b) Convey the object code in, or embodied in, a physical product
+    (including a physical distribution medium), accompanied by a
+    written offer, valid for at least three years and valid for as
+    long as you offer spare parts or customer support for that product
+    model, to give anyone who possesses the object code either (1) a
+    copy of the Corresponding Source for all the software in the
+    product that is covered by this License, on a durable physical
+    medium customarily used for software interchange, for a price no
+    more than your reasonable cost of physically performing this
+    conveying of source, or (2) access to copy the
+    Corresponding Source from a network server at no charge.
+
+    c) Convey individual copies of the object code with a copy of the
+    written offer to provide the Corresponding Source.  This
+    alternative is allowed only occasionally and noncommercially, and
+    only if you received the object code with such an offer, in accord
+    with subsection 6b.
+
+    d) Convey the object code by offering access from a designated
+    place (gratis or for a charge), and offer equivalent access to the
+    Corresponding Source in the same way through the same place at no
+    further charge.  You need not require recipients to copy the
+    Corresponding Source along with the object code.  If the place to
+    copy the object code is a network server, the Corresponding Source
+    may be on a different server (operated by you or a third party)
+    that supports equivalent copying facilities, provided you maintain
+    clear directions next to the object code saying where to find the
+    Corresponding Source.  Regardless of what server hosts the
+    Corresponding Source, you remain obligated to ensure that it is
+    available for as long as needed to satisfy these requirements.
+
+    e) Convey the object code using peer-to-peer transmission, provided
+    you inform other peers where the object code and Corresponding
+    Source of the work are being offered to the general public at no
+    charge under subsection 6d.
+
+  A separable portion of the object code, whose source code is excluded
+from the Corresponding Source as a System Library, need not be
+included in conveying the object code work.
+
+  A "User Product" is either (1) a "consumer product", which means any
+tangible personal property which is normally used for personal, family,
+or household purposes, or (2) anything designed or sold for incorporation
+into a dwelling.  In determining whether a product is a consumer product,
+doubtful cases shall be resolved in favor of coverage.  For a particular
+product received by a particular user, "normally used" refers to a
+typical or common use of that class of product, regardless of the status
+of the particular user or of the way in which the particular user
+actually uses, or expects or is expected to use, the product.  A product
+is a consumer product regardless of whether the product has substantial
+commercial, industrial or non-consumer uses, unless such uses represent
+the only significant mode of use of the product.
+
+  "Installation Information" for a User Product means any methods,
+procedures, authorization keys, or other information required to install
+and execute modified versions of a covered work in that User Product from
+a modified version of its Corresponding Source.  The information must
+suffice to ensure that the continued functioning of the modified object
+code is in no case prevented or interfered with solely because
+modification has been made.
+
+  If you convey an object code work under this section in, or with, or
+specifically for use in, a User Product, and the conveying occurs as
+part of a transaction in which the right of possession and use of the
+User Product is transferred to the recipient in perpetuity or for a
+fixed term (regardless of how the transaction is characterized), the
+Corresponding Source conveyed under this section must be accompanied
+by the Installation Information.  But this requirement does not apply
+if neither you nor any third party retains the ability to install
+modified object code on the User Product (for example, the work has
+been installed in ROM).
+
+  The requirement to provide Installation Information does not include a
+requirement to continue to provide support service, warranty, or updates
+for a work that has been modified or installed by the recipient, or for
+the User Product in which it has been modified or installed.  Access to a
+network may be denied when the modification itself materially and
+adversely affects the operation of the network or violates the rules and
+protocols for communication across the network.
+
+  Corresponding Source conveyed, and Installation Information provided,
+in accord with this section must be in a format that is publicly
+documented (and with an implementation available to the public in
+source code form), and must require no special password or key for
+unpacking, reading or copying.
+
+  7. Additional Terms.
+
+  "Additional permissions" are terms that supplement the terms of this
+License by making exceptions from one or more of its conditions.
+Additional permissions that are applicable to the entire Program shall
+be treated as though they were included in this License, to the extent
+that they are valid under applicable law.  If additional permissions
+apply only to part of the Program, that part may be used separately
+under those permissions, but the entire Program remains governed by
+this License without regard to the additional permissions.
+
+  When you convey a copy of a covered work, you may at your option
+remove any additional permissions from that copy, or from any part of
+it.  (Additional permissions may be written to require their own
+removal in certain cases when you modify the work.)  You may place
+additional permissions on material, added by you to a covered work,
+for which you have or can give appropriate copyright permission.
+
+  Notwithstanding any other provision of this License, for material you
+add to a covered work, you may (if authorized by the copyright holders of
+that material) supplement the terms of this License with terms:
+
+    a) Disclaiming warranty or limiting liability differently from the
+    terms of sections 15 and 16 of this License; or
+
+    b) Requiring preservation of specified reasonable legal notices or
+    author attributions in that material or in the Appropriate Legal
+    Notices displayed by works containing it; or
+
+    c) Prohibiting misrepresentation of the origin of that material, or
+    requiring that modified versions of such material be marked in
+    reasonable ways as different from the original version; or
+
+    d) Limiting the use for publicity purposes of names of licensors or
+    authors of the material; or
+
+    e) Declining to grant rights under trademark law for use of some
+    trade names, trademarks, or service marks; or
+
+    f) Requiring indemnification of licensors and authors of that
+    material by anyone who conveys the material (or modified versions of
+    it) with contractual assumptions of liability to the recipient, for
+    any liability that these contractual assumptions directly impose on
+    those licensors and authors.
+
+  All other non-permissive additional terms are considered "further
+restrictions" within the meaning of section 10.  If the Program as you
+received it, or any part of it, contains a notice stating that it is
+governed by this License along with a term that is a further
+restriction, you may remove that term.  If a license document contains
+a further restriction but permits relicensing or conveying under this
+License, you may add to a covered work material governed by the terms
+of that license document, provided that the further restriction does
+not survive such relicensing or conveying.
+
+  If you add terms to a covered work in accord with this section, you
+must place, in the relevant source files, a statement of the
+additional terms that apply to those files, or a notice indicating
+where to find the applicable terms.
+
+  Additional terms, permissive or non-permissive, may be stated in the
+form of a separately written license, or stated as exceptions;
+the above requirements apply either way.
+
+  8. Termination.
+
+  You may not propagate or modify a covered work except as expressly
+provided under this License.  Any attempt otherwise to propagate or
+modify it is void, and will automatically terminate your rights under
+this License (including any patent licenses granted under the third
+paragraph of section 11).
+
+  However, if you cease all violation of this License, then your
+license from a particular copyright holder is reinstated (a)
+provisionally, unless and until the copyright holder explicitly and
+finally terminates your license, and (b) permanently, if the copyright
+holder fails to notify you of the violation by some reasonable means
+prior to 60 days after the cessation.
+
+  Moreover, your license from a particular copyright holder is
+reinstated permanently if the copyright holder notifies you of the
+violation by some reasonable means, this is the first time you have
+received notice of violation of this License (for any work) from that
+copyright holder, and you cure the violation prior to 30 days after
+your receipt of the notice.
+
+  Termination of your rights under this section does not terminate the
+licenses of parties who have received copies or rights from you under
+this License.  If your rights have been terminated and not permanently
+reinstated, you do not qualify to receive new licenses for the same
+material under section 10.
+
+  9. Acceptance Not Required for Having Copies.
+
+  You are not required to accept this License in order to receive or
+run a copy of the Program.  Ancillary propagation of a covered work
+occurring solely as a consequence of using peer-to-peer transmission
+to receive a copy likewise does not require acceptance.  However,
+nothing other than this License grants you permission to propagate or
+modify any covered work.  These actions infringe copyright if you do
+not accept this License.  Therefore, by modifying or propagating a
+covered work, you indicate your acceptance of this License to do so.
+
+  10. Automatic Licensing of Downstream Recipients.
+
+  Each time you convey a covered work, the recipient automatically
+receives a license from the original licensors, to run, modify and
+propagate that work, subject to this License.  You are not responsible
+for enforcing compliance by third parties with this License.
+
+  An "entity transaction" is a transaction transferring control of an
+organization, or substantially all assets of one, or subdividing an
+organization, or merging organizations.  If propagation of a covered
+work results from an entity transaction, each party to that
+transaction who receives a copy of the work also receives whatever
+licenses to the work the party's predecessor in interest had or could
+give under the previous paragraph, plus a right to possession of the
+Corresponding Source of the work from the predecessor in interest, if
+the predecessor has it or can get it with reasonable efforts.
+
+  You may not impose any further restrictions on the exercise of the
+rights granted or affirmed under this License.  For example, you may
+not impose a license fee, royalty, or other charge for exercise of
+rights granted under this License, and you may not initiate litigation
+(including a cross-claim or counterclaim in a lawsuit) alleging that
+any patent claim is infringed by making, using, selling, offering for
+sale, or importing the Program or any portion of it.
+
+  11. Patents.
+
+  A "contributor" is a copyright holder who authorizes use under this
+License of the Program or a work on which the Program is based.  The
+work thus licensed is called the contributor's "contributor version".
+
+  A contributor's "essential patent claims" are all patent claims
+owned or controlled by the contributor, whether already acquired or
+hereafter acquired, that would be infringed by some manner, permitted
+by this License, of making, using, or selling its contributor version,
+but do not include claims that would be infringed only as a
+consequence of further modification of the contributor version.  For
+purposes of this definition, "control" includes the right to grant
+patent sublicenses in a manner consistent with the requirements of
+this License.
+
+  Each contributor grants you a non-exclusive, worldwide, royalty-free
+patent license under the contributor's essential patent claims, to
+make, use, sell, offer for sale, import and otherwise run, modify and
+propagate the contents of its contributor version.
+
+  In the following three paragraphs, a "patent license" is any express
+agreement or commitment, however denominated, not to enforce a patent
+(such as an express permission to practice a patent or covenant not to
+sue for patent infringement).  To "grant" such a patent license to a
+party means to make such an agreement or commitment not to enforce a
+patent against the party.
+
+  If you convey a covered work, knowingly relying on a patent license,
+and the Corresponding Source of the work is not available for anyone
+to copy, free of charge and under the terms of this License, through a
+publicly available network server or other readily accessible means,
+then you must either (1) cause the Corresponding Source to be so
+available, or (2) arrange to deprive yourself of the benefit of the
+patent license for this particular work, or (3) arrange, in a manner
+consistent with the requirements of this License, to extend the patent
+license to downstream recipients.  "Knowingly relying" means you have
+actual knowledge that, but for the patent license, your conveying the
+covered work in a country, or your recipient's use of the covered work
+in a country, would infringe one or more identifiable patents in that
+country that you have reason to believe are valid.
+
+  If, pursuant to or in connection with a single transaction or
+arrangement, you convey, or propagate by procuring conveyance of, a
+covered work, and grant a patent license to some of the parties
+receiving the covered work authorizing them to use, propagate, modify
+or convey a specific copy of the covered work, then the patent license
+you grant is automatically extended to all recipients of the covered
+work and works based on it.
+
+  A patent license is "discriminatory" if it does not include within
+the scope of its coverage, prohibits the exercise of, or is
+conditioned on the non-exercise of one or more of the rights that are
+specifically granted under this License.  You may not convey a covered
+work if you are a party to an arrangement with a third party that is
+in the business of distributing software, under which you make payment
+to the third party based on the extent of your activity of conveying
+the work, and under which the third party grants, to any of the
+parties who would receive the covered work from you, a discriminatory
+patent license (a) in connection with copies of the covered work
+conveyed by you (or copies made from those copies), or (b) primarily
+for and in connection with specific products or compilations that
+contain the covered work, unless you entered into that arrangement,
+or that patent license was granted, prior to 28 March 2007.
+
+  Nothing in this License shall be construed as excluding or limiting
+any implied license or other defenses to infringement that may
+otherwise be available to you under applicable patent law.
+
+  12. No Surrender of Others' Freedom.
+
+  If conditions are imposed on you (whether by court order, agreement or
+otherwise) that contradict the conditions of this License, they do not
+excuse you from the conditions of this License.  If you cannot convey a
+covered work so as to satisfy simultaneously your obligations under this
+License and any other pertinent obligations, then as a consequence you may
+not convey it at all.  For example, if you agree to terms that obligate you
+to collect a royalty for further conveying from those to whom you convey
+the Program, the only way you could satisfy both those terms and this
+License would be to refrain entirely from conveying the Program.
+
+  13. Use with the GNU Affero General Public License.
+
+  Notwithstanding any other provision of this License, you have
+permission to link or combine any covered work with a work licensed
+under version 3 of the GNU Affero General Public License into a single
+combined work, and to convey the resulting work.  The terms of this
+License will continue to apply to the part which is the covered work,
+but the special requirements of the GNU Affero General Public License,
+section 13, concerning interaction through a network will apply to the
+combination as such.
+
+  14. Revised Versions of this License.
+
+  The Free Software Foundation may publish revised and/or new versions of
+the GNU General Public License from time to time.  Such new versions will
+be similar in spirit to the present version, but may differ in detail to
+address new problems or concerns.
+
+  Each version is given a distinguishing version number.  If the
+Program specifies that a certain numbered version of the GNU General
+Public License "or any later version" applies to it, you have the
+option of following the terms and conditions either of that numbered
+version or of any later version published by the Free Software
+Foundation.  If the Program does not specify a version number of the
+GNU General Public License, you may choose any version ever published
+by the Free Software Foundation.
+
+  If the Program specifies that a proxy can decide which future
+versions of the GNU General Public License can be used, that proxy's
+public statement of acceptance of a version permanently authorizes you
+to choose that version for the Program.
+
+  Later license versions may give you additional or different
+permissions.  However, no additional obligations are imposed on any
+author or copyright holder as a result of your choosing to follow a
+later version.
+
+  15. Disclaimer of Warranty.
+
+  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
+APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
+HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
+OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
+THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
+IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
+ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
+
+  16. Limitation of Liability.
+
+  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
+WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
+THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
+GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
+USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
+DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
+PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
+EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
+SUCH DAMAGES.
+
+  17. Interpretation of Sections 15 and 16.
+
+  If the disclaimer of warranty and limitation of liability provided
+above cannot be given local legal effect according to their terms,
+reviewing courts shall apply local law that most closely approximates
+an absolute waiver of all civil liability in connection with the
+Program, unless a warranty or assumption of liability accompanies a
+copy of the Program in return for a fee.
+
+                     END OF TERMS AND CONDITIONS
+
+            How to Apply These Terms to Your New Programs
+
+  If you develop a new program, and you want it to be of the greatest
+possible use to the public, the best way to achieve this is to make it
+free software which everyone can redistribute and change under these terms.
+
+  To do so, attach the following notices to the program.  It is safest
+to attach them to the start of each source file to most effectively
+state the exclusion of warranty; and each file should have at least
+the "copyright" line and a pointer to where the full notice is found.
+
+    <one line to give the program's name and a brief idea of what it does.>
+    Copyright (C) <year>  <name of author>
+
+    This program is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+Also add information on how to contact you by electronic and paper mail.
+
+  If the program does terminal interaction, make it output a short
+notice like this when it starts in an interactive mode:
+
+    <program>  Copyright (C) <year>  <name of author>
+    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
+    This is free software, and you are welcome to redistribute it
+    under certain conditions; type `show c' for details.
+
+The hypothetical commands `show w' and `show c' should show the appropriate
+parts of the General Public License.  Of course, your program's commands
+might be different; for a GUI interface, you would use an "about box".
+
+  You should also get your employer (if you work as a programmer) or school,
+if any, to sign a "copyright disclaimer" for the program, if necessary.
+For more information on this, and how to apply and follow the GNU GPL, see
+<http://www.gnu.org/licenses/>.
+
+  The GNU General Public License does not permit incorporating your program
+into proprietary programs.  If your program is a subroutine library, you
+may consider it more useful to permit linking proprietary applications with
+the library.  If this is what you want to do, use the GNU Lesser General
+Public License instead of this License.  But first, please read
+<http://www.gnu.org/philosophy/why-not-lgpl.html>.
```

### Comparing `extract_msg-0.40.0/PKG-INFO` & `extract_msg-0.41.0/extract_msg.egg-info/PKG-INFO`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,16 @@
 Metadata-Version: 2.1
-Name: extract_msg
-Version: 0.40.0
+Name: extract-msg
+Version: 0.41.0
 Summary: Extracts emails and attachments saved in Microsoft Outlook's .msg files
 Home-page: https://github.com/TeamMsgExtractor/msg-extractor
+Download-URL: https://github.com/TeamMsgExtractor/msg-extractor/archives/master
 Author: Destiny Peterson & Matthew Walker
 Author-email: arceusthe@gmail.com, mattgwwalker@gmail.com
 License: GPL
-Download-URL: https://github.com/TeamMsgExtractor/msg-extractor/archives/master
-Platform: UNKNOWN
 Requires-Python: >=3.8
 Description-Content-Type: text/x-rst
 Provides-Extra: all
 Provides-Extra: mime
 License-File: LICENSE.txt
 
 |License: GPL v3| |PyPI3| |PyPI2|
@@ -71,60 +70,69 @@
 
 
 #########REWRITE COMMAND LINE USAGE#############
 Currently, the README is in the process of being redone. For now, please
 refer to the usage information provided from the program's help dialog:
 ::
 
-    usage: extract_msg [-h] [--use-content-id] [--dev] [--validate] [--json] [--file-logging] [--verbose] [--log LOG] [--config CONFIGPATH] [--out OUTPATH] [--use-filename]
-                   [--dump-stdout] [--html] [--pdf] [--wk-path WKPATH] [--wk-options [WKOPTIONS ...]] [--prepared-html] [--charset CHARSET] [--raw] [--rtf]
-                   [--allow-fallback] [--zip ZIP] [--attachments-only] [--no-folders] [--skip-embedded] [--out-name OUTNAME | --glob] [--ignore-rtfde] [--progress]
-                   msg [msg ...]
+    usage: extract_msg [-h] [--use-content-id] [--validate] [--json] [--file-logging] [-v] [--log LOG] [--config CONFIGPATH]
+                       [--out OUTPATH] [--use-filename] [--dump-stdout] [--html] [--pdf] [--wk-path WKPATH]
+                       [--wk-options [WKOPTIONS ...]] [--prepared-html] [--charset CHARSET] [--raw] [--rtf] [--allow-fallback]
+                       [--skip-body-not-found] [--zip ZIP] [--save-header] [--attachments-only] [--skip-hidden] [--no-folders]
+                       [--skip-embedded] [--extract-embedded] [--skip-not-implemented] [--out-name OUTNAME | --glob] [--ignore-rtfde]
+                       [--progress]
+                       msg [msg ...]
 
-    extract_msg: Extracts emails and attachments saved in Microsoft Outlook's .msg files. https://github.com/TeamMsgExtractor/msg-extractor
+    extract_msg: Extracts emails and attachments saved in Microsoft Outlook's .msg files. https://github.com/TeamMsgExtractor/msg-
+    extractor
 
     positional arguments:
       msg                   An MSG file to be parsed.
 
     optional arguments:
       -h, --help            show this help message and exit
       --use-content-id, --cid
                             Save attachments by their Content ID, if they have one. Useful when working with the HTML body.
-      --dev                 Changes to use developer mode. Automatically enables the --verbose flag. Takes precedence over the --validate flag.
       --validate            Turns on file validation mode. Turns off regular file output.
       --json                Changes to write output files as json.
       --file-logging        Enables file logging. Implies --verbose level 1.
       -v, --verbose         Turns on console logging. Specify more than once for higher verbosity.
       --log LOG             Set the path to write the file log to.
       --config CONFIGPATH   Set the path to load the logging config from.
       --out OUTPATH         Set the folder to use for the program output. (Default: Current directory)
       --use-filename        Sets whether the name of each output is based on the msg filename.
       --dump-stdout         Tells the program to dump the message body (plain text) to stdout. Overrides saving arguments.
       --html                Sets whether the output should be HTML. If this is not possible, will error.
       --pdf                 Saves the body as a PDF. If this is not possible, will error.
       --wk-path WKPATH      Overrides the path for finding wkhtmltopdf.
       --wk-options [WKOPTIONS ...]
-                            Sets additional options to be used in wkhtmltopdf. Should be a series of options and values, replacing the - or -- in the beginning with + or ++,
-                            respectively. For example: --wk-options "+O Landscape"
-      --prepared-html       When used in conjunction with --html, sets whether the HTML output should be prepared for embedded attachments.
+                            Sets additional options to be used in wkhtmltopdf. Should be a series of options and values, replacing the -
+                            or -- in the beginning with + or ++, respectively. For example: --wk-options "+O Landscape"
+      --prepared-html       When used in conjunction with --html, sets whether the HTML output should be prepared for embedded
+                            attachments.
       --charset CHARSET     Character set to use for the prepared HTML in the added tag. (Default: utf-8)
       --raw                 Sets whether the output should be raw. If this is not possible, will error.
       --rtf                 Sets whether the output should be RTF. If this is not possible, will error.
       --allow-fallback      Tells the program to fallback to a different save type if the selected one is not possible.
-      --skip-body-not-found Skips saving the body if the body cannot be found, rather than throwing an error.
+      --skip-body-not-found
+                            Skips saving the body if the body cannot be found, rather than throwing an error.
       --zip ZIP             Path to use for saving to a zip file.
       --save-header         Store the header in a separate file.
       --attachments-only    Specify to only save attachments from an msg file.
       --skip-hidden         Skips any attachment marked as hidden (usually ones embedded in the body).
-      --no-folders          When used with --attachments-only, stores everything in the location specified by --out. Incompatible with --out-name.
+      --no-folders          Stores everything in the location specified by --out. Requires --attachments-only and is incompatible with
+                            --out-name.
       --skip-embedded       Skips all embedded MSG files when saving attachments.
       --extract-embedded    Extracts the embedded MSG files as MSG files instead of running their save functions.
+      --skip-not-implemented, --skip-ni
+                            Skips any attachments that are not implemented, allowing saving of the rest of the message.
       --out-name OUTNAME    Name to be used with saving the file output. Cannot be used if you are saving more than one file.
       --glob, --wildcard    Interpret all paths as having wildcards. Incompatible with --out-name.
-      --ignore-rtfde        Ignores all errors thrown from RTFDE when trying to save. Useful for allowing fallback to continue when an exception happens.
+      --ignore-rtfde        Ignores all errors thrown from RTFDE when trying to save. Useful for allowing fallback to continue when an
+                            exception happens.
       --progress            Shows what file the program is currently working on during it's progress.
 
 **To use this in your own script**, start by using:
 
 ::
 
      import extract_msg
@@ -235,15 +243,15 @@
 
 `Philippe Lagadec`_ - Python OleFile module developer.
 
 `Joel Kaufman`_ - First implementations of the json and filename flags.
 
 `Dean Malmgren`_ - First implementation of the setup.py script.
 
-`Seamus Tuohy`_ - Developer of the Python RTFDE module. Gave first examples of how to use the module.
+`Seamus Tuohy`_ - Developer of the Python RTFDE module. Gave first examples of how to use the module and has worked with Destiny to ensure functionality.
 
 `Liam`_ - Significant reorganization and transfer of data.
 
 And thank you to everyone who has opened an issue and helped us track down those pesky bugs.
 
 Extra
 -----
@@ -253,16 +261,16 @@
 major release to ensure continued support. Because of this, it is recommended to
 install it to a separate environment (like a vitural env) to not interfere with
 your access to the newest major version of extract-msg.
 
 .. |License: GPL v3| image:: https://img.shields.io/badge/License-GPLv3-blue.svg
    :target: LICENSE.txt
 
-.. |PyPI3| image:: https://img.shields.io/badge/pypi-0.40.0-blue.svg
-   :target: https://pypi.org/project/extract-msg/0.40.0/
+.. |PyPI3| image:: https://img.shields.io/badge/pypi-0.41.0-blue.svg
+   :target: https://pypi.org/project/extract-msg/0.41.0/
 
 .. |PyPI2| image:: https://img.shields.io/badge/python-3.8+-brightgreen.svg
    :target: https://www.python.org/downloads/release/python-3816/
 .. _Matthew Walker: https://github.com/mattgwwalker
 .. _Destiny Peterson (The Elemental of Destruction): https://github.com/TheElementalOfDestruction
 .. _JP Bourget: https://github.com/punkrokk
 .. _Philippe Lagadec: https://github.com/decalage2
@@ -274,9 +282,7 @@
 .. _Buy Me a Coffee: https://www.buymeacoffee.com/DestructionE
 .. _Ko-fi: https://ko-fi.com/destructione
 .. _Patreon: https://www.patreon.com/DestructionE
 .. _msg-explorer: https://pypi.org/project/msg-explorer/
 .. _wiki: https://github.com/TeamMsgExtractor/msg-extractor/wiki
 .. _read the docs: https://msg-extractor.rtfd.io/
 .. _Changelog: https://github.com/TeamMsgExtractor/msg-extractor/blob/master/CHANGELOG.md
-
-
```

### Comparing `extract_msg-0.40.0/README.rst` & `extract_msg-0.41.0/PKG-INFO`

 * *Files 6% similar despite different names*

```diff
@@ -1,7 +1,22 @@
+Metadata-Version: 2.1
+Name: extract_msg
+Version: 0.41.0
+Summary: Extracts emails and attachments saved in Microsoft Outlook's .msg files
+Home-page: https://github.com/TeamMsgExtractor/msg-extractor
+Download-URL: https://github.com/TeamMsgExtractor/msg-extractor/archives/master
+Author: Destiny Peterson & Matthew Walker
+Author-email: arceusthe@gmail.com, mattgwwalker@gmail.com
+License: GPL
+Requires-Python: >=3.8
+Description-Content-Type: text/x-rst
+Provides-Extra: all
+Provides-Extra: mime
+License-File: LICENSE.txt
+
 |License: GPL v3| |PyPI3| |PyPI2|
 
 extract-msg
 =============
 
 Extracts emails and attachments saved in Microsoft Outlook's .msg files
 
@@ -55,60 +70,69 @@
 
 
 #########REWRITE COMMAND LINE USAGE#############
 Currently, the README is in the process of being redone. For now, please
 refer to the usage information provided from the program's help dialog:
 ::
 
-    usage: extract_msg [-h] [--use-content-id] [--dev] [--validate] [--json] [--file-logging] [--verbose] [--log LOG] [--config CONFIGPATH] [--out OUTPATH] [--use-filename]
-                   [--dump-stdout] [--html] [--pdf] [--wk-path WKPATH] [--wk-options [WKOPTIONS ...]] [--prepared-html] [--charset CHARSET] [--raw] [--rtf]
-                   [--allow-fallback] [--zip ZIP] [--attachments-only] [--no-folders] [--skip-embedded] [--out-name OUTNAME | --glob] [--ignore-rtfde] [--progress]
-                   msg [msg ...]
+    usage: extract_msg [-h] [--use-content-id] [--validate] [--json] [--file-logging] [-v] [--log LOG] [--config CONFIGPATH]
+                       [--out OUTPATH] [--use-filename] [--dump-stdout] [--html] [--pdf] [--wk-path WKPATH]
+                       [--wk-options [WKOPTIONS ...]] [--prepared-html] [--charset CHARSET] [--raw] [--rtf] [--allow-fallback]
+                       [--skip-body-not-found] [--zip ZIP] [--save-header] [--attachments-only] [--skip-hidden] [--no-folders]
+                       [--skip-embedded] [--extract-embedded] [--skip-not-implemented] [--out-name OUTNAME | --glob] [--ignore-rtfde]
+                       [--progress]
+                       msg [msg ...]
 
-    extract_msg: Extracts emails and attachments saved in Microsoft Outlook's .msg files. https://github.com/TeamMsgExtractor/msg-extractor
+    extract_msg: Extracts emails and attachments saved in Microsoft Outlook's .msg files. https://github.com/TeamMsgExtractor/msg-
+    extractor
 
     positional arguments:
       msg                   An MSG file to be parsed.
 
     optional arguments:
       -h, --help            show this help message and exit
       --use-content-id, --cid
                             Save attachments by their Content ID, if they have one. Useful when working with the HTML body.
-      --dev                 Changes to use developer mode. Automatically enables the --verbose flag. Takes precedence over the --validate flag.
       --validate            Turns on file validation mode. Turns off regular file output.
       --json                Changes to write output files as json.
       --file-logging        Enables file logging. Implies --verbose level 1.
       -v, --verbose         Turns on console logging. Specify more than once for higher verbosity.
       --log LOG             Set the path to write the file log to.
       --config CONFIGPATH   Set the path to load the logging config from.
       --out OUTPATH         Set the folder to use for the program output. (Default: Current directory)
       --use-filename        Sets whether the name of each output is based on the msg filename.
       --dump-stdout         Tells the program to dump the message body (plain text) to stdout. Overrides saving arguments.
       --html                Sets whether the output should be HTML. If this is not possible, will error.
       --pdf                 Saves the body as a PDF. If this is not possible, will error.
       --wk-path WKPATH      Overrides the path for finding wkhtmltopdf.
       --wk-options [WKOPTIONS ...]
-                            Sets additional options to be used in wkhtmltopdf. Should be a series of options and values, replacing the - or -- in the beginning with + or ++,
-                            respectively. For example: --wk-options "+O Landscape"
-      --prepared-html       When used in conjunction with --html, sets whether the HTML output should be prepared for embedded attachments.
+                            Sets additional options to be used in wkhtmltopdf. Should be a series of options and values, replacing the -
+                            or -- in the beginning with + or ++, respectively. For example: --wk-options "+O Landscape"
+      --prepared-html       When used in conjunction with --html, sets whether the HTML output should be prepared for embedded
+                            attachments.
       --charset CHARSET     Character set to use for the prepared HTML in the added tag. (Default: utf-8)
       --raw                 Sets whether the output should be raw. If this is not possible, will error.
       --rtf                 Sets whether the output should be RTF. If this is not possible, will error.
       --allow-fallback      Tells the program to fallback to a different save type if the selected one is not possible.
-      --skip-body-not-found Skips saving the body if the body cannot be found, rather than throwing an error.
+      --skip-body-not-found
+                            Skips saving the body if the body cannot be found, rather than throwing an error.
       --zip ZIP             Path to use for saving to a zip file.
       --save-header         Store the header in a separate file.
       --attachments-only    Specify to only save attachments from an msg file.
       --skip-hidden         Skips any attachment marked as hidden (usually ones embedded in the body).
-      --no-folders          When used with --attachments-only, stores everything in the location specified by --out. Incompatible with --out-name.
+      --no-folders          Stores everything in the location specified by --out. Requires --attachments-only and is incompatible with
+                            --out-name.
       --skip-embedded       Skips all embedded MSG files when saving attachments.
       --extract-embedded    Extracts the embedded MSG files as MSG files instead of running their save functions.
+      --skip-not-implemented, --skip-ni
+                            Skips any attachments that are not implemented, allowing saving of the rest of the message.
       --out-name OUTNAME    Name to be used with saving the file output. Cannot be used if you are saving more than one file.
       --glob, --wildcard    Interpret all paths as having wildcards. Incompatible with --out-name.
-      --ignore-rtfde        Ignores all errors thrown from RTFDE when trying to save. Useful for allowing fallback to continue when an exception happens.
+      --ignore-rtfde        Ignores all errors thrown from RTFDE when trying to save. Useful for allowing fallback to continue when an
+                            exception happens.
       --progress            Shows what file the program is currently working on during it's progress.
 
 **To use this in your own script**, start by using:
 
 ::
 
      import extract_msg
@@ -219,15 +243,15 @@
 
 `Philippe Lagadec`_ - Python OleFile module developer.
 
 `Joel Kaufman`_ - First implementations of the json and filename flags.
 
 `Dean Malmgren`_ - First implementation of the setup.py script.
 
-`Seamus Tuohy`_ - Developer of the Python RTFDE module. Gave first examples of how to use the module.
+`Seamus Tuohy`_ - Developer of the Python RTFDE module. Gave first examples of how to use the module and has worked with Destiny to ensure functionality.
 
 `Liam`_ - Significant reorganization and transfer of data.
 
 And thank you to everyone who has opened an issue and helped us track down those pesky bugs.
 
 Extra
 -----
@@ -237,16 +261,16 @@
 major release to ensure continued support. Because of this, it is recommended to
 install it to a separate environment (like a vitural env) to not interfere with
 your access to the newest major version of extract-msg.
 
 .. |License: GPL v3| image:: https://img.shields.io/badge/License-GPLv3-blue.svg
    :target: LICENSE.txt
 
-.. |PyPI3| image:: https://img.shields.io/badge/pypi-0.40.0-blue.svg
-   :target: https://pypi.org/project/extract-msg/0.40.0/
+.. |PyPI3| image:: https://img.shields.io/badge/pypi-0.41.0-blue.svg
+   :target: https://pypi.org/project/extract-msg/0.41.0/
 
 .. |PyPI2| image:: https://img.shields.io/badge/python-3.8+-brightgreen.svg
    :target: https://www.python.org/downloads/release/python-3816/
 .. _Matthew Walker: https://github.com/mattgwwalker
 .. _Destiny Peterson (The Elemental of Destruction): https://github.com/TheElementalOfDestruction
 .. _JP Bourget: https://github.com/punkrokk
 .. _Philippe Lagadec: https://github.com/decalage2
```

### Comparing `extract_msg-0.40.0/extract_msg/__init__.py` & `extract_msg-0.41.0/extract_msg/__init__.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,53 +1,79 @@
-#!/usr/bin/env python3
-# -*- coding: latin-1 -*-
-# Date Format: YYYY-MM-DD
-
-"""
-extract_msg:
-    Extracts emails and attachments saved in Microsoft Outlook's .msg files.
-
-https://github.com/TeamMsgExtractor/msg-extractor
-"""
-
-# --- LICENSE.txt --------------------------------------------------------------
-#
-#    Copyright 2013-2022 Matthew Walker and Destiny Peterson
-#
-#    This program is free software: you can redistribute it and/or modify
-#    it under the terms of the GNU General Public License as published by
-#    the Free Software Foundation, either version 3 of the License, or
-#    (at your option) any later version.
-#
-#    This program is distributed in the hope that it will be useful,
-#    but WITHOUT ANY WARRANTY; without even the implied warranty of
-#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-#    GNU General Public License for more details.
-#
-#    You should have received a copy of the GNU General Public License
-#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
-
-__author__ = 'Destiny Peterson & Matthew Walker'
-__date__ = '2023-03-18'
-__version__ = '0.40.0'
-
-import logging
-
-from . import constants, enums
-from .appointment import AppointmentMeeting
-from .attachment import Attachment
-from .contact import Contact
-from .exceptions import UnrecognizedMSGTypeError
-from .meeting_forward import MeetingForwardNotification
-from .meeting_request import MeetingRequest
-from .meeting_response import MeetingResponse
-from .message import Message
-from .message_base import MessageBase
-from .message_signed import MessageSigned
-from .message_signed_base import MessageSignedBase
-from .msg import MSGFile
-from .post import Post
-from .prop import createProp
-from .properties import Properties
-from .recipient import Recipient
-from .task import Task
-from .utils import openMsg, openMsgBulk, properHex
+#!/usr/bin/env python3
+# -*- coding: latin-1 -*-
+# Date Format: YYYY-MM-DD
+
+"""
+extract_msg:
+    Extracts emails and attachments saved in Microsoft Outlook's .msg files.
+
+https://github.com/TeamMsgExtractor/msg-extractor
+"""
+
+# --- LICENSE.txt --------------------------------------------------------------
+#
+#    Copyright 2013-2022 Matthew Walker and Destiny Peterson
+#
+#    This program is free software: you can redistribute it and/or modify
+#    it under the terms of the GNU General Public License as published by
+#    the Free Software Foundation, either version 3 of the License, or
+#    (at your option) any later version.
+#
+#    This program is distributed in the hope that it will be useful,
+#    but WITHOUT ANY WARRANTY; without even the implied warranty of
+#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+#    GNU General Public License for more details.
+#
+#    You should have received a copy of the GNU General Public License
+#    along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+__author__ = 'Destiny Peterson & Matthew Walker'
+__date__ = '2023-05-09'
+__version__ = '0.41.0'
+
+__all__ = [
+    # Modules:
+    'constants',
+    'enums',
+    'exceptions',
+
+    # Classes:
+    'AppointmentMeeting',
+    'Attachment',
+    'Contact',
+    'MeetingForwardNotification',
+    'MeetingRequest',
+    'MeetingResponse',
+    'Message',
+    'MessageBase',
+    'MessageSigned',
+    'MessageSignedBase',
+    'MSGFile',
+    'Post',
+    'Properties',
+    'Recipient',
+    'Task',
+
+    #Functions:
+    'createProp',
+    'openMsg',
+    'openMsgBulk',
+]
+
+from . import constants, enums, exceptions
+from .appointment import AppointmentMeeting
+from .attachment import Attachment
+from .contact import Contact
+from .meeting_forward import MeetingForwardNotification
+from .meeting_request import MeetingRequest
+from .meeting_response import MeetingResponse
+from .message import Message
+from .message_base import MessageBase
+from .message_signed import MessageSigned
+from .message_signed_base import MessageSignedBase
+from .msg import MSGFile
+from .post import Post
+from .prop import createProp
+from .properties import Properties
+from .recipient import Recipient
+from .task import Task
+from .utils import openMsg, openMsgBulk
```

### Comparing `extract_msg-0.40.0/extract_msg/_rtf/inject_rtf.py` & `extract_msg-0.41.0/extract_msg/_rtf/inject_rtf.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,166 +1,168 @@
-import copy
-
-from .token import Token, TokenType
-from .tokenize_rtf import tokenizeRTF
-
-from typing import List, Iterable, Optional, Union
-
-
-# A tuple of destinations used in the header. All ignorable ones are skipped
-# anyways, so we don't need to list those here.
-_HEADER_DESTINATIONS = (
-    b'fonttbl',
-    b'colortbl',
-    b'stylesheet',
-)
-
-# A tuple of control words that are part of the header and that we simply skip.
-_HEADER_SKIPPABLE = (
-    # Tag used to specify something.
-    b'fbidis',
-    # Character set tags.
-    b'ansi',
-    b'mac',
-    b'pc',
-    b'pca',
-    b'ansicpg',
-    # From.
-    b'fromtext',
-    b'fromhtml',
-    # Def font.
-    b'deff',
-    b'adeff',
-    b'stshfdbch',
-    b'stshfloch',
-    b'stshfhich',
-    b'stshfbi',
-    # Def lang.
-    b'deflang',
-    b'deflangfe',
-    b'adeflang',
-)
-
-
-def _listInsertMult(dest : List, source : Iterable, index : int = -1):
-    """
-    Inserts into :param dest: all the items in :param source: at the index
-    specified. :param dest: can be any mutable sequence with :method insert:,
-    :method __len__:, and :method extend:.
-
-    If :param index: is not specified, the default position is the end of the
-    list. This is also where things will be inserted if index is greater than or
-    equal to the size of the list.
-    """
-    if index == -1 or index >= len(dest):
-        dest.extend(source)
-    else:
-        for offset, item in enumerate(source):
-            dest.insert(index + offset, item)
-
-
-def injectStartRTF(document : bytes, injectTokens : Union[bytes, List[Token]]) -> List[Token]:
-    """
-    Injects the specified tokens into the document, returning a new copy of the
-    document as a list of Tokens. Injects the data just before the first
-    rendered character.
-
-    :param document: The bytes representing the RTF document.
-    :param injectTokens: The tokens to inject into the document. Can either be
-        a list of Tokens or bytes to be tokenized.
-
-    :raises TypeError: The data is not recognized as RTF.
-    :raises ValueError: An issue with basic parsing occured.
-    """
-    return injectStartRTFTokenized(tokenizeRTF(document), injectTokens)
-
-
-def injectStartRTFTokenized(document : List[Token], injectTokens : Union[bytes, Iterable[Token]]) -> List[Token]:
-    """
-    Like :function injectStartRTF:, injects the specified tokens into the
-    document, returning a reference to the document, except that it accepts a
-    document in the form of a list of tokens. Injects the data just before the
-    first rendered character.
-
-    :param document: The list of tokens representing the RTF document. Will only
-        be modified if the function is successful.
-    :param injectTokens: The tokens to inject into the document. Can either be
-        a list of Tokens or bytes to be tokenized.
-
-    :raises TypeError: The data is not recognized as RTF.
-    :raises ValueError: An issue with basic parsing occured.
-    """
-    # Get to a list of tokens to inject instead of
-    if isinstance(injectTokens, bytes):
-        injectTokens = tokenizeRTF(injectTokens, False)
-
-    # Find the location to insert into. THis is annoyingly complicated, and we
-    # do this by looking for the parts of the header (if they exist) as we go
-    # token by token. The moment we confirm we are no longer in the header (and
-    # we are not in a custom destination that we can simply ignore), we use the
-    # last recorded spot as the insert point. We don't move that recorded spot
-    # until we know that what we checked was part of the header.
-
-    currentLocation = 0
-
-    # First confirm the first two tokens are what we expect.
-    if len(document) < 3:
-        raise ValueError('RTF documents cannot be less than 3 tokens.')
-    if document[0].type is not TokenType.GROUP_START or document[1].raw != b'\\rtf1':
-        raise TypeError('RTF document *must* start with "{\\rtf1".')
-
-    # Confirm that all start groups have an end group somewhere.
-    if sum(x.type == TokenType.GROUP_START for x in document) != sum(x.type == TokenType.GROUP_END for x in document):
-        raise ValueError('Number of group opens did not match number of group closes.')
-
-    # If the length is exactly 3, insert right before the end and return.
-    if len(document) == 3:
-        _listInsertMult(document, injectTokens, 2)
-        return document
-
-    # We have verified the minimal amount. Now, iterate through the rest to find
-    # the injection point.
-    currentInsertPos = 2
-    # Current number of open groups.
-    groupCount = 1
-    # Set to True when looking for if the group is a destination.
-    checkingDest = False
-
-    for item in document[2:]:
-        if groupCount == 1:
-            if item.type is TokenType.GROUP_END:
-                break
-            elif item.type is TokenType.GROUP_START:
-                groupCount += 1
-                checkingDest = True
-            elif item.type is TokenType.CONTROL and item.name in _HEADER_SKIPPABLE:
-                # If the control is one we know about in the header, skip it.
-                currentInsertPos += 1
-            else:
-                # Anything else means we are out of the header.
-                break
-        elif checkingDest:
-            if item.type is TokenType.DESTINATION:
-                # If it is *not* a header destination, just break, otherwise add
-                # 2 to the insert location and skip the destination.
-                if item.name in _HEADER_DESTINATIONS:
-                    currentInsertPos += 2
-                else:
-                    break
-            elif item.type is TokenType.IGNORABLE_DESTINATION:
-                # Add 2 to insert location and skip.
-                currentInsertPos += 2
-            else:
-                # If it is not an ignorible destination, we are now out of the
-                # header, so break.
-                break
-            checkingDest = False
-        else:
-            # Skip the current token, keeping track of groups.
-            if item.type is TokenType.GROUP_START:
-                groupCount += 1
-            if item.type is TokenType.GROUP_END:
-                groupCount -= 1
-            currentInsertPos += 1
-
-    _listInsertMult(document, injectTokens, currentInsertPos)
-    return document
+__all__ = [
+    'injectStartRTF',
+    'injectStartRTFTokenized',
+]
+
+
+from .token import Token, TokenType
+from .tokenize_rtf import tokenizeRTF
+
+from typing import List, Iterable, Union
+
+
+# A tuple of destinations used in the header. All ignorable ones are skipped
+# anyways, so we don't need to list those here.
+_HEADER_DESTINATIONS = (
+    b'fonttbl',
+    b'colortbl',
+    b'stylesheet',
+)
+
+# A tuple of control words that are part of the header and that we simply skip.
+_HEADER_SKIPPABLE = (
+    # Tag used to specify something.
+    b'fbidis',
+    # Character set tags.
+    b'ansi',
+    b'mac',
+    b'pc',
+    b'pca',
+    b'ansicpg',
+    # From.
+    b'fromtext',
+    b'fromhtml',
+    # Def font.
+    b'deff',
+    b'adeff',
+    b'stshfdbch',
+    b'stshfloch',
+    b'stshfhich',
+    b'stshfbi',
+    # Def lang.
+    b'deflang',
+    b'deflangfe',
+    b'adeflang',
+)
+
+
+def _listInsertMult(dest : List, source : Iterable, index : int = -1):
+    """
+    Inserts into :param dest: all the items in :param source: at the index
+    specified. :param dest: can be any mutable sequence with :method insert:,
+    :method __len__:, and :method extend:.
+
+    If :param index: is not specified, the default position is the end of the
+    list. This is also where things will be inserted if index is greater than or
+    equal to the size of the list.
+    """
+    if index == -1 or index >= len(dest):
+        dest.extend(source)
+    else:
+        for offset, item in enumerate(source):
+            dest.insert(index + offset, item)
+
+
+def injectStartRTF(document : bytes, injectTokens : Union[bytes, List[Token]]) -> List[Token]:
+    """
+    Injects the specified tokens into the document, returning a new copy of the
+    document as a list of Tokens. Injects the data just before the first
+    rendered character.
+
+    :param document: The bytes representing the RTF document.
+    :param injectTokens: The tokens to inject into the document. Can either be
+        a list of Tokens or bytes to be tokenized.
+
+    :raises TypeError: The data is not recognized as RTF.
+    :raises ValueError: An issue with basic parsing occured.
+    """
+    return injectStartRTFTokenized(tokenizeRTF(document), injectTokens)
+
+
+def injectStartRTFTokenized(document : List[Token], injectTokens : Union[bytes, Iterable[Token]]) -> List[Token]:
+    """
+    Like :function injectStartRTF:, injects the specified tokens into the
+    document, returning a reference to the document, except that it accepts a
+    document in the form of a list of tokens. Injects the data just before the
+    first rendered character.
+
+    :param document: The list of tokens representing the RTF document. Will only
+        be modified if the function is successful.
+    :param injectTokens: The tokens to inject into the document. Can either be
+        a list of Tokens or bytes to be tokenized.
+
+    :raises TypeError: The data is not recognized as RTF.
+    :raises ValueError: An issue with basic parsing occured.
+    """
+    # Get to a list of tokens to inject instead of
+    if isinstance(injectTokens, bytes):
+        injectTokens = tokenizeRTF(injectTokens, False)
+
+    # Find the location to insert into. This is annoyingly complicated, and we
+    # do this by looking for the parts of the header (if they exist) as we go
+    # token by token. The moment we confirm we are no longer in the header (and
+    # we are not in a custom destination that we can simply ignore), we use the
+    # last recorded spot as the insert point. We don't move that recorded spot
+    # until we know that what we checked was part of the header.
+
+    # First confirm the first two tokens are what we expect.
+    if len(document) < 3:
+        raise ValueError('RTF documents cannot be less than 3 tokens.')
+    if document[0].type is not TokenType.GROUP_START or document[1].raw != b'\\rtf1':
+        raise TypeError('RTF document *must* start with "{\\rtf1".')
+
+    # Confirm that all start groups have an end group somewhere.
+    if sum(x.type == TokenType.GROUP_START for x in document) != sum(x.type == TokenType.GROUP_END for x in document):
+        raise ValueError('Number of group opens did not match number of group closes.')
+
+    # If the length is exactly 3, insert right before the end and return.
+    if len(document) == 3:
+        _listInsertMult(document, injectTokens, 2)
+        return document
+
+    # We have verified the minimal amount. Now, iterate through the rest to find
+    # the injection point.
+    currentInsertPos = 2
+    # Current number of open groups.
+    groupCount = 1
+    # Set to True when looking for if the group is a destination.
+    checkingDest = False
+
+    for item in document[2:]:
+        if groupCount == 1:
+            if item.type is TokenType.GROUP_END:
+                break
+            elif item.type is TokenType.GROUP_START:
+                groupCount += 1
+                checkingDest = True
+            elif item.type is TokenType.CONTROL and item.name in _HEADER_SKIPPABLE:
+                # If the control is one we know about in the header, skip it.
+                currentInsertPos += 1
+            else:
+                # Anything else means we are out of the header.
+                break
+        elif checkingDest:
+            if item.type is TokenType.DESTINATION:
+                # If it is *not* a header destination, just break, otherwise add
+                # 2 to the insert location and skip the destination.
+                if item.name in _HEADER_DESTINATIONS:
+                    currentInsertPos += 2
+                else:
+                    break
+            elif item.type is TokenType.IGNORABLE_DESTINATION:
+                # Add 2 to insert location and skip.
+                currentInsertPos += 2
+            else:
+                # If it is not an ignorible destination, we are now out of the
+                # header, so break.
+                break
+            checkingDest = False
+        else:
+            # Skip the current token, keeping track of groups.
+            if item.type is TokenType.GROUP_START:
+                groupCount += 1
+            if item.type is TokenType.GROUP_END:
+                groupCount -= 1
+            currentInsertPos += 1
+
+    _listInsertMult(document, injectTokens, currentInsertPos)
+    return document
```

### Comparing `extract_msg-0.40.0/extract_msg/_rtf/token.py` & `extract_msg-0.41.0/extract_msg/_rtf/token.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,29 +1,35 @@
-import enum
-
-from typing import NamedTuple, Optional
-
-
-class TokenType(enum.Enum):
-    GROUP_START = 0
-    GROUP_END = 1
-    CONTROL = 2
-    SYMBOL = 3
-    TEXT = 4
-    DESTINATION = 5
-    IGNORABLE_DESTINATION = 6
-    # This one is special, used for handling the binary data.
-    BINARY = 7
-
-
-
-class Token(NamedTuple):
-    # The raw bytes for the token, used to recreate the document.
-    raw : bytes
-    # The type of the token.
-    type : TokenType
-    ## The following are optional as they only apply for certain types of tokens.
-    # The name of the token, if it is a control or destination.
-    name : Optional[bytes] = None
-    # The parameter of the token, if it has one. If the token is a `\'hh` token,
-    # this will be the decimal equivelent of the hex value.
-    parameter : Optional[int] = None
+__all__ = [
+    'Token',
+    'TokenType',
+]
+
+
+import enum
+
+from typing import NamedTuple, Optional
+
+
+class TokenType(enum.Enum):
+    GROUP_START = 0
+    GROUP_END = 1
+    CONTROL = 2
+    SYMBOL = 3
+    TEXT = 4
+    DESTINATION = 5
+    IGNORABLE_DESTINATION = 6
+    # This one is special, used for handling the binary data.
+    BINARY = 7
+
+
+
+class Token(NamedTuple):
+    # The raw bytes for the token, used to recreate the document.
+    raw : bytes
+    # The type of the token.
+    type : TokenType
+    ## The following are optional as they only apply for certain types of tokens.
+    # The name of the token, if it is a control or destination.
+    name : Optional[bytes] = None
+    # The parameter of the token, if it has one. If the token is a `\'hh` token,
+    # this will be the decimal equivelent of the hex value.
+    parameter : Optional[int] = None
```

### Comparing `extract_msg-0.40.0/extract_msg/_rtf/tokenize_rtf.py` & `extract_msg-0.41.0/extract_msg/_rtf/tokenize_rtf.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,252 +1,255 @@
-import copy
-import enum
-import io
-
-from typing import List, NamedTuple, Optional, Tuple
-
-from .token import Token, TokenType
-
-
-_KNOWN_DESTINATIONS = (
-    b'aftncn',
-    b'aftnsep',
-    b'aftnsepc',
-    b'annotation',
-    b'author',
-    b'buptim',
-    b'category',
-    b'colortbl',
-    b'comment',
-    b'company',
-    b'creatim',
-    b'doccomm',
-    b'dptxbxtext',
-    b'factoidname',
-    b'fonttbl',
-    b'footer',
-    b'footerf',
-    b'footerl',
-    b'footerr',
-    b'ftncn',
-    b'ftnsep',
-    b'ftnsepc',
-    b'header',
-    b'headerf',
-    b'headerl',
-    b'headerr',
-    b'hlinkbase',
-    b'keywords',
-    b'manager',
-    b'operator',
-    b'pict',
-    b'printim',
-    b'private',
-    b'revtim',
-    b'stylesheet',
-    b'subject',
-    b'title',
-)
-
-
-def _finishTag(startText : bytes, reader : io.BytesIO) -> Tuple[bytes, Optional[bytes], Optional[int], bytes]:
-    """
-    Finishes reading a tag, returning the needed parameters to make it a
-    token. The return is a 4 tuple of the raw token bytes, the name field,
-    the parameter field (as an int), and the next character after the tag.
-    """
-    # Very simple rules here. Anything other than a letter and we change
-    # state. If the next character is a hypen, check if the character after
-    # is a digit, otherwise return. If it is a digit or that previously
-    # mentioned next character was a digit, read digits until anything else
-    # is detected, then return.
-    name = startText[-1:]
-    param = b''
-
-    while (nextChar := reader.read(1)) != b'' and nextChar.isalpha():
-        # Read until not alpha.
-        startText += nextChar
-        name += nextChar
-
-    # Check what the next character is to decide what to do with it.
-    if nextChar == b'-':
-        # We do this as a separate check.
-        nextNext = reader.read(1)
-        if nextNext == b'':
-            raise ValueError('Unexpected end of data.')
-        elif nextNext.isdigit():
-            startText += nextChar
-            nextChar = nextNext
-
-    if nextChar.isdigit():
-        startText += nextChar
-        param += nextChar
-        while (nextChar := reader.read(1)) != b'' and nextChar.isdigit():
-            startText += nextChar
-            param += nextChar
-
-        param = int(param)
-    else:
-        param = None
-
-    # Finally, check if the next char is a space, and if it is, read one
-    # more char to replace it.
-    if nextChar == b' ':
-        nextChar = reader.read(1)
-
-    return startText, name, param, nextChar
-
-
-def _readControl(startChar : bytes, reader : io.BytesIO) -> Tuple[Tuple[Token], bytes]:
-    """
-    Attempts to read the next data as a control, returning as many tokens
-    as necessary.
-    """
-    # First, read the next character, as it decides how to handle
-    # everything.
-    nextChar = reader.read(1)
-    if nextChar == b'':
-        raise ValueError('Unexpected end of data.')
-    elif nextChar.isalpha():
-        # If is an alphabetical character, so start the handling of a tag.
-        text, name, param, nextChar = _finishTag(startChar + nextChar, reader)
-        # Important, check if the name is "bin". If it is, handle that
-        # specially before returning.
-        if name == b'bin':
-            if nextChar == b'':
-                raise ValueError('Unexpected end of data.')
-            binText = nextChar + reader.read(param - 1)
-            if len(binText) != param:
-                raise ValueError('Unexpected end of data.')
-            return (Token(text, TokenType.CONTROL, name, param), Token(binText, TokenType.BINARY)), nextChar
-        elif name in _KNOWN_DESTINATIONS:
-            return (Token(text, TokenType.DESTINATION, name, param),), nextChar
-
-        return (Token(text, TokenType.CONTROL, name, param),), nextChar
-    else:
-        # Most control symbols would return immediately, but there are two
-        # exceptions.
-        startChar += nextChar
-        if nextChar == b'*':
-            # This is going to be a custom destination. First, validation.
-            if len(nextChar := reader.read(1)) != 1:
-                raise ValueError('Unexpected end of data.')
-            elif nextChar != b'\\':
-                raise ValueError(f'Bad custom destination (expected a backslash, got {nextChar}).')
-
-            startChar += nextChar
-
-            # Check the the next char is alpha.
-            if not (nextChar := reader.read(1)).isalpha():
-                raise ValueError(f'Expected alpha character for destination, got {nextChar}.')
-
-            startChar += nextChar
-
-            # Call the function to read until a clear end of tag.
-            text, name, param, nextChar = _finishTag(startChar, reader)
-            return (Token(text, TokenType.IGNORABLE_DESTINATION, name, param),), nextChar
-        elif nextChar == b'\'':
-            # This is a hex character, so immediately read 2 more bytes.
-            hexChars = reader.read(2)
-            if len(hexChars) != 2:
-                raise ValueError('Unexpected end of data.')
-            try:
-                param = int(hexChars, 16)
-            except ValueError:
-                context = e.__cause__ or e.__context__
-                raise ValueError(f'Hex data was not hexidecimal (got {hexChars}).') from context
-            return (Token(startChar + hexChars, TokenType.SYMBOL, None, param),), reader.read(1)
-        else:
-            # If it is a control symbol, immediately return.
-            return (Token(startChar, TokenType.SYMBOL),), reader.read(1)
-
-
-def _readText(startChar : bytes, reader : io.BytesIO) -> Tuple[Tuple[Token], bytes]:
-    """
-    Attempts to read the next data as text.
-    """
-    chars = [startChar]
-    # Text is actually the easiest to read, as we just read until end of
-    # stream or until a special character. However, a few characters are
-    # simply dropped during reading.
-    while (nextChar := reader.read(1)) != b'' and nextChar not in (b'{', b'}', b'\\'):
-        # Certain characters are simply dropped.
-        if nextChar not in (b'\r', b'\n'):
-            chars.append(nextChar)
-
-    # Now, we actually are reading the text as *individual tokens*, so we
-    # need to
-
-    return tuple(Token(x, TokenType.TEXT) for x in chars), nextChar
-
-
-def tokenizeRTF(data : bytes, validateStart : bool = True) -> None:
-    """
-    Reads in the bytes and sets the tokens list to the contents after
-    tokenizing. If tokenizing fails, the current tokens list will not be
-    changed.
-
-    Direct references to the previous tokens list will only point to the
-    previous and not to the current one.
-
-    :param validateStart: If False, does not check the first few tags. Useful
-        when tokenizing a snippet rather than a document.
-
-    :raises TypeError: The data is not recognized as RTF.
-    :raises ValueError: An issue with basic parsing occured.
-    """
-    reader = io.BytesIO(data)
-    if validateStart:
-        # This tokenizer *only* breaks things up. It does *not* care about
-        # groups and stuff, as that is for a parser to deal with. All we do is
-        # track the current backslash state and token state. We also simply
-        # check that the first token is "\rtf1" preceeded by a group start, and
-        # that is it.
-        start = reader.read(6)
-        if start != b'{\\rtf1':
-            raise TypeError('Data does not start with "{\\rtf1".')
-
-        tokens = [
-            Token(b'{', TokenType.GROUP_START),
-            Token(b'\\rtf1', TokenType.CONTROL, b'rtf', 1),
-        ]
-        nextChar = reader.read(1)
-
-        # If the next character is a space, ignore it.
-        if nextChar == ' ':
-            nextChar = reader.read(1)
-    else:
-        tokens = []
-        nextChar = reader.read(1)
-
-    newToken = None
-
-    # At every iteration, so long as there is more data, nextChar should be
-    # set. As such, use it to determine what kind of data to try to read,
-    # using the delimeter of that type of data to know what to do next.
-    while nextChar != b'':
-        # We should have exactly one character, the start of the next
-        # section. Use it to determine what to do.
-        if nextChar in (b'\r', b'\n'):
-            # Just read the next character and start the loop over.
-            nextChar = reader.read(1)
-            continue
-
-        if nextChar == b'\\':
-            newTokens, nextChar = _readControl(nextChar, reader)
-        elif nextChar == b'{':
-            # This will always be a group start, which has nothing left to
-            # read.
-            nextChar = reader.read(1)
-            newTokens = (Token(b'{', TokenType.GROUP_START),)
-        elif nextChar == b'}':
-            # This will always be a group end, which has nothing left to
-            # read.
-            nextChar = reader.read(1)
-            newTokens = (Token(b'}', TokenType.GROUP_END),)
-        else:
-            # Otherwise, it's just text.
-            newTokens, nextChar = _readText(nextChar, reader)
-
-        tokens.extend(newTokens)
-
-    return tokens
+__all__ = [
+    'tokenizeRTF',
+]
+
+
+import io
+
+from typing import Optional, Tuple
+
+from .token import Token, TokenType
+
+
+_KNOWN_DESTINATIONS = (
+    b'aftncn',
+    b'aftnsep',
+    b'aftnsepc',
+    b'annotation',
+    b'author',
+    b'buptim',
+    b'category',
+    b'colortbl',
+    b'comment',
+    b'company',
+    b'creatim',
+    b'doccomm',
+    b'dptxbxtext',
+    b'factoidname',
+    b'fonttbl',
+    b'footer',
+    b'footerf',
+    b'footerl',
+    b'footerr',
+    b'ftncn',
+    b'ftnsep',
+    b'ftnsepc',
+    b'header',
+    b'headerf',
+    b'headerl',
+    b'headerr',
+    b'hlinkbase',
+    b'keywords',
+    b'manager',
+    b'operator',
+    b'pict',
+    b'printim',
+    b'private',
+    b'revtim',
+    b'stylesheet',
+    b'subject',
+    b'title',
+)
+
+
+def _finishTag(startText : bytes, reader : io.BytesIO) -> Tuple[bytes, Optional[bytes], Optional[int], bytes]:
+    """
+    Finishes reading a tag, returning the needed parameters to make it a
+    token. The return is a 4 tuple of the raw token bytes, the name field,
+    the parameter field (as an int), and the next character after the tag.
+    """
+    # Very simple rules here. Anything other than a letter and we change
+    # state. If the next character is a hypen, check if the character after
+    # is a digit, otherwise return. If it is a digit or that previously
+    # mentioned next character was a digit, read digits until anything else
+    # is detected, then return.
+    name = startText[-1:]
+    param = b''
+
+    while (nextChar := reader.read(1)) != b'' and nextChar.isalpha():
+        # Read until not alpha.
+        startText += nextChar
+        name += nextChar
+
+    # Check what the next character is to decide what to do with it.
+    if nextChar == b'-':
+        # We do this as a separate check.
+        nextNext = reader.read(1)
+        if nextNext == b'':
+            raise ValueError('Unexpected end of data.')
+        elif nextNext.isdigit():
+            startText += nextChar
+            nextChar = nextNext
+
+    if nextChar.isdigit():
+        startText += nextChar
+        param += nextChar
+        while (nextChar := reader.read(1)) != b'' and nextChar.isdigit():
+            startText += nextChar
+            param += nextChar
+
+        param = int(param)
+    else:
+        param = None
+
+    # Finally, check if the next char is a space, and if it is, read one
+    # more char to replace it.
+    if nextChar == b' ':
+        nextChar = reader.read(1)
+
+    return startText, name, param, nextChar
+
+
+def _readControl(startChar : bytes, reader : io.BytesIO) -> Tuple[Tuple[Token], bytes]:
+    """
+    Attempts to read the next data as a control, returning as many tokens
+    as necessary.
+    """
+    # First, read the next character, as it decides how to handle
+    # everything.
+    nextChar = reader.read(1)
+    if nextChar == b'':
+        raise ValueError('Unexpected end of data.')
+    elif nextChar.isalpha():
+        # If is an alphabetical character, so start the handling of a tag.
+        text, name, param, nextChar = _finishTag(startChar + nextChar, reader)
+        # Important, check if the name is "bin". If it is, handle that
+        # specially before returning.
+        if name == b'bin':
+            if nextChar == b'':
+                raise ValueError('Unexpected end of data.')
+            binText = nextChar + reader.read(param - 1)
+            if len(binText) != param:
+                raise ValueError('Unexpected end of data.')
+            return (Token(text, TokenType.CONTROL, name, param), Token(binText, TokenType.BINARY)), nextChar
+        elif name in _KNOWN_DESTINATIONS:
+            return (Token(text, TokenType.DESTINATION, name, param),), nextChar
+
+        return (Token(text, TokenType.CONTROL, name, param),), nextChar
+    else:
+        # Most control symbols would return immediately, but there are two
+        # exceptions.
+        startChar += nextChar
+        if nextChar == b'*':
+            # This is going to be a custom destination. First, validation.
+            if len(nextChar := reader.read(1)) != 1:
+                raise ValueError('Unexpected end of data.')
+            elif nextChar != b'\\':
+                raise ValueError(f'Bad custom destination (expected a backslash, got {nextChar}).')
+
+            startChar += nextChar
+
+            # Check the the next char is alpha.
+            if not (nextChar := reader.read(1)).isalpha():
+                raise ValueError(f'Expected alpha character for destination, got {nextChar}.')
+
+            startChar += nextChar
+
+            # Call the function to read until a clear end of tag.
+            text, name, param, nextChar = _finishTag(startChar, reader)
+            return (Token(text, TokenType.IGNORABLE_DESTINATION, name, param),), nextChar
+        elif nextChar == b'\'':
+            # This is a hex character, so immediately read 2 more bytes.
+            hexChars = reader.read(2)
+            if len(hexChars) != 2:
+                raise ValueError('Unexpected end of data.')
+            try:
+                param = int(hexChars, 16)
+            except ValueError as e:
+                context = e.__cause__ or e.__context__
+                raise ValueError(f'Hex data was not hexidecimal (got {hexChars}).') from context
+            return (Token(startChar + hexChars, TokenType.SYMBOL, None, param),), reader.read(1)
+        else:
+            # If it is a control symbol, immediately return.
+            return (Token(startChar, TokenType.SYMBOL),), reader.read(1)
+
+
+def _readText(startChar : bytes, reader : io.BytesIO) -> Tuple[Tuple[Token], bytes]:
+    """
+    Attempts to read the next data as text.
+    """
+    chars = [startChar]
+    # Text is actually the easiest to read, as we just read until end of
+    # stream or until a special character. However, a few characters are
+    # simply dropped during reading.
+    while (nextChar := reader.read(1)) != b'' and nextChar not in (b'{', b'}', b'\\'):
+        # Certain characters are simply dropped.
+        if nextChar not in (b'\r', b'\n'):
+            chars.append(nextChar)
+
+    # Now, we actually are reading the text as *individual tokens*, so we
+    # need to
+
+    return tuple(Token(x, TokenType.TEXT) for x in chars), nextChar
+
+
+def tokenizeRTF(data : bytes, validateStart : bool = True) -> None:
+    """
+    Reads in the bytes and sets the tokens list to the contents after
+    tokenizing. If tokenizing fails, the current tokens list will not be
+    changed.
+
+    Direct references to the previous tokens list will only point to the
+    previous and not to the current one.
+
+    :param validateStart: If False, does not check the first few tags. Useful
+        when tokenizing a snippet rather than a document.
+
+    :raises TypeError: The data is not recognized as RTF.
+    :raises ValueError: An issue with basic parsing occured.
+    """
+    reader = io.BytesIO(data)
+    if validateStart:
+        # This tokenizer *only* breaks things up. It does *not* care about
+        # groups and stuff, as that is for a parser to deal with. All we do is
+        # track the current backslash state and token state. We also simply
+        # check that the first token is "\rtf1" preceeded by a group start, and
+        # that is it.
+        start = reader.read(6)
+        if start != b'{\\rtf1':
+            raise TypeError('Data does not start with "{\\rtf1".')
+
+        tokens = [
+            Token(b'{', TokenType.GROUP_START),
+            Token(b'\\rtf1', TokenType.CONTROL, b'rtf', 1),
+        ]
+        nextChar = reader.read(1)
+
+        # If the next character is a space, ignore it.
+        if nextChar == ' ':
+            nextChar = reader.read(1)
+    else:
+        tokens = []
+        nextChar = reader.read(1)
+
+    newToken = None
+
+    # At every iteration, so long as there is more data, nextChar should be
+    # set. As such, use it to determine what kind of data to try to read,
+    # using the delimeter of that type of data to know what to do next.
+    while nextChar != b'':
+        # We should have exactly one character, the start of the next
+        # section. Use it to determine what to do.
+        if nextChar in (b'\r', b'\n'):
+            # Just read the next character and start the loop over.
+            nextChar = reader.read(1)
+            continue
+
+        if nextChar == b'\\':
+            newTokens, nextChar = _readControl(nextChar, reader)
+        elif nextChar == b'{':
+            # This will always be a group start, which has nothing left to
+            # read.
+            nextChar = reader.read(1)
+            newTokens = (Token(b'{', TokenType.GROUP_START),)
+        elif nextChar == b'}':
+            # This will always be a group end, which has nothing left to
+            # read.
+            nextChar = reader.read(1)
+            newTokens = (Token(b'}', TokenType.GROUP_END),)
+        else:
+            # Otherwise, it's just text.
+            newTokens, nextChar = _readText(nextChar, reader)
+
+        tokens.extend(newTokens)
+
+    return tokens
```

### Comparing `extract_msg-0.40.0/extract_msg/appointment.py` & `extract_msg-0.41.0/extract_msg/appointment.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,172 +1,177 @@
-import datetime
-
-from typing import Optional
-
-from . import constants
-from .enums import AppointmentStateFlag, BusyStatus, RecurPatternType, ResponseStatus
-from .calendar import Calendar
-from .structures.entry_id import EntryID
-
-
-class AppointmentMeeting(Calendar):
-    """
-    Parser for Microsoft Outlook Appointment or Meeting files.
-
-    Both Appointment and Meeting have the same class type but Meeting has
-    additional properties. These properties are meaningless on an Appointment
-    object.
-    """
-
-    @property
-    def appointmentCounterProposal(self) -> bool:
-        """
-        Indicates to the organizer that there are counter proposals that have
-        not been accepted or rejected by the organizer.
-        """
-        return self._ensureSetNamed('_appointmentCounterProposal', '8257', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
-
-    @property
-    def appointmentLastSequence(self) -> Optional[int]:
-        """
-        The last sequence number that was sent to any attendee.
-        """
-        return self._ensureSetNamed('_appointmentLastSequence', '8203', constants.PSETID_APPOINTMENT)
-
-    @property
-    def appointmentProposalNumber(self) -> Optional[int]:
-        """
-        The number of attendees who have sent counter propostals that have not
-        been accepted or rejected by the organizer.
-        """
-        return self._ensureSetNamed('_appointmentProposalNumber', '8259', constants.PSETID_APPOINTMENT)
-
-    @property
-    def appointmentReplyName(self) -> Optional[datetime.datetime]:
-        """
-        The user who last replied to the meeting request or meeting update.
-        """
-        return self._ensureSetNamed('_appointmentReplyName', '8230', constants.PSETID_APPOINTMENT)
-
-    @property
-    def appointmentReplyTime(self) -> Optional[datetime.datetime]:
-        """
-        The date and time at which the attendee responded to a received Meeting
-        Request object of Meeting Update object in UTC.
-        """
-        return self._ensureSetNamed('_appointmentReplyTime', '8220', constants.PSETID_APPOINTMENT)
-
-    @property
-    def appointmentSequenceTime(self) -> Optional[datetime.datetime]:
-        """
-        The date and time at which the appointmentSequence property was last
-        modified.
-        """
-        return self._ensureSetNamed('_appointmentSequenceTime', '8202', constants.PSETID_APPOINTMENT)
-
-    @property
-    def autoFillLocation(self) -> bool:
-        """
-        A value of True indicates that the value of the location property is set
-        to the value of the displayName property from the recipientRow structure
-        that represents a Resource object.
-
-        A value of False indicates that the value of the location property is
-        not automatically set.
-        """
-        return self._ensureSetNamed('_autoFillLocation', '823A', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
-
-    @property
-    def fInvited(self) -> bool:
-        """
-        Whether a Meeting Request object has been sent out.
-        """
-        return self._ensureSetNamed('_fInvited', '8229', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
-
-    @property
-    def headerFormatProperties(self) -> constants.HEADER_FORMAT_TYPE:
-        """
-        Returns a dictionary of properties, in order, to be formatted into the
-        header. Keys are the names to use in the header while the values are one
-        of the following:
-        None: Signifies no data was found for the property and it should be
-            omitted from the header.
-        str: A string to be formatted into the header using the string encoding.
-        Tuple[Union[str, None], bool]: A string should be formatted into the
-            header. If the bool is True, then place an empty string if the value
-            is None, otherwise follow the same behavior as regular None.
-
-        Additional note: If the value is an empty string, it will be dropped as
-        well by default.
-
-        Additionally you can group members of a header together by placing them
-        in an embedded dictionary. Groups will be spaced out using a second
-        instance of the join string. If any member of a group is being printed,
-        it will be spaced apart from the next group/item.
-
-        If you class should not do *any* header injection, return None from this
-        property.
-        """
-        meetingStatusString = {
-            ResponseStatus.NONE: None,
-            ResponseStatus.ORGANIZED: 'Meeting organizer',
-            ResponseStatus.TENTATIVE: 'Tentatively accepted',
-            ResponseStatus.ACCEPTED: 'Accepted',
-            ResponseStatus.DECLINED: 'Declined',
-            ResponseStatus.NOT_RESPONDED: 'Not yet responded',
-        }[self.responseStatus]
-
-        # Get the recurrence string.
-        recur = '(none)'
-        if self.appointmentRecur:
-            recur = {
-                RecurPatternType.DAY: 'Daily',
-                RecurPatternType.WEEK: 'Weekly',
-                RecurPatternType.MONTH: 'Monthly',
-                RecurPatternType.MONTH_NTH: 'Monthly',
-                RecurPatternType.MONTH_END: 'Monthly',
-                RecurPatternType.HJ_MONTH: 'Monthly',
-                RecurPatternType.HJ_MONTH_NTH: 'Monthly',
-                RecurPatternType.HJ_MONTH_END: 'Monthly',
-            }[self.appointmentRecur.patternType]
-
-        return {
-            '-main info-': {
-                'Subject': self.subject,
-                'Location': self.location,
-            },
-            '-date-': {
-                'Start': self.startDate.__format__('%a, %d %b %Y %H:%M %z') if self.startDate else None,
-                'End': self.endDate.__format__('%a, %d %b %Y %H:%M %z') if self.endDate else None,
-            },
-            '-recurrence-': {
-                'Recurrance': recur,
-                'Recurrence Pattern': self.recurrencePattern,
-            },
-            '-status-': {
-                'Meeting Status': meetingStatusString,
-            },
-            '-attendees-': {
-                'Organizer': self.organizer,
-                'Required Attendees': self.to,
-                'Optional Attendees': self.cc,
-                'Resources': self.bcc,
-            },
-            '-importance-': {
-                'Importance': self.importanceString,
-            },
-        }
-
-    @property
-    def isMeeting(self) -> bool:
-        """
-        Attempts to determine if the object is a Meeting. True if meeting, False
-        if appointment.
-        """
-        return self.appointmentStateFlags and AppointmentStateFlag.MEETING in self.appointmentStateFlags
-
-    @property
-    def originalStoreEntryID(self) -> Optional[EntryID]:
-        """
-        The EntryID of the delegator's message store.
-        """
-        return self._ensureSetNamed('_originalStoreEntryID', '8237', constants.PSETID_APPOINTMENT, overrideClass = EntryID.autoCreate)
+__all__ = [
+    'AppointmentMeeting',
+]
+
+
+import datetime
+
+from typing import Optional
+
+from . import constants
+from .enums import AppointmentStateFlag, RecurPatternType, ResponseStatus
+from .calendar import Calendar
+from .structures.entry_id import EntryID
+
+
+class AppointmentMeeting(Calendar):
+    """
+    Parser for Microsoft Outlook Appointment or Meeting files.
+
+    Both Appointment and Meeting have the same class type but Meeting has
+    additional properties. These properties are meaningless on an Appointment
+    object.
+    """
+
+    @property
+    def appointmentCounterProposal(self) -> bool:
+        """
+        Indicates to the organizer that there are counter proposals that have
+        not been accepted or rejected by the organizer.
+        """
+        return self._ensureSetNamed('_appointmentCounterProposal', '8257', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
+
+    @property
+    def appointmentLastSequence(self) -> Optional[int]:
+        """
+        The last sequence number that was sent to any attendee.
+        """
+        return self._ensureSetNamed('_appointmentLastSequence', '8203', constants.PSETID_APPOINTMENT)
+
+    @property
+    def appointmentProposalNumber(self) -> Optional[int]:
+        """
+        The number of attendees who have sent counter propostals that have not
+        been accepted or rejected by the organizer.
+        """
+        return self._ensureSetNamed('_appointmentProposalNumber', '8259', constants.PSETID_APPOINTMENT)
+
+    @property
+    def appointmentReplyName(self) -> Optional[datetime.datetime]:
+        """
+        The user who last replied to the meeting request or meeting update.
+        """
+        return self._ensureSetNamed('_appointmentReplyName', '8230', constants.PSETID_APPOINTMENT)
+
+    @property
+    def appointmentReplyTime(self) -> Optional[datetime.datetime]:
+        """
+        The date and time at which the attendee responded to a received Meeting
+        Request object of Meeting Update object in UTC.
+        """
+        return self._ensureSetNamed('_appointmentReplyTime', '8220', constants.PSETID_APPOINTMENT)
+
+    @property
+    def appointmentSequenceTime(self) -> Optional[datetime.datetime]:
+        """
+        The date and time at which the appointmentSequence property was last
+        modified.
+        """
+        return self._ensureSetNamed('_appointmentSequenceTime', '8202', constants.PSETID_APPOINTMENT)
+
+    @property
+    def autoFillLocation(self) -> bool:
+        """
+        A value of True indicates that the value of the location property is set
+        to the value of the displayName property from the recipientRow structure
+        that represents a Resource object.
+
+        A value of False indicates that the value of the location property is
+        not automatically set.
+        """
+        return self._ensureSetNamed('_autoFillLocation', '823A', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
+
+    @property
+    def fInvited(self) -> bool:
+        """
+        Whether a Meeting Request object has been sent out.
+        """
+        return self._ensureSetNamed('_fInvited', '8229', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
+
+    @property
+    def headerFormatProperties(self) -> constants.HEADER_FORMAT_TYPE:
+        """
+        Returns a dictionary of properties, in order, to be formatted into the
+        header. Keys are the names to use in the header while the values are one
+        of the following:
+        None: Signifies no data was found for the property and it should be
+            omitted from the header.
+        str: A string to be formatted into the header using the string encoding.
+        Tuple[Union[str, None], bool]: A string should be formatted into the
+            header. If the bool is True, then place an empty string if the value
+            is None, otherwise follow the same behavior as regular None.
+
+        Additional note: If the value is an empty string, it will be dropped as
+        well by default.
+
+        Additionally you can group members of a header together by placing them
+        in an embedded dictionary. Groups will be spaced out using a second
+        instance of the join string. If any member of a group is being printed,
+        it will be spaced apart from the next group/item.
+
+        If you class should not do *any* header injection, return None from this
+        property.
+        """
+        meetingStatusString = {
+            ResponseStatus.NONE: None,
+            ResponseStatus.ORGANIZED: 'Meeting organizer',
+            ResponseStatus.TENTATIVE: 'Tentatively accepted',
+            ResponseStatus.ACCEPTED: 'Accepted',
+            ResponseStatus.DECLINED: 'Declined',
+            ResponseStatus.NOT_RESPONDED: 'Not yet responded',
+        }[self.responseStatus]
+
+        # Get the recurrence string.
+        recur = '(none)'
+        if self.appointmentRecur:
+            recur = {
+                RecurPatternType.DAY: 'Daily',
+                RecurPatternType.WEEK: 'Weekly',
+                RecurPatternType.MONTH: 'Monthly',
+                RecurPatternType.MONTH_NTH: 'Monthly',
+                RecurPatternType.MONTH_END: 'Monthly',
+                RecurPatternType.HJ_MONTH: 'Monthly',
+                RecurPatternType.HJ_MONTH_NTH: 'Monthly',
+                RecurPatternType.HJ_MONTH_END: 'Monthly',
+            }[self.appointmentRecur.patternType]
+
+        return {
+            '-main info-': {
+                'Subject': self.subject,
+                'Location': self.location,
+            },
+            '-date-': {
+                'Start': self.startDate.__format__('%a, %d %b %Y %H:%M %z') if self.startDate else None,
+                'End': self.endDate.__format__('%a, %d %b %Y %H:%M %z') if self.endDate else None,
+            },
+            '-recurrence-': {
+                'Recurrance': recur,
+                'Recurrence Pattern': self.recurrencePattern,
+            },
+            '-status-': {
+                'Meeting Status': meetingStatusString,
+            },
+            '-attendees-': {
+                'Organizer': self.organizer,
+                'Required Attendees': self.to,
+                'Optional Attendees': self.cc,
+                'Resources': self.bcc,
+            },
+            '-importance-': {
+                'Importance': self.importanceString,
+            },
+        }
+
+    @property
+    def isMeeting(self) -> bool:
+        """
+        Attempts to determine if the object is a Meeting. True if meeting, False
+        if appointment.
+        """
+        return self.appointmentStateFlags and AppointmentStateFlag.MEETING in self.appointmentStateFlags
+
+    @property
+    def originalStoreEntryID(self) -> Optional[EntryID]:
+        """
+        The EntryID of the delegator's message store.
+        """
+        return self._ensureSetNamed('_originalStoreEntryID', '8237', constants.PSETID_APPOINTMENT, overrideClass = EntryID.autoCreate)
```

### Comparing `extract_msg-0.40.0/extract_msg/attachment.py` & `extract_msg-0.41.0/extract_msg/attachment.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,317 +1,331 @@
-import logging
-import os
-import pathlib
-import random
-import string
-import zipfile
-
-from typing import Optional, Union
-
-from . import constants
-from .attachment_base import AttachmentBase
-from .enums import AttachmentType
-from .exceptions import StandardViolationError
-from .utils import createZipOpen, inputToString, openMsg, prepareFilename
-
-
-logger = logging.getLogger(__name__)
-logger.addHandler(logging.NullHandler())
-
-
-class Attachment(AttachmentBase):
-    """
-    Stores the attachment data of a Message instance.
-    Should the attachment be an embeded message, the
-    class used to create it will be the same as the
-    Message class used to create the attachment.
-    """
-
-    def __init__(self, msg, dir_):
-        """
-        :param msg: the Message instance that the attachment belongs to.
-        :param dir_: the directory inside the msg file where the attachment is
-            located.
-        """
-        super().__init__(msg, dir_)
-
-        if '37050003' not in self.props:
-            from .prop import createProp
-
-            logger.warning('Attachment method property not found on attachment. Code will attempt to guess the type.')
-
-            # Because this condition is actually kind of a violation of the
-            # standard, we are just going to do this in a dumb way. Basically we
-            # are going to try to set the attach method *manually* just so I
-            # don't have to go and modify the following code.
-            if self.exists('__substg1.0_37010102'):
-                # Set it as data and call it a day.
-                propData = b'\x03\x00\x057\x07\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00'
-            elif self.exists('__substg1.0_3701000D'):
-                # If it is a folder and we have properties, call it an MSG file.
-                if self.exists('__substg1.0_3701000D/__properties_version1.0'):
-                    propData = b'\x03\x00\x057\x07\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00'
-                else:
-                    # Call if custom attachment data.
-                    propData = b'\x03\x00\x057\x07\x00\x00\x00\x06\x00\x00\x00\x00\x00\x00\x00'
-            else:
-                # Can't autodetect it, so throw an error.
-                raise StandardViolationError('Attachment method missing, and it could not be determined automatically.')
-
-            self.props._propDict['37050003'] = createProp(propData)
-
-        # Get attachment data.
-        if self.exists('__substg1.0_37010102'):
-            self.__type = AttachmentType.DATA
-            self.__data = self._getStream('__substg1.0_37010102')
-        elif self.exists('__substg1.0_3701000D'):
-            if (self.props['37050003'].value & 0x7) != 0x5:
-                raise NotImplementedError(
-                    'Current version of extract_msg does not support extraction of containers that are not embedded msg files.')
-                # TODO add implementation.
-            else:
-                self.__prefix = msg.prefixList + [dir_, '__substg1.0_3701000D']
-                self.__type = AttachmentType.MSG
-                self.__data = openMsg(self.msg.path, prefix = self.__prefix, parentMsg = self.msg, treePath = self.treePath, **self.msg.kwargs)
-        elif (self.props['37050003'].value & 0x7) == 0x7:
-            # TODO Handling for special attacment type 0x7.
-            self.__type = AttachmentType.WEB
-            raise NotImplementedError('Attachments of type afByWebReference are not currently supported.')
-        else:
-            raise TypeError('Unknown attachment type.')
-
-    def getFilename(self, **kwargs) -> str:
-        """
-        Returns the filename to use for the attachment.
-
-        :param contentId:      Use the contentId, if available.
-        :param customFilename: A custom name to use for the file.
-
-        If the filename starts with "UnknownFilename" then there is no guarentee
-        that the files will have exactly the same filename.
-        """
-        filename = None
-        customFilename = kwargs.get('customFilename')
-        if customFilename:
-            customFilename = str(customFilename)
-            # First we need to validate it. If there are invalid characters,
-            # this will detect it.
-            if constants.RE_INVALID_FILENAME_CHARACTERS.search(customFilename):
-                raise ValueError('Invalid character found in customFilename. Must not contain any of the following characters: \\/:*?"<>|')
-            filename = customFilename
-        else:
-            # If not...
-            # Check if user wants to save the file under the Content-ID.
-            if kwargs.get('contentId', False):
-                filename = self.cid
-            # If filename is None at this point, use long filename as first
-            # preference.
-            if not filename:
-                filename = self.name
-            # Otherwise just make something up!
-            if not filename:
-                return self.randomFilename
-
-        return filename
-
-    def regenerateRandomName(self) -> str:
-        """
-        Used to regenerate the random filename used if the attachment cannot
-        find a usable filename.
-        """
-        self.__randomName = inputToString('UnknownFilename ' + \
-                   ''.join(random.choice(string.ascii_uppercase + string.digits)
-                           for _ in range(5)) + '.bin', 'ascii')
-
-    def save(self, **kwargs) -> Optional[Union[str, 'MSGFile']]:
-        """
-        Saves the attachment data.
-
-        The name of the file is determined by several factors. The first
-        thing that is checked is if you have provided :param customFilename:
-        to this function. If you have, that is the name that will be used.
-        If no custom name has been provided and :param contentId: is True,
-        the file will be saved using the content ID of the attachment. If
-        it is not found or :param contentId: is False, the long filename
-        will be used. If the long filename is not found, the short one will
-        be used. If after all of this a usable filename has not been found, a
-        random one will be used (accessible from `Attachment.randomFilename`).
-        After the name to use has been determined, it will then be shortened to
-        make sure that it is not more than the value of :param maxNameLength:.
-
-        To change the directory that the attachment is saved to, set the value
-        of :param customPath: when calling this function. The default save
-        directory is the working directory.
-
-        If you want to save the contents into a ZipFile or similar object,
-        either pass a path to where you want to create one or pass an instance
-        to :param zip:. If :param zip: is an instance, :param customPath: will
-        refer to a location inside the zip file.
-
-        :param extractEmbedded: If True, causes the attachment, should it be an
-            embedded MSG file, to save as a .msg file instead of calling it's
-            save function.
-        :param skipEmbedded: If True, skips saving this attachment if it is an
-            embedded MSG file.
-        """
-        # First check if we are skipping embedded messages and stop
-        # *immediately* if we are.
-        if self.type is AttachmentType.MSG and kwargs.get('skipEmbedded'):
-            return None
-
-        # Get the filename to use.
-        filename = self.getFilename(**kwargs)
-
-        # Someone managed to have a null character here, so let's get rid of that
-        filename = prepareFilename(inputToString(filename, self.msg.stringEncoding))
-
-        # Get the maximum name length.
-        maxNameLength = kwargs.get('maxNameLength', 256)
-
-        # Make sure the filename is not longer than it should be.
-        if len(filename) > maxNameLength:
-            name, ext = os.path.splitext(filename)
-            filename = name[:maxNameLength - len(ext)] + ext
-
-        # Check if we are doing a zip file.
-        _zip = kwargs.get('zip')
-
-        # ZipFile handling.
-        if _zip:
-            # If we are doing a zip file, first check that we have been given a path.
-            if isinstance(_zip, (str, pathlib.Path)):
-                # If we have a path then we use the zip file.
-                _zip = zipfile.ZipFile(_zip, 'a', zipfile.ZIP_DEFLATED)
-                kwargs['zip'] = _zip
-                createdZip = True
-            else:
-                createdZip = False
-            # Path needs to be done in a special way if we are in a zip file.
-            customPath = pathlib.Path(kwargs.get('customPath', ''))
-            # Set the open command to be that of the zip file.
-            _open = createZipOpen(_zip.open)
-            # Zip files use w for writing in binary.
-            mode = 'w'
-        else:
-            customPath = pathlib.Path(kwargs.get('customPath', '.')).absolute()
-            mode = 'wb'
-            _open = open
-
-        fullFilename = customPath / filename
-
-        if self.type is AttachmentType.DATA:
-            if _zip:
-                name, ext = os.path.splitext(filename)
-                nameList = _zip.namelist()
-                if str(fullFilename).replace('\\', '/') in nameList:
-                    for i in range(2, 100):
-                        testName = customPath / f'{name} ({i}){ext}'
-                        if str(testName).replace('\\', '/') not in nameList:
-                            fullFilename = testName
-                            break
-                    else:
-                        # If we couldn't find one that didn't exist.
-                        raise FileExistsError(f'Could not create the specified file because it already exists ("{fullFilename}").')
-            else:
-                if fullFilename.exists():
-                    # Try to split the filename into a name and extention.
-                    name, ext = os.path.splitext(filename)
-                    # Try to add a number to it so that we can save without overwriting.
-                    for i in range(2, 100):
-                        testName = customPath / f'{name} ({i}){ext}'
-                        if not testName.exists():
-                            fullFilename = testName
-                            break
-                    else:
-                        # If we couldn't find one that didn't exist.
-                        raise FileExistsError(f'Could not create the specified file because it already exists ("{fullFilename}").')
-
-            with _open(str(fullFilename), mode) as f:
-                f.write(self.__data)
-
-            # Close the ZipFile if this function created it.
-            if _zip and createdZip:
-                _zip.close()
-
-            return str(fullFilename)
-        else:
-            if kwargs.get('extractEmbedded', False):
-                # TODO
-                with _open(str(fullFilename), mode) as f:
-                    self.data.export(f)
-            else:
-                self.saveEmbededMessage(**kwargs)
-
-            # Close the ZipFile if this function created it.
-            if _zip and createdZip:
-                _zip.close()
-
-            return self.msg
-
-    def saveEmbededMessage(self, **kwargs) -> None:
-        """
-        Seperate function from save to allow it to easily be overridden by a
-        subclass.
-        """
-        self.data.save(**kwargs)
-
-    @property
-    def data(self) -> Optional[Union[bytes, 'MSGFile']]:
-        """
-        Returns the attachment data.
-        """
-        return self.__data
-
-    @property
-    def randomFilename(self) -> str:
-        """
-        Returns the random filename to be used by this attachment.
-        """
-        try:
-            return self.__randomName
-        except AttributeError:
-            self.regenerateRandomName()
-            return self.__randomName
-
-    @property
-    def type(self) -> AttachmentType:
-        """
-        Returns the (internally used) type of the data.
-        """
-        return self.__type
-
-
-
-class BrokenAttachment(AttachmentBase):
-    """
-    An attachment that has suffered a fatal error. Will not generate from a
-    NotImplementedError exception.
-    """
-
-    @property
-    def type(self) -> AttachmentType:
-        """
-        Returns the (internally used) type of the data.
-        """
-        return AttachmentType.BROKEN
-
-class UnsupportedAttachment(AttachmentBase):
-    """
-    An attachment whose type is not currently supported.
-    """
-
-    def save(self, **kwargs) -> None:
-        """
-        Raises a NotImplementedError unless :param skipNotImplemented: is set to
-        True. If it is, returns None to signify the attachment was skipped. This
-        allows for the easy implementation of the option to skip this type of
-        attachment.
-        """
-        if not kwargs.get('skipNotImplemented', False):
-            raise NotImplementedError('Unsupported attachments cannot be saved.')
-
-    @property
-    def type(self) -> AttachmentType:
-        """
-        Returns the (internally used) type of the data.
-        """
-        return AttachmentType.UNSUPPORTED
+from __future__ import annotations
+
+
+__all__ = [
+    'Attachment',
+    'BrokenAttachment',
+    'UnsupportedAttachment',
+]
+
+
+import logging
+import os
+import pathlib
+import random
+import string
+import zipfile
+
+from typing import Optional, TYPE_CHECKING, Union
+
+from . import constants
+from .attachment_base import AttachmentBase
+from .enums import AttachmentType
+from .exceptions import StandardViolationError
+from .utils import createZipOpen, inputToString, openMsg, prepareFilename
+
+
+# Allow for nice type checking.
+if TYPE_CHECKING:
+    from .msg import MSGFile
+
+logger = logging.getLogger(__name__)
+logger.addHandler(logging.NullHandler())
+
+
+class Attachment(AttachmentBase):
+    """
+    Stores the attachment data of a Message instance.
+    Should the attachment be an embeded message, the
+    class used to create it will be the same as the
+    Message class used to create the attachment.
+    """
+
+    def __init__(self, msg, dir_):
+        """
+        :param msg: the Message instance that the attachment belongs to.
+        :param dir_: the directory inside the msg file where the attachment is
+            located.
+        """
+        super().__init__(msg, dir_)
+
+        if '37050003' not in self.props:
+            from .prop import createProp
+
+            logger.warning(f'Attachment method property not found on attachment {dir_}. Code will attempt to guess the type.')
+            logger.log(5, self.props)
+
+            # Because this condition is actually kind of a violation of the
+            # standard, we are just going to do this in a dumb way. Basically we
+            # are going to try to set the attach method *manually* just so I
+            # don't have to go and modify the following code.
+            if self.exists('__substg1.0_37010102'):
+                # Set it as data and call it a day.
+                propData = b'\x03\x00\x057\x07\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00'
+            elif self.exists('__substg1.0_3701000D'):
+                # If it is a folder and we have properties, call it an MSG file.
+                if self.exists('__substg1.0_3701000D/__properties_version1.0'):
+                    propData = b'\x03\x00\x057\x07\x00\x00\x00\x05\x00\x00\x00\x00\x00\x00\x00'
+                else:
+                    # Call if custom attachment data.
+                    propData = b'\x03\x00\x057\x07\x00\x00\x00\x06\x00\x00\x00\x00\x00\x00\x00'
+            else:
+                # Can't autodetect it, so throw an error.
+                raise StandardViolationError(f'Attachment method missing on attachment {dir_}, and it could not be determined automatically.')
+
+            self.props._propDict['37050003'] = createProp(propData)
+
+        # Get attachment data.
+        if self.exists('__substg1.0_37010102'):
+            self.__type = AttachmentType.DATA
+            self.__data = self._getStream('__substg1.0_37010102')
+        elif self.exists('__substg1.0_3701000D'):
+            if (self.props['37050003'].value & 0x7) != 0x5:
+                raise NotImplementedError(
+                    'Current version of extract_msg does not support extraction of containers that are not embedded msg files.')
+                # TODO add implementation.
+            else:
+                self.__prefix = msg.prefixList + [dir_, '__substg1.0_3701000D']
+                self.__type = AttachmentType.MSG
+                self.__data = openMsg(self.msg.path, prefix = self.__prefix, parentMsg = self.msg, treePath = self.treePath, **self.msg.kwargs)
+        elif (self.props['37050003'].value & 0x7) == 0x7:
+            # TODO Handling for special attacment type 0x7.
+            self.__type = AttachmentType.WEB
+            raise NotImplementedError('Attachments of type afByWebReference are not currently supported.')
+        else:
+            raise TypeError('Unknown attachment type.')
+
+    def getFilename(self, **kwargs) -> str:
+        """
+        Returns the filename to use for the attachment.
+
+        :param contentId:      Use the contentId, if available.
+        :param customFilename: A custom name to use for the file.
+
+        If the filename starts with "UnknownFilename" then there is no guarentee
+        that the files will have exactly the same filename.
+        """
+        filename = None
+        customFilename = kwargs.get('customFilename')
+        if customFilename:
+            customFilename = str(customFilename)
+            # First we need to validate it. If there are invalid characters,
+            # this will detect it.
+            if constants.RE_INVALID_FILENAME_CHARACTERS.search(customFilename):
+                raise ValueError('Invalid character found in customFilename. Must not contain any of the following characters: \\/:*?"<>|')
+            filename = customFilename
+        else:
+            # If not...
+            # Check if user wants to save the file under the Content-ID.
+            if kwargs.get('contentId', False):
+                filename = self.cid
+            # If filename is None at this point, use long filename as first
+            # preference.
+            if not filename:
+                filename = self.name
+            # Otherwise just make something up!
+            if not filename:
+                return self.randomFilename
+
+        return filename
+
+    def regenerateRandomName(self) -> str:
+        """
+        Used to regenerate the random filename used if the attachment cannot
+        find a usable filename.
+        """
+        self.__randomName = inputToString('UnknownFilename ' + \
+                   ''.join(random.choice(string.ascii_uppercase + string.digits)
+                           for _ in range(5)) + '.bin', 'ascii')
+
+    def save(self, **kwargs) -> Optional[Union[str, MSGFile]]:
+        """
+        Saves the attachment data.
+
+        The name of the file is determined by several factors. The first
+        thing that is checked is if you have provided :param customFilename:
+        to this function. If you have, that is the name that will be used.
+        If no custom name has been provided and :param contentId: is True,
+        the file will be saved using the content ID of the attachment. If
+        it is not found or :param contentId: is False, the long filename
+        will be used. If the long filename is not found, the short one will
+        be used. If after all of this a usable filename has not been found, a
+        random one will be used (accessible from `Attachment.randomFilename`).
+        After the name to use has been determined, it will then be shortened to
+        make sure that it is not more than the value of :param maxNameLength:.
+
+        To change the directory that the attachment is saved to, set the value
+        of :param customPath: when calling this function. The default save
+        directory is the working directory.
+
+        If you want to save the contents into a ZipFile or similar object,
+        either pass a path to where you want to create one or pass an instance
+        to :param zip:. If :param zip: is an instance, :param customPath: will
+        refer to a location inside the zip file.
+
+        :param extractEmbedded: If True, causes the attachment, should it be an
+            embedded MSG file, to save as a .msg file instead of calling it's
+            save function.
+        :param skipEmbedded: If True, skips saving this attachment if it is an
+            embedded MSG file.
+        """
+        # First check if we are skipping embedded messages and stop
+        # *immediately* if we are.
+        if self.type is AttachmentType.MSG and kwargs.get('skipEmbedded'):
+            return None
+
+        # Get the filename to use.
+        filename = self.getFilename(**kwargs)
+
+        # Someone managed to have a null character here, so let's get rid of that
+        filename = prepareFilename(inputToString(filename, self.msg.stringEncoding))
+
+        # Get the maximum name length.
+        maxNameLength = kwargs.get('maxNameLength', 256)
+
+        # Make sure the filename is not longer than it should be.
+        if len(filename) > maxNameLength:
+            name, ext = os.path.splitext(filename)
+            filename = name[:maxNameLength - len(ext)] + ext
+
+        # Check if we are doing a zip file.
+        _zip = kwargs.get('zip')
+
+        # ZipFile handling.
+        if _zip:
+            # If we are doing a zip file, first check that we have been given a path.
+            if isinstance(_zip, (str, pathlib.Path)):
+                # If we have a path then we use the zip file.
+                _zip = zipfile.ZipFile(_zip, 'a', zipfile.ZIP_DEFLATED)
+                kwargs['zip'] = _zip
+                createdZip = True
+            else:
+                createdZip = False
+            # Path needs to be done in a special way if we are in a zip file.
+            customPath = pathlib.Path(kwargs.get('customPath', ''))
+            # Set the open command to be that of the zip file.
+            _open = createZipOpen(_zip.open)
+            # Zip files use w for writing in binary.
+            mode = 'w'
+        else:
+            customPath = pathlib.Path(kwargs.get('customPath', '.')).absolute()
+            mode = 'wb'
+            _open = open
+
+        fullFilename = customPath / filename
+
+        if self.type is AttachmentType.DATA:
+            if _zip:
+                name, ext = os.path.splitext(filename)
+                nameList = _zip.namelist()
+                if str(fullFilename).replace('\\', '/') in nameList:
+                    for i in range(2, 100):
+                        testName = customPath / f'{name} ({i}){ext}'
+                        if str(testName).replace('\\', '/') not in nameList:
+                            fullFilename = testName
+                            break
+                    else:
+                        # If we couldn't find one that didn't exist.
+                        raise FileExistsError(f'Could not create the specified file because it already exists ("{fullFilename}").')
+            else:
+                if fullFilename.exists():
+                    # Try to split the filename into a name and extention.
+                    name, ext = os.path.splitext(filename)
+                    # Try to add a number to it so that we can save without overwriting.
+                    for i in range(2, 100):
+                        testName = customPath / f'{name} ({i}){ext}'
+                        if not testName.exists():
+                            fullFilename = testName
+                            break
+                    else:
+                        # If we couldn't find one that didn't exist.
+                        raise FileExistsError(f'Could not create the specified file because it already exists ("{fullFilename}").')
+
+            with _open(str(fullFilename), mode) as f:
+                f.write(self.__data)
+
+            # Close the ZipFile if this function created it.
+            if _zip and createdZip:
+                _zip.close()
+
+            return str(fullFilename)
+        else:
+            if kwargs.get('extractEmbedded', False):
+                with _open(str(fullFilename), mode) as f:
+                    self.data.export(f)
+            else:
+                self.saveEmbededMessage(**kwargs)
+
+            # Close the ZipFile if this function created it.
+            if _zip and createdZip:
+                _zip.close()
+
+            return self.msg
+
+    def saveEmbededMessage(self, **kwargs) -> None:
+        """
+        Seperate function from save to allow it to easily be overridden by a
+        subclass.
+        """
+        self.data.save(**kwargs)
+
+    @property
+    def data(self) -> Optional[Union[bytes, MSGFile]]:
+        """
+        Returns the attachment data.
+        """
+        return self.__data
+
+    @property
+    def randomFilename(self) -> str:
+        """
+        Returns the random filename to be used by this attachment.
+        """
+        try:
+            return self.__randomName
+        except AttributeError:
+            self.regenerateRandomName()
+            return self.__randomName
+
+    @property
+    def type(self) -> AttachmentType:
+        """
+        Returns the (internally used) type of the data.
+        """
+        return self.__type
+
+
+
+class BrokenAttachment(AttachmentBase):
+    """
+    An attachment that has suffered a fatal error. Will not generate from a
+    NotImplementedError exception.
+    """
+
+    @property
+    def type(self) -> AttachmentType:
+        """
+        Returns the (internally used) type of the data.
+        """
+        return AttachmentType.BROKEN
+
+class UnsupportedAttachment(AttachmentBase):
+    """
+    An attachment whose type is not currently supported.
+    """
+
+    def save(self, **kwargs) -> None:
+        """
+        Raises a NotImplementedError unless :param skipNotImplemented: is set to
+        True. If it is, returns None to signify the attachment was skipped. This
+        allows for the easy implementation of the option to skip this type of
+        attachment.
+        """
+        if not kwargs.get('skipNotImplemented', False):
+            raise NotImplementedError('Unsupported attachments cannot be saved.')
+
+    @property
+    def type(self) -> AttachmentType:
+        """
+        Returns the (internally used) type of the data.
+        """
+        return AttachmentType.UNSUPPORTED
```

### Comparing `extract_msg-0.40.0/extract_msg/attachment_base.py` & `extract_msg-0.41.0/extract_msg/attachment_base.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,401 +1,418 @@
-import datetime
-import logging
-
-from functools import partial
-from typing import Optional, Tuple
-
-from . import constants
-from .enums import AttachmentType, PropertiesType
-from .named import NamedProperties
-from .prop import FixedLengthProp
-from .properties import Properties
-from .utils import tryGetMimetype, verifyPropertyId, verifyType
-
-
-logger = logging.getLogger(__name__)
-logger.addHandler(logging.NullHandler())
-
-
-class AttachmentBase:
-    """
-    Stores the attachment data of a Message instance.
-    Should the attachment be an embeded message, the
-    class used to create it will be the same as the
-    Message class used to create the attachment.
-    """
-
-    def __init__(self, msg, dir_):
-        """
-        :param msg: the Message instance that the attachment belongs to.
-        :param dir_: the directory inside the msg file where the attachment is located.
-        """
-        self.__msg = msg
-        self.__dir = dir_
-        self.__props = Properties(self._getStream('__properties_version1.0'), PropertiesType.ATTACHMENT)
-        self.__namedProperties = NamedProperties(msg.named, self)
-        self.__treePath = msg.treePath + (self,)
-
-    def _ensureSet(self, variable, streamID, stringStream = True, **kwargs):
-        """
-        Ensures that the variable exists, otherwise will set it using the
-        specified stream. After that, return said variable.
-
-        If the specified stream is not a string stream, make sure to set
-        :param stringStream: to False.
-
-        :param overrideClass: Class/function to use to morph the data that was
-            read. The data will be the first argument to the class's __init__
-            function or the function itself, if that is what is provided. By
-            default, this will be completely ignored if the value was not found.
-        :param preserveNone: If true (default), causes the function to ignore
-            :param overrideClass: when the value could not be found (is None).
-            If this is changed to False, then the value will be used regardless.
-        """
-        try:
-            return getattr(self, variable)
-        except AttributeError:
-            if stringStream:
-                value = self._getStringStream(streamID)
-            else:
-                value = self._getStream(streamID)
-            # Check if we should be overriding the data type for this instance.
-            if kwargs:
-                overrideClass = kwargs.get('overrideClass')
-                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
-                    value = overrideClass(value)
-            setattr(self, variable, value)
-            return value
-
-    def _ensureSetNamed(self, variable, propertyName : str, guid : str, **kwargs):
-        """
-        Ensures that the variable exists, otherwise will set it using the named
-        property. After that, return said variable.
-
-        :param overrideClass: Class/function to use to morph the data that was
-            read. The data will be the first argument to the class's __init__
-            function or the function itself, if that is what is provided. By
-            default, this will be completely ignored if the value was not found.
-        :param preserveNone: If true (default), causes the function to ignore
-            :param overrideClass: when the value could not be found (is None).
-            If this is changed to False, then the value will be used regardless.
-        """
-        try:
-            return getattr(self, variable)
-        except AttributeError:
-            value = self.namedProperties.get((propertyName, guid))
-            # Check if we should be overriding the data type for this instance.
-            if kwargs:
-                overrideClass = kwargs.get('overrideClass')
-                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
-                    value = overrideClass(value)
-            setattr(self, variable, value)
-            return value
-
-    def _ensureSetProperty(self, variable, propertyName, **kwargs):
-        """
-        Ensures that the variable exists, otherwise will set it using the
-        property. After that, return said variable.
-
-        :param overrideClass: Class/function to use to morph the data that was
-            read. The data will be the first argument to the class's __init__
-            function or the function itself, if that is what is provided. By
-            default, this will be completely ignored if the value was not found.
-        :param preserveNone: If true (default), causes the function to ignore
-            :param overrideClass: when the value could not be found (is None).
-            If this is changed to False, then the value will be used regardless.
-        """
-        try:
-            return getattr(self, variable)
-        except AttributeError:
-            try:
-                value = self.props[propertyName].value
-            except (KeyError, AttributeError):
-                value = None
-            # Check if we should be overriding the data type for this instance.
-            if kwargs:
-                overrideClass = kwargs.get('overrideClass')
-                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
-                    value = overrideClass(value)
-            setattr(self, variable, value)
-            return value
-
-    def _ensureSetTyped(self, variable, _id, **kwargs):
-        """
-        Like the other ensure set functions, but designed for when something
-        could be multiple types (where only one will be present). This way you
-        have no need to set the type, it will be handled for you.
-
-        :param overrideClass: Class/function to use to morph the data that was
-            read. The data will be the first argument to the class's __init__
-            function or the function itself, if that is what is provided. By
-            default, this will be completely ignored if the value was not found.
-        :param preserveNone: If true (default), causes the function to ignore
-            :param overrideClass: when the value could not be found (is None).
-            If this is changed to False, then the value will be used regardless.
-        """
-        try:
-            return getattr(self, variable)
-        except AttributeError:
-            value = self._getTypedData(_id)
-            # Check if we should be overriding the data type for this instance.
-            if kwargs:
-                overrideClass = kwargs.get('overrideClass')
-                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
-                    value = overrideClass(value)
-            setattr(self, variable, value)
-            return value
-
-    def _getStream(self, filename) -> Optional[bytes]:
-        return self.__msg._getStream([self.__dir, filename])
-
-    def _getStringStream(self, filename) -> Optional[str]:
-        """
-        Gets a string representation of the requested filename.
-        Checks for both ASCII and Unicode representations and returns
-        a value if possible.  If there are both ASCII and Unicode
-        versions, then :param prefer: specifies which will be
-        returned.
-        """
-        return self.__msg._getStringStream([self.__dir, filename])
-
-    def _getTypedData(self, id, _type = None):
-        """
-        Gets the data for the specified id as the type that it is
-        supposed to be. :param id: MUST be a 4 digit hexadecimal
-        string.
-
-        If you know for sure what type the data is before hand,
-        you can specify it as being one of the strings in the
-        constant FIXED_LENGTH_PROPS_STRING or
-        VARIABLE_LENGTH_PROPS_STRING.
-        """
-        verifyPropertyId(id)
-        id = id.upper()
-        found, result = self._getTypedStream('__substg1.0_' + id, _type)
-        if found:
-            return result
-        else:
-            found, result = self._getTypedProperty(id, _type)
-            return result if found else None
-
-    def _getTypedProperty(self, propertyID, _type = None):
-        """
-        Gets the property with the specified id as the type that it
-        is supposed to be. :param id: MUST be a 4 digit hexadecimal
-        string.
-
-        If you know for sure what type the property is before hand,
-        you can specify it as being one of the strings in the
-        constant FIXED_LENGTH_PROPS_STRING or
-        VARIABLE_LENGTH_PROPS_STRING.
-        """
-        verifyPropertyId(propertyID)
-        verifyType(_type)
-        propertyID = propertyID.upper()
-        for x in (propertyID + _type,) if _type is not None else self.props:
-            if x.startswith(propertyID):
-                prop = self.props[x]
-                return True, (prop.value if isinstance(prop, FixedLengthProp) else prop)
-        return False, None
-
-    def _getTypedStream(self, filename, _type = None):
-        """
-        Gets the contents of the specified stream as the type that
-        it is supposed to be.
-
-        Rather than the full filename, you should only feed this
-        function the filename sans the type. So if the full name
-        is "__substg1.0_001A001F", the filename this function
-        should receive should be "__substg1.0_001A".
-
-        If you know for sure what type the stream is before hand,
-        you can specify it as being one of the strings in the
-        constant FIXED_LENGTH_PROPS_STRING or
-        VARIABLE_LENGTH_PROPS_STRING.
-
-        If you have not specified the type, the type this function
-        returns in many cases cannot be predicted. As such, when
-        using this function it is best for you to check the type
-        that it returns. If the function returns None, that means
-        it could not find the stream specified.
-        """
-        return self.__msg._getTypedStream([self.__dir, filename], True, _type)
-
-    def exists(self, filename) -> bool:
-        """
-        Checks if stream exists inside the attachment folder.
-        """
-        return self.__msg.exists([self.__dir, filename])
-
-    def sExists(self, filename) -> bool:
-        """
-        Checks if the string stream exists inside the attachment folder.
-        """
-        return self.__msg.sExists([self.__dir, filename])
-
-    def existsTypedProperty(self, id, _type = None) -> bool:
-        """
-        Determines if the stream with the provided id exists. The return of this
-        function is 2 values, the first being a boolean for if anything was
-        found, and the second being how many were found.
-        """
-        return self.__msg.existsTypedProperty(id, self.__dir, _type, True, self.__props)
-
-    @property
-    def attachmentEncoding(self) -> Optional[bytes]:
-        """
-        The encoding information about the attachment object. Will return
-        b'*\x86H\x86\xf7\x14\x03\x0b\x01' if encoded in MacBinary format,
-        otherwise it is unset.
-        """
-        return self._ensureSet('_attachmentEncoding', '__substg1.0_37020102', False)
-
-    @property
-    def additionalInformation(self) -> Optional[str]:
-        """
-        The additional information about the attachment. This property MUST be
-        an empty string if attachmentEncoding is not set. Otherwise it MUST be
-        set to a string of the format ":CREA:TYPE" where ":CREA" is the
-        four-letter Macintosh file creator code and ":TYPE" is a four-letter
-        Macintosh type code.
-        """
-        return self._ensureSet('_additionalInformation', '__substg1.0_370F')
-
-    @property
-    def cid(self) -> Optional[str]:
-        """
-        Returns the Content ID of the attachment, if it exists.
-        """
-        return self._ensureSet('_cid', '__substg1.0_3712')
-
-    contendId = cid
-
-    @property
-    def dir(self):
-        """
-        Returns the directory inside the msg file where the attachment is
-        located.
-        """
-        return self.__dir
-
-    @property
-    def displayName(self) -> Optional[str]:
-        """
-        Returns the display name of the folder.
-        """
-        return self._ensureSet('_displayName', '__substg1.0_3001')
-
-    @property
-    def exceptionReplaceTime(self) -> Optional[datetime.datetime]:
-        """
-        The original date and time at which the instance in the recurrence
-        pattern would have occurred if it were not an exception.
-
-        Only applicable if the attachment is an Exception object.
-        """
-        return self._ensureSetProperty('_exceptionReplaceTime', '7FF90040')
-
-    @property
-    def extension(self) -> Optional[str]:
-        """
-        The reported extension for the file.
-        """
-        return self._ensureSet('_extension', '__substg1.0_3703')
-
-    @property
-    def hidden(self) -> bool:
-        """
-        Indicates whether an Attachment object is hidden from the end user.
-        """
-        return self._ensureSetProperty('_hidden', '7FFE000B', overrideClass = bool, preserveNone = False)
-
-    @property
-    def isAttachmentContactPhoto(self) -> bool:
-        """
-        Whether the attachment is a contact photo for a Contact object.
-        """
-        return self._ensureSetProperty('_isAttachmentContactPhoto', '7FFF000B', overrideClass = bool, preserveNone = False)
-
-    @property
-    def longFilename(self) -> Optional[str]:
-        """
-        Returns the long file name of the attachment, if it exists.
-        """
-        return self._ensureSet('_longFilename', '__substg1.0_3707')
-
-    @property
-    def mimetype(self) -> Optional[str]:
-        """
-        The content-type mime header of the attachment, if specified.
-        """
-        return self._ensureSet('_mimetype', '__substg1.0_370E', overrideClass = partial(tryGetMimetype, self), preserveNone = False)
-
-    @property
-    def msg(self) -> 'MSGFile':
-        """
-        Returns the Message instance the attachment belongs to.
-        """
-        return self.__msg
-
-    @property
-    def name(self) -> Optional[str]:
-        """
-        The best name available for the file. Uses long filename before short.
-        """
-        if self.type is AttachmentType.MSG:
-            if self.displayName:
-                return self.displayName + '.msg'
-        return self.longFilename or self.shortFilename
-
-    @property
-    def namedProperties(self) -> NamedProperties:
-        """
-        The NamedAttachmentProperties instance for this attachment.
-        """
-        return self.__namedProperties
-
-    @property
-    def payloadClass(self) -> Optional[str]:
-        """
-        The class name of an object that can display the contents of the
-        message.
-        """
-        return self._ensureSet('_payloadClass', '__substg1.0_371A')
-
-    @property
-    def props(self) -> Properties:
-        """
-        Returns the Properties instance of the attachment.
-        """
-        return self.__props
-
-    @property
-    def renderingPosition(self) -> Optional[int]:
-        """
-        The offset, in redered characters, to use when rendering the attachment
-        within the main message text. A value of 0xFFFFFFFF indicates a hidden
-        attachment that is not to be rendered.
-        """
-        return self._ensureSetProperty('_renderingPosition', '370B0003')
-
-    @property
-    def shortFilename(self) -> Optional[str]:
-        """
-        Returns the short file name of the attachment, if it exists.
-        """
-        return self._ensureSet('_shortFilename', '__substg1.0_3704')
-
-    @property
-    def treePath(self) -> Tuple:
-        """
-        A path, as a tuple of instances, needed to get to this instance through
-        the MSGFile-Attachment tree.
-        """
-        return self.__treePath
-
-    @property
-    def type(self) -> AttachmentType:
-        """
-        Returns the (internally used) type of the data.
-        """
-        return AttachmentType.UNKNOWN
+from __future__ import annotations
+
+
+__all__ = [
+    'AttachmentBase',
+]
+
+
+import datetime
+import logging
+
+from functools import partial
+from typing import Optional, Tuple, TYPE_CHECKING
+
+from .enums import AttachmentType, ErrorBehavior, PropertiesType
+from .exceptions import StandardViolationError
+from .named import NamedProperties
+from .prop import FixedLengthProp
+from .properties import Properties
+from .utils import tryGetMimetype, verifyPropertyId, verifyType
+
+
+# Allow for nice type checking.
+if TYPE_CHECKING:
+    from .msg import MSGFile
+
+logger = logging.getLogger(__name__)
+logger.addHandler(logging.NullHandler())
+
+
+class AttachmentBase:
+    """
+    Stores the attachment data of a Message instance.
+    Should the attachment be an embeded message, the
+    class used to create it will be the same as the
+    Message class used to create the attachment.
+    """
+
+    def __init__(self, msg, dir_):
+        """
+        :param msg: the Message instance that the attachment belongs to.
+        :param dir_: the directory inside the msg file where the attachment is located.
+        """
+        self.__msg = msg
+        self.__dir = dir_
+        if not self.exists('__properties_version1.0'):
+            if (msg.errorBehavior & ErrorBehavior.STANDARDS_VIOLATION):
+                logger.error('Attachments MUST have a property stream.')
+            else:
+                raise StandardViolationError('Attachments MUST have a property stream.') from None
+        self.__props = Properties(self._getStream('__properties_version1.0'), PropertiesType.ATTACHMENT)
+        self.__namedProperties = NamedProperties(msg.named, self)
+        self.__treePath = msg.treePath + (self,)
+
+    def _ensureSet(self, variable, streamID, stringStream = True, **kwargs):
+        """
+        Ensures that the variable exists, otherwise will set it using the
+        specified stream. After that, return said variable.
+
+        If the specified stream is not a string stream, make sure to set
+        :param stringStream: to False.
+
+        :param overrideClass: Class/function to use to morph the data that was
+            read. The data will be the first argument to the class's __init__
+            function or the function itself, if that is what is provided. By
+            default, this will be completely ignored if the value was not found.
+        :param preserveNone: If true (default), causes the function to ignore
+            :param overrideClass: when the value could not be found (is None).
+            If this is changed to False, then the value will be used regardless.
+        """
+        try:
+            return getattr(self, variable)
+        except AttributeError:
+            if stringStream:
+                value = self._getStringStream(streamID)
+            else:
+                value = self._getStream(streamID)
+            # Check if we should be overriding the data type for this instance.
+            if kwargs:
+                overrideClass = kwargs.get('overrideClass')
+                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
+                    value = overrideClass(value)
+            setattr(self, variable, value)
+            return value
+
+    def _ensureSetNamed(self, variable, propertyName : str, guid : str, **kwargs):
+        """
+        Ensures that the variable exists, otherwise will set it using the named
+        property. After that, return said variable.
+
+        :param overrideClass: Class/function to use to morph the data that was
+            read. The data will be the first argument to the class's __init__
+            function or the function itself, if that is what is provided. By
+            default, this will be completely ignored if the value was not found.
+        :param preserveNone: If true (default), causes the function to ignore
+            :param overrideClass: when the value could not be found (is None).
+            If this is changed to False, then the value will be used regardless.
+        """
+        try:
+            return getattr(self, variable)
+        except AttributeError:
+            value = self.namedProperties.get((propertyName, guid))
+            # Check if we should be overriding the data type for this instance.
+            if kwargs:
+                overrideClass = kwargs.get('overrideClass')
+                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
+                    value = overrideClass(value)
+            setattr(self, variable, value)
+            return value
+
+    def _ensureSetProperty(self, variable, propertyName, **kwargs):
+        """
+        Ensures that the variable exists, otherwise will set it using the
+        property. After that, return said variable.
+
+        :param overrideClass: Class/function to use to morph the data that was
+            read. The data will be the first argument to the class's __init__
+            function or the function itself, if that is what is provided. By
+            default, this will be completely ignored if the value was not found.
+        :param preserveNone: If true (default), causes the function to ignore
+            :param overrideClass: when the value could not be found (is None).
+            If this is changed to False, then the value will be used regardless.
+        """
+        try:
+            return getattr(self, variable)
+        except AttributeError:
+            try:
+                value = self.props[propertyName].value
+            except (KeyError, AttributeError):
+                value = None
+            # Check if we should be overriding the data type for this instance.
+            if kwargs:
+                overrideClass = kwargs.get('overrideClass')
+                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
+                    value = overrideClass(value)
+            setattr(self, variable, value)
+            return value
+
+    def _ensureSetTyped(self, variable, _id, **kwargs):
+        """
+        Like the other ensure set functions, but designed for when something
+        could be multiple types (where only one will be present). This way you
+        have no need to set the type, it will be handled for you.
+
+        :param overrideClass: Class/function to use to morph the data that was
+            read. The data will be the first argument to the class's __init__
+            function or the function itself, if that is what is provided. By
+            default, this will be completely ignored if the value was not found.
+        :param preserveNone: If true (default), causes the function to ignore
+            :param overrideClass: when the value could not be found (is None).
+            If this is changed to False, then the value will be used regardless.
+        """
+        try:
+            return getattr(self, variable)
+        except AttributeError:
+            value = self._getTypedData(_id)
+            # Check if we should be overriding the data type for this instance.
+            if kwargs:
+                overrideClass = kwargs.get('overrideClass')
+                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
+                    value = overrideClass(value)
+            setattr(self, variable, value)
+            return value
+
+    def _getStream(self, filename) -> Optional[bytes]:
+        return self.__msg._getStream([self.__dir, filename])
+
+    def _getStringStream(self, filename) -> Optional[str]:
+        """
+        Gets a string representation of the requested filename.
+        Checks for both ASCII and Unicode representations and returns
+        a value if possible.  If there are both ASCII and Unicode
+        versions, then :param prefer: specifies which will be
+        returned.
+        """
+        return self.__msg._getStringStream([self.__dir, filename])
+
+    def _getTypedData(self, id, _type = None):
+        """
+        Gets the data for the specified id as the type that it is
+        supposed to be. :param id: MUST be a 4 digit hexadecimal
+        string.
+
+        If you know for sure what type the data is before hand,
+        you can specify it as being one of the strings in the
+        constant FIXED_LENGTH_PROPS_STRING or
+        VARIABLE_LENGTH_PROPS_STRING.
+        """
+        verifyPropertyId(id)
+        id = id.upper()
+        found, result = self._getTypedStream('__substg1.0_' + id, _type)
+        if found:
+            return result
+        else:
+            found, result = self._getTypedProperty(id, _type)
+            return result if found else None
+
+    def _getTypedProperty(self, propertyID, _type = None):
+        """
+        Gets the property with the specified id as the type that it
+        is supposed to be. :param id: MUST be a 4 digit hexadecimal
+        string.
+
+        If you know for sure what type the property is before hand,
+        you can specify it as being one of the strings in the
+        constant FIXED_LENGTH_PROPS_STRING or
+        VARIABLE_LENGTH_PROPS_STRING.
+        """
+        verifyPropertyId(propertyID)
+        verifyType(_type)
+        propertyID = propertyID.upper()
+        for x in (propertyID + _type,) if _type is not None else self.props:
+            if x.startswith(propertyID):
+                prop = self.props[x]
+                return True, (prop.value if isinstance(prop, FixedLengthProp) else prop)
+        return False, None
+
+    def _getTypedStream(self, filename, _type = None):
+        """
+        Gets the contents of the specified stream as the type that
+        it is supposed to be.
+
+        Rather than the full filename, you should only feed this
+        function the filename sans the type. So if the full name
+        is "__substg1.0_001A001F", the filename this function
+        should receive should be "__substg1.0_001A".
+
+        If you know for sure what type the stream is before hand,
+        you can specify it as being one of the strings in the
+        constant FIXED_LENGTH_PROPS_STRING or
+        VARIABLE_LENGTH_PROPS_STRING.
+
+        If you have not specified the type, the type this function
+        returns in many cases cannot be predicted. As such, when
+        using this function it is best for you to check the type
+        that it returns. If the function returns None, that means
+        it could not find the stream specified.
+        """
+        return self.__msg._getTypedStream([self.__dir, filename], True, _type)
+
+    def exists(self, filename) -> bool:
+        """
+        Checks if stream exists inside the attachment folder.
+        """
+        return self.__msg.exists([self.__dir, filename])
+
+    def sExists(self, filename) -> bool:
+        """
+        Checks if the string stream exists inside the attachment folder.
+        """
+        return self.__msg.sExists([self.__dir, filename])
+
+    def existsTypedProperty(self, id, _type = None) -> bool:
+        """
+        Determines if the stream with the provided id exists. The return of this
+        function is 2 values, the first being a boolean for if anything was
+        found, and the second being how many were found.
+        """
+        return self.__msg.existsTypedProperty(id, self.__dir, _type, True, self.__props)
+
+    @property
+    def attachmentEncoding(self) -> Optional[bytes]:
+        """
+        The encoding information about the attachment object. Will return
+        b'*\x86H\x86\xf7\x14\x03\x0b\x01' if encoded in MacBinary format,
+        otherwise it is unset.
+        """
+        return self._ensureSet('_attachmentEncoding', '__substg1.0_37020102', False)
+
+    @property
+    def additionalInformation(self) -> Optional[str]:
+        """
+        The additional information about the attachment. This property MUST be
+        an empty string if attachmentEncoding is not set. Otherwise it MUST be
+        set to a string of the format ":CREA:TYPE" where ":CREA" is the
+        four-letter Macintosh file creator code and ":TYPE" is a four-letter
+        Macintosh type code.
+        """
+        return self._ensureSet('_additionalInformation', '__substg1.0_370F')
+
+    @property
+    def cid(self) -> Optional[str]:
+        """
+        Returns the Content ID of the attachment, if it exists.
+        """
+        return self._ensureSet('_cid', '__substg1.0_3712')
+
+    contendId = cid
+
+    @property
+    def dir(self):
+        """
+        Returns the directory inside the msg file where the attachment is
+        located.
+        """
+        return self.__dir
+
+    @property
+    def displayName(self) -> Optional[str]:
+        """
+        Returns the display name of the folder.
+        """
+        return self._ensureSet('_displayName', '__substg1.0_3001')
+
+    @property
+    def exceptionReplaceTime(self) -> Optional[datetime.datetime]:
+        """
+        The original date and time at which the instance in the recurrence
+        pattern would have occurred if it were not an exception.
+
+        Only applicable if the attachment is an Exception object.
+        """
+        return self._ensureSetProperty('_exceptionReplaceTime', '7FF90040')
+
+    @property
+    def extension(self) -> Optional[str]:
+        """
+        The reported extension for the file.
+        """
+        return self._ensureSet('_extension', '__substg1.0_3703')
+
+    @property
+    def hidden(self) -> bool:
+        """
+        Indicates whether an Attachment object is hidden from the end user.
+        """
+        return self._ensureSetProperty('_hidden', '7FFE000B', overrideClass = bool, preserveNone = False)
+
+    @property
+    def isAttachmentContactPhoto(self) -> bool:
+        """
+        Whether the attachment is a contact photo for a Contact object.
+        """
+        return self._ensureSetProperty('_isAttachmentContactPhoto', '7FFF000B', overrideClass = bool, preserveNone = False)
+
+    @property
+    def longFilename(self) -> Optional[str]:
+        """
+        Returns the long file name of the attachment, if it exists.
+        """
+        return self._ensureSet('_longFilename', '__substg1.0_3707')
+
+    @property
+    def mimetype(self) -> Optional[str]:
+        """
+        The content-type mime header of the attachment, if specified.
+        """
+        return self._ensureSet('_mimetype', '__substg1.0_370E', overrideClass = partial(tryGetMimetype, self), preserveNone = False)
+
+    @property
+    def msg(self) -> MSGFile:
+        """
+        Returns the Message instance the attachment belongs to.
+        """
+        return self.__msg
+
+    @property
+    def name(self) -> Optional[str]:
+        """
+        The best name available for the file. Uses long filename before short.
+        """
+        if self.type is AttachmentType.MSG:
+            if self.displayName:
+                return self.displayName + '.msg'
+        return self.longFilename or self.shortFilename
+
+    @property
+    def namedProperties(self) -> NamedProperties:
+        """
+        The NamedAttachmentProperties instance for this attachment.
+        """
+        return self.__namedProperties
+
+    @property
+    def payloadClass(self) -> Optional[str]:
+        """
+        The class name of an object that can display the contents of the
+        message.
+        """
+        return self._ensureSet('_payloadClass', '__substg1.0_371A')
+
+    @property
+    def props(self) -> Properties:
+        """
+        Returns the Properties instance of the attachment.
+        """
+        return self.__props
+
+    @property
+    def renderingPosition(self) -> Optional[int]:
+        """
+        The offset, in redered characters, to use when rendering the attachment
+        within the main message text. A value of 0xFFFFFFFF indicates a hidden
+        attachment that is not to be rendered.
+        """
+        return self._ensureSetProperty('_renderingPosition', '370B0003')
+
+    @property
+    def shortFilename(self) -> Optional[str]:
+        """
+        Returns the short file name of the attachment, if it exists.
+        """
+        return self._ensureSet('_shortFilename', '__substg1.0_3704')
+
+    @property
+    def treePath(self) -> Tuple:
+        """
+        A path, as a tuple of instances, needed to get to this instance through
+        the MSGFile-Attachment tree.
+        """
+        return self.__treePath
+
+    @property
+    def type(self) -> AttachmentType:
+        """
+        Returns the (internally used) type of the data.
+        """
+        return AttachmentType.UNKNOWN
```

### Comparing `extract_msg-0.40.0/extract_msg/calendar.py` & `extract_msg-0.41.0/extract_msg/calendar.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,86 +1,91 @@
-import datetime
-
-from typing import Optional, Set
-
-from . import constants
-from .calendar_base import CalendarBase
-from .enums import ClientIntentFlag
-
-
-class Calendar(CalendarBase):
-    """
-    A calendar object.
-    """
-
-    @property
-    def clientIntent(self) -> Optional[Set[ClientIntentFlag]]:
-        """
-        A set of the actions a user has taken on a Meeting object.
-        """
-        return self._ensureSetNamed('_clientIntent', '0015', constants.PSETID_CALENDAR_ASSISTANT, overrideClass = ClientIntentFlag.fromBits)
-
-    @property
-    def fExceptionalAttendees(self) -> Optional[bool]:
-        """
-        Indicates that it is a Recurring Calendar object with one or more
-        excpetions and that at least one of the Exception Embedded Message
-        objects has at least one RecipientRow structure.
-
-        SHOULD NOT be set for any Calendar object other than that of the
-        organizer's.
-        """
-        return self._ensureSetNamed('_fExceptionalAttendees', '822B', constants.PSETID_APPOINTMENT)
-
-    @property
-    def reminderDelta(self) -> Optional[int]:
-        """
-        The interval, in minutes, between the time at which the reminder first
-        becomes overdue and the start time of the Calendar object.
-        """
-        return self._ensureSetNamed('_reminderDelta', '8501', constants.PSETID_COMMON)
-
-    @property
-    def reminderFileParameter(self) -> Optional[str]:
-        """
-        The full path (MAY only specify the file name) of the sound that a
-        client SHOULD play when the reminder for the Message Object becomes
-        overdue.
-        """
-        return self._ensureSetNamed('_reminderFileParameter', '851F', constants.PSETID_COMMON)
-
-    @property
-    def reminderOverride(self) -> bool:
-        """
-        Specifies if clients SHOULD respect the value of the reminderPlaySound
-        property and the reminderFileParameter property.
-        """
-        return self._ensureSetNamed('_reminderOverride', '851C', constants.PSETID_COMMON, overrideClass = bool, preserveNone = False)
-
-    @property
-    def reminderPlaySound(self) -> bool:
-        """
-        Specified that the cliebnt should play a sound when the reminder becomes
-        overdue.
-        """
-        return self._ensureSetNamed('_reminderPlaySound', '851E', constants.PSETID_COMMON, overrideClass = bool, preserveNone = False)
-
-    @property
-    def reminderSet(self) -> bool:
-        """
-        Specifies whether a reminder is set on the object.
-        """
-        return self._ensureSetNamed('_reminderSet', '8503', constants.PSETID_COMMON, overrideClass = bool, preserveNone = False)
-
-    @property
-    def reminderSignalTime(self) -> Optional[datetime.datetime]:
-        """
-        The point in time when a reminder transitions from pending to overdue.
-        """
-        return self._ensureSetNamed('_reminderSignalTime', '8560', constants.PSETID_COMMON)
-
-    @property
-    def reminderTime(self) -> Optional[datetime.datetime]:
-        """
-        The time after which the user would be late.
-        """
-        return self._ensureSetNamed('_reminderTime', '8502', constants.PSETID_COMMON)
+__all__ = [
+    'Calendar',
+]
+
+
+import datetime
+
+from typing import Optional, Set
+
+from . import constants
+from .calendar_base import CalendarBase
+from .enums import ClientIntentFlag
+
+
+class Calendar(CalendarBase):
+    """
+    A calendar object.
+    """
+
+    @property
+    def clientIntent(self) -> Optional[Set[ClientIntentFlag]]:
+        """
+        A set of the actions a user has taken on a Meeting object.
+        """
+        return self._ensureSetNamed('_clientIntent', '0015', constants.PSETID_CALENDAR_ASSISTANT, overrideClass = ClientIntentFlag.fromBits)
+
+    @property
+    def fExceptionalAttendees(self) -> Optional[bool]:
+        """
+        Indicates that it is a Recurring Calendar object with one or more
+        excpetions and that at least one of the Exception Embedded Message
+        objects has at least one RecipientRow structure.
+
+        SHOULD NOT be set for any Calendar object other than that of the
+        organizer's.
+        """
+        return self._ensureSetNamed('_fExceptionalAttendees', '822B', constants.PSETID_APPOINTMENT)
+
+    @property
+    def reminderDelta(self) -> Optional[int]:
+        """
+        The interval, in minutes, between the time at which the reminder first
+        becomes overdue and the start time of the Calendar object.
+        """
+        return self._ensureSetNamed('_reminderDelta', '8501', constants.PSETID_COMMON)
+
+    @property
+    def reminderFileParameter(self) -> Optional[str]:
+        """
+        The full path (MAY only specify the file name) of the sound that a
+        client SHOULD play when the reminder for the Message Object becomes
+        overdue.
+        """
+        return self._ensureSetNamed('_reminderFileParameter', '851F', constants.PSETID_COMMON)
+
+    @property
+    def reminderOverride(self) -> bool:
+        """
+        Specifies if clients SHOULD respect the value of the reminderPlaySound
+        property and the reminderFileParameter property.
+        """
+        return self._ensureSetNamed('_reminderOverride', '851C', constants.PSETID_COMMON, overrideClass = bool, preserveNone = False)
+
+    @property
+    def reminderPlaySound(self) -> bool:
+        """
+        Specified that the cliebnt should play a sound when the reminder becomes
+        overdue.
+        """
+        return self._ensureSetNamed('_reminderPlaySound', '851E', constants.PSETID_COMMON, overrideClass = bool, preserveNone = False)
+
+    @property
+    def reminderSet(self) -> bool:
+        """
+        Specifies whether a reminder is set on the object.
+        """
+        return self._ensureSetNamed('_reminderSet', '8503', constants.PSETID_COMMON, overrideClass = bool, preserveNone = False)
+
+    @property
+    def reminderSignalTime(self) -> Optional[datetime.datetime]:
+        """
+        The point in time when a reminder transitions from pending to overdue.
+        """
+        return self._ensureSetNamed('_reminderSignalTime', '8560', constants.PSETID_COMMON)
+
+    @property
+    def reminderTime(self) -> Optional[datetime.datetime]:
+        """
+        The time after which the user would be late.
+        """
+        return self._ensureSetNamed('_reminderTime', '8502', constants.PSETID_COMMON)
```

### Comparing `extract_msg-0.40.0/extract_msg/calendar_base.py` & `extract_msg-0.41.0/extract_msg/calendar_base.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,525 +1,530 @@
-import datetime
-import logging
-
-from typing import List, Optional, Set, Tuple, Union
-
-from . import constants
-from .enums import AppointmentAuxilaryFlag, AppointmentColor, AppointmentStateFlag, BusyStatus, IconIndex, MeetingRecipientType, ResponseStatus
-from .message_base import MessageBase
-from .structures.entry_id import EntryID
-from .structures.misc_id import GlobalObjectID
-from .structures.recurrence_pattern import RecurrencePattern
-from .structures.time_zone_definition import TimeZoneDefinition
-from .structures.time_zone_struct import TimeZoneStruct
-
-
-logger = logging.getLogger(__name__)
-logger.addHandler(logging.NullHandler())
-
-
-class CalendarBase(MessageBase):
-    """
-    Common base for all Appointment and Meeting objects.
-    """
-
-    def _genRecipient(self, recipientType, recipientInt : MeetingRecipientType) -> Optional[str]:
-        """
-        Returns the specified recipient field.
-        """
-        private = '_' + recipientType
-        recipientInt = MeetingRecipientType(recipientInt)
-        try:
-            return getattr(self, private)
-        except AttributeError:
-            value = None
-            # Check header first.
-            if self.headerInit():
-                value = self.header[recipientType]
-                if value:
-                    value = value.replace(',', self.recipientSeparator)
-
-            # If the header had a blank field or didn't have the field, generate
-            # it manually.
-            if not value:
-                # Check if the header has initialized.
-                if self.headerInit():
-                    logger.info(f'Header found, but "{recipientType}" is not included. Will be generated from other streams.')
-
-                # Get a list of the recipients of the specified type.
-                foundRecipients = tuple(recipient.formatted for recipient in self.recipients if recipient.type == recipientInt)
-
-                # If we found recipients, join them with the recipient separator
-                # and a space.
-                if len(foundRecipients) > 0:
-                    value = (self.recipientSeparator + ' ').join(foundRecipients)
-
-            # Code to fix the formatting so it's all a single line. This allows
-            # the user to format it themself if they want. This should probably
-            # be redone to use re or something, but I can do that later. This
-            # shouldn't be a huge problem for now.
-            if value:
-                value = value.replace(' \r\n\t', ' ').replace('\r\n\t ', ' ').replace('\r\n\t', ' ')
-                value = value.replace('\r\n', ' ').replace('\r', ' ').replace('\n', ' ')
-                while value.find('  ') != -1:
-                    value = value.replace('  ', ' ')
-
-            # Set the field in the class.
-            setattr(self, private, value)
-
-            return value
-
-    @property
-    def allAttendeesString(self) -> Optional[str]:
-        """
-        A list of all attendees, excluding the organizer.
-        """
-        return self._ensureSetNamed('_allAttendeesString', '8238', constants.PSETID_APPOINTMENT)
-
-    @property
-    def appointmentAuxilaryFlags(self) -> Optional[Set[AppointmentAuxilaryFlag]]:
-        """
-        The auxiliary state of the object.
-        """
-        return self._ensureSetNamed('_appointmentAuxilaryFlags', '8207', constants.PSETID_APPOINTMENT, overrideClass = AppointmentAuxilaryFlag.fromBits)
-
-    @property
-    def appointmentColor(self) -> Optional[AppointmentColor]:
-        """
-        The color to be used when displaying a Calendar object.
-        """
-        return self._ensureSetNamed('_appointmentColor', '8214', constants.PSETID_APPOINTMENT, overrideClass = AppointmentColor)
-
-    @property
-    def appointmentDuration(self) -> Optional[int]:
-        """
-        The length of the event, in minutes.
-        """
-        return self._ensureSetNamed('_appointmentDuration', '8213', constants.PSETID_APPOINTMENT)
-
-    @property
-    def appointmentEndWhole(self) -> Optional[datetime.datetime]:
-        """
-        The end date and time of the event in UTC.
-        """
-        return self._ensureSetNamed('_appointmentEndWhole', '820E', constants.PSETID_APPOINTMENT)
-
-    @property
-    def appointmentNotAllowPropose(self) -> bool:
-        """
-        Indicates that attendees are not allowed to propose a new date and/or
-        time for the meeting if True.
-        """
-        return self._ensureSetNamed('_appointmentNotAllowPropose', '8259', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
-
-    @property
-    def appointmentRecur(self) -> Optional[RecurrencePattern]:
-        """
-        Specifies the dates and times when a recurring series occurs by using
-        one of the recurrence patterns and ranges specified in this section.
-        """
-        return self._ensureSetNamed('_appointmentRecur', '8216', constants.PSETID_APPOINTMENT, overrideClass = RecurrencePattern)
-
-    @property
-    def appointmentSequence(self) -> Optional[int]:
-        """
-        Specified the sequence number of a Meeting object. A meeting object
-        begins with the sequence number set to 0 and is incremented each time
-        the organizer sends out a Meeting Update object.
-        """
-        return self._ensureSetNamed('_appointmentSequence', '8201', constants.PSETID_APPOINTMENT)
-
-    @property
-    def appointmentStartWhole(self) -> Optional[datetime.datetime]:
-        """
-        The start date and time of the event in UTC.
-        """
-        return self._ensureSetNamed('_appointmentStartWhole', '820D', constants.PSETID_APPOINTMENT)
-
-    @property
-    def appointmentStateFlags(self) -> Optional[Set[AppointmentStateFlag]]:
-        """
-        The appointment state of the object.
-        """
-        return self._ensureSetNamed('_appointmentStateFlags', '8217', constants.PSETID_APPOINTMENT, overrideClass = AppointmentStateFlag.fromBits)
-
-    @property
-    def appointmentSubType(self) -> bool:
-        """
-        Whether the event is an all-day event or not.
-        """
-        return self._ensureSetNamed('_appointmentSubType', '8215', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
-
-    @property
-    def appointmentTimeZoneDefinitionEndDisplay(self) -> Optional[TimeZoneDefinition]:
-        """
-        Specifies the time zone information for the appointmentEndWhole property
-        Used to convert the end date and time to and from UTC.
-        """
-        return self._ensureSetNamed('_appointmentTimeZoneDefinitionEndDisplay', '825F', constants.PSETID_APPOINTMENT, overrideClass = TimeZoneDefinition)
-
-    @property
-    def appointmentTimeZoneDefinitionRecur(self) -> Optional[TimeZoneDefinition]:
-        """
-        Specified the time zone information that specifies how to convert the
-        meeting date and time on a recurring series to and from UTC.
-        """
-        return self._ensureSetNamed('_appointmentTimeZoneDefinitionRecur', '8260', constants.PSETID_APPOINTMENT, overrideClass = TimeZoneDefinition)
-
-    @property
-    def appointmentTimeZoneDefinitionStartDisplay(self) -> Optional[TimeZoneDefinition]:
-        """
-        Specifies the time zone information for the appointmentStartWhole
-        property. Used to convert the start date and time to and from UTC.
-        """
-        return self._ensureSetNamed('_appointmentTimeZoneDefinitionStartDisplay', '825E', constants.PSETID_APPOINTMENT, overrideClass = TimeZoneDefinition)
-
-    @property
-    def appointmentUnsendableRecipients(self) -> Optional[bytes]:
-        """
-        A list of unsendable attendees.
-
-        I want to return the structure parsed, but my one example does not match
-        the specifications. If you have examples, let me know and I can ask you
-        to run a verification on it.
-        """
-        return self._ensureSetNamed('_appointmentUnsendableRecipients', '825D', constants.PSETID_APPOINTMENT)
-
-    @property
-    def bcc(self) -> Optional[str]:
-        """
-        Returns the bcc field, if it exists.
-        """
-        return self._genRecipient('bcc', MeetingRecipientType.SENDABLE_RESOURCE_OBJECT)
-
-    @property
-    def birthdayContactAttributionDisplayName(self) -> Optional[str]:
-        """
-        Indicated the name of the contact associated with the birthday event.
-        """
-        return self._ensureSetNamed('_birthdayContactAttributionDisplayName', 'BirthdayContactAttributionDisplayName', constants.PSETID_ADDRESS)
-
-    @property
-    def birthdayContactEntryID(self) -> Optional[EntryID]:
-        """
-        Indicates the EntryID of the contact associated with the birthday event.
-        """
-        return self._ensureSetNamed('_birthdayContactEntryID', 'BirthdayContactEntryId', constants.PSETID_ADDRESS, overrideClass = EntryID.autoCreate)
-
-    @property
-    def birthdayContactPersonGuid(self) -> Optional[bytes]:
-        """
-        Indicates the person ID's GUID of the contact associated with the
-        birthday event.
-        """
-        return self._ensureSetNamed('_birthdayContactPersonGuid', 'BirthdayContactPersonGuid', constants.PSETID_ADDRESS)
-
-    @property
-    def busyStatus(self) -> Optional[BusyStatus]:
-        """
-        Specified the availability of a user for the event described by the
-        object.
-        """
-        return self._ensureSetNamed('_busyStatus', '8205', constants.PSETID_APPOINTMENT, overrideClass = BusyStatus)
-
-    @property
-    def cc(self) -> Optional[str]:
-        """
-        Returns the cc field, if it exists.
-        """
-        return self._genRecipient('cc', MeetingRecipientType.SENDABLE_OPTIONAL_ATTENDEE)
-
-    @property
-    def ccAttendeesString(self) -> Optional[str]:
-        """
-        A list of all the sendable attendees, who are also optional attendees.
-        """
-        return self._ensureSetNamed('_ccAttendeesString', '823C', constants.PSETID_APPOINTMENT)
-
-    @property
-    def cleanGlobalObjectID(self) -> Optional[GlobalObjectID]:
-        """
-        The value of the globalObjectID property for an object that represents
-        an Exception object to a recurring series, where the year, month, and
-        day fields are all 0.
-        """
-        return self._ensureSetNamed('_cleanGlobalObjectID', '0023', constants.PSETID_MEETING, overrideClass = GlobalObjectID)
-
-    @property
-    def clipEnd(self) -> Optional[datetime.datetime]:
-        """
-        For single-instance Calendar objects, the end date and time of the
-        event in UTC. For a recurring series, midnight in the user's machine
-        time zone, on the date of the last instance, then is persisted in UTC,
-        unless the recurring series has no end, in which case the value MUST be
-        "31 August 4500 11:49 PM".
-
-        Honestly, not sure what this is. [MS-OXOCAL]: PidLidClipEnd.
-        """
-        return self._ensureSetNamed('_clipEnd', '8236', constants.PSETID_APPOINTMENT)
-
-    @property
-    def clipStart(self) -> Optional[datetime.datetime]:
-        """
-        For single-instance Calendar objects, the start date and time of the
-        event in UTC. For a recurring series, midnight in the user's machine
-        time zone, on the date of the first instance, then is persisted in UTC.
-
-        Honestly, not sure what this is. [MS-OXOCAL]: PidLidClipStart.
-        """
-        return self._ensureSetNamed('_clipStart', '8235', constants.PSETID_APPOINTMENT)
-
-    @property
-    def commonEnd(self) -> Optional[datetime.datetime]:
-        """
-        The end date and time of an event. MUST be equal to appointmentEndWhole.
-        """
-        return self._ensureSetNamed('_commonEnd', '8517', constants.PSETID_COMMON)
-
-    @property
-    def commonStart(self) -> Optional[datetime.datetime]:
-        """
-        The start date and time of an event. MUST be equal to
-        appointmentStartWhole.
-        """
-        return self._ensureSetNamed('_commonStart', '8516', constants.PSETID_COMMON)
-
-    @property
-    def endDate(self) -> Optional[datetime.datetime]:
-        """
-        The end date of the appointment.
-        """
-        return self._ensureSetProperty('_endDate', '00610040')
-
-    @property
-    def globalObjectID(self) -> Optional[GlobalObjectID]:
-        """
-        The unique identifier or the Calendar object.
-        """
-        return self._ensureSetNamed('_globalObjectID', '0003', constants.PSETID_MEETING, overrideClass = GlobalObjectID)
-
-    @property
-    def iconIndex(self) -> Optional[Union[IconIndex, int]]:
-        """
-        The icon to use for the object.
-        """
-        return self._ensureSetProperty('_iconIndex', '10800003', overrideClass = IconIndex.tryMake)
-
-    @property
-    def isBirthdayContactWritable(self) -> bool:
-        """
-        Indicates whether the contact associated with the birthday event is
-        writable.
-        """
-        return self._ensureSetNamed('_isBirthdayContactWritable', 'IsBirthdayContactWritable', constants.PSETID_ADDRESS, overrideClass = bool, preserveNone = False)
-
-    @property
-    def isException(self) -> bool:
-        """
-        Whether the object represents an exception. False indicates that the
-        object represents a recurring series or a single-instance object.
-        """
-        return self._ensureSetNamed('_isException', '000A', constants.PSETID_MEETING, overrideClass = bool, preserveNone = False)
-
-    @property
-    def isRecurring(self) -> bool:
-        """
-        Whether the object is associated with a recurring series.
-        """
-        return self._ensureSetNamed('_isRecurring', '0005', constants.PSETID_MEETING, overrideClass = bool, preserveNone = False)
-
-    @property
-    def keywords(self) -> Optional[List[str]]:
-        """
-        The color to be used when displaying a Calendar object.
-        """
-        return self._ensureSet('_keywords', 'Keywords')
-
-    @property
-    def linkedTaskItems(self) -> Optional[Tuple[EntryID]]:
-        """
-        A list of PidTagEntryId properties of Task objects related to the
-        Calendar object that are set by a client.
-        """
-        return self._ensureSetNamed('_linkedTaskItems', '820C', constants.PSETID_APPOINTMENT, overrideClass = lambda x : tuple(EntryID.autoCreate(y) for y in x))
-
-    @property
-    def location(self) -> Optional[str]:
-        """
-        Returns the location of the meeting.
-        """
-        return self._ensureSetNamed('_location', '8208', constants.PSETID_APPOINTMENT)
-
-    @property
-    def meetingDoNotForward(self) -> bool:
-        """
-        Whether to allow the meeting to be forwarded. True disallows forwarding.
-        """
-        return self._ensureSetNamed('_meetingDoNotForward', 'DoNotForward', constants.PS_PUBLIC_STRINGS, overrideClass = bool, preserveNone = False)
-
-    @property
-    def meetingWorkspaceUrl(self) -> Optional[str]:
-        """
-        The URL of the Meeting Workspace, as specified in [MS-MEETS], that is
-        associated with a Calendar object.
-        """
-        return self._ensureSetNamed('_meetingWorkspaceUrl', '8209', constants.PSETID_APPOINTMENT)
-
-    @property
-    def nonSendableBcc(self) -> Optional[str]:
-        """
-        A list of all unsendable attendees who are also resource objects.
-        """
-        return self._ensureSetNamed('_nonSendableBcc', '8538', constants.PSETID_COMMON)
-
-    @property
-    def nonSendableCc(self) -> Optional[str]:
-        """
-        A list of all unsendable attendees who are also optional attendees.
-        """
-        return self._ensureSetNamed('_nonSendableCc', '8537', constants.PSETID_COMMON)
-
-    @property
-    def nonSendableTo(self) -> Optional[str]:
-        """
-        A list of all unsendable attendees who are also required attendees.
-        """
-        return self._ensureSetNamed('_nonSendableTo', '8536', constants.PSETID_COMMON)
-
-    @property
-    def nonSendBccTrackStatus(self) -> Optional[List[ResponseStatus]]:
-        """
-        A ResponseStatus for each of the attendees in nonSendableBcc.
-        """
-        return self._ensureSetNamed('_nonSendBccTrackStatus', '8545', constants.PSETID_COMMON, overrideClass = (lambda x : (ResponseStatus(y) for y in x)))
-
-    @property
-    def nonSendCcTrackStatus(self) -> Optional[List[ResponseStatus]]:
-        """
-        A ResponseStatus for each of the attendees in nonSendableCc.
-        """
-        return self._ensureSetNamed('_nonSendCcTrackStatus', '8544', constants.PSETID_COMMON, overrideClass = (lambda x : (ResponseStatus(y) for y in x)))
-
-    @property
-    def nonSendToTrackStatus(self) -> Optional[List[ResponseStatus]]:
-        """
-        A ResponseStatus for each of the attendees in nonSendableTo.
-        """
-        return self._ensureSetNamed('_nonSendToTrackStatus', '8543', constants.PSETID_COMMON, overrideClass = (lambda x : (ResponseStatus(y) for y in x)))
-
-    @property
-    def optionalAttendees(self) -> Optional[str]:
-        """
-        Returns the optional attendees of the meeting.
-        """
-        return self._ensureSetNamed('_optionalAttendees', '0007', constants.PSETID_MEETING)
-
-    @property
-    def organizer(self) -> Optional[str]:
-        """
-        The meeting organizer.
-        """
-        return self._ensureSet('_organizer', '__substg1.0_0042')
-
-    @property
-    def ownerAppointmentID(self) -> Optional[int]:
-        """
-        A quasi-unique value amond all Calendar objects in a user's mailbox.
-        Assists a client or server in finding a Calendar object but is not
-        guarenteed to be unique amoung all objects.
-        """
-        return self._ensureSetProperty('_ownerAppointmentID', '00620003')
-
-    @property
-    def ownerCriticalChange(self) -> Optional[datetime.datetime]:
-        """
-        The date and time at which a Meeting Request object was sent by the
-        organizer, in UTC.
-        """
-        return self._ensureSetNamed('_ownerCriticalChange', '001A', constants.PSETID_MEETING)
-
-    @property
-    def recurrencePattern(self) -> Optional[str]:
-        """
-        A description of the recurrence specified by the appointmentRecur
-        property.
-        """
-        return self._ensureSetNamed('_recurrencePattern', '8232', constants.PSETID_APPOINTMENT)
-
-    @property
-    def recurring(self) -> bool:
-        """
-        Specifies whether the object represents a recurring series.
-        """
-        return self._ensureSetNamed('_recurring', '8223', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = True)
-
-    @property
-    def replyRequested(self) -> bool:
-        """
-        Whether the organizer requests a reply from attendees.
-        """
-        return self._ensureSetProperty('_replyRequested', '0C17000B', overrideClass = bool, preserveNone = False)
-
-    @property
-    def requiredAttendees(self) -> Optional[str]:
-        """
-        Returns the required attendees of the meeting.
-        """
-        return self._ensureSetNamed('_requiredAttendees', '0006', constants.PSETID_MEETING)
-
-    @property
-    def resourceAttendees(self) -> Optional[str]:
-        """
-        Returns the resource attendees of the meeting.
-        """
-        return self._ensureSetNamed('_resourceAttendees', '0008', constants.PSETID_MEETING)
-
-    @property
-    def responseRequested(self) -> bool:
-        """
-        Whether to send Meeting Response objects to the organizer.
-        """
-        return self._ensureSetProperty('_responseRequested', '0063000B', overrideClass = bool, preserveNone = False)
-
-    @property
-    def responseStatus(self) -> ResponseStatus:
-        """
-        The response status of an attendee.
-        """
-        return self._ensureSetNamed('_responseStatus', '8218', constants.PSETID_APPOINTMENT, overrideClass = lambda x: ResponseStatus(x or 0), preserveNone = False)
-
-    @property
-    def startDate(self) -> Optional[datetime.datetime]:
-        """
-        The start date of the appointment.
-        """
-        return self._ensureSetProperty('_startDate', '00600040')
-
-    @property
-    def timeZoneDescription(self) -> Optional[str]:
-        """
-        A human-readable description of the time zone that is represented by the
-        data in the timeZoneStruct property.
-        """
-        return self._ensureSetNamed('_timeZoneDescription', '8234', constants.PSETID_APPOINTMENT)
-
-    @property
-    def timeZoneStruct(self) -> Optional[TimeZoneStruct]:
-        """
-        Set on a recurring series to specify time zone information. Specifies
-        how to convert time fields between local time and UTC.
-        """
-        return self._ensureSetNamed('_timeZoneStruct', '8233', constants.PSETID_APPOINTMENT, overrideClass = TimeZoneStruct)
-
-    @property
-    def to(self) -> Optional[str]:
-        """
-        Returns the to field, if it exists.
-        """
-        return self._genRecipient('to', MeetingRecipientType.SENDABLE_REQUIRED_ATTENDEE)
-
-    @property
-    def toAttendeesString(self) -> Optional[str]:
-        """
-        A list of all the sendable attendees, who are also required attendees.
-        """
-        return self._ensureSetNamed('_toAttendeesString', '823B', constants.PSETID_APPOINTMENT)
+__all__ = [
+    'CalendarBase',
+]
+
+
+import datetime
+import logging
+
+from typing import List, Optional, Set, Tuple, Union
+
+from . import constants
+from .enums import AppointmentAuxilaryFlag, AppointmentColor, AppointmentStateFlag, BusyStatus, IconIndex, MeetingRecipientType, ResponseStatus
+from .message_base import MessageBase
+from .structures.entry_id import EntryID
+from .structures.misc_id import GlobalObjectID
+from .structures.recurrence_pattern import RecurrencePattern
+from .structures.time_zone_definition import TimeZoneDefinition
+from .structures.time_zone_struct import TimeZoneStruct
+
+
+logger = logging.getLogger(__name__)
+logger.addHandler(logging.NullHandler())
+
+
+class CalendarBase(MessageBase):
+    """
+    Common base for all Appointment and Meeting objects.
+    """
+
+    def _genRecipient(self, recipientType, recipientInt : MeetingRecipientType) -> Optional[str]:
+        """
+        Returns the specified recipient field.
+        """
+        private = '_' + recipientType
+        recipientInt = MeetingRecipientType(recipientInt)
+        try:
+            return getattr(self, private)
+        except AttributeError:
+            value = None
+            # Check header first.
+            if self.headerInit():
+                value = self.header[recipientType]
+                if value:
+                    value = value.replace(',', self.recipientSeparator)
+
+            # If the header had a blank field or didn't have the field, generate
+            # it manually.
+            if not value:
+                # Check if the header has initialized.
+                if self.headerInit():
+                    logger.info(f'Header found, but "{recipientType}" is not included. Will be generated from other streams.')
+
+                # Get a list of the recipients of the specified type.
+                foundRecipients = tuple(recipient.formatted for recipient in self.recipients if recipient.type == recipientInt)
+
+                # If we found recipients, join them with the recipient separator
+                # and a space.
+                if len(foundRecipients) > 0:
+                    value = (self.recipientSeparator + ' ').join(foundRecipients)
+
+            # Code to fix the formatting so it's all a single line. This allows
+            # the user to format it themself if they want. This should probably
+            # be redone to use re or something, but I can do that later. This
+            # shouldn't be a huge problem for now.
+            if value:
+                value = value.replace(' \r\n\t', ' ').replace('\r\n\t ', ' ').replace('\r\n\t', ' ')
+                value = value.replace('\r\n', ' ').replace('\r', ' ').replace('\n', ' ')
+                while value.find('  ') != -1:
+                    value = value.replace('  ', ' ')
+
+            # Set the field in the class.
+            setattr(self, private, value)
+
+            return value
+
+    @property
+    def allAttendeesString(self) -> Optional[str]:
+        """
+        A list of all attendees, excluding the organizer.
+        """
+        return self._ensureSetNamed('_allAttendeesString', '8238', constants.PSETID_APPOINTMENT)
+
+    @property
+    def appointmentAuxilaryFlags(self) -> Optional[Set[AppointmentAuxilaryFlag]]:
+        """
+        The auxiliary state of the object.
+        """
+        return self._ensureSetNamed('_appointmentAuxilaryFlags', '8207', constants.PSETID_APPOINTMENT, overrideClass = AppointmentAuxilaryFlag.fromBits)
+
+    @property
+    def appointmentColor(self) -> Optional[AppointmentColor]:
+        """
+        The color to be used when displaying a Calendar object.
+        """
+        return self._ensureSetNamed('_appointmentColor', '8214', constants.PSETID_APPOINTMENT, overrideClass = AppointmentColor)
+
+    @property
+    def appointmentDuration(self) -> Optional[int]:
+        """
+        The length of the event, in minutes.
+        """
+        return self._ensureSetNamed('_appointmentDuration', '8213', constants.PSETID_APPOINTMENT)
+
+    @property
+    def appointmentEndWhole(self) -> Optional[datetime.datetime]:
+        """
+        The end date and time of the event in UTC.
+        """
+        return self._ensureSetNamed('_appointmentEndWhole', '820E', constants.PSETID_APPOINTMENT)
+
+    @property
+    def appointmentNotAllowPropose(self) -> bool:
+        """
+        Indicates that attendees are not allowed to propose a new date and/or
+        time for the meeting if True.
+        """
+        return self._ensureSetNamed('_appointmentNotAllowPropose', '8259', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
+
+    @property
+    def appointmentRecur(self) -> Optional[RecurrencePattern]:
+        """
+        Specifies the dates and times when a recurring series occurs by using
+        one of the recurrence patterns and ranges specified in this section.
+        """
+        return self._ensureSetNamed('_appointmentRecur', '8216', constants.PSETID_APPOINTMENT, overrideClass = RecurrencePattern)
+
+    @property
+    def appointmentSequence(self) -> Optional[int]:
+        """
+        Specified the sequence number of a Meeting object. A meeting object
+        begins with the sequence number set to 0 and is incremented each time
+        the organizer sends out a Meeting Update object.
+        """
+        return self._ensureSetNamed('_appointmentSequence', '8201', constants.PSETID_APPOINTMENT)
+
+    @property
+    def appointmentStartWhole(self) -> Optional[datetime.datetime]:
+        """
+        The start date and time of the event in UTC.
+        """
+        return self._ensureSetNamed('_appointmentStartWhole', '820D', constants.PSETID_APPOINTMENT)
+
+    @property
+    def appointmentStateFlags(self) -> Optional[Set[AppointmentStateFlag]]:
+        """
+        The appointment state of the object.
+        """
+        return self._ensureSetNamed('_appointmentStateFlags', '8217', constants.PSETID_APPOINTMENT, overrideClass = AppointmentStateFlag.fromBits)
+
+    @property
+    def appointmentSubType(self) -> bool:
+        """
+        Whether the event is an all-day event or not.
+        """
+        return self._ensureSetNamed('_appointmentSubType', '8215', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
+
+    @property
+    def appointmentTimeZoneDefinitionEndDisplay(self) -> Optional[TimeZoneDefinition]:
+        """
+        Specifies the time zone information for the appointmentEndWhole property
+        Used to convert the end date and time to and from UTC.
+        """
+        return self._ensureSetNamed('_appointmentTimeZoneDefinitionEndDisplay', '825F', constants.PSETID_APPOINTMENT, overrideClass = TimeZoneDefinition)
+
+    @property
+    def appointmentTimeZoneDefinitionRecur(self) -> Optional[TimeZoneDefinition]:
+        """
+        Specified the time zone information that specifies how to convert the
+        meeting date and time on a recurring series to and from UTC.
+        """
+        return self._ensureSetNamed('_appointmentTimeZoneDefinitionRecur', '8260', constants.PSETID_APPOINTMENT, overrideClass = TimeZoneDefinition)
+
+    @property
+    def appointmentTimeZoneDefinitionStartDisplay(self) -> Optional[TimeZoneDefinition]:
+        """
+        Specifies the time zone information for the appointmentStartWhole
+        property. Used to convert the start date and time to and from UTC.
+        """
+        return self._ensureSetNamed('_appointmentTimeZoneDefinitionStartDisplay', '825E', constants.PSETID_APPOINTMENT, overrideClass = TimeZoneDefinition)
+
+    @property
+    def appointmentUnsendableRecipients(self) -> Optional[bytes]:
+        """
+        A list of unsendable attendees.
+
+        I want to return the structure parsed, but my one example does not match
+        the specifications. If you have examples, let me know and I can ask you
+        to run a verification on it.
+        """
+        return self._ensureSetNamed('_appointmentUnsendableRecipients', '825D', constants.PSETID_APPOINTMENT)
+
+    @property
+    def bcc(self) -> Optional[str]:
+        """
+        Returns the bcc field, if it exists.
+        """
+        return self._genRecipient('bcc', MeetingRecipientType.SENDABLE_RESOURCE_OBJECT)
+
+    @property
+    def birthdayContactAttributionDisplayName(self) -> Optional[str]:
+        """
+        Indicated the name of the contact associated with the birthday event.
+        """
+        return self._ensureSetNamed('_birthdayContactAttributionDisplayName', 'BirthdayContactAttributionDisplayName', constants.PSETID_ADDRESS)
+
+    @property
+    def birthdayContactEntryID(self) -> Optional[EntryID]:
+        """
+        Indicates the EntryID of the contact associated with the birthday event.
+        """
+        return self._ensureSetNamed('_birthdayContactEntryID', 'BirthdayContactEntryId', constants.PSETID_ADDRESS, overrideClass = EntryID.autoCreate)
+
+    @property
+    def birthdayContactPersonGuid(self) -> Optional[bytes]:
+        """
+        Indicates the person ID's GUID of the contact associated with the
+        birthday event.
+        """
+        return self._ensureSetNamed('_birthdayContactPersonGuid', 'BirthdayContactPersonGuid', constants.PSETID_ADDRESS)
+
+    @property
+    def busyStatus(self) -> Optional[BusyStatus]:
+        """
+        Specified the availability of a user for the event described by the
+        object.
+        """
+        return self._ensureSetNamed('_busyStatus', '8205', constants.PSETID_APPOINTMENT, overrideClass = BusyStatus)
+
+    @property
+    def cc(self) -> Optional[str]:
+        """
+        Returns the cc field, if it exists.
+        """
+        return self._genRecipient('cc', MeetingRecipientType.SENDABLE_OPTIONAL_ATTENDEE)
+
+    @property
+    def ccAttendeesString(self) -> Optional[str]:
+        """
+        A list of all the sendable attendees, who are also optional attendees.
+        """
+        return self._ensureSetNamed('_ccAttendeesString', '823C', constants.PSETID_APPOINTMENT)
+
+    @property
+    def cleanGlobalObjectID(self) -> Optional[GlobalObjectID]:
+        """
+        The value of the globalObjectID property for an object that represents
+        an Exception object to a recurring series, where the year, month, and
+        day fields are all 0.
+        """
+        return self._ensureSetNamed('_cleanGlobalObjectID', '0023', constants.PSETID_MEETING, overrideClass = GlobalObjectID)
+
+    @property
+    def clipEnd(self) -> Optional[datetime.datetime]:
+        """
+        For single-instance Calendar objects, the end date and time of the
+        event in UTC. For a recurring series, midnight in the user's machine
+        time zone, on the date of the last instance, then is persisted in UTC,
+        unless the recurring series has no end, in which case the value MUST be
+        "31 August 4500 11:49 PM".
+
+        Honestly, not sure what this is. [MS-OXOCAL]: PidLidClipEnd.
+        """
+        return self._ensureSetNamed('_clipEnd', '8236', constants.PSETID_APPOINTMENT)
+
+    @property
+    def clipStart(self) -> Optional[datetime.datetime]:
+        """
+        For single-instance Calendar objects, the start date and time of the
+        event in UTC. For a recurring series, midnight in the user's machine
+        time zone, on the date of the first instance, then is persisted in UTC.
+
+        Honestly, not sure what this is. [MS-OXOCAL]: PidLidClipStart.
+        """
+        return self._ensureSetNamed('_clipStart', '8235', constants.PSETID_APPOINTMENT)
+
+    @property
+    def commonEnd(self) -> Optional[datetime.datetime]:
+        """
+        The end date and time of an event. MUST be equal to appointmentEndWhole.
+        """
+        return self._ensureSetNamed('_commonEnd', '8517', constants.PSETID_COMMON)
+
+    @property
+    def commonStart(self) -> Optional[datetime.datetime]:
+        """
+        The start date and time of an event. MUST be equal to
+        appointmentStartWhole.
+        """
+        return self._ensureSetNamed('_commonStart', '8516', constants.PSETID_COMMON)
+
+    @property
+    def endDate(self) -> Optional[datetime.datetime]:
+        """
+        The end date of the appointment.
+        """
+        return self._ensureSetProperty('_endDate', '00610040')
+
+    @property
+    def globalObjectID(self) -> Optional[GlobalObjectID]:
+        """
+        The unique identifier or the Calendar object.
+        """
+        return self._ensureSetNamed('_globalObjectID', '0003', constants.PSETID_MEETING, overrideClass = GlobalObjectID)
+
+    @property
+    def iconIndex(self) -> Optional[Union[IconIndex, int]]:
+        """
+        The icon to use for the object.
+        """
+        return self._ensureSetProperty('_iconIndex', '10800003', overrideClass = IconIndex.tryMake)
+
+    @property
+    def isBirthdayContactWritable(self) -> bool:
+        """
+        Indicates whether the contact associated with the birthday event is
+        writable.
+        """
+        return self._ensureSetNamed('_isBirthdayContactWritable', 'IsBirthdayContactWritable', constants.PSETID_ADDRESS, overrideClass = bool, preserveNone = False)
+
+    @property
+    def isException(self) -> bool:
+        """
+        Whether the object represents an exception. False indicates that the
+        object represents a recurring series or a single-instance object.
+        """
+        return self._ensureSetNamed('_isException', '000A', constants.PSETID_MEETING, overrideClass = bool, preserveNone = False)
+
+    @property
+    def isRecurring(self) -> bool:
+        """
+        Whether the object is associated with a recurring series.
+        """
+        return self._ensureSetNamed('_isRecurring', '0005', constants.PSETID_MEETING, overrideClass = bool, preserveNone = False)
+
+    @property
+    def keywords(self) -> Optional[List[str]]:
+        """
+        The color to be used when displaying a Calendar object.
+        """
+        return self._ensureSet('_keywords', 'Keywords')
+
+    @property
+    def linkedTaskItems(self) -> Optional[Tuple[EntryID]]:
+        """
+        A list of PidTagEntryId properties of Task objects related to the
+        Calendar object that are set by a client.
+        """
+        return self._ensureSetNamed('_linkedTaskItems', '820C', constants.PSETID_APPOINTMENT, overrideClass = lambda x : tuple(EntryID.autoCreate(y) for y in x))
+
+    @property
+    def location(self) -> Optional[str]:
+        """
+        Returns the location of the meeting.
+        """
+        return self._ensureSetNamed('_location', '8208', constants.PSETID_APPOINTMENT)
+
+    @property
+    def meetingDoNotForward(self) -> bool:
+        """
+        Whether to allow the meeting to be forwarded. True disallows forwarding.
+        """
+        return self._ensureSetNamed('_meetingDoNotForward', 'DoNotForward', constants.PS_PUBLIC_STRINGS, overrideClass = bool, preserveNone = False)
+
+    @property
+    def meetingWorkspaceUrl(self) -> Optional[str]:
+        """
+        The URL of the Meeting Workspace, as specified in [MS-MEETS], that is
+        associated with a Calendar object.
+        """
+        return self._ensureSetNamed('_meetingWorkspaceUrl', '8209', constants.PSETID_APPOINTMENT)
+
+    @property
+    def nonSendableBcc(self) -> Optional[str]:
+        """
+        A list of all unsendable attendees who are also resource objects.
+        """
+        return self._ensureSetNamed('_nonSendableBcc', '8538', constants.PSETID_COMMON)
+
+    @property
+    def nonSendableCc(self) -> Optional[str]:
+        """
+        A list of all unsendable attendees who are also optional attendees.
+        """
+        return self._ensureSetNamed('_nonSendableCc', '8537', constants.PSETID_COMMON)
+
+    @property
+    def nonSendableTo(self) -> Optional[str]:
+        """
+        A list of all unsendable attendees who are also required attendees.
+        """
+        return self._ensureSetNamed('_nonSendableTo', '8536', constants.PSETID_COMMON)
+
+    @property
+    def nonSendBccTrackStatus(self) -> Optional[List[ResponseStatus]]:
+        """
+        A ResponseStatus for each of the attendees in nonSendableBcc.
+        """
+        return self._ensureSetNamed('_nonSendBccTrackStatus', '8545', constants.PSETID_COMMON, overrideClass = (lambda x : (ResponseStatus(y) for y in x)))
+
+    @property
+    def nonSendCcTrackStatus(self) -> Optional[List[ResponseStatus]]:
+        """
+        A ResponseStatus for each of the attendees in nonSendableCc.
+        """
+        return self._ensureSetNamed('_nonSendCcTrackStatus', '8544', constants.PSETID_COMMON, overrideClass = (lambda x : (ResponseStatus(y) for y in x)))
+
+    @property
+    def nonSendToTrackStatus(self) -> Optional[List[ResponseStatus]]:
+        """
+        A ResponseStatus for each of the attendees in nonSendableTo.
+        """
+        return self._ensureSetNamed('_nonSendToTrackStatus', '8543', constants.PSETID_COMMON, overrideClass = (lambda x : (ResponseStatus(y) for y in x)))
+
+    @property
+    def optionalAttendees(self) -> Optional[str]:
+        """
+        Returns the optional attendees of the meeting.
+        """
+        return self._ensureSetNamed('_optionalAttendees', '0007', constants.PSETID_MEETING)
+
+    @property
+    def organizer(self) -> Optional[str]:
+        """
+        The meeting organizer.
+        """
+        return self._ensureSet('_organizer', '__substg1.0_0042')
+
+    @property
+    def ownerAppointmentID(self) -> Optional[int]:
+        """
+        A quasi-unique value amond all Calendar objects in a user's mailbox.
+        Assists a client or server in finding a Calendar object but is not
+        guarenteed to be unique amoung all objects.
+        """
+        return self._ensureSetProperty('_ownerAppointmentID', '00620003')
+
+    @property
+    def ownerCriticalChange(self) -> Optional[datetime.datetime]:
+        """
+        The date and time at which a Meeting Request object was sent by the
+        organizer, in UTC.
+        """
+        return self._ensureSetNamed('_ownerCriticalChange', '001A', constants.PSETID_MEETING)
+
+    @property
+    def recurrencePattern(self) -> Optional[str]:
+        """
+        A description of the recurrence specified by the appointmentRecur
+        property.
+        """
+        return self._ensureSetNamed('_recurrencePattern', '8232', constants.PSETID_APPOINTMENT)
+
+    @property
+    def recurring(self) -> bool:
+        """
+        Specifies whether the object represents a recurring series.
+        """
+        return self._ensureSetNamed('_recurring', '8223', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = True)
+
+    @property
+    def replyRequested(self) -> bool:
+        """
+        Whether the organizer requests a reply from attendees.
+        """
+        return self._ensureSetProperty('_replyRequested', '0C17000B', overrideClass = bool, preserveNone = False)
+
+    @property
+    def requiredAttendees(self) -> Optional[str]:
+        """
+        Returns the required attendees of the meeting.
+        """
+        return self._ensureSetNamed('_requiredAttendees', '0006', constants.PSETID_MEETING)
+
+    @property
+    def resourceAttendees(self) -> Optional[str]:
+        """
+        Returns the resource attendees of the meeting.
+        """
+        return self._ensureSetNamed('_resourceAttendees', '0008', constants.PSETID_MEETING)
+
+    @property
+    def responseRequested(self) -> bool:
+        """
+        Whether to send Meeting Response objects to the organizer.
+        """
+        return self._ensureSetProperty('_responseRequested', '0063000B', overrideClass = bool, preserveNone = False)
+
+    @property
+    def responseStatus(self) -> ResponseStatus:
+        """
+        The response status of an attendee.
+        """
+        return self._ensureSetNamed('_responseStatus', '8218', constants.PSETID_APPOINTMENT, overrideClass = lambda x: ResponseStatus(x or 0), preserveNone = False)
+
+    @property
+    def startDate(self) -> Optional[datetime.datetime]:
+        """
+        The start date of the appointment.
+        """
+        return self._ensureSetProperty('_startDate', '00600040')
+
+    @property
+    def timeZoneDescription(self) -> Optional[str]:
+        """
+        A human-readable description of the time zone that is represented by the
+        data in the timeZoneStruct property.
+        """
+        return self._ensureSetNamed('_timeZoneDescription', '8234', constants.PSETID_APPOINTMENT)
+
+    @property
+    def timeZoneStruct(self) -> Optional[TimeZoneStruct]:
+        """
+        Set on a recurring series to specify time zone information. Specifies
+        how to convert time fields between local time and UTC.
+        """
+        return self._ensureSetNamed('_timeZoneStruct', '8233', constants.PSETID_APPOINTMENT, overrideClass = TimeZoneStruct)
+
+    @property
+    def to(self) -> Optional[str]:
+        """
+        Returns the to field, if it exists.
+        """
+        return self._genRecipient('to', MeetingRecipientType.SENDABLE_REQUIRED_ATTENDEE)
+
+    @property
+    def toAttendeesString(self) -> Optional[str]:
+        """
+        A list of all the sendable attendees, who are also required attendees.
+        """
+        return self._ensureSetNamed('_toAttendeesString', '823B', constants.PSETID_APPOINTMENT)
```

### Comparing `extract_msg-0.40.0/extract_msg/constants.py` & `extract_msg-0.41.0/extract_msg/constants.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,777 +1,805 @@
-"""
-The constants used in extract_msg. If you modify any of these
-without explicit instruction to do so from one of the
-contributers, please do not complain about bugs.
-"""
-
-import datetime
-import re
-import struct
-
-import ebcdic
-
-from typing import Dict, Tuple, Union
-
-
-# DEFINE CONSTANTS
-# WARNING DO NOT CHANGE ANY OF THESE VALUES UNLESS YOU KNOW
-# WHAT YOU ARE DOING! FAILURE TO FOLLOW THIS INSTRUCTION
-# CAN AND WILL BREAK THIS SCRIPT!
-
-# Typing Constants.
-HEADER_FORMAT_VALUE_TYPE = Union[str, Tuple[Union[str, None], bool], None]
-# Basically a dict of HEADER_FORMAT_TYPE and dicts containing them.
-HEADER_FORMAT_TYPE = Dict[str, Union[HEADER_FORMAT_VALUE_TYPE, Dict[str, HEADER_FORMAT_VALUE_TYPE]]]
-
-# Regular expresion constants.
-RE_INVALID_FILENAME_CHARACTERS = re.compile(r'[\\/:*?"<>|]')
-# Regular expression to find sections of spaces for htmlSanitize.
-RE_HTML_SAN_SPACE = re.compile('  +')
-# Regular expression to find the start of the html body.
-RE_HTML_BODY_START = re.compile(b'<body[^>]*>')
-# Regular expression to find the start of the html body in encapsulated RTF.
-# This is used for one of the pattern types that makes life easy.
-RE_RTF_ENC_BODY_START = re.compile(br'\{\\\*\\htmltag[0-9]* ?<body[^>]*>\}')
-# This is used in the workaround for decoding issues in RTFDE. We find `\bin`
-# sections and try to remove all of them to help with the decoding.
-RE_BIN = re.compile(br'\\bin([0-9]+) ?')
-# Used in the vaildation of OLE paths. Any of these characters in a name make it
-# invalid.
-RE_INVALID_OLE_PATH = re.compile(r'[:/\\!]')
-
-FIXED_LENGTH_PROPS = (
-    0x0000,
-    0x0001,
-    0x0002,
-    0x0003,
-    0x0004,
-    0x0005,
-    0x0006,
-    0x0007,
-    0x000A,
-    0x000B,
-    0x0014,
-    0x0040,
-    0x0048,
-)
-
-FIXED_LENGTH_PROPS_STRING = (
-    '0000',
-    '0001',
-    '0002',
-    '0003',
-    '0004',
-    '0005',
-    '0006',
-    '0007',
-    '000A',
-    '000B',
-    '0014',
-    '0040',
-    '0048',
-)
-
-VARIABLE_LENGTH_PROPS = (
-    0x000D,
-    0x001E,
-    0x001F,
-    0x00FB,
-    0x00FD,
-    0x00FE,
-    0X0102,
-    0x1002,
-    0x1003,
-    0x1004,
-    0x1005,
-    0x1006,
-    0x1007,
-    0x1014,
-    0x101E,
-    0x101F,
-    0x1040,
-    0x1048,
-    0x1102,
-)
-
-VARIABLE_LENGTH_PROPS_STRING = (
-    '000D',
-    '001E',
-    '001F',
-    '00FB',
-    '00FD',
-    '00FE',
-    '0102',
-    '1002',
-    '1003',
-    '1004',
-    '1005',
-    '1006',
-    '1007',
-    '1014',
-    '101E',
-    '101F',
-    '1040',
-    '1048',
-    '1102',
-)
-
-# Multiple type properties that take up 2 bytes
-MULTIPLE_2_BYTES = (
-    '1002',
-)
-
-MULTIPLE_2_BYTES_HEX = (
-    0x1002,
-)
-
-# Multiple type properties that take up 4 bytes
-MULTIPLE_4_BYTES = (
-    '1003',
-    '1004',
-)
-
-MULTIPLE_4_BYTES_HEX = (
-    0x1003,
-    0x1004,
-)
-
-# Multiple type properties that take up 4 bytes
-MULTIPLE_8_BYTES = (
-    '1005',
-    '1007',
-    '1014',
-    '1040',
-)
-
-MULTIPLE_8_BYTES_HEX = (
-    0x1005,
-    0x1007,
-    0x1014,
-    0x1040,
-)
-
-# Multiple type properties that take up 4 bytes
-MULTIPLE_16_BYTES = (
-    '1048',
-)
-
-MULTIPLE_16_BYTES_HEX = (
-    0x1048,
-)
-
-
-# Used to format the header for saving only the header.
-HEADER_FORMAT = """From: {From}
-To: {To}
-Cc: {Cc}
-Bcc: {Bcc}
-Subject: {subject}
-Date: {Date}
-Message-ID: {Message-Id}
-"""
-
-
-KNOWN_CLASS_TYPES = (
-    'ipm.activity',
-    'ipm.appointment', # [MS-OXOCAL]
-    'ipm.contact', # [MS-OXOCNTC]
-    'ipm.configuration', # [MS-OXOCFG]
-    'ipm.distlist',
-    'ipm.document',
-    'ipm.ole.class',
-    'ipm.outlook.recall',
-    'ipm.note',
-    'ipm.post',
-    'ipm.stickynote',
-    'ipm.recall.report',
-    'ipm.remote',
-    'ipm.report',
-    'ipm.resend',
-    'ipm.schedule',
-    'ipm.task',
-    'ipm.taskrequest',
-    'report',
-)
-
-# This is a dictionary matching the code page number to it's encoding name.
-# The list used to make this can be found here:
-# https://docs.microsoft.com/en-us/windows/win32/intl/code-page-identifiers
-### TODO:
-# Many of these code pages are not supported by Python. As such, we should
-# really implement them ourselves to make sure that if someone wants to use an
-# msg file with one of those encodings, they are able to. Perhaps we should
-# create a seperate module for that?
-# Code pages that currently don't have a supported encoding will be preceded by
-# `# UNSUPPORTED`.
-# For some of these, it is also possible that the name we are trying to find
-# them with is not known to Python. I have already confirmed this for a few of
-# them, and adjusted their names to ones that python would recognize. It is
-# Possible I missed a few.
-CODE_PAGES = {
-    37: 'IBM037', # IBM EBCDIC US-Canada
-    437: 'IBM437', # OEM United States
-    500: 'IBM500', # IBM EBCDIC International
-    708: 'ASMO-708', # Arabic (ASMO 708)
-    # UNSUPPORTED.
-    709: '', # Arabic (ASMO-449+, BCON V4)
-    # UNSUPPORTED.
-    710: '', # Arabic - Transparent Arabic
-    # UNSUPPORTED.
-    720: 'DOS-720', # Arabic (Transparent ASMO); Arabic (DOS)
-    737: 'cp737', # OEM Greek (formerly 437G); Greek (DOS)
-    775: 'ibm775', # OEM Baltic; Baltic (DOS)
-    850: 'ibm850', # OEM Multilingual Latin 1; Western European (DOS)
-    852: 'ibm852', # OEM Latin 2; Central European (DOS)
-    855: 'IBM855', # OEM Cyrillic (primarily Russian)
-    857: 'ibm857', # OEM Turkish; Turkish (DOS)
-    858: 'cp858', # OEM Multilingual Latin 1 + Euro symbol
-    860: 'IBM860', # OEM Portuguese; Portuguese (DOS)
-    861: 'ibm861', # OEM Icelandic; Icelandic (DOS)
-    862: 'cp862', # OEM Hebrew; Hebrew (DOS)
-    863: 'IBM863', # OEM French Canadian; French Canadian (DOS)
-    864: 'IBM864', # OEM Arabic; Arabic (864)
-    865: 'IBM865', # OEM Nordic; Nordic (DOS)
-    866: 'cp866', # OEM Russian; Cyrillic (DOS)
-    869: 'ibm869', # OEM Modern Greek; Greek, Modern (DOS)
-    870: 'cp870', # IBM870 # IBM EBCDIC Multilingual/ROECE (Latin 2); IBM EBCDIC Multilingual Latin 2
-    # UNSUPPORTED.
-    874: 'windows-874', # ANSI/OEM Thai (ISO 8859-11); Thai (Windows)
-    875: 'cp875', # IBM EBCDIC Greek Modern
-    932: 'shift_jis', # ANSI/OEM Japanese; Japanese (Shift-JIS)
-    936: 'gb2312', # ANSI/OEM Simplified Chinese (PRC, Singapore); Chinese Simplified (GB2312)
-    949: 'ks_c_5601-1987', # ANSI/OEM Korean (Unified Hangul Code)
-    950: 'big5', # ANSI/OEM Traditional Chinese (Taiwan; Hong Kong SAR, PRC); Chinese Traditional (Big5)
-    1026: 'IBM1026', # IBM EBCDIC Turkish (Latin 5)
-    1047: 'cp1047', # IBM EBCDIC Latin 1/Open System
-    1140: 'cp1140', # IBM EBCDIC US-Canada (037 + Euro symbol); IBM EBCDIC (US-Canada-Euro)
-    1141: 'cp1141', # IBM EBCDIC Germany (20273 + Euro symbol); IBM EBCDIC (Germany-Euro)
-    1142: 'cp1142', # IBM EBCDIC Denmark-Norway (20277 + Euro symbol); IBM EBCDIC (Denmark-Norway-Euro)
-    1143: 'cp1143', # IBM EBCDIC Finland-Sweden (20278 + Euro symbol); IBM EBCDIC (Finland-Sweden-Euro)
-    1144: 'cp1144', # IBM EBCDIC Italy (20280 + Euro symbol); IBM EBCDIC (Italy-Euro)
-    1145: 'cp1145', # IBM EBCDIC Latin America-Spain (20284 + Euro symbol); IBM EBCDIC (Spain-Euro)
-    1146: 'cp1146', # IBM EBCDIC United Kingdom (20285 + Euro symbol); IBM EBCDIC (UK-Euro)
-    1147: 'cp1147', # IBM EBCDIC France (20297 + Euro symbol); IBM EBCDIC (France-Euro)
-    1148: 'cp1148ms', # IBM EBCDIC International (500 + Euro symbol); IBM EBCDIC (International-Euro)
-    1149: 'cp1149', # IBM EBCDIC Icelandic (20871 + Euro symbol); IBM EBCDIC (Icelandic-Euro)
-    1200: 'utf-16-le', # Unicode UTF-16, little endian byte order (BMP of ISO 10646); available only to managed applications
-    1201: 'utf-16-be', # Unicode UTF-16, big endian byte order; available only to managed applications
-    1250: 'windows-1250', # ANSI Central European; Central European (Windows)
-    1251: 'windows-1251', # ANSI Cyrillic; Cyrillic (Windows)
-    1252: 'windows-1252', # ANSI Latin 1; Western European (Windows)
-    1253: 'windows-1253', # ANSI Greek; Greek (Windows)
-    1254: 'windows-1254', # ANSI Turkish; Turkish (Windows)
-    1255: 'windows-1255', # ANSI Hebrew; Hebrew (Windows)
-    1256: 'windows-1256', # ANSI Arabic; Arabic (Windows)
-    1257: 'windows-1257', # ANSI Baltic; Baltic (Windows)
-    1258: 'windows-1258', # ANSI/OEM Vietnamese; Vietnamese (Windows)
-    1361: 'Johab', # Korean (Johab)
-    10000: 'macintosh', # MAC Roman; Western European (Mac)
-    10001: 'x-mac-japanese', # Japanese (Mac)
-    # UNSUPPORTED.
-    10002: 'x-mac-chinesetrad', # MAC Traditional Chinese (Big5); Chinese Traditional (Mac)
-    10003: 'x-mac-korean', # Korean (Mac)
-    # UNSUPPORTED.
-    10004: 'x-mac-arabic', # Arabic (Mac)
-    # UNSUPPORTED.
-    10005: 'x-mac-hebrew', # Hebrew (Mac)
-    # UNSUPPORTED.
-    10006: 'x-mac-greek', # Greek (Mac)
-    # UNSUPPORTED.
-    10007: 'x-mac-cyrillic', # Cyrillic (Mac)
-    # UNSUPPORTED.
-    10008: 'x-mac-chinesesimp', # MAC Simplified Chinese (GB 2312); Chinese Simplified (Mac)
-    # UNSUPPORTED.
-    10010: 'x-mac-romanian', # Romanian (Mac)
-    # UNSUPPORTED.
-    10017: 'x-mac-ukrainian', # Ukrainian (Mac)
-    # UNSUPPORTED.
-    10021: 'x-mac-thai', # Thai (Mac)
-    # UNSUPPORTED.
-    10029: 'x-mac-ce', # MAC Latin 2; Central European (Mac)
-    # UNSUPPORTED.
-    10079: 'x-mac-icelandic', # Icelandic (Mac)
-    # UNSUPPORTED.
-    10081: 'x-mac-turkish', # Turkish (Mac)
-    # UNSUPPORTED.
-    10082: 'x-mac-croatian', # Croatian (Mac)
-    12000: 'utf-32', # Unicode UTF-32, little endian byte order; available only to managed applications
-    12001: 'utf-32BE', # Unicode UTF-32, big endian byte order; available only to managed applications
-    # UNSUPPORTED.
-    20000: 'x-Chinese_CNS', # CNS Taiwan; Chinese Traditional (CNS)
-    # UNSUPPORTED.
-    20001: 'x-cp20001', # TCA Taiwan
-    # UNSUPPORTED.
-    20002: 'x_Chinese-Eten', # Eten Taiwan; Chinese Traditional (Eten)
-    # UNSUPPORTED.
-    20003: 'x-cp20003', # IBM5550 Taiwan
-    # UNSUPPORTED.
-    20004: 'x-cp20004', # TeleText Taiwan
-    # UNSUPPORTED.
-    20005: 'x-cp20005', # Wang Taiwan
-    # UNSUPPORTED.
-    20105: 'x-IA5', # IA5 (IRV International Alphabet No. 5, 7-bit); Western European (IA5)
-    # UNSUPPORTED.
-    20106: 'x-IA5-German', # IA5 German (7-bit)
-    # UNSUPPORTED.
-    20107: 'x-IA5-Swedish', # IA5 Swedish (7-bit)
-    # UNSUPPORTED.
-    20108: 'x-IA5-Norwegian', # IA5 Norwegian (7-bit)
-    20127: 'us-ascii', # US-ASCII (7-bit)
-    # UNSUPPORTED.
-    20261: 'x-cp20261', # T.61
-    # UNSUPPORTED.
-    20269: 'x-cp20269', # ISO 6937 Non-Spacing Accent
-    20273: 'IBM273', # IBM EBCDIC Germany
-    20277: 'cp277', # IBM EBCDIC Denmark-Norway
-    20278: 'cp278', # IBM EBCDIC Finland-Sweden
-    20280: 'cp280', # IBM EBCDIC Italy
-    20284: 'cp284', # IBM EBCDIC Latin America-Spain
-    20285: 'cp285', # IBM EBCDIC United Kingdom
-    20290: 'cp290', # IBM EBCDIC Japanese Katakana Extended
-    20297: 'cp297', # IBM EBCDIC France
-    20420: 'cp420', # IBM EBCDIC Arabic
-    # UNSUPPORTED.
-    20423: 'IBM423', # IBM EBCDIC Greek
-    20424: 'IBM424', # IBM EBCDIC Hebrew
-    20833: 'cp833', # IBM EBCDIC Korean Extended
-    20838: 'cp838', # IBM EBCDIC Thai
-    20866: 'koi8-r', # Russian (KOI8-R); Cyrillic (KOI8-R)
-    20871: 'cp871', # IBM EBCDIC Icelandic
-    # UNSUPPORTED.
-    20880: 'IBM880', # IBM EBCDIC Cyrillic Russian
-    # UNSUPPORTED.
-    20905: 'IBM905', # IBM EBCDIC Turkish
-    # UNSUPPORTED.
-    20924: 'IBM00924', # IBM EBCDIC Latin 1/Open System (1047 + Euro symbol)
-    20932: 'EUC-JP', # Japanese (JIS 0208-1990 and 0212-1990)
-    # UNSUPPORTED.
-    20936: 'x-cp20936', # Simplified Chinese (GB2312); Chinese Simplified (GB2312-80)
-    # UNSUPPORTED.
-    20949: 'x-cp20949', # Korean Wansung
-    21025: 'cp1025', # IBM EBCDIC Cyrillic Serbian-Bulgarian
-    # UNSUPPORTED.
-    21027: '', # (deprecated)
-    21866: 'koi8-u', # Ukrainian (KOI8-U); Cyrillic (KOI8-U)
-    28591: 'iso-8859-1', # ISO 8859-1 Latin 1; Western European (ISO)
-    28592: 'iso-8859-2', # ISO 8859-2 Central European; Central European (ISO)
-    28593: 'iso-8859-3', # ISO 8859-3 Latin 3
-    28594: 'iso-8859-4', # ISO 8859-4 Baltic
-    28595: 'iso-8859-5', # ISO 8859-5 Cyrillic
-    28596: 'iso-8859-6', # ISO 8859-6 Arabic
-    28597: 'iso-8859-7', # ISO 8859-7 Greek
-    28598: 'iso-8859-8', # ISO 8859-8 Hebrew; Hebrew (ISO-Visual)
-    28599: 'iso-8859-9', # ISO 8859-9 Turkish
-    28603: 'iso-8859-13', # ISO 8859-13 Estonian
-    28605: 'iso-8859-15', # ISO 8859-15 Latin 9
-    # UNSUPPORTED.
-    29001: 'x-Europa', # Europa 3
-    # UNSUPPORTED.
-    38598: 'iso-8859-8-i', # ISO 8859-8 Hebrew; Hebrew (ISO-Logical)
-    50220: 'iso-2022-jp', # ISO 2022 Japanese with no halfwidth Katakana; Japanese (JIS)
-    50221: 'csISO2022JP', # ISO 2022 Japanese with halfwidth Katakana; Japanese (JIS-Allow 1 byte Kana)
-    50222: 'iso-2022-jp', # ISO 2022 Japanese JIS X 0201-1989; Japanese (JIS-Allow 1 byte Kana - SO/SI)
-    50225: 'iso-2022-kr', # ISO 2022 Korean
-    # UNSUPPORTED.
-    50227: 'x-cp50227', # ISO 2022 Simplified Chinese; Chinese Simplified (ISO 2022)
-    # UNSUPPORTED.
-    50229: '', # ISO 2022 Traditional Chinese
-    # UNSUPPORTED.
-    50930: '', # EBCDIC Japanese (Katakana) Extended
-    # UNSUPPORTED.
-    50931: '', # EBCDIC US-Canada and Japanese
-    # UNSUPPORTED.
-    50933: '', # EBCDIC Korean Extended and Korean
-    # UNSUPPORTED.
-    50935: '', # EBCDIC Simplified Chinese Extended and Simplified Chinese
-    # UNSUPPORTED.
-    50936: '', # EBCDIC Simplified Chinese
-    # UNSUPPORTED.
-    50937: '', # EBCDIC US-Canada and Traditional Chinese
-    # UNSUPPORTED.
-    50939: '', # EBCDIC Japanese (Latin) Extended and Japanese
-    51932: 'euc-jp', # EUC Japanese
-    51936: 'EUC-CN', # EUC Simplified Chinese; Chinese Simplified (EUC)
-    51949: 'euc-kr', # EUC Korean
-    # UNSUPPORTED.
-    51950: '', # EUC Traditional Chinese
-    52936: 'hz-gb-2312', # HZ-GB2312 Simplified Chinese; Chinese Simplified (HZ)
-    54936: 'GB18030', # Windows XP and later: GB18030 Simplified Chinese (4 byte); Chinese Simplified (GB18030)
-    # UNSUPPORTED.
-    57002: 'x-iscii-de', # ISCII Devanagari
-    # UNSUPPORTED.
-    57003: 'x-iscii-be', # ISCII Bangla
-    # UNSUPPORTED.
-    57004: 'x-iscii-ta', # ISCII Tamil
-    # UNSUPPORTED.
-    57005: 'x-iscii-te', # ISCII Telugu
-    # UNSUPPORTED.
-    57006: 'x-iscii-as', # ISCII Assamese
-    # UNSUPPORTED.
-    57007: 'x-iscii-or', # ISCII Odia
-    # UNSUPPORTED.
-    57008: 'x-iscii-ka', # ISCII Kannada
-    # UNSUPPORTED.
-    57009: 'x-iscii-ma', # ISCII Malayalam
-    # UNSUPPORTED.
-    57010: 'x-iscii-gu', # ISCII Gujarati
-    # UNSUPPORTED.
-    57011: 'x-iscii-pa', # ISCII Punjabi
-    65000: 'utf-7', # Unicode (UTF-7)
-    65001: 'utf-8', # Unicode (UTF-8)
-}
-
-PYTPFLOATINGTIME_START = datetime.datetime(1899, 12, 30)
-NULL_DATE = datetime.datetime(4500, 8, 31, 23, 59)
-
-# Constants used for argparse stuff
-KNOWN_FILE_FLAGS = (
-    '--out-name',
-)
-NEEDS_ARG = (
-    '--out-name',
-)
-MAINDOC = "extract_msg:\n\tExtracts emails and attachments saved in Microsoft Outlook's .msg files.\n\n" \
-          "https://github.com/TeamMsgExtractor/msg-extractor"
-
-# Default class ID for the root entry for OleWriter. This should be
-# referencing Outlook if I understand it correctly.
-DEFAULT_CLSID = b'\x0b\r\x02\x00\x00\x00\x00\x00\xc0\x00\x00\x00\x00\x00\x00F'
-
-# Define pre-compiled structs to make unpacking slightly faster.
-# General structs.
-ST1 = struct.Struct('<8x4I')
-ST2 = struct.Struct('<H2xI8x')
-ST3 = struct.Struct('<Q')
-# Struct used for unpacking a system time.
-ST_SYSTEMTIME = struct.Struct('<8H')
-# Struct used for unpacking a GUID from bytes.
-ST_GUID = struct.Struct('<IHH8s')
-# Struct for unpacking a TimeZoneStruct from bytes.
-ST_TZ = struct.Struct('<iiiH16sH16s')
-# Struct for packing a compount file directory entry.
-ST_CF_DIR_ENTRY = struct.Struct('<64sHBBIII16sIQQIQ')
-# Structs used by data.py
-ST_DATA_UI32 = struct.Struct('<I')
-ST_DATA_UI16 = struct.Struct('<H')
-ST_DATA_UI8 = struct.Struct('<B')
-# Structs used by named.py
-STNP_NAM = struct.Struct('<i')
-# Struct used for unpacking the entries in the entry stream
-STNP_ENT = struct.Struct('<IHH')
-# Structs used by prop.py
-STFIX = struct.Struct('<8x8s')
-STVAR = struct.Struct('<8xi4s')
-# Structs to help with email type to python type conversions
-STI8 = struct.Struct('<b');
-STI16 = struct.Struct('<h6x')
-STI32 = struct.Struct('<I4x')
-STI64 = struct.Struct('<q')
-STF32 = struct.Struct('<f4x')
-STF64 = struct.Struct('<d')
-STUI32 = struct.Struct('<I4x')
-STMI16 = struct.Struct('<h')
-STMI32 = struct.Struct('<i')
-STMI64 = struct.Struct('<q')
-STMF32 = struct.Struct('<f')
-STMF64 = struct.Struct('<d')
-# PermanentEntryID parsing struct
-STPEID = struct.Struct('<B3x16s4xI')
-# Struct for unpacking the first part of the BusinessCardDisplayDefinition
-# structure.
-ST_BC_HEAD = struct.Struct('BBBBBBBBIB')
-# Struct for completely unpacking the FieldInfo structure.
-ST_BC_FIELD_INFO = struct.Struct('HBBBxHII')
-# Structs for reading from a BytesReader. Some are just aliases for existing
-# structs, used for clarity and consistency in the code.
-ST_LE_I8 = STI8
-ST_LE_I16 = STMI16
-ST_LE_I32 = STMI32
-ST_LE_I64 = STMI64
-ST_LE_UI8 = ST_DATA_UI8
-ST_LE_UI16 = ST_DATA_UI16
-ST_LE_UI32 = ST_DATA_UI32
-ST_LE_UI64 = ST3
-ST_LE_F32 = STF32
-ST_LE_F64 = STF64
-ST_BE_I8 = struct.Struct('>b')
-ST_BE_I16 = struct.Struct('>h')
-ST_BE_I32 = struct.Struct('>i')
-ST_BE_I64 = struct.Struct('>q')
-ST_BE_UI8 = struct.Struct('>B')
-ST_BE_UI16 = struct.Struct('>H')
-ST_BE_UI32 = struct.Struct('>I')
-ST_BE_UI64 = struct.Struct('>Q')
-ST_BE_F32 = struct.Struct('>f')
-ST_BE_F64 = struct.Struct('>d')
-
-PTYPES = {
-    0x0000: 'PtypUnspecified',
-    0x0001: 'PtypNull',
-    0x0002: 'PtypInteger16',  # Signed short
-    0x0003: 'PtypInteger32',  # Signed int
-    0x0004: 'PtypFloating32',  # Float
-    0x0005: 'PtypFloating64',  # Double
-    0x0006: 'PtypCurrency',
-    0x0007: 'PtypFloatingTime',
-    0x000A: 'PtypErrorCode',
-    0x000B: 'PtypBoolean',
-    0x000D: 'PtypObject/PtypEmbeddedTable/Storage',
-    0x0014: 'PtypInteger64',  # Signed longlong
-    0x001E: 'PtypString8',
-    0x001F: 'PtypString',
-    0x0040: 'PtypTime',  # Use filetimeToUtc to convert to unix time stamp
-    0x0048: 'PtypGuid',
-    0x00FB: 'PtypServerId',
-    0x00FD: 'PtypRestriction',
-    0x00FE: 'PtypRuleAction',
-    0x0102: 'PtypBinary',
-    0x1002: 'PtypMultipleInteger16',
-    0x1003: 'PtypMultipleInteger32',
-    0x1004: 'PtypMultipleFloating32',
-    0x1005: 'PtypMultipleFloating64',
-    0x1006: 'PtypMultipleCurrency',
-    0x1007: 'PtypMultipleFloatingTime',
-    0x1014: 'PtypMultipleInteger64',
-    0x101E: 'PtypMultipleString8',
-    0x101F: 'PtypMultipleString',
-    0x1040: 'PtypMultipleTime',
-    0x1048: 'PtypMultipleGuid',
-    0x1102: 'PtypMultipleBinary',
-}
-
-# This property information was sourced from
-# http://www.fileformat.info/format/outlookmsg/index.htm
-# on 2013-07-22.
-# It was extended by The Elemental of Destruction on 2018-10-12.
-PROPERTIES = {
-    '00010102': 'Template data',
-    '0002000B': 'Alternate recipient allowed',
-    '0004001F': 'Auto forward comment',
-    '00040102': 'Script data',
-    '0005000B': 'Auto forwarded',
-    '000F000F': 'Deferred delivery time',
-    '00100040': 'Deliver time',
-    '00150040': 'Expiry time',
-    '00170003': 'Importance',
-    '001A001F': 'Message class',
-    '0023001F': 'Originator delivery report requested',
-    '00250102': 'Parent key',
-    '00260003': 'Priority',
-    '0029000B': 'Read receipt requested',
-    '002A0040': 'Receipt time',
-    '002B000B': 'Recipient reassignment prohibited',
-    '002E0003': 'Original sensitivity',
-    '00300040': 'Reply time',
-    '00310102': 'Report tag',
-    '00320040': 'Report time',
-    '00360003': 'Sensitivity',
-    '0037001F': 'Subject',
-    '00390040': 'Client Submit Time',
-    '003A001F': '',
-    '003B0102': '',
-    '003D001F': 'Subject prefix',
-    '003F0102': '',
-    '0040001F': 'Received by name',
-    '00410102': '',
-    '0042001F': 'Sent repr name',
-    '00430102': '',
-    '0044001F': 'Rcvd repr name',
-    '00450102': '',
-    '0046001F': '',
-    '00470102': '',
-    '0049001F': '',
-    '004B001F': '',
-    '004C0102': '',
-    '004D001F': 'Org author name',
-    '004E0040': '',
-    '004F0102': '',
-    '0050001F': 'Reply rcipnt names',
-    '00510102': '',
-    '00520102': '',
-    '00530102': '',
-    '00540102': '',
-    '00550040': '',
-    '0057000B': '',
-    '0058000B': '',
-    '0059000B': '',
-    '005A001F': 'Org sender name',
-    '005B0102': '',
-    '005C0102': '',
-    '005D001F': '',
-    '005E0102': '',
-    '005F0102': '',
-    '00600040': '',
-    '00610040': '',
-    '00620003': '',
-    '0063000B': '',
-    '0064001F': 'Sent repr adrtype',
-    '0065001F': 'Sent repr email',
-    '0066001F': '',
-    '00670102': '',
-    '0068001F': '',
-    '0069001F': '',
-    '0070001F': 'Topic',
-    '00710102': '',
-    '0072001F': '',
-    '0073001F': '',
-    '0074001F': '',
-    '0075001F': 'Rcvd by adrtype',
-    '0076001F': 'Rcvd by email',
-    '0077001F': 'Repr adrtype',
-    '0078001F': 'Repr email',
-    '007D001F': 'Message header',
-    '007F0102': '',
-    '0080001F': '',
-    '0081001F': '',
-    '08070003': '',
-    '0809001F': '',
-    '0C040003': '',
-    '0C050003': '',
-    '0C06000B': '',
-    '0C08000B': '',
-    '0C150003': '',
-    '0C17000B': '',
-    '0C190102': '',
-    '0C1A001F': 'Sender name',
-    '0C1B001F': '',
-    '0C1D0102': '',
-    '0C1E001F': 'Sender adr type',
-    '0C1F001F': 'Sender email',
-    '0C200003': '',
-    '0C21001F': '',
-    '0E01000B': '',
-    '0E02001F': 'Display BCC',
-    '0E03001F': 'Display CC',
-    '0E04001F': 'Display To',
-    '0E060040': '',
-    '0E070003': '',
-    '0E080003': '',
-    '0E080014': '',
-    '0E090102': '',
-    '0E0F000B': '',
-    '0E12000D': '',
-    '0E13000D': '',
-    '0E170003': '',
-    '0E1B000B': '',
-    '0E1D001F': 'Subject (normalized)',
-    '0E1F000B': '',
-    '0E200003': '',
-    '0E210003': '',
-    '0E28001F': 'Recvd account1 (uncertain)',
-    '0E29001F': 'Recvd account2 (uncertain)',
-    '1000001F': 'Message body',
-    '1008': 'RTF sync body tag', # Where did this come from ??? It's not listed in the docs
-    '10090102': 'Compressed RTF body',
-    '1013001F': 'HTML body',
-    '1035001F': 'Message ID (uncertain)',
-    '1046001F': 'Sender email (uncertain)',
-    '3001001F': 'Display name',
-    '3002001F': 'Address type',
-    '3003001F': 'Email address',
-    '30070040': 'Creation date',
-    '39FE001F': '7-bit email (uncertain)',
-    '39FF001F': '7-bit display name',
-
-    # Attachments (37xx)
-    '37010102': 'Attachment data',
-    '37020102': '',
-    '3703001F': 'Attachment extension',
-    '3704001F': 'Attachment short filename',
-    '37050003': 'Attachment attach method',
-    '3707001F': 'Attachment long filename',
-    '370E001F': 'Attachment mime tag',
-    '3712001F': 'Attachment ID (uncertain)',
-
-    # Address book (3Axx):
-    '3A00001F': 'Account',
-    '3A02001F': 'Callback phone no',
-    '3A05001F': 'Generation',
-    '3A06001F': 'Given name',
-    '3A08001F': 'Business phone',
-    '3A09001F': 'Home phone',
-    '3A0A001F': 'Initials',
-    '3A0B001F': 'Keyword',
-    '3A0C001F': 'Language',
-    '3A0D001F': 'Location',
-    '3A11001F': 'Surname',
-    '3A15001F': 'Postal address',
-    '3A16001F': 'Company name',
-    '3A17001F': 'Title',
-    '3A18001F': 'Department',
-    '3A19001F': 'Office location',
-    '3A1A001F': 'Primary phone',
-    '3A1B101F': 'Business phone 2',
-    '3A1C001F': 'Mobile phone',
-    '3A1D001F': 'Radio phone no',
-    '3A1E001F': 'Car phone no',
-    '3A1F001F': 'Other phone',
-    '3A20001F': 'Transmit dispname',
-    '3A21001F': 'Pager',
-    '3A220102': 'User certificate',
-    '3A23001F': 'Primary Fax',
-    '3A24001F': 'Business Fax',
-    '3A25001F': 'Home Fax',
-    '3A26001F': 'Country',
-    '3A27001F': 'Locality',
-    '3A28001F': 'State/Province',
-    '3A29001F': 'Street address',
-    '3A2A001F': 'Postal Code',
-    '3A2B001F': 'Post Office Box',
-    '3A2C001F': 'Telex',
-    '3A2D001F': 'ISDN',
-    '3A2E001F': 'Assistant phone',
-    '3A2F001F': 'Home phone 2',
-    '3A30001F': 'Assistant',
-    '3A44001F': 'Middle name',
-    '3A45001F': 'Dispname prefix',
-    '3A46001F': 'Profession',
-    '3A47001F': '',
-    '3A48001F': 'Spouse name',
-    '3A4B001F': 'TTYTTD radio phone',
-    '3A4C001F': 'FTP site',
-    '3A4E001F': 'Manager name',
-    '3A4F001F': 'Nickname',
-    '3A51001F': 'Business homepage',
-    '3A57001F': 'Company main phone',
-    '3A58101F': 'Childrens names',
-    '3A59001F': 'Home City',
-    '3A5A001F': 'Home Country',
-    '3A5B001F': 'Home Postal Code',
-    '3A5C001F': 'Home State/Provnce',
-    '3A5D001F': 'Home Street',
-    '3A5F001F': 'Other adr City',
-    '3A60': 'Other adr Country',
-    '3A61': 'Other adr PostCode',
-    '3A62': 'Other adr Province',
-    '3A63': 'Other adr Street',
-    '3A64': 'Other adr PO box',
-
-    '3FF7': 'Server (uncertain)',
-    '3FF8': 'Creator1 (uncertain)',
-    '3FFA': 'Creator2 (uncertain)',
-    '3FFC': 'To email (uncertain)',
-    '403D': 'To adrtype (uncertain)',
-    '403E': 'To email (uncertain)',
-    '5FF6': 'To (uncertain)',
-}
-
-PS_MAPI = '{00020328-0000-0000-C000-000000000046}'
-PS_PUBLIC_STRINGS = '{00020329-0000-0000-C000-000000000046}'
-PSETID_COMMON = '{00062008-0000-0000-C000-000000000046}'
-PSETID_ADDRESS = '{00062004-0000-0000-C000-000000000046}'
-PS_INTERNET_HEADERS = '{00020386-0000-0000-C000-000000000046}'
-PSETID_APPOINTMENT = '{00062002-0000-0000-C000-000000000046}'
-PSETID_MEETING = '{6ED8DA90-450B-101B-98DA-00AA003F1305}'
-PSETID_LOG = '{0006200A-0000-0000-C000-000000000046}'
-PSETID_MESSAGING = '{41F28F13-83F4-4114-A584-EEDB5A6B0BFF}'
-PSETID_NOTE = '{0006200E-0000-0000-C000-000000000046}'
-PSETID_POSTRSS = '{00062041-0000-0000-C000-000000000046}'
-PSETID_TASK = '{00062003-0000-0000-C000-000000000046}'
-PSETID_UNIFIEDMESSAGING = '{4442858E-A9E3-4E80-B900-317A210CC15B}'
-PSETID_AIRSYNC = '{71035549-0739-4DCB-9163-00F0580DBBDF}'
-PSETID_SHARING = '{00062040-0000-0000-C000-000000000046}'
-PSETID_XMLEXTRACTEDENTITIES = '{23239608-685D-4732-9C55-4C95CB4E8E33}'
-PSETID_ATTACHMENT = '{96357F7F-59E1-47D0-99A7-46515C183B54}'
-PSETID_CALENDAR_ASSISTANT = '{11000E07-B51B-40D6-AF21-CAA85EDAB1D0}'
-
-# END CONSTANTS
+"""
+The constants used in extract_msg. If you modify any of these
+without explicit instruction to do so from one of the
+contributers, please do not complain about bugs.
+"""
+
+__all__ = [
+    'CODE_PAGES', 'DEFAULT_CLSID', 'FIXED_LENGTH_PROPS',
+    'FIXED_LENGTH_PROPS_STRING', 'HEADER_FORMAT', 'HEADER_FORMAT_TYPE',
+    'HEADER_FORMAT_VALUE_TYPE', 'KNOWN_CLASS_TYPES', 'KNOWN_FILE_FLAGS',
+    'MAINDOC', 'MULTIPLE_16_BYTES', 'MULTIPLE_16_BYTES_HEX',
+    'MULTIPLE_2_BYTES', 'MULTIPLE_2_BYTES_HEX', 'MULTIPLE_4_BYTES',
+    'MULTIPLE_4_BYTES_HEX', 'MULTIPLE_8_BYTES', 'MULTIPLE_8_BYTES_HEX',
+    'NEEDS_ARG', 'NULL_DATE', 'PROPERTIES', 'PSETID_ADDRESS', 'PSETID_AIRSYNC',
+    'PSETID_APPOINTMENT', 'PSETID_ATTACHMENT', 'PSETID_CALENDAR_ASSISTANT',
+    'PSETID_COMMON', 'PSETID_LOG', 'PSETID_MEETING', 'PSETID_MESSAGING',
+    'PSETID_NOTE', 'PSETID_POSTRSS', 'PSETID_SHARING', 'PSETID_TASK',
+    'PSETID_UNIFIEDMESSAGING', 'PSETID_XMLEXTRACTEDENTITIES',
+    'PS_INTERNET_HEADERS', 'PS_MAPI', 'PS_PUBLIC_STRINGS', 'PTYPES',
+    'PYTPFLOATINGTIME_START', 'RE_BIN', 'RE_HTML_BODY_START',
+    'RE_HTML_SAN_SPACE', 'RE_INVALID_FILENAME_CHARACTERS',
+    'RE_INVALID_OLE_PATH', 'RE_RTF_ENC_BODY_START', 'ST1', 'ST2', 'ST3',
+    'STF32', 'STF64', 'STFIX', 'STI16', 'STI32', 'STI64', 'STI8', 'STMF32',
+    'STMF64', 'STMI16', 'STMI32', 'STMI64', 'STNP_ENT', 'STNP_NAM', 'STPEID',
+    'STUI32', 'STVAR', 'ST_BC_FIELD_INFO', 'ST_BC_HEAD', 'ST_BE_F32',
+    'ST_BE_F64', 'ST_BE_I16', 'ST_BE_I32', 'ST_BE_I64', 'ST_BE_I8',
+    'ST_BE_UI16', 'ST_BE_UI32', 'ST_BE_UI64', 'ST_BE_UI8', 'ST_CF_DIR_ENTRY',
+    'ST_DATA_UI16', 'ST_DATA_UI32', 'ST_DATA_UI8', 'ST_GUID', 'ST_LE_F32',
+    'ST_LE_F64', 'ST_LE_I16', 'ST_LE_I32', 'ST_LE_I64', 'ST_LE_I8',
+    'ST_LE_UI16', 'ST_LE_UI32', 'ST_LE_UI64', 'ST_LE_UI8', 'ST_SYSTEMTIME',
+    'ST_TZ', 'VARIABLE_LENGTH_PROPS', 'VARIABLE_LENGTH_PROPS_STRING',
+]
+
+
+import datetime
+import re
+import struct
+
+import ebcdic
+
+from typing import Dict, Tuple, Union
+
+
+# DEFINE CONSTANTS
+# WARNING DO NOT CHANGE ANY OF THESE VALUES UNLESS YOU KNOW
+# WHAT YOU ARE DOING! FAILURE TO FOLLOW THIS INSTRUCTION
+# CAN AND WILL BREAK THIS SCRIPT!
+
+# Typing Constants.
+HEADER_FORMAT_VALUE_TYPE = Union[str, Tuple[Union[str, None], bool], None]
+# Basically a dict of HEADER_FORMAT_TYPE and dicts containing them.
+HEADER_FORMAT_TYPE = Dict[str, Union[HEADER_FORMAT_VALUE_TYPE, Dict[str, HEADER_FORMAT_VALUE_TYPE]]]
+
+# Regular expresion constants.
+RE_INVALID_FILENAME_CHARACTERS = re.compile(r'[\\/:*?"<>|]')
+# Regular expression to find sections of spaces for htmlSanitize.
+RE_HTML_SAN_SPACE = re.compile('  +')
+# Regular expression to find the start of the html body.
+RE_HTML_BODY_START = re.compile(b'<body[^>]*>')
+# Regular expression to find the start of the html body in encapsulated RTF.
+# This is used for one of the pattern types that makes life easy.
+RE_RTF_ENC_BODY_START = re.compile(br'\{\\\*\\htmltag[0-9]* ?<body[^>]*>\}')
+# This is used in the workaround for decoding issues in RTFDE. We find `\bin`
+# sections and try to remove all of them to help with the decoding.
+RE_BIN = re.compile(br'\\bin([0-9]+) ?')
+# Used in the vaildation of OLE paths. Any of these characters in a name make it
+# invalid.
+RE_INVALID_OLE_PATH = re.compile(r'[:/\\!]')
+
+FIXED_LENGTH_PROPS = (
+    0x0000,
+    0x0001,
+    0x0002,
+    0x0003,
+    0x0004,
+    0x0005,
+    0x0006,
+    0x0007,
+    0x000A,
+    0x000B,
+    0x0014,
+    0x0040,
+    0x0048,
+)
+
+FIXED_LENGTH_PROPS_STRING = (
+    '0000',
+    '0001',
+    '0002',
+    '0003',
+    '0004',
+    '0005',
+    '0006',
+    '0007',
+    '000A',
+    '000B',
+    '0014',
+    '0040',
+    '0048',
+)
+
+VARIABLE_LENGTH_PROPS = (
+    0x000D,
+    0x001E,
+    0x001F,
+    0x00FB,
+    0x00FD,
+    0x00FE,
+    0X0102,
+    0x1002,
+    0x1003,
+    0x1004,
+    0x1005,
+    0x1006,
+    0x1007,
+    0x1014,
+    0x101E,
+    0x101F,
+    0x1040,
+    0x1048,
+    0x1102,
+)
+
+VARIABLE_LENGTH_PROPS_STRING = (
+    '000D',
+    '001E',
+    '001F',
+    '00FB',
+    '00FD',
+    '00FE',
+    '0102',
+    '1002',
+    '1003',
+    '1004',
+    '1005',
+    '1006',
+    '1007',
+    '1014',
+    '101E',
+    '101F',
+    '1040',
+    '1048',
+    '1102',
+)
+
+# Multiple type properties that take up 2 bytes
+MULTIPLE_2_BYTES = (
+    '1002',
+)
+
+MULTIPLE_2_BYTES_HEX = (
+    0x1002,
+)
+
+# Multiple type properties that take up 4 bytes
+MULTIPLE_4_BYTES = (
+    '1003',
+    '1004',
+)
+
+MULTIPLE_4_BYTES_HEX = (
+    0x1003,
+    0x1004,
+)
+
+# Multiple type properties that take up 4 bytes
+MULTIPLE_8_BYTES = (
+    '1005',
+    '1007',
+    '1014',
+    '1040',
+)
+
+MULTIPLE_8_BYTES_HEX = (
+    0x1005,
+    0x1007,
+    0x1014,
+    0x1040,
+)
+
+# Multiple type properties that take up 4 bytes
+MULTIPLE_16_BYTES = (
+    '1048',
+)
+
+MULTIPLE_16_BYTES_HEX = (
+    0x1048,
+)
+
+
+# Used to format the header for saving only the header.
+HEADER_FORMAT = """From: {From}
+To: {To}
+Cc: {Cc}
+Bcc: {Bcc}
+Subject: {subject}
+Date: {Date}
+Message-ID: {Message-Id}
+"""
+
+
+KNOWN_CLASS_TYPES = (
+    'ipm.activity',
+    'ipm.appointment', # [MS-OXOCAL]
+    'ipm.contact', # [MS-OXOCNTC]
+    'ipm.configuration', # [MS-OXOCFG]
+    'ipm.distlist',
+    'ipm.document',
+    'ipm.ole.class',
+    'ipm.outlook.recall',
+    'ipm.note',
+    'ipm.post',
+    'ipm.stickynote',
+    'ipm.recall.report',
+    'ipm.remote',
+    'ipm.report',
+    'ipm.resend',
+    'ipm.schedule',
+    'ipm.task',
+    'ipm.taskrequest',
+    'report',
+)
+
+# This is a dictionary matching the code page number to it's encoding name.
+# The list used to make this can be found here:
+# https://docs.microsoft.com/en-us/windows/win32/intl/code-page-identifiers
+### TODO:
+# Many of these code pages are not supported by Python. As such, we should
+# really implement them ourselves to make sure that if someone wants to use an
+# msg file with one of those encodings, they are able to. Perhaps we should
+# create a seperate module for that?
+# Code pages that currently don't have a supported encoding will be preceded by
+# `# UNSUPPORTED`.
+# For some of these, it is also possible that the name we are trying to find
+# them with is not known to Python. I have already confirmed this for a few of
+# them, and adjusted their names to ones that python would recognize. It is
+# Possible I missed a few.
+CODE_PAGES = {
+    37: 'IBM037', # IBM EBCDIC US-Canada
+    437: 'IBM437', # OEM United States
+    500: 'IBM500', # IBM EBCDIC International
+    708: 'ASMO-708', # Arabic (ASMO 708)
+    # UNSUPPORTED.
+    709: '', # Arabic (ASMO-449+, BCON V4)
+    # UNSUPPORTED.
+    710: '', # Arabic - Transparent Arabic
+    # UNSUPPORTED.
+    720: 'DOS-720', # Arabic (Transparent ASMO); Arabic (DOS)
+    737: 'cp737', # OEM Greek (formerly 437G); Greek (DOS)
+    775: 'ibm775', # OEM Baltic; Baltic (DOS)
+    850: 'ibm850', # OEM Multilingual Latin 1; Western European (DOS)
+    852: 'ibm852', # OEM Latin 2; Central European (DOS)
+    855: 'IBM855', # OEM Cyrillic (primarily Russian)
+    857: 'ibm857', # OEM Turkish; Turkish (DOS)
+    858: 'cp858', # OEM Multilingual Latin 1 + Euro symbol
+    860: 'IBM860', # OEM Portuguese; Portuguese (DOS)
+    861: 'ibm861', # OEM Icelandic; Icelandic (DOS)
+    862: 'cp862', # OEM Hebrew; Hebrew (DOS)
+    863: 'IBM863', # OEM French Canadian; French Canadian (DOS)
+    864: 'IBM864', # OEM Arabic; Arabic (864)
+    865: 'IBM865', # OEM Nordic; Nordic (DOS)
+    866: 'cp866', # OEM Russian; Cyrillic (DOS)
+    869: 'ibm869', # OEM Modern Greek; Greek, Modern (DOS)
+    870: 'cp870', # IBM870 # IBM EBCDIC Multilingual/ROECE (Latin 2); IBM EBCDIC Multilingual Latin 2
+    # UNSUPPORTED.
+    874: 'windows-874', # ANSI/OEM Thai (ISO 8859-11); Thai (Windows)
+    875: 'cp875', # IBM EBCDIC Greek Modern
+    932: 'shift_jis', # ANSI/OEM Japanese; Japanese (Shift-JIS)
+    936: 'gb2312', # ANSI/OEM Simplified Chinese (PRC, Singapore); Chinese Simplified (GB2312)
+    949: 'ks_c_5601-1987', # ANSI/OEM Korean (Unified Hangul Code)
+    950: 'big5', # ANSI/OEM Traditional Chinese (Taiwan; Hong Kong SAR, PRC); Chinese Traditional (Big5)
+    1026: 'IBM1026', # IBM EBCDIC Turkish (Latin 5)
+    1047: 'cp1047', # IBM EBCDIC Latin 1/Open System
+    1140: 'cp1140', # IBM EBCDIC US-Canada (037 + Euro symbol); IBM EBCDIC (US-Canada-Euro)
+    1141: 'cp1141', # IBM EBCDIC Germany (20273 + Euro symbol); IBM EBCDIC (Germany-Euro)
+    1142: 'cp1142', # IBM EBCDIC Denmark-Norway (20277 + Euro symbol); IBM EBCDIC (Denmark-Norway-Euro)
+    1143: 'cp1143', # IBM EBCDIC Finland-Sweden (20278 + Euro symbol); IBM EBCDIC (Finland-Sweden-Euro)
+    1144: 'cp1144', # IBM EBCDIC Italy (20280 + Euro symbol); IBM EBCDIC (Italy-Euro)
+    1145: 'cp1145', # IBM EBCDIC Latin America-Spain (20284 + Euro symbol); IBM EBCDIC (Spain-Euro)
+    1146: 'cp1146', # IBM EBCDIC United Kingdom (20285 + Euro symbol); IBM EBCDIC (UK-Euro)
+    1147: 'cp1147', # IBM EBCDIC France (20297 + Euro symbol); IBM EBCDIC (France-Euro)
+    1148: 'cp1148ms', # IBM EBCDIC International (500 + Euro symbol); IBM EBCDIC (International-Euro)
+    1149: 'cp1149', # IBM EBCDIC Icelandic (20871 + Euro symbol); IBM EBCDIC (Icelandic-Euro)
+    1200: 'utf-16-le', # Unicode UTF-16, little endian byte order (BMP of ISO 10646); available only to managed applications
+    1201: 'utf-16-be', # Unicode UTF-16, big endian byte order; available only to managed applications
+    1250: 'windows-1250', # ANSI Central European; Central European (Windows)
+    1251: 'windows-1251', # ANSI Cyrillic; Cyrillic (Windows)
+    1252: 'windows-1252', # ANSI Latin 1; Western European (Windows)
+    1253: 'windows-1253', # ANSI Greek; Greek (Windows)
+    1254: 'windows-1254', # ANSI Turkish; Turkish (Windows)
+    1255: 'windows-1255', # ANSI Hebrew; Hebrew (Windows)
+    1256: 'windows-1256', # ANSI Arabic; Arabic (Windows)
+    1257: 'windows-1257', # ANSI Baltic; Baltic (Windows)
+    1258: 'windows-1258', # ANSI/OEM Vietnamese; Vietnamese (Windows)
+    1361: 'Johab', # Korean (Johab)
+    10000: 'macintosh', # MAC Roman; Western European (Mac)
+    10001: 'x-mac-japanese', # Japanese (Mac)
+    # UNSUPPORTED.
+    10002: 'x-mac-chinesetrad', # MAC Traditional Chinese (Big5); Chinese Traditional (Mac)
+    10003: 'x-mac-korean', # Korean (Mac)
+    # UNSUPPORTED.
+    10004: 'x-mac-arabic', # Arabic (Mac)
+    # UNSUPPORTED.
+    10005: 'x-mac-hebrew', # Hebrew (Mac)
+    # UNSUPPORTED.
+    10006: 'x-mac-greek', # Greek (Mac)
+    # UNSUPPORTED.
+    10007: 'x-mac-cyrillic', # Cyrillic (Mac)
+    # UNSUPPORTED.
+    10008: 'x-mac-chinesesimp', # MAC Simplified Chinese (GB 2312); Chinese Simplified (Mac)
+    # UNSUPPORTED.
+    10010: 'x-mac-romanian', # Romanian (Mac)
+    # UNSUPPORTED.
+    10017: 'x-mac-ukrainian', # Ukrainian (Mac)
+    # UNSUPPORTED.
+    10021: 'x-mac-thai', # Thai (Mac)
+    # UNSUPPORTED.
+    10029: 'x-mac-ce', # MAC Latin 2; Central European (Mac)
+    # UNSUPPORTED.
+    10079: 'x-mac-icelandic', # Icelandic (Mac)
+    # UNSUPPORTED.
+    10081: 'x-mac-turkish', # Turkish (Mac)
+    # UNSUPPORTED.
+    10082: 'x-mac-croatian', # Croatian (Mac)
+    12000: 'utf-32', # Unicode UTF-32, little endian byte order; available only to managed applications
+    12001: 'utf-32BE', # Unicode UTF-32, big endian byte order; available only to managed applications
+    # UNSUPPORTED.
+    20000: 'x-Chinese_CNS', # CNS Taiwan; Chinese Traditional (CNS)
+    # UNSUPPORTED.
+    20001: 'x-cp20001', # TCA Taiwan
+    # UNSUPPORTED.
+    20002: 'x_Chinese-Eten', # Eten Taiwan; Chinese Traditional (Eten)
+    # UNSUPPORTED.
+    20003: 'x-cp20003', # IBM5550 Taiwan
+    # UNSUPPORTED.
+    20004: 'x-cp20004', # TeleText Taiwan
+    # UNSUPPORTED.
+    20005: 'x-cp20005', # Wang Taiwan
+    # UNSUPPORTED.
+    20105: 'x-IA5', # IA5 (IRV International Alphabet No. 5, 7-bit); Western European (IA5)
+    # UNSUPPORTED.
+    20106: 'x-IA5-German', # IA5 German (7-bit)
+    # UNSUPPORTED.
+    20107: 'x-IA5-Swedish', # IA5 Swedish (7-bit)
+    # UNSUPPORTED.
+    20108: 'x-IA5-Norwegian', # IA5 Norwegian (7-bit)
+    20127: 'us-ascii', # US-ASCII (7-bit)
+    # UNSUPPORTED.
+    20261: 'x-cp20261', # T.61
+    # UNSUPPORTED.
+    20269: 'x-cp20269', # ISO 6937 Non-Spacing Accent
+    20273: 'IBM273', # IBM EBCDIC Germany
+    20277: 'cp277', # IBM EBCDIC Denmark-Norway
+    20278: 'cp278', # IBM EBCDIC Finland-Sweden
+    20280: 'cp280', # IBM EBCDIC Italy
+    20284: 'cp284', # IBM EBCDIC Latin America-Spain
+    20285: 'cp285', # IBM EBCDIC United Kingdom
+    20290: 'cp290', # IBM EBCDIC Japanese Katakana Extended
+    20297: 'cp297', # IBM EBCDIC France
+    20420: 'cp420', # IBM EBCDIC Arabic
+    # UNSUPPORTED.
+    20423: 'IBM423', # IBM EBCDIC Greek
+    20424: 'IBM424', # IBM EBCDIC Hebrew
+    20833: 'cp833', # IBM EBCDIC Korean Extended
+    20838: 'cp838', # IBM EBCDIC Thai
+    20866: 'koi8-r', # Russian (KOI8-R); Cyrillic (KOI8-R)
+    20871: 'cp871', # IBM EBCDIC Icelandic
+    # UNSUPPORTED.
+    20880: 'IBM880', # IBM EBCDIC Cyrillic Russian
+    # UNSUPPORTED.
+    20905: 'IBM905', # IBM EBCDIC Turkish
+    # UNSUPPORTED.
+    20924: 'IBM00924', # IBM EBCDIC Latin 1/Open System (1047 + Euro symbol)
+    20932: 'EUC-JP', # Japanese (JIS 0208-1990 and 0212-1990)
+    # UNSUPPORTED.
+    20936: 'x-cp20936', # Simplified Chinese (GB2312); Chinese Simplified (GB2312-80)
+    # UNSUPPORTED.
+    20949: 'x-cp20949', # Korean Wansung
+    21025: 'cp1025', # IBM EBCDIC Cyrillic Serbian-Bulgarian
+    # UNSUPPORTED.
+    21027: '', # (deprecated)
+    21866: 'koi8-u', # Ukrainian (KOI8-U); Cyrillic (KOI8-U)
+    28591: 'iso-8859-1', # ISO 8859-1 Latin 1; Western European (ISO)
+    28592: 'iso-8859-2', # ISO 8859-2 Central European; Central European (ISO)
+    28593: 'iso-8859-3', # ISO 8859-3 Latin 3
+    28594: 'iso-8859-4', # ISO 8859-4 Baltic
+    28595: 'iso-8859-5', # ISO 8859-5 Cyrillic
+    28596: 'iso-8859-6', # ISO 8859-6 Arabic
+    28597: 'iso-8859-7', # ISO 8859-7 Greek
+    28598: 'iso-8859-8', # ISO 8859-8 Hebrew; Hebrew (ISO-Visual)
+    28599: 'iso-8859-9', # ISO 8859-9 Turkish
+    28603: 'iso-8859-13', # ISO 8859-13 Estonian
+    28605: 'iso-8859-15', # ISO 8859-15 Latin 9
+    # UNSUPPORTED.
+    29001: 'x-Europa', # Europa 3
+    # UNSUPPORTED.
+    38598: 'iso-8859-8-i', # ISO 8859-8 Hebrew; Hebrew (ISO-Logical)
+    50220: 'iso-2022-jp', # ISO 2022 Japanese with no halfwidth Katakana; Japanese (JIS)
+    50221: 'csISO2022JP', # ISO 2022 Japanese with halfwidth Katakana; Japanese (JIS-Allow 1 byte Kana)
+    50222: 'iso-2022-jp', # ISO 2022 Japanese JIS X 0201-1989; Japanese (JIS-Allow 1 byte Kana - SO/SI)
+    50225: 'iso-2022-kr', # ISO 2022 Korean
+    # UNSUPPORTED.
+    50227: 'x-cp50227', # ISO 2022 Simplified Chinese; Chinese Simplified (ISO 2022)
+    # UNSUPPORTED.
+    50229: '', # ISO 2022 Traditional Chinese
+    # UNSUPPORTED.
+    50930: '', # EBCDIC Japanese (Katakana) Extended
+    # UNSUPPORTED.
+    50931: '', # EBCDIC US-Canada and Japanese
+    # UNSUPPORTED.
+    50933: '', # EBCDIC Korean Extended and Korean
+    # UNSUPPORTED.
+    50935: '', # EBCDIC Simplified Chinese Extended and Simplified Chinese
+    # UNSUPPORTED.
+    50936: '', # EBCDIC Simplified Chinese
+    # UNSUPPORTED.
+    50937: '', # EBCDIC US-Canada and Traditional Chinese
+    # UNSUPPORTED.
+    50939: '', # EBCDIC Japanese (Latin) Extended and Japanese
+    51932: 'euc-jp', # EUC Japanese
+    51936: 'EUC-CN', # EUC Simplified Chinese; Chinese Simplified (EUC)
+    51949: 'euc-kr', # EUC Korean
+    # UNSUPPORTED.
+    51950: '', # EUC Traditional Chinese
+    52936: 'hz-gb-2312', # HZ-GB2312 Simplified Chinese; Chinese Simplified (HZ)
+    54936: 'GB18030', # Windows XP and later: GB18030 Simplified Chinese (4 byte); Chinese Simplified (GB18030)
+    # UNSUPPORTED.
+    57002: 'x-iscii-de', # ISCII Devanagari
+    # UNSUPPORTED.
+    57003: 'x-iscii-be', # ISCII Bangla
+    # UNSUPPORTED.
+    57004: 'x-iscii-ta', # ISCII Tamil
+    # UNSUPPORTED.
+    57005: 'x-iscii-te', # ISCII Telugu
+    # UNSUPPORTED.
+    57006: 'x-iscii-as', # ISCII Assamese
+    # UNSUPPORTED.
+    57007: 'x-iscii-or', # ISCII Odia
+    # UNSUPPORTED.
+    57008: 'x-iscii-ka', # ISCII Kannada
+    # UNSUPPORTED.
+    57009: 'x-iscii-ma', # ISCII Malayalam
+    # UNSUPPORTED.
+    57010: 'x-iscii-gu', # ISCII Gujarati
+    # UNSUPPORTED.
+    57011: 'x-iscii-pa', # ISCII Punjabi
+    65000: 'utf-7', # Unicode (UTF-7)
+    65001: 'utf-8', # Unicode (UTF-8)
+}
+
+PYTPFLOATINGTIME_START = datetime.datetime(1899, 12, 30)
+NULL_DATE = datetime.datetime(4500, 8, 31, 23, 59)
+
+# Constants used for argparse stuff
+KNOWN_FILE_FLAGS = (
+    '--out-name',
+)
+NEEDS_ARG = (
+    '--out-name',
+)
+MAINDOC = "extract_msg:\n\tExtracts emails and attachments saved in Microsoft Outlook's .msg files.\n\n" \
+          "https://github.com/TeamMsgExtractor/msg-extractor"
+
+# Default class ID for the root entry for OleWriter. This should be
+# referencing Outlook if I understand it correctly.
+DEFAULT_CLSID = b'\x0b\r\x02\x00\x00\x00\x00\x00\xc0\x00\x00\x00\x00\x00\x00F'
+
+# Define pre-compiled structs to make unpacking slightly faster.
+# General structs.
+ST1 = struct.Struct('<8x4I')
+ST2 = struct.Struct('<H2xI8x')
+ST3 = struct.Struct('<Q')
+# Struct used for unpacking a system time.
+ST_SYSTEMTIME = struct.Struct('<8H')
+# Struct used for unpacking a GUID from bytes.
+ST_GUID = struct.Struct('<IHH8s')
+# Struct for unpacking a TimeZoneStruct from bytes.
+ST_TZ = struct.Struct('<iiiH16sH16s')
+# Struct for packing a compount file directory entry.
+ST_CF_DIR_ENTRY = struct.Struct('<64sHBBIII16sIQQIQ')
+# Structs used by data.py
+ST_DATA_UI32 = struct.Struct('<I')
+ST_DATA_UI16 = struct.Struct('<H')
+ST_DATA_UI8 = struct.Struct('<B')
+# Structs used by named.py
+STNP_NAM = struct.Struct('<i')
+# Struct used for unpacking the entries in the entry stream
+STNP_ENT = struct.Struct('<IHH')
+# Structs used by prop.py
+STFIX = struct.Struct('<8x8s')
+STVAR = struct.Struct('<8xi4s')
+# Structs to help with email type to python type conversions
+STI8 = struct.Struct('<b');
+STI16 = struct.Struct('<h6x')
+STI32 = struct.Struct('<I4x')
+STI64 = struct.Struct('<q')
+STF32 = struct.Struct('<f4x')
+STF64 = struct.Struct('<d')
+STUI32 = struct.Struct('<I4x')
+STMI16 = struct.Struct('<h')
+STMI32 = struct.Struct('<i')
+STMI64 = struct.Struct('<q')
+STMF32 = struct.Struct('<f')
+STMF64 = struct.Struct('<d')
+# PermanentEntryID parsing struct
+STPEID = struct.Struct('<B3x16s4xI')
+# Struct for unpacking the first part of the BusinessCardDisplayDefinition
+# structure.
+ST_BC_HEAD = struct.Struct('BBBBBBBBIB')
+# Struct for completely unpacking the FieldInfo structure.
+ST_BC_FIELD_INFO = struct.Struct('HBBBxHII')
+# Structs for reading from a BytesReader. Some are just aliases for existing
+# structs, used for clarity and consistency in the code.
+ST_LE_I8 = STI8
+ST_LE_I16 = STMI16
+ST_LE_I32 = STMI32
+ST_LE_I64 = STMI64
+ST_LE_UI8 = ST_DATA_UI8
+ST_LE_UI16 = ST_DATA_UI16
+ST_LE_UI32 = ST_DATA_UI32
+ST_LE_UI64 = ST3
+ST_LE_F32 = STF32
+ST_LE_F64 = STF64
+ST_BE_I8 = struct.Struct('>b')
+ST_BE_I16 = struct.Struct('>h')
+ST_BE_I32 = struct.Struct('>i')
+ST_BE_I64 = struct.Struct('>q')
+ST_BE_UI8 = struct.Struct('>B')
+ST_BE_UI16 = struct.Struct('>H')
+ST_BE_UI32 = struct.Struct('>I')
+ST_BE_UI64 = struct.Struct('>Q')
+ST_BE_F32 = struct.Struct('>f')
+ST_BE_F64 = struct.Struct('>d')
+
+PTYPES = {
+    0x0000: 'PtypUnspecified',
+    0x0001: 'PtypNull',
+    0x0002: 'PtypInteger16',  # Signed short
+    0x0003: 'PtypInteger32',  # Signed int
+    0x0004: 'PtypFloating32',  # Float
+    0x0005: 'PtypFloating64',  # Double
+    0x0006: 'PtypCurrency',
+    0x0007: 'PtypFloatingTime',
+    0x000A: 'PtypErrorCode',
+    0x000B: 'PtypBoolean',
+    0x000D: 'PtypObject/PtypEmbeddedTable/Storage',
+    0x0014: 'PtypInteger64',  # Signed longlong
+    0x001E: 'PtypString8',
+    0x001F: 'PtypString',
+    0x0040: 'PtypTime',  # Use filetimeToUtc to convert to unix time stamp
+    0x0048: 'PtypGuid',
+    0x00FB: 'PtypServerId',
+    0x00FD: 'PtypRestriction',
+    0x00FE: 'PtypRuleAction',
+    0x0102: 'PtypBinary',
+    0x1002: 'PtypMultipleInteger16',
+    0x1003: 'PtypMultipleInteger32',
+    0x1004: 'PtypMultipleFloating32',
+    0x1005: 'PtypMultipleFloating64',
+    0x1006: 'PtypMultipleCurrency',
+    0x1007: 'PtypMultipleFloatingTime',
+    0x1014: 'PtypMultipleInteger64',
+    0x101E: 'PtypMultipleString8',
+    0x101F: 'PtypMultipleString',
+    0x1040: 'PtypMultipleTime',
+    0x1048: 'PtypMultipleGuid',
+    0x1102: 'PtypMultipleBinary',
+}
+
+# This property information was sourced from
+# http://www.fileformat.info/format/outlookmsg/index.htm
+# on 2013-07-22.
+# It was extended by The Elemental of Destruction on 2018-10-12.
+PROPERTIES = {
+    '00010102': 'Template data',
+    '0002000B': 'Alternate recipient allowed',
+    '0004001F': 'Auto forward comment',
+    '00040102': 'Script data',
+    '0005000B': 'Auto forwarded',
+    '000F000F': 'Deferred delivery time',
+    '00100040': 'Deliver time',
+    '00150040': 'Expiry time',
+    '00170003': 'Importance',
+    '001A001F': 'Message class',
+    '0023001F': 'Originator delivery report requested',
+    '00250102': 'Parent key',
+    '00260003': 'Priority',
+    '0029000B': 'Read receipt requested',
+    '002A0040': 'Receipt time',
+    '002B000B': 'Recipient reassignment prohibited',
+    '002E0003': 'Original sensitivity',
+    '00300040': 'Reply time',
+    '00310102': 'Report tag',
+    '00320040': 'Report time',
+    '00360003': 'Sensitivity',
+    '0037001F': 'Subject',
+    '00390040': 'Client Submit Time',
+    '003A001F': '',
+    '003B0102': '',
+    '003D001F': 'Subject prefix',
+    '003F0102': '',
+    '0040001F': 'Received by name',
+    '00410102': '',
+    '0042001F': 'Sent repr name',
+    '00430102': '',
+    '0044001F': 'Rcvd repr name',
+    '00450102': '',
+    '0046001F': '',
+    '00470102': '',
+    '0049001F': '',
+    '004B001F': '',
+    '004C0102': '',
+    '004D001F': 'Org author name',
+    '004E0040': '',
+    '004F0102': '',
+    '0050001F': 'Reply rcipnt names',
+    '00510102': '',
+    '00520102': '',
+    '00530102': '',
+    '00540102': '',
+    '00550040': '',
+    '0057000B': '',
+    '0058000B': '',
+    '0059000B': '',
+    '005A001F': 'Org sender name',
+    '005B0102': '',
+    '005C0102': '',
+    '005D001F': '',
+    '005E0102': '',
+    '005F0102': '',
+    '00600040': '',
+    '00610040': '',
+    '00620003': '',
+    '0063000B': '',
+    '0064001F': 'Sent repr adrtype',
+    '0065001F': 'Sent repr email',
+    '0066001F': '',
+    '00670102': '',
+    '0068001F': '',
+    '0069001F': '',
+    '0070001F': 'Topic',
+    '00710102': '',
+    '0072001F': '',
+    '0073001F': '',
+    '0074001F': '',
+    '0075001F': 'Rcvd by adrtype',
+    '0076001F': 'Rcvd by email',
+    '0077001F': 'Repr adrtype',
+    '0078001F': 'Repr email',
+    '007D001F': 'Message header',
+    '007F0102': '',
+    '0080001F': '',
+    '0081001F': '',
+    '08070003': '',
+    '0809001F': '',
+    '0C040003': '',
+    '0C050003': '',
+    '0C06000B': '',
+    '0C08000B': '',
+    '0C150003': '',
+    '0C17000B': '',
+    '0C190102': '',
+    '0C1A001F': 'Sender name',
+    '0C1B001F': '',
+    '0C1D0102': '',
+    '0C1E001F': 'Sender adr type',
+    '0C1F001F': 'Sender email',
+    '0C200003': '',
+    '0C21001F': '',
+    '0E01000B': '',
+    '0E02001F': 'Display BCC',
+    '0E03001F': 'Display CC',
+    '0E04001F': 'Display To',
+    '0E060040': '',
+    '0E070003': '',
+    '0E080003': '',
+    '0E080014': '',
+    '0E090102': '',
+    '0E0F000B': '',
+    '0E12000D': '',
+    '0E13000D': '',
+    '0E170003': '',
+    '0E1B000B': '',
+    '0E1D001F': 'Subject (normalized)',
+    '0E1F000B': '',
+    '0E200003': '',
+    '0E210003': '',
+    '0E28001F': 'Recvd account1 (uncertain)',
+    '0E29001F': 'Recvd account2 (uncertain)',
+    '1000001F': 'Message body',
+    '1008': 'RTF sync body tag', # Where did this come from ??? It's not listed in the docs
+    '10090102': 'Compressed RTF body',
+    '1013001F': 'HTML body',
+    '1035001F': 'Message ID (uncertain)',
+    '1046001F': 'Sender email (uncertain)',
+    '3001001F': 'Display name',
+    '3002001F': 'Address type',
+    '3003001F': 'Email address',
+    '30070040': 'Creation date',
+    '39FE001F': '7-bit email (uncertain)',
+    '39FF001F': '7-bit display name',
+
+    # Attachments (37xx)
+    '37010102': 'Attachment data',
+    '37020102': '',
+    '3703001F': 'Attachment extension',
+    '3704001F': 'Attachment short filename',
+    '37050003': 'Attachment attach method',
+    '3707001F': 'Attachment long filename',
+    '370E001F': 'Attachment mime tag',
+    '3712001F': 'Attachment ID (uncertain)',
+
+    # Address book (3Axx):
+    '3A00001F': 'Account',
+    '3A02001F': 'Callback phone no',
+    '3A05001F': 'Generation',
+    '3A06001F': 'Given name',
+    '3A08001F': 'Business phone',
+    '3A09001F': 'Home phone',
+    '3A0A001F': 'Initials',
+    '3A0B001F': 'Keyword',
+    '3A0C001F': 'Language',
+    '3A0D001F': 'Location',
+    '3A11001F': 'Surname',
+    '3A15001F': 'Postal address',
+    '3A16001F': 'Company name',
+    '3A17001F': 'Title',
+    '3A18001F': 'Department',
+    '3A19001F': 'Office location',
+    '3A1A001F': 'Primary phone',
+    '3A1B101F': 'Business phone 2',
+    '3A1C001F': 'Mobile phone',
+    '3A1D001F': 'Radio phone no',
+    '3A1E001F': 'Car phone no',
+    '3A1F001F': 'Other phone',
+    '3A20001F': 'Transmit dispname',
+    '3A21001F': 'Pager',
+    '3A220102': 'User certificate',
+    '3A23001F': 'Primary Fax',
+    '3A24001F': 'Business Fax',
+    '3A25001F': 'Home Fax',
+    '3A26001F': 'Country',
+    '3A27001F': 'Locality',
+    '3A28001F': 'State/Province',
+    '3A29001F': 'Street address',
+    '3A2A001F': 'Postal Code',
+    '3A2B001F': 'Post Office Box',
+    '3A2C001F': 'Telex',
+    '3A2D001F': 'ISDN',
+    '3A2E001F': 'Assistant phone',
+    '3A2F001F': 'Home phone 2',
+    '3A30001F': 'Assistant',
+    '3A44001F': 'Middle name',
+    '3A45001F': 'Dispname prefix',
+    '3A46001F': 'Profession',
+    '3A47001F': '',
+    '3A48001F': 'Spouse name',
+    '3A4B001F': 'TTYTTD radio phone',
+    '3A4C001F': 'FTP site',
+    '3A4E001F': 'Manager name',
+    '3A4F001F': 'Nickname',
+    '3A51001F': 'Business homepage',
+    '3A57001F': 'Company main phone',
+    '3A58101F': 'Childrens names',
+    '3A59001F': 'Home City',
+    '3A5A001F': 'Home Country',
+    '3A5B001F': 'Home Postal Code',
+    '3A5C001F': 'Home State/Provnce',
+    '3A5D001F': 'Home Street',
+    '3A5F001F': 'Other adr City',
+    '3A60': 'Other adr Country',
+    '3A61': 'Other adr PostCode',
+    '3A62': 'Other adr Province',
+    '3A63': 'Other adr Street',
+    '3A64': 'Other adr PO box',
+
+    '3FF7': 'Server (uncertain)',
+    '3FF8': 'Creator1 (uncertain)',
+    '3FFA': 'Creator2 (uncertain)',
+    '3FFC': 'To email (uncertain)',
+    '403D': 'To adrtype (uncertain)',
+    '403E': 'To email (uncertain)',
+    '5FF6': 'To (uncertain)',
+}
+
+PS_MAPI = '{00020328-0000-0000-C000-000000000046}'
+PS_PUBLIC_STRINGS = '{00020329-0000-0000-C000-000000000046}'
+PSETID_COMMON = '{00062008-0000-0000-C000-000000000046}'
+PSETID_ADDRESS = '{00062004-0000-0000-C000-000000000046}'
+PS_INTERNET_HEADERS = '{00020386-0000-0000-C000-000000000046}'
+PSETID_APPOINTMENT = '{00062002-0000-0000-C000-000000000046}'
+PSETID_MEETING = '{6ED8DA90-450B-101B-98DA-00AA003F1305}'
+PSETID_LOG = '{0006200A-0000-0000-C000-000000000046}'
+PSETID_MESSAGING = '{41F28F13-83F4-4114-A584-EEDB5A6B0BFF}'
+PSETID_NOTE = '{0006200E-0000-0000-C000-000000000046}'
+PSETID_POSTRSS = '{00062041-0000-0000-C000-000000000046}'
+PSETID_TASK = '{00062003-0000-0000-C000-000000000046}'
+PSETID_UNIFIEDMESSAGING = '{4442858E-A9E3-4E80-B900-317A210CC15B}'
+PSETID_AIRSYNC = '{71035549-0739-4DCB-9163-00F0580DBBDF}'
+PSETID_SHARING = '{00062040-0000-0000-C000-000000000046}'
+PSETID_XMLEXTRACTEDENTITIES = '{23239608-685D-4732-9C55-4C95CB4E8E33}'
+PSETID_ATTACHMENT = '{96357F7F-59E1-47D0-99A7-46515C183B54}'
+PSETID_CALENDAR_ASSISTANT = '{11000E07-B51B-40D6-AF21-CAA85EDAB1D0}'
+
+# END CONSTANTS
```

### Comparing `extract_msg-0.40.0/extract_msg/enums.py` & `extract_msg-0.41.0/extract_msg/enums.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,1670 +1,1756 @@
-import enum
-
-from typing import Set, Union
-
-
-class AddressBookType(enum.Enum):
-    """
-    The type of object that an address book entry ID represents. MUST be one of
-    these or it is invalid.
-    """
-    LOCAL_MAIL_USER = 0x000
-    DISTRIBUTION_LIST = 0x001
-    BULLETIN_BOARD_OR_PUBLIC_FOLDER = 0x002
-    AUTOMATED_MAILBOX = 0x003
-    ORGANIZATIONAL_MAILBOX = 0x004
-    PRIVATE_DISTRIBUTION_LIST = 0x005
-    REMOTE_MAIL_USER = 0x006
-    CONTAINER = 0x100
-    TEMPLATE = 0x101
-    ONE_OFF_USER = 0x102
-    SEARCH = 0x200
-
-
-
-class AppointmentAuxilaryFlag(enum.Enum):
-    """
-    Describes the auxilary state of the object.
-
-    COPIED: The Calendar object was copied from another Calendar folder.
-    FORCE_MEETING_RESPONSE: The client of server can require that a Meeting
-        Response object be sent to the organizer when a response is chosen.
-    FORWARDED: The object was forwarded by the organizer or another recipient.
-    REPAIR_UPDATE_MESSAGE: The meeting request is a Repair Update Message sent
-        from a server-side calendar repair system.
-    """
-    @classmethod
-    def fromBits(cls, value : int) -> Set['AppointmentAuxilaryFlag']:
-        """
-        Takes an int and returns a set of the flags.
-        """
-        flags = set()
-        for x in range(7):
-            bit = value & (1 << x)
-            if bit:
-                if x in (3, 4, 6):
-                    raise ValueError('Reserved bit was set.')
-                flags.add(cls(bit))
-
-        return flags
-
-    COPIED = 0b1
-    FORCE_MEETING_RESPONSE = 0b10
-    FORWARDED = 0b100
-    REPAIR_UPDATE_MESSAGE = 0b100000
-
-
-
-class AppointmentColor(enum.Enum):
-    NONE = 0x00000000
-    RED = 0x00000001
-    BLUE = 0x00000002
-    GREEN = 0x00000003
-    GREY = 0x00000004
-    ORANGE = 0x00000005
-    CYAN = 0x00000006
-    OLIVE = 0x00000007
-    PURPLE = 0x00000008
-    TEAL = 0x00000009
-    YELLOW = 0x0000000A
-
-
-
-class AppointmentStateFlag(enum.Enum):
-    """
-    MEETING: The object is a Meeting object or meeting-related object.
-    RECEIVED: The represented object was received from someone else.
-    CANCELED: The Meeting object that is represented has been canceled.
-    """
-    @classmethod
-    def fromBits(cls, value : int) -> Set['AppointmentStateFlag']:
-        """
-        Takes an int and returns a set of the flags.
-        """
-        return {cls(1 << x) for x in range(3) if (value & (1 << x)) != 0}
-
-    MEETING = 0b1
-    RECEIVED = 0b10
-    CANCELED = 0b100
-
-
-
-class AttachErrorBehavior(enum.Enum):
-    """
-    The behavior to follow when handling an error in an attachment.
-    THROW: Throw the exception regardless of type.
-    NOT_IMPLEMENTED: Silence the exception for NotImplementedError.
-    BROKEN: Silence the exception for NotImplementedError and for broken
-        attachments.
-    """
-    THROW = 0
-    NOT_IMPLEMENTED = 1
-    BROKEN = 2
-
-
-
-class AttachmentType(enum.Enum):
-    """
-    The type represented by the attachment.
-
-    DATA: An attachment stored as plain bytes in the MSG file.
-    MSG: A normally embedded MSG file.
-    WEB: An attachment referencing a resource on the web.
-    SIGNED: An attachment of a signed message that is *not* an MSG file.
-    SIGNED_EMBEDDED: An MSG file embedded in a signed message.
-
-    BROKEN: An attachment with a critical issue.
-    UNSUPPORTED: An attachment that does not match any supported types.
-    UNKNOWN: The attachment type could not be determined.
-    """
-    DATA = 0
-    MSG = 1
-    WEB = 2
-    SIGNED = 3
-    BROKEN = 4
-    UNSUPPORTED = 5
-    SIGNED_EMBEDDED = 6
-
-    UNKNOWN = 0xFFFFFFFF
-
-
-
-class BCImageAlignment(enum.Enum):
-    STRETCH = 0x00
-    TOP_LEFT = 0x01
-    TOP_CENTER = 0x02
-    TOP_RIGHT = 0x03
-    MIDDLE_LEFT = 0x04
-    MIDDLE_CENTER = 0x05
-    MIDDLE_RIGHT = 0x06
-    BOTTOM_LEFT = 0x07
-    BOTTOM_CENTER = 0x08
-    BOTTOM_RIGHT = 0x09
-
-
-
-class BCImageSource(enum.Enum):
-    CONTACT_PHOTO = 0
-    CARD_PHOTO = 1
-
-
-
-class BCLabelFormat(enum.Enum):
-    """
-    The format for a label of a business card. Left of the underscore represents
-    the alignment, right indicates reading order.
-    A
-    """
-    NO_LABEL = 0b000
-    RIGHT_LTR = 0b001
-    LEFT_LTR = 0b010
-    UNKNOWN = 0b100
-    RIGHT_RTL = 0b101
-    LEFT_RTL = 0b110
-
-
-
-class BCTemplateID(enum.Enum):
-    """
-    The template ID for a business card.
-
-    IM_ALIGN_LEFT: The image area will be left aligned, stretching the full
-        height of the card vertically; text fields will appear to the right of
-        the image area.
-    IM_ALIGN_RIGHT: The image area will be right aligned, stretching the full
-        height of the card vertically; text fields will appear to the left of
-        the image area.
-    IM_ALIGN_TOP: The image area will be aligned to the top, stretching the full
-        width of the card horizontally; text fields will appear under the image
-        area.
-    IM_ALIGN_BOTTOM: The image area will be aligned to the bottom, stretching
-        the full width of the card horizontally; text fields will appear above
-        the image area.
-    NO_IMAGE: No image area is included in the card, only text fields are
-        included.
-    BACKGROUND: The image area will be used as a background for the card,
-        stretching the full height and width of the card. Text fields are
-        displayed on top of the image area.
-    """
-    IM_ALIGN_LEFT = 0x00
-    IM_ALIGN_RIGHT = 0x01
-    IM_ALIGN_TOP = 0x02
-    IM_ALIGN_BOTTOM = 0x03
-    NO_IMAGE = 0x04
-    BACKGROUND = 0x05
-
-
-
-class BCTextFormat(enum.Enum):
-    """
-    Converts the bits of the text format to an understandable enum value.
-
-    Right value is the alignment, with left is the flags. The following flags
-    exist and will be in the following order if present:
-        U: Underline.
-        I: Italics.
-        B: Bold.
-        M: The text is multiline.
-    """
-    LEFT = 0b00000000
-    LEFT_M = 0b00000001
-    LEFT_B = 0b00000010
-    LEFT_BM = 0b00000011
-    LEFT_I = 0b00000100
-    LEFT_IM = 0b00000101
-    LEFT_IB = 0b00000110
-    LEFT_IBM = 0b00000111
-    LEFT_U = 0b00001000
-    LEFT_UM = 0b00001001
-    LEFT_UB = 0b00001010
-    LEFT_UBM = 0b00001011
-    LEFT_UI = 0b00001100
-    LEFT_UIM = 0b00001101
-    LEFT_UIB = 0b00001110
-    LEFT_UIBM = 0b00001111
-    CENTER = 0b00100000
-    CENTER_M = 0b00100001
-    CENTER_B = 0b00100010
-    CENTER_BM = 0b00100011
-    CENTER_I = 0b00100100
-    CENTER_IM = 0b00100101
-    CENTER_IB = 0b00100110
-    CENTER_IBM = 0b00100111
-    CENTER_U = 0b00101000
-    CENTER_UM = 0b00101001
-    CENTER_UB = 0b00101010
-    CENTER_UBM = 0b00101011
-    CENTER_UI = 0b00101100
-    CENTER_UIM = 0b00101101
-    CENTER_UIB = 0b00101110
-    CENTER_UIBM = 0b00101111
-    RIGHT = 0b00010000
-    RIGHT_M = 0b00010001
-    RIGHT_B = 0b00010010
-    RIGHT_BM = 0b00010011
-    RIGHT_I = 0b00010100
-    RIGHT_IM = 0b00010101
-    RIGHT_IB = 0b00010110
-    RIGHT_IBM = 0b00010111
-    RIGHT_U = 0b00011000
-    RIGHT_UM = 0b00011001
-    RIGHT_UB = 0b00011010
-    RIGHT_UBM = 0b00011011
-    RIGHT_UI = 0b00011100
-    RIGHT_UIM = 0b00011101
-    RIGHT_UIB = 0b00011110
-    RIGHT_UIBM = 0b00011111
-
-
-
-class BusyStatus(enum.Enum):
-    """
-    The availability of a use for the event described by the object.
-
-    OL_FREE: The user is available.
-    OL_TENTATIVE: The user has a tentative event scheduled.
-    OL_BUSY: The user is busy.
-    OL_OUT_OF_OFFICE: The user is Out of Office.
-    OL_WORKING_ELSEWHERE: The user is working from a location other than the
-        office.
-    """
-    OL_FREE = 0x00000000
-    OL_TENTATIVE = 0x00000001
-    OL_BUSY = 0x00000002
-    OL_OUT_OF_OFFICE = 0x00000003
-    OL_WORKING_ELSEWHERE = 0x00000004
-
-
-
-class ClientIntentFlag(enum.Enum):
-    """
-    An action a user has taken on a Meeting object.
-
-    MANAGER: The user is the owner of the Meeting object's Calendar folder. If
-        set, DELEGATE SHOULD NOT be set.
-    DELEGATE: The user is a delegate acting on a Meeting object in a delegator's
-        Calendar folder. If set, MANAGER SHOULD NOT be set.
-    DELETED_WITH_NO_RESPONSE: The user deleted the Meeting object with no
-        response sent to the organizer.
-    DELETED_EXCEPTION_WITH_NO_RESPONSE: The user deleted an exception to a
-        recurring series with no response sent to the organizer.
-    RESPONDED_TENTATIVE: The user tentatively accepted the meeting request.
-    RESPONSED_ACCEPT: The user accepted the meeting request.
-    RESPONDED_DECLINE: The user declined the meeting request.
-    MODIFIED_START_TIME: The user modified the start time.
-    MODIFIED_END_TIME: The user modified the end time.
-    MODIFIED_LOCATION: The user changed the location of the meeting.
-    RESPONDED_EXCEPTION_DECLINE: The user declined an exception to a recurring
-        series.
-    CANCELED: The user canceled a meeting request.
-    EXCEPTION_CANCELED: The user canceled an exception to a recurring series.
-    """
-    @classmethod
-    def fromBits(cls, value : int) -> Set['ClientIntentFlag']:
-        """
-        Takes an int and returns a set of the flags.
-        """
-        return {cls(1 << x) for x in range(13) if (value & (1 << x))}
-
-    MANAGER = 0b1
-    DELEGATE = 0b10
-    DELETED_WITH_NO_RESPONSE = 0b100
-    DELETED_EXCEPTION_WITH_NO_RESPONSE = 0b1000
-    RESPONDED_TENTATIVE = 0b10000
-    RESPONSED_ACCEPT = 0b100000
-    RESPONDED_DECLINE = 0b1000000
-    MODIFIED_START_TIME = 0b10000000
-    MODIFIED_END_TIME = 0b100000000
-    MODIFIED_LOCATION = 0b1000000000
-    RESPONDED_EXCEPTION_DECLINE = 0b10000000000
-    CANCELED = 0b100000000000
-    EXCEPTION_CANCELED = 0b1000000000000
-
-
-
-class Color(enum.IntEnum):
-    RED = 0
-    BLACK = 1
-
-
-class ContactAddressIndex(enum.Enum):
-    EMAIL_1 = 0
-    EMAIL_2 = 1
-    EMAIL_3 = 2
-    FAX_1 = 3
-    FAX_2 = 4
-    FAX_3 = 5
-
-
-
-class ContactLinkState(enum.Enum):
-    """
-    Values for PidLidContactLinkGlobalAddressListLinkState.
-
-    DUPLICATE_NOT_LINKED: The duplicate contact is not linked to the GAL contact
-        or the GAL contact is not downloaded.
-    DUPLICATE_LINKED: The duplicate contact is linked to the GAL contact.
-    DUPLICATE_CANNOT_LINK: The duplicate contact cannot be automatically linked
-        to the GAL contact.
-    """
-    DUPLICATE_NOT_LINKED = 0
-    DUPLICATE_LINKED = 1
-    DUPLICATE_CANNOT_LINK = 2
-
-
-
-class DeencapType(enum.Enum):
-    """
-    Enum to specify to custom deencapsulation functions the type of data being
-    requested.
-    """
-    PLAIN = 0
-    HTML = 1
-
-
-
-class DirectoryEntryType(enum.IntEnum):
-    UNALLOCATED = 0
-    UNKNOWN = 0
-    STORAGE = 1
-    STREAM = 2
-    ROOT_STORAGE = 5
-
-
-
-class DisplayType(enum.Enum):
-    MAILUSER = 0x0000
-    DISTLIST = 0x0001
-    FORUM = 0x0002
-    AGENT = 0x0003
-    ORGANIZATION = 0x0004
-    PRIVATE_DISTLIST = 0x0005
-    REMOTE_MAILUSER = 0x0006
-    CONTAINER = 0x0100
-    TEMPLATE = 0x0101
-    ADDRESS_TEMPLATE = 0x0102
-    SEARCH = 0x0200
-
-
-
-class ElectronicAddressProperties(enum.Enum):
-    @classmethod
-    def fromBits(cls, value : int) -> Set['ElectronicAddressProperties']:
-        """
-        Converts an int, with the left most bit referring to 0x00000000, to a
-        set of this enum.
-
-        :raises ValueError: The value was less than 0.
-        """
-        if value < 0:
-            raise ValueError('Value must not be negative.')
-        # This is a quick compressed way to convert the bits in the int into
-        # a tuple of instances of this class should any bit be a 1.
-        return {cls(int(x)) for index, val in enumerate(bin(value)[:1:-1]) if val == '1'}
-
-    EMAIL_1 = 0x00000000
-    EMAIL_2 = 0x00000001
-    EMAIL_3 = 0x00000002
-    BUSINESS_FAX = 0x00000003
-    HOME_FAX = 0x00000004
-    PRIMARY_FAX = 0x00000005
-
-
-
-class EntryIDType(enum.Enum):
-    """
-    Converts a UID to the type of Entry ID structure.
-    """
-    def toHex(self):
-        """
-        Converts an EntryIDType to it's hex equivelent.
-        """
-        return EntryIDTypeHex[self.name]
-
-    # This is the same as the one used for permanent IDs, and the strucutre is
-    # near identical too. Anything that needs a PermanentEntryID will need to
-    # specifically ask for it instead of autogenerating it.
-    ADDRESS_BOOK_RECIPIENT = b'\xDC\xA7\x40\xC8\xC0\x42\x10\x1A\xB4\xB9\x08\x00\x2B\x2F\xE1\x82'
-    # Contact address or personal distribution list recipient.
-    CA_OR_PDL_RECIPIENT = b'\xFE\x42\xAA\x0A\x18\xC7\x1A\x10\xE8\x85\x0B\x65\x1C\x24\x00\x00'
-    # This is also used for the Store Object EntryID structure.
-    NNTP_NEWSGROUP_FOLDER = b'\x38\xA1\xBB\x10\x05\xE5\x10\x1A\xA1\xBB\x08\x00\x2B\x2A\x56\xC2'
-    ONE_OFF_RECIPIENT = b'\x81\x2B\x1F\xA4\xBE\xA3\x10\x19\x9D\x6E\x00\xDD\x01\x0F\x54\x02'
-    PUBLIC_MESSAGE_STORE = b'\x1A\x44\x73\x90\xAA\x66\x11\xCD\x9B\xC8\x00\xAA\x00\x2F\xC4\x5A'
-    # [MS-OXOCNTC] WrappedEntryId Structure.
-    WRAPPED = b'\xC0\x91\xAD\xD3\x51\x9D\xCF\x11\xA4\xA9\x00\xAA\x00\x47\xFA\xA4'
-
-
-
-class EntryIDTypeHex(enum.Enum):
-    """
-    Converts a UID to the type of Entry ID structure. Uses a hex string instead
-    of bytes for the value.
-    """
-    def toRaw(self):
-        """
-        Converts and EntryIDTypeHex to it's raw equivelent.
-        """
-        return EntryIDType[self.name]
-
-    ADDRESS_BOOK_RECIPIENT = 'DCA740C8C042101AB4B908002B2FE182'
-    # Contact address or personal distribution list recipient.
-    CA_OR_PDL_RECIPIENT = 'FE42AA0A18C71A10E8850B651C240000'
-    NNTP_NEWSGROUP_FOLDER = '38A1BB1005E5101AA1BB08002B2A56C2'
-    ONE_OFF_RECIPIENT = '812B1FA4BEA310199D6E00DD010F5402'
-    PUBLIC_MESSAGE_STORE = '1A447390AA6611CD9BC800AA002FC45A'
-    # [MS-OXOCNTC] WrappedEntryId Structure.
-    WRAPPED = 'C091ADD3519DCF11A4A900AA0047FAA4'
-
-
-
-class ErrorCode(enum.Enum):
-    SUCCESS = 0x00000000
-    GENERAL_FAILURE = 0x80004005
-    OUT_OF_MEMORY = 0x8007000E
-    INVALID_PARAMETER = 0x80070057
-    NO_INTERFACE = 0x80004002
-    ACCESS_DENIED = 0x80070005
-    STORAGE_INVALID_FUNCTION = 0x80030001
-    STORAGE_ACCESS_DENIED = 0x80030005
-    STORAGE_INSUFFICIENT_MEMORY = 0x80030008
-    STORAGE_INVALID_POINTER = 0x80030009
-    STORAGE_READ_FAULT = 0x8003001E
-    STORAGE_LOCK_VIOLATION = 0x80030021
-    STORAGE_INVALID_PARAMETER = 0x80030057
-    STREAM_SIZE_ERROR = 0x80030070
-    STORAGE_INVALID_FLAG = 0x800300FF
-    STORAGE_CANNOT_SAVE = 0x80030103
-    NOT_SUPPORTED = 0x80040102
-    INVALID_CHARACTER_WIDTH = 0x80040103
-    STRING_TOO_LONG = 0x80040105
-    INVALID_FLAG = 0x80040106
-    INVALID_ENTRY_ID = 0x80040107
-    INVALID_OBJECT = 0x80040108
-    OBJECT_CHANGED = 0x80040109
-    OBJECT_DELETED = 0x8004010A
-    SERVER_BUSY = 0x8004010B
-    OUT_OF_DISK = 0x8004010D
-    OUT_OF_RESOURCES = 0x8004010E
-    NOT_FOUND = 0x8004010F
-    VERSION_MISMATCH = 0x80040110
-    LOGON_FAILED = 0x80040111
-    TOO_MANY_SESSIONS = 0x80040112
-    USER_CANCELED = 0x80040113
-    ABORT_FAILED = 0x80040114
-    NETWORK_ERROR = 0x80040115
-    DISK_ERROR = 0x80040116
-    TOO_COMPLEX = 0x80040117
-    INVALID_COLUMN = 0x80040118
-    COMPUTED_VALUE = 0x8004011A
-    CORRUPT_DATA = 0x8004011B
-    INVALID_CODEPAGE = 0x8004011E
-    INVALID_LOCALE = 0x8004011F
-    TIME_SKEW = 0x80040123
-    END_OF_SESSION = 0x80040200
-    UNKNOWN_ENTRY_ID = 0x80040201
-    NOT_COMPLETED = 0x80040400
-    TIMEOUT = 0x80040401
-    EMPTY_TABLE = 0x80040402
-    TABLE_TOO_BIG = 0x80040403
-    INVALID_BOOKMARK = 0x80040405
-    ERROR_WAIT = 0x80040500
-    ERROR_CANCEL = 0x80040501
-    NO_SUPPRESS = 0x80040602
-    COLLIDING_NAMES = 0x80040604
-    NOT_INITIALIZED = 0x80040605
-    NO_RECIPIENTS = 0x80040607
-    ALREADY_SENT = 0x80040608
-    HAS_FOLDERS = 0x80040609
-    HAS_MESSAGES = 0x8004060A
-    FOLDER_CYCLE = 0x8004060B
-    TOO_MANY_LOCKS = 0x8004060D
-    AMBIGUOUS_RECIPIENT = 0x80040700
-    SYNC_OBJECT_DELETED = 0x80040800
-    IGNORE_FAILURE = 0x80040801
-    SYNC_CONFLICT = 0x80040802
-    NO_PARENT_FOLDER = 0x80040803
-    CYCLE_DETECTED = 0x80040804
-    NOT_SYNCHRONIZED = 0x80040805
-    NAMED_PROPERTY_QUOTA = 0x80040900
-    NOT_IMPLEMENTED = 0x80040FFF
-
-
-
-class ErrorCodeType(enum.Enum):
-    """
-    Enum representing values for PtypErrorCode.
-
-    See "Additional Error Codes" in [MS-OXCDATA].
-    """
-    SUCCESS = 0x00000000
-    ISAM_ERROR = 0x000003EA
-    UNKNOWN_USER = 0x000003EB
-    EXITING = 0x000003ED
-    BAD_CONFIGURATION = 0x000003EE
-    UNKNOWN_CODE_PAGE = 0x000003EF
-    SERVER_MEMORY = 0x000003F0
-    LOGIN_PERMISSION = 0x000003F2
-    DATABASE_ROLLED_BACK = 0x000003F3
-    DATABASE_COPIED_ERROR = 0x000003F4
-    AUDIT_NOT_ALLOWED = 0x000003F5
-    ZOMBIE_USER = 0x000003F6
-    UNCONVERTABLE_ACL = 0x000003F7
-    NO_FREE_JET_SESSIONS = 0x0000044C
-    DIFFERENT_JET_SESSION = 0x0000044D
-    FILE_REMOVE = 0x0000044F
-    PARAMETER_OVERFLOW = 0x00000450
-    BAD_VERSION = 0x00000451
-    TOO_MANY_COLUMNS = 0x00000452
-    HAVE_MORE = 0x00000453
-    DATABASE_ERROR = 0x00000454
-    INDEX_NAME_TOO_BIG = 0x00000455
-    UNSUPPORTED_PROPERTY = 0x00000456
-    MESSAGE_NOT_SAVED = 0x00000457
-    UNPUBLISHED_NOTIFICATION = 0x00000459
-    DIFFERENT_ROOT = 0x0000045B
-    BAD_FOLDER_NAME = 0x0000045C
-    ATTACHMENT_OPEN = 0x0000045D
-    INVALID_COLLAPSE_STATE = 0x0000045E
-    SKIP_MY_CHILDREN = 0x0000045F
-    SEARCH_FOLDER = 0x00000460
-    NOT_SEARCH_FOLDER = 0x00000461
-    FOLDER_SET_RECEIVE = 0x00000462
-    NO_RECEIVE_FOLDER = 0x00000463
-    DELETE_SUBMITTED_MESSAGE = 0x00000465
-    INVALID_RECIPIENTS = 0x00000467
-    NO_REPLICA_HERE = 0x00000468
-    NO_REPLICA_AVAILABLE = 0x00000469
-    PUBLIC_DATABASE = 0x0000046A
-    NOT_PUBLIC_DATABASE = 0x0000046B
-    RECORD_NOT_FOUND = 0x0000046C
-    REPLICATION_CONFLICT = 0x0000046D
-    FX_BUFFER_OVERRUN = 0x00000470
-    FX_BUFFER_EMPTY = 0x00000471
-    FX_PARTIAL_VALUE = 0x00000472
-    FX_NO_ROOM = 0x00000473
-    TIME_EXPIRED = 0x00000474
-    DESTINATION_ERROR = 0x00000475
-    DATABASE_NOT_INITIALIZED = 0x00000476
-    WRONG_SERVER = 0x00000478
-    BUFFER_TOO_SMALL = 0x0000047D
-    ATTACHMENT_RESOLUTION_REQUIRED = 0x0000047E
-    SERVER_PAUSED = 0x0000047F
-    SERVER_BUSY = 0x00000480
-    NO_SUCH_LOGON = 0x00000481
-    LOAD_LIBRARY_FAILED = 0x00000482
-    ALREADY_CONFIGURED = 0x00000483
-    NOT_CONFIGURED = 0x00000484
-    DATA_LOSS = 0x00000485
-    MAXIMUM_SEND_THREAD_EXCEEDED = 0x00000488
-    FX_ERROR_MARKER = 0x00000489
-    NO_FREE_JTABS = 0x0000048A
-    NOT_PRIVATE_DATABASE = 0x0000048B
-    ISINTEG_MDB = 0x0000048C
-    RECOVERY_MISMATCH = 0x0000048D
-    TABLE_MAY_NOT_BE_DELETED = 0x0000048E
-    SEARCH_FOLDER_SCOPE_VIOLATION = 0x00000490
-    RPC_REGISTER_IF = 0x000004B1
-    RPC_LISTEN = 0x000004B2
-    RPC_FORMAT = 0x000004B6
-    NO_COPY_TO = 0x000004B7
-    NULL_OBJECT = 0x000004B9
-    RPC_AUTHENTICATION = 0x000004BC
-    RPC_BAD_AUTHENTICATION_LEVEL = 0x000004BD
-    NULL_COMMENT_RESTRICTION = 0x000004BE
-    RULES_LOAD_ERROR = 0x000004CC
-    RULES_DELIVER_ERR = 0x000004CD
-    RULES_PARSING_ERR = 0x000004CE
-    RULES_CREATE_DAE = 0x000004CF
-    RULES_CREATE_DAM = 0x000004D0
-    RULES_NO_MOVE_COPY_FOLDER = 0x000004D1
-    RULES_NO_FOLDER_RIGHTS = 0x000004D2
-    MESSAGE_TOO_BIG = 0x000004D4
-    FORM_NOT_VALID = 0x000004D5
-    NOT_AUTHORIZED = 0x000004D6
-    DELETE_MESSAGE = 0x000004D7
-    BOUNCE_MESSAGE = 0x000004D8
-    QUOTA_EXCEEDED = 0x000004D9
-    MAX_SUBMISSION_EXCEEDED = 0x000004DA
-    MAX_ATTACHMENT_EXCEEDED = 0x000004DB
-    SEND_AS_DENIED = 0x000004DC
-    SHUTOFF_QUOTA_EXCEEDED = 0x000004DD
-    TOO_MANY_OPEN_OBJECTS = 0x000004DE
-    CLIENT_VERSION_BLOCKED = 0x000004DF
-    RPC_HTTP_DISALLOWED = 0x000004E0
-    CACHED_MODE_REQUIRED = 0x000004E1
-    FOLDER_NOT_CLEANED_UP = 0x000004E3
-    FORMAT_ERROR = 0x000004ED
-    NOT_EXPANDED = 0x000004F7
-    NOT_COLLAPSED = 0x000004F8
-    NO_EXPAND_LEAF_ROW = 0x000004F9
-    UNREGISTERED_NAME_PROP = 0x000004FA
-    FOLDER_DISABLED = 0x000004FB
-    DOMAIN_ERROR = 0x000004FC
-    NO_CREATE_RIGHT = 0x000004FF
-    PUBLIC_ROOT = 0x00000500
-    NO_READ_RIGHT = 0x00000501
-    NO_CREATE_SUBFOLDER_RIGHT = 0x00000502
-    MESSAGE_CYCLE = 0x00000504
-    NULL_DESTINATION_OBJECT = 0x00000503
-    TOO_MANY_RECIPS = 0x00000505
-    VIRUS_SCAN_IN_PROGRESS = 0x0000050A
-    VIRUS_DETECTED = 0x0000050B
-    MAILBOX_IN_TRANSIT = 0x0000050C
-    BACKUP_IN_PROGRESS = 0x0000050D
-    VIRUS_MESSAGE_DELETED = 0x0000050E
-    INVALID_BACKUP_SEQUENCE = 0x0000050F
-    INVALID_BACKUP_TYPE = 0x00000510
-    TOO_MANY_BACKUPS = 0x00000511
-    RESTORE_IN_PROGRESS = 0x00000512
-    DUPLICATE_OBJECT = 0x00000579
-    OBJECT_NOT_FOUND = 0x0000057A
-    FIXUP_REPLY_RULE = 0x0000057B
-    TEMPLATE_NOT_FOUND = 0x0000057C
-    RULE_EXECUTION = 0x0000057D
-    DS_NO_SUCH_OBJECT = 0x0000057E
-    ALREADY_TOMBSTONED = 0x0000057F
-    READ_ONLY_TRANSACTION = 0x00000596
-    PAUSED = 0x0000060E
-    NOT_PAUSED = 0x0000060F
-    WRONG_MAILBOX = 0x00000648
-    CHANGE_PASSWORD = 0x0000064C
-    PASSWORD_EXPIRED = 0x0000064D
-    INVALID_WORKSTATION = 0x0000064E
-    INVALID_LOGON_HOURS = 0x0000064F
-    ACCOUNT_DISABLED = 0x00000650
-    RULE_VERSION = 0x000006A4
-    RULE_FORMAT = 0x000006A5
-    RULE_SEND_AS_DENIED = 0x000006A6
-    NO_SERVER_SUPPORT = 0x000006B9
-    LOCK_TIMED_OUT = 0x000006BA
-    OBJECT_LOCKED = 0x000006BB
-    INVALID_LOCK_NAMESPACE = 0x000006BD
-    MESSAGE_DELETED = 0x000007D6
-    PROTOCOL_DISABLED = 0x000007D8
-    CLEARTEXT_LOGON_DISABLED = 0x000007D9
-    REJECTED = 0x000007EE
-    AMBIGUOUS_ALIAS = 0x0000089A
-    UNKNOWN_MAILBOX = 0x0000089B
-    EXPRESSION_RESERVED = 0x000008FC
-    EXPRESSION_PARSE_DEPTH = 0x000008FD
-    EXPRESSION_ARGUMENT_TYPE = 0x000008FE
-    EXPRESSION_SYNTAX = 0x000008FF
-    EXPRESSION_BAD_STRING_TOKEN = 0x00000900
-    EXPRESSION_BAD_COL_TOKEN = 0x00000901
-    EXPRESSION_TYPE_MISMATCH = 0x00000902
-    EXPRESSION_OPERATOR_NOT_SUPPORTED = 0x00000903
-    EXPRESSION_DIVIDE_BY_ZERO = 0x00000904
-    EXPRESSION_UNARY_ARGUMENT = 0x00000905
-    NOT_LOCKED = 0x00000960
-    CLIENT_EVENT = 0x00000961
-    CORRUPT_EVENT = 0x00000965
-    CORRUPT_WATERMARK = 0x00000966
-    EVENT_ERROR = 0x00000967
-    WATERMARK_ERROR = 0x00000968
-    NON_CANONICAL_ACL = 0x00000969
-    MAILBOX_DISABLED = 0x0000096C
-    RULES_FOLDER_OVER_QUOTA = 0x0000096D
-    ADDRESS_BOOK_UNAVAILABLE = 0x0000096E
-    ADDRESS_BOOK_ERROR = 0x0000096F
-    ADDRESS_BOOK_OBJECT_NOT_FOUND = 0x00000971
-    ADDRESS_BOOK_PROPERTY_ERROR = 0x00000972
-    NOT_ENCRYPTED = 0x00000970
-    RPC_SERVER_TOO_BUSY = 0x00000973
-    RPC_OUT_OF_MEMORY = 0x00000974
-    RPC_SERVER_OUT_OF_MEMORY = 0x00000975
-    RPC_OUT_OF_RESOURCES = 0x00000976
-    RPC_SERVER_UNAVAILABLE = 0x00000977
-    SECURE_SUBMIT_ERROR = 0x0000097A
-    EVENTS_DELETED = 0x0000097C
-    SUBSYSTEM_STOPPING = 0x0000097D
-    ATTENDANT_UNAVAILABLE = 0x0000097E
-    CI_STOPPING = 0x00000A28
-    FX_INVALID_STATE = 0x00000A29
-    FX_UNEXPECTED_MARKER = 0x00000A2A
-    DUPLICATE_DELIVERY = 0x00000A2B
-    CONDITION_VIOLATION = 0x00000A2C
-    MAXIMUM_CONNECTION_POOLS_EXCEEDED = 0x00000A2D
-    INVALID_RPC_HANDLE = 0x00000A2E
-    EVENT_NOT_FOUND = 0x00000A2F
-    PROPERTY_NOT_PROMOTED = 0x00000A30
-    LOW_FREE_SPACE_FOR_DATABASE = 0x00000A31
-    LOW_FREE_SPACE_FOR_LOGS = 0x00000A32
-    MAILBOX_IS_QUARANTINED = 0x00000A33
-    DATABASE_MOUNT_IN_PROGRESS = 0x00000A34
-    DATABASE_DISMOUNT_IN_PROGRESS = 0x00000A35
-    CONNECTIONS_OVER_BUDGET = 0x00000A36
-    NOT_FOUND_IN_CONTAINER = 0x00000A37
-    CANNOT_REMOVE = 0x00000A38
-    INVALID_CONNECTION_POOL = 0x00000A39
-    VIRUS_SCAN_GENERAL_FAILURE = 0x00000A3A
-    ISAM_ERROR_RFS_FAILURE = 0xFFFFFF9C
-    ISAM_ERROR_RFS_NOT_ARMED = 0xFFFFFF9B
-    ISAM_ERROR_FILE_CLOSE = 0xFFFFFF9A
-    ISAM_ERROR_OUT_OF_THREADS = 0xFFFFFF99
-    ISAM_ERROR_TOO_MANY_IO = 0xFFFFFF97
-    ISAM_ERROR_TASK_DROPPED = 0xFFFFFF96
-    ISAM_ERROR_INTERNAL_ERROR = 0xFFFFFF95
-    ISAM_ERROR_DATABASE_BUFFER_DEPENDENCIES_CORRUPTED = 0xFFFFFF01
-    ISAM_ERROR_PREVIOUS_VERSION = 0xFFFFFEBE
-    ISAM_ERROR_PAGE_BOUNDARY = 0xFFFFFEBD
-    ISAM_ERROR_KEY_BOUNDARY = 0xFFFFFEBC
-    ISAM_ERROR_BAD_PAGE_LINK = 0xFFFFFEB9
-    ISAM_ERROR_BAD_BOOKMARK = 0xFFFFFEB8
-    ISAM_ERROR_NT_SYSTEM_CALL_FAILED = 0xFFFFFEB2
-    ISAM_ERROR_BAD_PARENT_PAGE_LINK = 0xFFFFFEAE
-    ISAM_ERROR_SP_AVAIL_EXT_CACHE_OUT_OF_SYNC = 0xFFFFFEAC
-    ISAM_ERROR_SP_AVAIL_EXT_CORRUPTED = 0xFFFFFEAB
-    ISAM_ERROR_SP_AVAIL_EXT_CACHE_OUT_OF_MEMORY = 0xFFFFFEAA
-    ISAM_ERROR_SP_OWN_EXT_CORRUPTED = 0xFFFFFEA9
-    ISAM_ERROR_DB_TIME_CORRUPTED = 0xFFFFFEA8
-    ISAM_ERROR_KEY_TRUNCATED = 0xFFFFFEA6
-    ISAM_ERROR_KEY_TOO_BIG = 0xFFFFFE68
-    ISAM_ERROR_INVALID_LOGGED_OPERATION = 0xFFFFFE0C
-    ISAM_ERROR_LOG_FILE_CORRUPT = 0xFFFFFE0B
-    ISAM_ERROR_NO_BACKUP_DIRECTORY = 0xFFFFFE09
-    ISAM_ERROR_BACKUP_DIRECTORY_NOT_EMPTY = 0xFFFFFE08
-    ISAM_ERROR_BACKUP_IN_PROGRESS = 0xFFFFFE07
-    ISAM_ERROR_RESTORE_IN_PROGRESS = 0xFFFFFE06
-    ISAM_ERROR_MISSING_PREVIOUS_LOG_FILE = 0xFFFFFE03
-    ISAM_ERROR_LOG_WRITE_FAIL = 0xFFFFFE02
-    ISAM_ERROR_LOG_DISABLED_DUE_TO_RECOVERY_FAILURE = 0xFFFFFE01
-    ISAM_ERROR_CANNOT_LOG_DURING_RECOVERY_REDO = 0xFFFFFE00
-    ISAM_ERROR_LOG_GENERATION_MISMATCH = 0xFFFFFDFF
-    ISAM_ERROR_BAD_LOG_VERSION = 0xFFFFFDFE
-    ISAM_ERROR_INVALID_LOG_SEQUENCE = 0xFFFFFDFD
-    ISAM_ERROR_LOGGING_DISABLED = 0xFFFFFDFC
-    ISAM_ERROR_LOG_BUFFER_TOO_SMALL = 0xFFFFFDFB
-    ISAM_ERROR_LOG_SEQUENCE_END = 0xFFFFFDF9
-    ISAM_ERROR_NO_BACKUP = 0xFFFFFDF8
-    ISAM_ERROR_INVALID_BACKUP_SEQUENCE = 0xFFFFFDF7
-    ISAM_ERROR_BACKUP_NOT_ALLOWED_YET = 0xFFFFFDF5
-    ISAM_ERROR_DELETE_BACKUP_FILE_FAIL = 0xFFFFFDF4
-    ISAM_ERROR_MAKE_BACKUP_DIRECTORY_FAIL = 0xFFFFFDF3
-    ISAM_ERROR_INVALID_BACKUP = 0xFFFFFDF2
-    ISAM_ERROR_RECOVERED_WITH_ERRORS = 0xFFFFFDF1
-    ISAM_ERROR_MISSING_LOG_FILE = 0xFFFFFDF0
-    ISAM_ERROR_LOG_DISK_FULL = 0xFFFFFDEF
-    ISAM_ERROR_BAD_LOG_SIGNATURE = 0xFFFFFDEE
-    ISAM_ERROR_BAD_DB_SIGNATURE = 0xFFFFFDED
-    ISAM_ERROR_BAD_CHECKPOINT_SIGNATURE = 0xFFFFFDEC
-    ISAM_ERROR_CHECKPOINT_CORRUPT = 0xFFFFFDEB
-    ISAM_ERROR_MISSING_PATCH_PAGE = 0xFFFFFDEA
-    ISAM_ERROR_BAD_PATCH_PAGE = 0xFFFFFDE9
-    ISAM_ERROR_REDO_ABRUPT_ENDED = 0xFFFFFDE8
-    ISAM_ERROR_BAD_SLV_SIGNATURE = 0xFFFFFDE7
-    ISAM_ERROR_PATCH_FILE_MISSING = 0xFFFFFDE6
-    ISAM_ERROR_DATABASE_LOG_SET_MISMATCH = 0xFFFFFDE5
-    ISAM_ERROR_DATABASE_STREAMING_FILE_MISMATCH = 0xFFFFFDE4
-    ISAM_ERROR_LOG_FILE_SIZE_MISMATCH = 0xFFFFFDE3
-    ISAM_ERROR_CHECKPOINT_FILE_NOT_FOUND = 0xFFFFFDE2
-    ISAM_ERROR_REQUIRED_LOG_FILES_MISSING = 0xFFFFFDE1
-    ISAM_ERROR_SOFT_RECOVERY_ON_BACKUP_DATABASE = 0xFFFFFDE0
-    ISAM_ERROR_LOG_FILE_SIZE_MISMATCH_DATABASES_CONSISTENT = 0xFFFFFDDF
-    ISAM_ERROR_LOG_SECTOR_SIZE_MISMATCH = 0xFFFFFDDE
-    ISAM_ERROR_LOG_SECTOR_SIZE_MISMATCH_DATABASES_CONSISTENT = 0xFFFFFDDD
-    ISAM_ERROR_LOG_SEQUENCE_END_DATABASES_CONSISTENT = 0xFFFFFDDC
-    ISAM_ERROR_STREAMING_DATA_NOT_LOGGED = 0xFFFFFDDB
-    ISAM_ERROR_DATABASE_DIRTY_SHUTDOWN = 0xFFFFFDDA
-    ISAM_ERROR_CONSISTENT_TIME_MISMATCH = 0xFFFFFDD9
-    ISAM_ERROR_DATABASE_PATCH_FILE_MISMATCH = 0xFFFFFDD8
-    ISAM_ERROR_ENDING_RESTORE_LOG_TOO_LOW = 0xFFFFFDD7
-    ISAM_ERROR_STARTING_RESTORE_LOG_TOO_HIGH = 0xFFFFFDD6
-    ISAM_ERROR_GIVEN_LOG_FILE_HAS_BAD_SIGNATURE = 0xFFFFFDD5
-    ISAM_ERROR_GIVEN_LOG_FILE_IS_NOT_CONTIGUOUS = 0xFFFFFDD4
-    ISAM_ERROR_MISSING_RESTORE_LOG_FILES = 0xFFFFFDD3
-    ISAM_ERROR_MISSING_FULL_BACKUP = 0xFFFFFDD0
-    ISAM_ERROR_BAD_BACKUP_DATABASE_SIZE = 0xFFFFFDCF
-    ISAM_ERROR_DATABASE_ALREADY_UPGRADED = 0xFFFFFDCE
-    ISAM_ERROR_DATABASE_INCOMPLETE_UPGRADE = 0xFFFFFDCD
-    ISAM_ERROR_MISSING_CURRENT_LOG_FILES = 0xFFFFFDCB
-    ISAM_ERROR_DB_TIME_TOO_OLD = 0xFFFFFDCA
-    ISAM_ERROR_DB_TIME_TOO_NEW = 0xFFFFFDC9
-    ISAM_ERROR_MISSING_FILE_TO_BACKUP = 0xFFFFFDC7
-    ISAM_ERROR_LOG_TORN_WRITE_DURING_HARD_RESTORE = 0xFFFFFDC6
-    ISAM_ERROR_LOG_TORN_WRITE_DURING_HARD_RECOVERY = 0xFFFFFDC5
-    ISAM_ERROR_LOG_CORRUPT_DURING_HARD_RESTORE = 0xFFFFFDC3
-    ISAM_ERROR_LOG_CORRUPT_DURING_HARD_RECOVERY = 0xFFFFFDC2
-    ISAM_ERROR_MUST_DISABLE_LOGGING_FOR_DB_UPGRADE = 0xFFFFFDC1
-    ISAM_ERROR_BAD_RESTORE_TARGET_INSTANCE = 0xFFFFFDBF
-    ISAM_ERROR_RECOVERED_WITHOUT_UNDO = 0xFFFFFDBD
-    ISAM_ERROR_DATABASES_NOT_FROM_SAME_SNAPSHOT = 0xFFFFFDBC
-    ISAM_ERROR_SOFT_RECOVERY_ON_SNAPSHOT = 0xFFFFFDBB
-    ISAM_ERROR_COMMITTED_LOG_FILES_MISSING = 0xFFFFFDBA
-    ISAM_ERROR_COMMITTED_LOG_FILES_CORRUPT = 0xFFFFFDB6
-    ISAM_ERROR_UNICODE_TRANSLATION_BUFFER_TOO_SMALL = 0xFFFFFDA7
-    ISAM_ERROR_UNICODE_TRANSLATION_FAIL = 0xFFFFFDA6
-    ISAM_ERROR_UNICODE_NORMALIZATION_NOT_SUPPORTED = 0xFFFFFDA5
-    ISAM_ERROR_EXISTING_LOG_FILE_HAS_BAD_SIGNATURE = 0xFFFFFD9E
-    ISAM_ERROR_EXISTING_LOG_FILE_IS_NOT_CONTIGUOUS = 0xFFFFFD9D
-    ISAM_ERROR_LOG_READ_VERIFY_FAILURE = 0xFFFFFD9C
-    ISAM_ERROR_SLV_READ_VERIFY_FAILURE = 0xFFFFFD9B
-    ISAM_ERROR_CHECKPOINT_DEPTH_TOO_DEEP = 0xFFFFFD9A
-    ISAM_ERROR_RESTORE_OF_NON_BACKUP_DATABASE = 0xFFFFFD99
-    ISAM_ERROR_INVALID_GRBIT = 0xFFFFFC7C
-    ISAM_ERROR_TERM_IN_PROGRESS = 0xFFFFFC18
-    ISAM_ERROR_FEATURE_NOT_AVAILABLE = 0xFFFFFC17
-    ISAM_ERROR_INVALID_NAME = 0xFFFFFC16
-    ISAM_ERROR_INVALID_PARAMETER = 0xFFFFFC15
-    ISAM_ERROR_DATABASE_FILE_READ_ONLY = 0xFFFFFC10
-    ISAM_ERROR_INVALID_DATABASE_ID = 0xFFFFFC0E
-    ISAM_ERROR_OUT_OF_MEMORY = 0xFFFFFC0D
-    ISAM_ERROR_OUT_OF_DATABASE_SPACE = 0xFFFFFC0C
-    ISAM_ERROR_OUT_OF_CURSORS = 0xFFFFFC0B
-    ISAM_ERROR_OUT_OF_BUFFERS = 0xFFFFFC0A
-    ISAM_ERROR_TOO_MANY_INDEXES = 0xFFFFFC09
-    ISAM_ERROR_TOO_MANY_KEYS = 0xFFFFFC08
-    ISAM_ERROR_RECORD_DELETED = 0xFFFFFC07
-    ISAM_ERROR_READ_VERIFY_FAILURE = 0xFFFFFC06
-    ISAM_ERROR_PAGE_NOT_INITIALIZED = 0xFFFFFC05
-    ISAM_ERROR_OUT_OF_FILE_HANDLES = 0xFFFFFC04
-    ISAM_ERROR_DISK_IO = 0xFFFFFC02
-    ISAM_ERROR_INVALID_PATH = 0xFFFFFC01
-    ISAM_ERROR_INVALID_SYSTEM_PATH = 0xFFFFFC00
-    ISAM_ERROR_INVALID_LOG_DIRECTORY = 0xFFFFFBFF
-    ISAM_ERROR_RECORD_TOO_BIG = 0xFFFFFBFE
-    ISAM_ERROR_TOO_MANY_OPEN_DATABASES = 0xFFFFFBFD
-    ISAM_ERROR_INVALID_DATABASE = 0xFFFFFBFC
-    ISAM_ERROR_NOT_INITIALIZED = 0xFFFFFBFB
-    ISAM_ERROR_ALREADY_INITIALIZED = 0xFFFFFBFA
-    ISAM_ERROR_INIT_IN_PROGRESS = 0xFFFFFBF9
-    ISAM_ERROR_FILE_ACCESS_DENIED = 0xFFFFFBF8
-    ISAM_ERROR_BUFFER_TOO_SMALL = 0xFFFFFBF2
-    ISAM_ERROR_TOO_MANY_COLUMNS = 0xFFFFFBF0
-    ISAM_ERROR_CONTAINER_NOT_EMPTY = 0xFFFFFBED
-    ISAM_ERROR_INVALID_FILENAME = 0xFFFFFBEC
-    ISAM_ERROR_INVALID_BOOKMARK = 0xFFFFFBEB
-    ISAM_ERROR_COLUMN_IN_USE = 0xFFFFFBEA
-    ISAM_ERROR_INVALID_BUFFER_SIZE = 0xFFFFFBE9
-    ISAM_ERROR_COLUMN_NOT_UPDATABLE = 0xFFFFFBE8
-    ISAM_ERROR_INDEX_IN_USE = 0xFFFFFBE5
-    ISAM_ERROR_LINK_NOT_SUPPORTED = 0xFFFFFBE4
-    ISAM_ERROR_NULL_KEY_DISALLOWED = 0xFFFFFBE3
-    ISAM_ERROR_NOT_IN_TRANSACTION = 0xFFFFFBE2
-    ISAM_ERROR_TOO_MANY_ACTIVE_USERS = 0xFFFFFBDD
-    ISAM_ERROR_INVALID_COUNTRY = 0xFFFFFBDB
-    ISAM_ERROR_INVALID_LANGUAGE_ID = 0xFFFFFBDA
-    ISAM_ERROR_INVALID_CODE_PAGE = 0xFFFFFBD9
-    ISAM_ERROR_INVALID_LC_MAP_STRING_FLAGS = 0xFFFFFBD8
-    ISAM_ERROR_VERSION_STORE_ENTRY_TOO_BIG = 0xFFFFFBD7
-    ISAM_ERROR_VERSION_STORE_OUT_OF_MEMORY_AND_CLEANUP_TIMED_OUT = 0xFFFFFBD6
-    ISAM_ERROR_VERSION_STORE_OUT_OF_MEMORY = 0xFFFFFBD3
-    ISAM_ERROR_CANNOT_INDEX = 0xFFFFFBD1
-    ISAM_ERROR_RECORD_NOT_DELETED = 0xFFFFFBD0
-    ISAM_ERROR_TOO_MANY_MEMPOOL_ENTRIES = 0xFFFFFBCF
-    ISAM_ERROR_OUT_OF_OBJECT_I_DS = 0xFFFFFBCE
-    ISAM_ERROR_OUT_OF_LONG_VALUE_I_DS = 0xFFFFFBCD
-    ISAM_ERROR_OUT_OF_AUTOINCREMENT_VALUES = 0xFFFFFBCC
-    ISAM_ERROR_OUT_OF_DBTIME_VALUES = 0xFFFFFBCB
-    ISAM_ERROR_OUT_OF_SEQUENTIAL_INDEX_VALUES = 0xFFFFFBCA
-    ISAM_ERROR_RUNNING_IN_ONE_INSTANCE_MODE = 0xFFFFFBC8
-    ISAM_ERROR_RUNNING_IN_MULTI_INSTANCE_MODE = 0xFFFFFBC7
-    ISAM_ERROR_SYSTEM_PARAMS_ALREADY_SET = 0xFFFFFBC6
-    ISAM_ERROR_SYSTEM_PATH_IN_USE = 0xFFFFFBC5
-    ISAM_ERROR_LOG_FILE_PATH_IN_USE = 0xFFFFFBC4
-    ISAM_ERROR_TEMP_PATH_IN_USE = 0xFFFFFBC3
-    ISAM_ERROR_INSTANCE_NAME_IN_USE = 0xFFFFFBC2
-    ISAM_ERROR_INSTANCE_UNAVAILABLE = 0xFFFFFBBE
-    ISAM_ERROR_DATABASE_UNAVAILABLE = 0xFFFFFBBD
-    ISAM_ERROR_INSTANCE_UNAVAILABLE_DUE_TO_FATAL_LOG_DISK_FULL = 0xFFFFFBBC
-    ISAM_ERROR_OUT_OF_SESSIONS = 0xFFFFFBB3
-    ISAM_ERROR_WRITE_CONFLICT = 0xFFFFFBB2
-    ISAM_ERROR_TRANS_TOO_DEEP = 0xFFFFFBB1
-    ISAM_ERROR_INVALID_SESID = 0xFFFFFBB0
-    ISAM_ERROR_WRITE_CONFLICT_PRIMARY_INDEX = 0xFFFFFBAF
-    ISAM_ERROR_IN_TRANSACTION = 0xFFFFFBAC
-    ISAM_ERROR_ROLLBACK_REQUIRED = 0xFFFFFBAB
-    ISAM_ERROR_TRANS_READ_ONLY = 0xFFFFFBAA
-    ISAM_ERROR_SESSION_WRITE_CONFLICT = 0xFFFFFBA9
-    ISAM_ERROR_RECORD_TOO_BIG_FOR_BACKWARD_COMPATIBILITY = 0xFFFFFBA8
-    ISAM_ERROR_CANNOT_MATERIALIZE_FORWARD_ONLY_SORT = 0xFFFFFBA7
-    ISAM_ERROR_SESID_TABLE_ID_MISMATCH = 0xFFFFFBA6
-    ISAM_ERROR_INVALID_INSTANCE = 0xFFFFFBA5
-    ISAM_ERROR_DATABASE_DUPLICATE = 0xFFFFFB4F
-    ISAM_ERROR_DATABASE_IN_USE = 0xFFFFFB4E
-    ISAM_ERROR_DATABASE_NOT_FOUND = 0xFFFFFB4D
-    ISAM_ERROR_DATABASE_INVALID_NAME = 0xFFFFFB4C
-    ISAM_ERROR_DATABASE_INVALID_PAGES = 0xFFFFFB4B
-    ISAM_ERROR_DATABASE_CORRUPTED = 0xFFFFFB4A
-    ISAM_ERROR_DATABASE_LOCKED = 0xFFFFFB49
-    ISAM_ERROR_CANNOT_DISABLE_VERSIONING = 0xFFFFFB48
-    ISAM_ERROR_INVALID_DATABASE_VERSION = 0xFFFFFB47
-    ISAM_ERROR_DATABASE200_FORMAT = 0xFFFFFB46
-    ISAM_ERROR_DATABASE400_FORMAT = 0xFFFFFB45
-    ISAM_ERROR_DATABASE500_FORMAT = 0xFFFFFB44
-    ISAM_ERROR_PAGE_SIZE_MISMATCH = 0xFFFFFB43
-    ISAM_ERROR_TOO_MANY_INSTANCES = 0xFFFFFB42
-    ISAM_ERROR_DATABASE_SHARING_VIOLATION = 0xFFFFFB41
-    ISAM_ERROR_ATTACHED_DATABASE_MISMATCH = 0xFFFFFB40
-    ISAM_ERROR_DATABASE_INVALID_PATH = 0xFFFFFB3F
-    ISAM_ERROR_DATABASE_ID_IN_USE = 0xFFFFFB3E
-    ISAM_ERROR_FORCE_DETACH_NOT_ALLOWED = 0xFFFFFB3D
-    ISAM_ERROR_CATALOG_CORRUPTED = 0xFFFFFB3C
-    ISAM_ERROR_PARTIALLY_ATTACHED_DB = 0xFFFFFB3B
-    ISAM_ERROR_DATABASE_SIGN_IN_USE = 0xFFFFFB3A
-    ISAM_ERROR_DATABASE_CORRUPTED_NO_REPAIR = 0xFFFFFB38
-    ISAM_ERROR_INVALID_CREATE_DB_VERSION = 0xFFFFFB37
-    ISAM_ERROR_TABLE_LOCKED = 0xFFFFFAEA
-    ISAM_ERROR_TABLE_DUPLICATE = 0xFFFFFAE9
-    ISAM_ERROR_TABLE_IN_USE = 0xFFFFFAE8
-    ISAM_ERROR_OBJECT_NOT_FOUND = 0xFFFFFAE7
-    ISAM_ERROR_DENSITY_INVALID = 0xFFFFFAE5
-    ISAM_ERROR_TABLE_NOT_EMPTY = 0xFFFFFAE4
-    ISAM_ERROR_INVALID_TABLE_ID = 0xFFFFFAE2
-    ISAM_ERROR_TOO_MANY_OPEN_TABLES = 0xFFFFFAE1
-    ISAM_ERROR_ILLEGAL_OPERATION = 0xFFFFFAE0
-    ISAM_ERROR_TOO_MANY_OPEN_TABLES_AND_CLEANUP_TIMED_OUT = 0xFFFFFADF
-    ISAM_ERROR_OBJECT_DUPLICATE = 0xFFFFFADE
-    ISAM_ERROR_INVALID_OBJECT = 0xFFFFFADC
-    ISAM_ERROR_CANNOT_DELETE_TEMP_TABLE = 0xFFFFFADB
-    ISAM_ERROR_CANNOT_DELETE_SYSTEM_TABLE = 0xFFFFFADA
-    ISAM_ERROR_CANNOT_DELETE_TEMPLATE_TABLE = 0xFFFFFAD9
-    ISAM_ERROR_EXCLUSIVE_TABLE_LOCK_REQUIRED = 0xFFFFFAD6
-    ISAM_ERROR_FIXED_DDL = 0xFFFFFAD5
-    ISAM_ERROR_FIXED_INHERITED_DDL = 0xFFFFFAD4
-    ISAM_ERROR_CANNOT_NEST_DDL = 0xFFFFFAD3
-    ISAM_ERROR_DDL_NOT_INHERITABLE = 0xFFFFFAD2
-    ISAM_ERROR_INVALID_SETTINGS = 0xFFFFFAD0
-    ISAM_ERROR_CLIENT_REQUEST_TO_STOP_JET_SERVICE = 0xFFFFFACF
-    ISAM_ERROR_CANNOT_ADD_FIXED_VAR_COLUMN_TO_DERIVED_TABLE = 0xFFFFFACE
-    ISAM_ERROR_INDEX_CANT_BUILD = 0xFFFFFA87
-    ISAM_ERROR_INDEX_HAS_PRIMARY = 0xFFFFFA86
-    ISAM_ERROR_INDEX_DUPLICATE = 0xFFFFFA85
-    ISAM_ERROR_INDEX_NOT_FOUND = 0xFFFFFA84
-    ISAM_ERROR_INDEX_MUST_STAY = 0xFFFFFA83
-    ISAM_ERROR_INDEX_INVALID_DEF = 0xFFFFFA82
-    ISAM_ERROR_INVALID_CREATE_INDEX = 0xFFFFFA7F
-    ISAM_ERROR_TOO_MANY_OPEN_INDEXES = 0xFFFFFA7E
-    ISAM_ERROR_MULTI_VALUED_INDEX_VIOLATION = 0xFFFFFA7D
-    ISAM_ERROR_INDEX_BUILD_CORRUPTED = 0xFFFFFA7C
-    ISAM_ERROR_PRIMARY_INDEX_CORRUPTED = 0xFFFFFA7B
-    ISAM_ERROR_SECONDARY_INDEX_CORRUPTED = 0xFFFFFA7A
-    ISAM_ERROR_INVALID_INDEX_ID = 0xFFFFFA78
-    ISAM_ERROR_INDEX_TUPLES_SECONDARY_INDEX_ONLY = 0xFFFFFA6A
-    ISAM_ERROR_INDEX_TUPLES_TOO_MANY_COLUMNS = 0xFFFFFA69
-    ISAM_ERROR_INDEX_TUPLES_NON_UNIQUE_ONLY = 0xFFFFFA68
-    ISAM_ERROR_INDEX_TUPLES_TEXT_BINARY_COLUMNS_ONLY = 0xFFFFFA67
-    ISAM_ERROR_INDEX_TUPLES_VAR_SEG_MAC_NOT_ALLOWED = 0xFFFFFA66
-    ISAM_ERROR_INDEX_TUPLES_INVALID_LIMITS = 0xFFFFFA65
-    ISAM_ERROR_INDEX_TUPLES_CANNOT_RETRIEVE_FROM_INDEX = 0xFFFFFA64
-    ISAM_ERROR_INDEX_TUPLES_KEY_TOO_SMALL = 0xFFFFFA63
-    ISAM_ERROR_COLUMN_LONG = 0xFFFFFA23
-    ISAM_ERROR_COLUMN_NO_CHUNK = 0xFFFFFA22
-    ISAM_ERROR_COLUMN_DOES_NOT_FIT = 0xFFFFFA21
-    ISAM_ERROR_NULL_INVALID = 0xFFFFFA20
-    ISAM_ERROR_COLUMN_INDEXED = 0xFFFFFA1F
-    ISAM_ERROR_COLUMN_TOO_BIG = 0xFFFFFA1E
-    ISAM_ERROR_COLUMN_NOT_FOUND = 0xFFFFFA1D
-    ISAM_ERROR_COLUMN_DUPLICATE = 0xFFFFFA1C
-    ISAM_ERROR_MULTI_VALUED_COLUMN_MUST_BE_TAGGED = 0xFFFFFA1B
-    ISAM_ERROR_COLUMN_REDUNDANT = 0xFFFFFA1A
-    ISAM_ERROR_INVALID_COLUMN_TYPE = 0xFFFFFA19
-    ISAM_ERROR_TAGGED_NOT_NULL = 0xFFFFFA16
-    ISAM_ERROR_NO_CURRENT_INDEX = 0xFFFFFA15
-    ISAM_ERROR_KEY_IS_MADE = 0xFFFFFA14
-    ISAM_ERROR_BAD_COLUMN_ID = 0xFFFFFA13
-    ISAM_ERROR_BAD_ITAG_SEQUENCE = 0xFFFFFA12
-    ISAM_ERROR_COLUMN_IN_RELATIONSHIP = 0xFFFFFA11
-    ISAM_ERROR_CANNOT_BE_TAGGED = 0xFFFFFA0F
-    ISAM_ERROR_DEFAULT_VALUE_TOO_BIG = 0xFFFFFA0C
-    ISAM_ERROR_MULTI_VALUED_DUPLICATE = 0xFFFFFA0B
-    ISAM_ERROR_LV_CORRUPTED = 0xFFFFFA0A
-    ISAM_ERROR_MULTI_VALUED_DUPLICATE_AFTER_TRUNCATION = 0xFFFFFA08
-    ISAM_ERROR_DERIVED_COLUMN_CORRUPTION = 0xFFFFFA07
-    ISAM_ERROR_INVALID_PLACEHOLDER_COLUMN = 0xFFFFFA06
-    ISAM_ERROR_RECORD_NOT_FOUND = 0xFFFFF9BF
-    ISAM_ERROR_RECORD_NO_COPY = 0xFFFFF9BE
-    ISAM_ERROR_NO_CURRENT_RECORD = 0xFFFFF9BD
-    ISAM_ERROR_RECORD_PRIMARY_CHANGED = 0xFFFFF9BC
-    ISAM_ERROR_KEY_DUPLICATE = 0xFFFFF9BB
-    ISAM_ERROR_ALREADY_PREPARED = 0xFFFFF9B9
-    ISAM_ERROR_KEY_NOT_MADE = 0xFFFFF9B8
-    ISAM_ERROR_UPDATE_NOT_PREPARED = 0xFFFFF9B7
-    ISAM_ERROR_DATA_HAS_CHANGED = 0xFFFFF9B5
-    ISAM_ERROR_LANGUAGE_NOT_SUPPORTED = 0xFFFFF9AD
-    ISAM_ERROR_TOO_MANY_SORTS = 0xFFFFF95B
-    ISAM_ERROR_INVALID_ON_SORT = 0xFFFFF95A
-    ISAM_ERROR_TEMP_FILE_OPEN_ERROR = 0xFFFFF8F5
-    ISAM_ERROR_TOO_MANY_ATTACHED_DATABASES = 0xFFFFF8F3
-    ISAM_ERROR_DISK_FULL = 0xFFFFF8F0
-    ISAM_ERROR_PERMISSION_DENIED = 0xFFFFF8EF
-    ISAM_ERROR_FILE_NOT_FOUND = 0xFFFFF8ED
-    ISAM_ERROR_FILE_INVALID_TYPE = 0xFFFFF8EC
-    ISAM_ERROR_AFTER_INITIALIZATION = 0xFFFFF8C6
-    ISAM_ERROR_LOG_CORRUPTED = 0xFFFFF8C4
-    ISAM_ERROR_INVALID_OPERATION = 0xFFFFF88E
-    ISAM_ERROR_ACCESS_DENIED = 0xFFFFF88D
-    ISAM_ERROR_TOO_MANY_SPLITS = 0xFFFFF88B
-    ISAM_ERROR_SESSION_SHARING_VIOLATION = 0xFFFFF88A
-    ISAM_ERROR_ENTRY_POINT_NOT_FOUND = 0xFFFFF889
-    ISAM_ERROR_SESSION_CONTEXT_ALREADY_SET = 0xFFFFF888
-    ISAM_ERROR_SESSION_CONTEXT_NOT_SET_BY_THIS_THREAD = 0xFFFFF887
-    ISAM_ERROR_SESSION_IN_USE = 0xFFFFF886
-    ISAM_ERROR_RECORD_FORMAT_CONVERSION_FAILED = 0xFFFFF885
-    ISAM_ERROR_ONE_DATABASE_PER_SESSION = 0xFFFFF884
-    ISAM_ERROR_ROLLBACK_ERROR = 0xFFFFF883
-    ISAM_ERROR_CALLBACK_FAILED = 0xFFFFF7CB
-    ISAM_ERROR_CALLBACK_NOT_RESOLVED = 0xFFFFF7CA
-    ISAM_ERROR_OS_SNAPSHOT_INVALID_SEQUENCE = 0xFFFFF69F
-    ISAM_ERROR_OS_SNAPSHOT_TIME_OUT = 0xFFFFF69E
-    ISAM_ERROR_OS_SNAPSHOT_NOT_ALLOWED = 0xFFFFF69D
-    ISAM_ERROR_OS_SNAPSHOT_INVALID_SNAP_ID = 0xFFFFF69C
-    ISAM_ERROR_LS_CALLBACK_NOT_SPECIFIED = 0xFFFFF448
-    ISAM_ERROR_LS_ALREADY_SET = 0xFFFFF447
-    ISAM_ERROR_LS_NOT_SET = 0xFFFFF446
-    ISAM_ERROR_FILE_IO_SPARSE = 0xFFFFF060
-    ISAM_ERROR_FILE_IO_BEYOND_EOF = 0xFFFFF05F
-    ISAM_ERROR_FILE_COMPRESSED = 0xFFFFF05B
-
-
-
-class Gender(enum.Enum):
-    # Seems rather binary, which is less than ideal. We are directly using the
-    # terms used by the documentation.
-    UNSPECIFIED = 0x0000
-    FEMALE = 0x0001
-    MALE = 0x0002
-
-
-
-class IconIndex(enum.Enum):
-    @classmethod
-    def tryMake(cls, value : int) -> Union['IconIndex', int]:
-        """
-        Try to make an instance, returning the value on failure.
-        """
-        try:
-            return cls(value)
-        except ValueError:
-            return value
-
-    UNSPECIFIED = 0xFFFFFFFF
-    SINGLE_INSTANCE_APPOINTMENT = 0x00000400
-    RECURRING_APPOINTMENT = 0x00000401
-    SINGLE_INSTANCE_MEETING = 0x00000402
-    RECURRING_MEETING = 0x00000403
-    MEETING_REQUEST_UPDATE = 0x00000404
-    ACCEPT_MEETING_REQUEST = 0x00000405
-    DECLINE_MEETING_REQUEST = 0x00000406
-    TENTATIVELY_ACCEPT_MEETING_REQUEST = 0x00000407
-    MEETING_CANCELLATION = 0x00000408
-    MEETING_UPDATE_INFORMATIONAL = 0x00000409
-    FORWARD_NOTIFICATION = 0x0000040B
-
-
-
-class Importance(enum.Enum):
-    LOW = 0
-    MEDIUM = 1
-    HIGH = 2
-
-
-
-class Intelligence(enum.Enum):
-    ERROR = -1
-    DUMB = 0
-    SMART = 1
-
-
-
-class MacintoshEncoding(enum.Enum):
-    """
-    The encoding to use for Macintosh-specific data attachments.
-    """
-    BIN_HEX = 0
-    UUENCODE = 1
-    APPLE_SINGLE = 2
-    APPLE_DOUBLE = 3
-
-
-
-class MeetingObjectChange(enum.Enum):
-    """
-    Indicates a property that has changed on a meeting object.
-
-    START: The start has changed.
-    END: The end has changed.
-    RECUR: The recurrence pattern has changed.
-    LOCATION: The location has changed.
-    SUBJECT: The subject has changed.
-    REQUIRED_ATTENDEE: One or more required attendees were added.
-    OPTIONAL_ATTENDEE: One or more optional attendees were added.
-    BODY: The body was modified.
-    RESPONSE: The responseRequested or replyRequested property has changed.
-    ALLOW_PROPOSE: The appointmentNotAllowPropose property has changed.
-    """
-    @classmethod
-    def fromBits(cls, value : int) -> Set['MeetingObjectChange']:
-        """
-        Takes an int and returns a set of the changes.
-        """
-        changes = set()
-        for x in range(32):
-            if x in (8, 11) or (12 < x < 31):
-                continue
-            bit = value & (1 << x)
-            if bit:
-                if x in (12, 31):
-                    raise ValueError('Reserved bit was set.')
-                changes.add(cls(bit))
-
-        return changes
-
-    START = 0b1
-    END = 0b10
-    RECUR = 0b100
-    LOCATION = 0b1000
-    SUBJECT = 0b10000
-    REQUIRED_ATTENDEE = 0b100000
-    OPTIONAL_ATTENDEE = 0b1000000
-    BODY = 0b10000000
-    RESPONSE = 0b1000000000
-    ALLOW_PROPOSE = 0b10000000000
-    DEPRECATED = 0b100000000000
-
-
-
-class MeetingRecipientType(enum.Enum):
-    ORGANIZER = 0x01
-    SENDABLE_REQUIRED_ATTENDEE = 0x01
-    SENDABLE_OPTIONAL_ATTENDEE = 0x02
-    SENDABLE_RESOURCE_OBJECT = 0x03
-
-
-
-class MeetingType(enum.Enum):
-    """
-    The type of Meeting Request object of Meeting Update object.
-
-    EMPTY: Unspecified.
-    REQUEST: The meeting request is the initial request.
-    FULL: Attendees were added, the meeting was cancelled and the organizer is
-        uncancelling it, and or the start, end, or recurrance property was
-        changed.
-    INFO: An informational update was made to the meeting and it is not one of
-        the conditions for FULL.
-    OUT_OF_DATE: A newer Meeting Request object or MeetingUpdate object was
-        received after this one.
-    DELEGATOR_COPY: Set on the delegator's copy when a delegate will handle
-        meeting-related objects.
-    """
-    EMPTY = 0x00000000
-    REQUEST = 0x00000001
-    FULL = 0x00010000
-    INFO = 0x00020000
-    OUT_OF_DATE = 0x00080000
-    DELEGATOR_COPY = 0x00100000
-
-
-
-class MessageFormat(enum.Enum):
-    TNEF = 0
-    MIME = 1
-
-
-
-class MessageType(enum.Enum):
-    PRIVATE_FOLDER = 0x0001
-    PUBLIC_FOLDER = 0x0003
-    MAPPED_PUBLIC_FOLDER = 0x0005
-    PRIVATE_MESSAGE = 0x0007
-    PUBLIC_MESSAGE = 0x0009
-    MAPPED_PUBLIC_MESSAGE = 0x000B
-    PUBLIC_NEWSGROUP_FOLDER = 0x000C
-
-
-
-class NamedPropertyType(enum.Enum):
-    NUMERICAL_NAMED = 0
-    STRING_NAMED = 1
-
-
-
-class OORBodyFormat(enum.Enum):
-    """
-    The body format for One Off Recipients.
-    """
-    TEXT_ONLY = 0b0011
-    HTML_ONLY = 0b0111
-    TEXT_AND_HTML = 0b1011
-    # This one isn't actually listed in the documentation, but I've seen it and
-    # this is my best guess for what a format of `0` is meant to mean. This will
-    # also prevent the code from failing on a 0 format.
-    UNSPECIFIED = 0b0000
-
-
-
-class PostalAddressID(enum.Enum):
-    UNSPECIFIED = 0x00000000
-    HOME = 0x00000001
-    WORK = 0x00000002
-    OTHER = 0x00000003
-
-
-
-class Priority(enum.Enum):
-    URGENT = 0x00000001
-    NORMAL = 0x00000000
-    NOT_URGENT = 0xFFFFFFFF
-
-
-
-class PropertiesType(enum.Enum):
-    """
-    The type of the properties instance.
-    """
-    MESSAGE = 0
-    MESSAGE_EMBED = 1
-    ATTACHMENT = 2
-    RECIPIENT = 3
-
-
-
-class RecipientRowFlagType(enum.Enum):
-    NOTYPE = 0x0
-    X500DN = 0x1
-    MSMAIL = 0x2
-    SMTP = 0x3
-    FAX = 0x4
-    PROFESSIONALOFFICESYSTEM = 0x5
-    PERSONALDESTRIBUTIONLIST1 = 0x6
-    PERSONALDESTRIBUTIONLIST2 = 0x7
-
-
-
-class RecipientType(enum.Enum):
-    """
-    The type of recipient.
-    """
-    SENDER = 0
-    TO = 1
-    CC = 2
-    BCC = 3
-
-
-
-class RecurCalendarType(enum.Enum):
-    DEFAULT = 0x0000
-    CAL_GREGORIAN = 0x0001
-    CAL_GREGORIAN_US = 0x0002
-    CAL_JAPAN = 0x0003
-    CAL_TAIWAN = 0x0004
-    CAL_KOREA = 0x0005
-    CAL_HIJRI = 0x0006
-    CAL_THAI = 0x0007
-    CAL_HEBREW = 0x0008
-    CAL_GREGORIAN_ME_FRENCH = 0x0009
-    CAL_GREGORIAN_ARABIC = 0x000A
-    CAL_GREGORIAN_XLIT_ENGLISH = 0x000B
-    CAL_GREGORIAN_XLIT_FRENCH = 0x000C
-    CAL_LUNAR_JAPANESE = 0x000E
-    CAL_CHINESE_LUNAR = 0x000F
-    CAL_SAKA = 0x0010
-    CAL_LUNAR_ETO_CHN = 0x0011
-    CAL_LUNAR_ETO_KOR = 0x0012
-    CAL_LUNAR_ROKUYOU = 0x0013
-    CAL_LUNAR_KOREAN = 0x0014
-    CAL_UMALQURA = 0x0017
-
-
-
-class RecurDOW(enum.Enum):
-    SUNDAY = 0x00000000
-    MONDAY = 0x00000001
-    TUESDAY = 0x00000002
-    WEDNESDAY = 0x00000003
-    THURSDAY = 0x00000004
-    FRIDAY = 0x00000005
-    SATURDAY = 0x00000006
-
-
-
-class RecurEndType(enum.Enum):
-    @classmethod
-    def fromInt(cls, value) -> 'RecurEndType':
-        """
-        Some enum values CAN be created from more than one int, so handle that.
-        """
-        return cls(0x00002023) if value == 0xFFFFFFFF else cls(value)
-
-    END_AFTER_DATE = 0x00002021
-    END_AFTER_N_OCCURRENCES = 0x00002022
-    NEVER_END = 0x00002023
-
-
-class RecurFrequency(enum.Enum):
-    """
-    See [MS-OXOCAL] for details.
-    """
-    DAILY = 0x200A
-    WEEKLY = 0x200B
-    MONTHLY = 0x200C
-    YEARLY = 0x200D
-
-
-
-class RecurMonthNthWeek(enum.Enum):
-    FIRST = 0x00000001
-    SECOND = 0x00000002
-    THIRD = 0x00000003
-    FOURTH = 0x00000004
-    LAST = 0x00000005
-
-
-
-class RecurPatternTypeSpecificWeekday(enum.Enum):
-    """
-    See [MS-OXOCAL] for details.
-    """
-    @classmethod
-    def fromBits(cls, value : int) -> Set['RecurPatternTypeSpecificWeekday']:
-        """
-        Takes an int and returns a set of the weekdays.
-        """
-        return {cls(1 << x) for x in range(1, 8) if (value & (1 << x))}
-
-    SATURDAY = 0b10
-    FRIDAY = 0b100
-    THURSDAY = 0b1000
-    WEDNESDAY = 0b10000
-    TUESDAY = 0b100000
-    MONDAY = 0b1000000
-    SUNDAY = 0b10000000
-
-
-
-class RecurPatternType(enum.Enum):
-    """
-    See [MS-OXOCAL] for details.
-    """
-    DAY = 0x0000
-    WEEK = 0x0001
-    MONTH = 0x0002
-    MONTH_NTH = 0x0003
-    MONTH_END = 0x0004
-    HJ_MONTH = 0x000A
-    HJ_MONTH_NTH = 0x000B
-    HJ_MONTH_END = 0x000C
-
-
-
-class ResponseStatus(enum.Enum):
-    """
-    The response status of an attendee.
-
-    NONE: No response is required for this object.
-    ORGANIZED: This Meeting object belongs to the organizer.
-    TENTATIVE: The attendee has tentatively accepted.
-    ACCEPTED: The attendee has accepted.
-    DECLINED: The attendee has declined.
-    NOT_RESPONDED: The attendee has not yet responded.
-    """
-    NONE = 0x00000000
-    ORGANIZED = 0x00000001
-    TENTATIVE = 0x00000002
-    ACCEPTED = 0x00000003
-    DECLINED = 0x00000004
-    NOT_RESPONDED = 0x00000005
-
-
-
-class ResponseType(enum.Enum):
-    """
-    The type of response for a Meeting Response object.
-    """
-    ACCEPT = 'pos'
-    DECLINE = 'neg'
-    TENTATIVE = 'tent'
-
-
-
-class RuleActionType(enum.Enum):
-    OP_MOVE = 0x01
-    OP_COPY = 0x02
-    OP_REPLY = 0x03
-    OP_OOF_REPLY = 0x04
-    OP_DEFER_ACTION = 0x05
-    OP_BOUNCE = 0x06
-    OP_FORWARD = 0x07
-    OP_DELEGATE = 0x08
-    OP_TAG = 0x09
-    OP_DELETE = 0x0A
-    OP_MARK_AS_READ = 0x0B
-
-
-
-class Sensitivity(enum.Enum):
-    NORMAL = 0
-    PERSONAL = 1
-    PRIVATE = 2
-    CONFIDENTIAL = 3
-
-
-
-class ServerProcessingAction(enum.Enum):
-    """
-    Actions taken on a meeting-related object.
-    """
-    @classmethod
-    def fromBits(cls, value : int) -> Set['ServerProcessingAction']:
-        """
-        Takes an int and returns a set of the weekdays.
-        """
-        return {cls(1 << x) for x in range(16) if (value & (1 << x))}
-
-    DELEGATOR_WANTS_COPY = 0x00000002
-    CREATED_ON_PRINCIPLE = 0x00000010
-    UPDATED_CAL_ITEM = 0x00000080
-    COPIED_OLD_PROPERTIES = 0x00000100
-    SEND_AUTO_RESPONSE = 0x00000400
-    REVIVED_EXCEPTION = 0x00000800
-    PROCESSED_MEETING_FORWARD_NOTIFICATION = 0x00001000
-
-
-
-class SideEffect(enum.Enum):
-    """
-    A flag for how a Message object is handled by the client in relation to
-    certain user interface actions.
-
-    OPEN_TO_DELETE: The client opens the Message object when deleting.
-    NO_FRAME: No UI is associated with the Message object.
-    COERCE_TO_INDEX: The client moves the Message object to the Inbox folder
-        when moving or copying to a Folder object with the PidTagContainerClass
-        property set to "IPF.Note".
-    OPEN_TO_COPY: The client opens the Message object when copying to another
-        folder.
-    OPEN_TO_MOVE: The client opens the Message object when moving to another
-        folder.
-    OPEN_FOR_CTX_MENU: The client opens the Message object when displaying
-        context-sensitive commands, such as a context menu, to the end user.
-    CANNOT_UNDO_DELETE: The client cannot undo a delete operation. Must not be
-        set unless the OPEN_TO_DELETE flag is set.
-    CANNOT_UNDO_COPY: The client cannot undo a copy operation. Must not be set
-        unless the OPEN_TO_COPY flag is set.
-    CANNOT_UNDO_MOVE: The client cannot undo a move operation. Must not be set
-        unless the OPEN_TO_MOVE flag is set.
-    HAS_SCRIPT: The Message object contains end-user script.
-    OPEN_TO_PERM_DELETE: The client opens the Message object to permanently
-        delete it.
-    """
-    @classmethod
-    def fromBits(cls, value : int) -> Set['SideEffect']:
-        """
-        Takes an int and returns a set of the side effects.
-        """
-        return {cls(1 << x) for x in range(15) if (value & (1 << x))}
-
-    OPEN_TO_DELETE = 0b1
-    NO_FRAME = 0b1000
-    COERCE_TO_INDEX = 0b10000
-    OPEN_TO_COPY = 0b100000
-    OPEN_TO_MOVE = 0b1000000
-    OPEN_FOR_CTX_MENU = 0b100000000
-    CANNOT_UNDO_DELETE = 0b10000000000
-    CANNOT_UNDO_COPY = 0b100000000000
-    CANNOT_UNDO_MOVE = 0b1000000000000
-    HAS_SCRIPT = 0b10000000000000
-    OPEN_TO_PERM_DELETE = 0b100000000000000
-
-
-
-class TaskAcceptance(enum.Enum):
-    """
-    The acceptance state of the task.
-    """
-    NOT_ASSIGNED = 0x00000000
-    UNKNOWN = 0x00000001
-    ACCEPTED = 0x00000002
-    REJECTED = 0x00000003
-
-
-
-class TaskHistory(enum.Enum):
-    """
-    The type of the last change to the Task object.
-    """
-    NONE = 0x00000000
-    ACCEPTED = 0x00000001
-    REJECTED = 0x00000002
-    OTHER = 0x00000003
-    DUE_DATE_CHANGED = 0x00000004
-    ASSIGNED = 0x00000005
-
-
-
-class TaskMode(enum.Enum):
-    """
-    The mode of the Task object used in task communication (PidLidTaskMode).
-
-    UNASSIGNED: The Task object is not assigned.
-    EMBEDDED_REQUEST: The Task object is embedded in a task request.
-    ACCEPTED: The Task object has been accepted by the task assignee.
-    REJECTED: The Task object was rejected by the task assignee.
-    EMBEDDED_UPDATE: The Task object is embedded in a task update.
-    SELF_ASSIGNED: The Task object was assigned to the task assigner
-        (self-delegation).
-    """
-    UNASSIGNED = 0
-    EMBEDDED_REQUEST = 1
-    ACCEPTED = 2
-    REJECTED = 3
-    EMBEDDED_UPDATE = 4
-    SELF_ASSIGNED = 5
-
-
-
-class TaskMultipleRecipients(enum.Enum):
-    @classmethod
-    def fromBits(cls, value : int) -> Set['TaskMultipleRecipients']:
-        """
-        Takes an int and returns a set of the flags.
-        """
-        return {cls(1 << x) for x in range(2) if (value & (1 << x))}
-
-    SENT = 0x00000001
-    RECEIVED = 0x00000002
-
-
-
-class TaskOwnership(enum.Enum):
-    """
-    The role of the current user relative to the Task object.
-
-    NOT_ASSIGNED: The Task object is not assigned.
-    ASSIGNERS_COPY: The Task object is the task assigner's copy of the Task
-        object.
-    ASSIGNEES_COPY: The Task object is the task assignee's copy of the Task
-        object.
-    """
-    NOT_ASSIGNED = 0x00000000
-    ASSIGNERS_COPY = 0x00000001
-    ASSIGNEES_COPY = 0x00000002
-
-
-
-class TaskRequestType(enum.Enum):
-    """
-    The type of task request.
-
-    REQUEST: A plain request.
-    ACCEPT: Task has been accepted.
-    DECLINE: Task has been declined.
-    UPDATE: Task has been updated.
-    """
-    @classmethod
-    def fromClassType(cls, classType : str) -> 'TaskRequestType':
-        """
-        Convert a class type string into a TaskRequestType.
-        """
-        classType = classType.lower()
-        if 'accept' in classType:
-            return cls(1)
-        if 'decline' in classType:
-            return cls(2)
-        if 'update' in classType:
-            return cls(3)
-        return cls(0)
-
-    REQUEST = 0
-    ACCEPT = 1
-    DECLINE = 2
-    UPDATE = 3
-
-
-
-class TaskState(enum.Enum):
-    """
-    NOT_ASSIGNED: The Task object is not assigned.
-    ASSIGNEES_COPY_ACCEPTED: The Task object is the task assignee's copy of an
-        assigned Task object.
-    ASSIGNERS_COPY_ACCEPTED: The Task object is the task assigner's copy of an
-        assigned Task object.
-    ASSIGNERS_COPY_REJECTED: The Task object is the task assigner's copy of a
-        rejected Task object.
-    EMBEDDED_REJECTION: This Task object was created to correspond to a Task
-        object that was embedded in a task rejection but could not be found
-        locally.
-    """
-    NOT_ASSIGNED = 0x00000001
-    ASSIGNEES_COPY_ACCEPTED = 0x00000002
-    ASSIGNERS_COPY_ACCEPTED = 0x00000003
-    ASSIGNERS_COPY_REJECTED = 0x00000004
-    EMBEDDED_REJECTION = 0x00000005
-
-
-
-class TaskStatus(enum.Enum):
-    """
-    The status of a task object (PidLidTaskStatus).
-
-    NOT_STARTED: The user has not started the task.
-    IN_PROGRESS: The users's work on the Task object is in progress.
-    COMPLETE: The user's work on the Task object is complete.
-    WAITING_ON_OTHER: The user is waiting on somebody else.
-    DEFERRED: The user has deferred work on the Task object.
-    """
-    NOT_STARTED = 0x00000000
-    IN_PROGRESS = 0x00000001
-    COMPLETE = 0x00000002
-    WAITING_ON_OTHER = 0x00000003
-    DEFERRED = 0x00000004
-
-
-
-class TZFlag(enum.Enum):
-    """
-    Flags for a TZRule object as defined in [MS-OXOCAL].
-
-    RECUR_CURRENT_TZREG: The rule is associated with a recurring series.
-    EFFECTIVE_TZREG: The rule is the effective rule.
-    """
-    @classmethod
-    def fromBits(cls, value : int) -> Set['TZFlag']:
-        """
-        Takes an int and returns a set of the flags.
-        """
-        return {cls(1 << x) for x in range(2) if (value & (1 << x))}
-
-    RECUR_CURRENT_TZREG = 0b1
-    EFFECTIVE_TZREG = 0b10
+__all__ = [
+    'AddressBookType', 'AppointmentAuxilaryFlag', 'AppointmentColor',
+    'AppointmentStateFlag', 'AttachErrorBehavior', 'AttachmentType',
+    'BCImageAlignment', 'BCImageSource', 'BCLabelFormat', 'BCTemplateID',
+    'BCTextFormat', 'BusyStatus', 'ClientIntentFlag', 'Color',
+    'ContactAddressIndex', 'ContactLinkState', 'DeencapType',
+    'DirectoryEntryType', 'DisplayType', 'ElectronicAddressProperties',
+    'EntryIDType', 'EntryIDTypeHex', 'ErrorCode', 'ErrorCodeType', 'Gender',
+    'IconIndex', 'Importance', 'Intelligence', 'MacintoshEncoding',
+    'MeetingObjectChange', 'MeetingRecipientType', 'MeetingType',
+    'MessageFormat', 'MessageType', 'NamedPropertyType', 'OORBodyFormat',
+    'PostalAddressID', 'Priority', 'PropertiesType', 'RecipientRowFlagType',
+    'RecipientType', 'RecurCalendarType', 'RecurDOW', 'RecurEndType',
+    'RecurFrequency', 'RecurMonthNthWeek', 'RecurPatternTypeSpecificWeekday',
+    'RecurPatternType', 'ResponseStatus', 'ResponseType', 'RuleActionType',
+    'Sensitivity', 'ServerProcessingAction', 'SideEffect', 'TaskAcceptance',
+    'TaskHistory', 'TaskMode', 'TaskMultipleRecipients', 'TaskOwnership',
+    'TaskRequestType', 'TaskState', 'TaskStatus', 'TZFlag',
+]
+
+
+import enum
+
+from typing import Set, Union
+
+
+class AddressBookType(enum.Enum):
+    """
+    The type of object that an address book entry ID represents. MUST be one of
+    these or it is invalid.
+    """
+    LOCAL_MAIL_USER = 0x000
+    DISTRIBUTION_LIST = 0x001
+    BULLETIN_BOARD_OR_PUBLIC_FOLDER = 0x002
+    AUTOMATED_MAILBOX = 0x003
+    ORGANIZATIONAL_MAILBOX = 0x004
+    PRIVATE_DISTRIBUTION_LIST = 0x005
+    REMOTE_MAIL_USER = 0x006
+    CONTAINER = 0x100
+    TEMPLATE = 0x101
+    ONE_OFF_USER = 0x102
+    SEARCH = 0x200
+
+
+
+class AppointmentAuxilaryFlag(enum.Enum):
+    """
+    Describes the auxilary state of the object.
+
+    COPIED: The Calendar object was copied from another Calendar folder.
+    FORCE_MEETING_RESPONSE: The client of server can require that a Meeting
+        Response object be sent to the organizer when a response is chosen.
+    FORWARDED: The object was forwarded by the organizer or another recipient.
+    REPAIR_UPDATE_MESSAGE: The meeting request is a Repair Update Message sent
+        from a server-side calendar repair system.
+    """
+    @classmethod
+    def fromBits(cls, value : int) -> Set['AppointmentAuxilaryFlag']:
+        """
+        Takes an int and returns a set of the flags.
+        """
+        flags = set()
+        for x in range(7):
+            bit = value & (1 << x)
+            if bit:
+                if x in (3, 4, 6):
+                    raise ValueError('Reserved bit was set.')
+                flags.add(cls(bit))
+
+        return flags
+
+    COPIED = 0b1
+    FORCE_MEETING_RESPONSE = 0b10
+    FORWARDED = 0b100
+    REPAIR_UPDATE_MESSAGE = 0b100000
+
+
+
+class AppointmentColor(enum.Enum):
+    NONE = 0x00000000
+    RED = 0x00000001
+    BLUE = 0x00000002
+    GREEN = 0x00000003
+    GREY = 0x00000004
+    ORANGE = 0x00000005
+    CYAN = 0x00000006
+    OLIVE = 0x00000007
+    PURPLE = 0x00000008
+    TEAL = 0x00000009
+    YELLOW = 0x0000000A
+
+
+
+class AppointmentStateFlag(enum.Enum):
+    """
+    MEETING: The object is a Meeting object or meeting-related object.
+    RECEIVED: The represented object was received from someone else.
+    CANCELED: The Meeting object that is represented has been canceled.
+    """
+    @classmethod
+    def fromBits(cls, value : int) -> Set['AppointmentStateFlag']:
+        """
+        Takes an int and returns a set of the flags.
+        """
+        return {cls(1 << x) for x in range(3) if (value & (1 << x)) != 0}
+
+    MEETING = 0b1
+    RECEIVED = 0b10
+    CANCELED = 0b100
+
+
+
+class AttachmentType(enum.Enum):
+    """
+    The type represented by the attachment.
+
+    DATA: An attachment stored as plain bytes in the MSG file.
+    MSG: A normally embedded MSG file.
+    WEB: An attachment referencing a resource on the web.
+    SIGNED: An attachment of a signed message that is *not* an MSG file.
+    SIGNED_EMBEDDED: An MSG file embedded in a signed message.
+
+    BROKEN: An attachment with a critical issue.
+    UNSUPPORTED: An attachment that does not match any supported types.
+    UNKNOWN: The attachment type could not be determined.
+    """
+    DATA = 0
+    MSG = 1
+    WEB = 2
+    SIGNED = 3
+    BROKEN = 4
+    UNSUPPORTED = 5
+    SIGNED_EMBEDDED = 6
+
+    UNKNOWN = 0xFFFFFFFF
+
+
+
+class BCImageAlignment(enum.Enum):
+    STRETCH = 0x00
+    TOP_LEFT = 0x01
+    TOP_CENTER = 0x02
+    TOP_RIGHT = 0x03
+    MIDDLE_LEFT = 0x04
+    MIDDLE_CENTER = 0x05
+    MIDDLE_RIGHT = 0x06
+    BOTTOM_LEFT = 0x07
+    BOTTOM_CENTER = 0x08
+    BOTTOM_RIGHT = 0x09
+
+
+
+class BCImageSource(enum.Enum):
+    CONTACT_PHOTO = 0
+    CARD_PHOTO = 1
+
+
+
+class BCLabelFormat(enum.Enum):
+    """
+    The format for a label of a business card. Left of the underscore represents
+    the alignment, right indicates reading order.
+    A
+    """
+    NO_LABEL = 0b000
+    RIGHT_LTR = 0b001
+    LEFT_LTR = 0b010
+    UNKNOWN = 0b100
+    RIGHT_RTL = 0b101
+    LEFT_RTL = 0b110
+
+
+
+class BCTemplateID(enum.Enum):
+    """
+    The template ID for a business card.
+
+    IM_ALIGN_LEFT: The image area will be left aligned, stretching the full
+        height of the card vertically; text fields will appear to the right of
+        the image area.
+    IM_ALIGN_RIGHT: The image area will be right aligned, stretching the full
+        height of the card vertically; text fields will appear to the left of
+        the image area.
+    IM_ALIGN_TOP: The image area will be aligned to the top, stretching the full
+        width of the card horizontally; text fields will appear under the image
+        area.
+    IM_ALIGN_BOTTOM: The image area will be aligned to the bottom, stretching
+        the full width of the card horizontally; text fields will appear above
+        the image area.
+    NO_IMAGE: No image area is included in the card, only text fields are
+        included.
+    BACKGROUND: The image area will be used as a background for the card,
+        stretching the full height and width of the card. Text fields are
+        displayed on top of the image area.
+    """
+    IM_ALIGN_LEFT = 0x00
+    IM_ALIGN_RIGHT = 0x01
+    IM_ALIGN_TOP = 0x02
+    IM_ALIGN_BOTTOM = 0x03
+    NO_IMAGE = 0x04
+    BACKGROUND = 0x05
+
+
+
+class BCTextFormat(enum.Enum):
+    """
+    Converts the bits of the text format to an understandable enum value.
+
+    Right value is the alignment, with left is the flags. The following flags
+    exist and will be in the following order if present:
+        U: Underline.
+        I: Italics.
+        B: Bold.
+        M: The text is multiline.
+    """
+    LEFT = 0b00000000
+    LEFT_M = 0b00000001
+    LEFT_B = 0b00000010
+    LEFT_BM = 0b00000011
+    LEFT_I = 0b00000100
+    LEFT_IM = 0b00000101
+    LEFT_IB = 0b00000110
+    LEFT_IBM = 0b00000111
+    LEFT_U = 0b00001000
+    LEFT_UM = 0b00001001
+    LEFT_UB = 0b00001010
+    LEFT_UBM = 0b00001011
+    LEFT_UI = 0b00001100
+    LEFT_UIM = 0b00001101
+    LEFT_UIB = 0b00001110
+    LEFT_UIBM = 0b00001111
+    CENTER = 0b00100000
+    CENTER_M = 0b00100001
+    CENTER_B = 0b00100010
+    CENTER_BM = 0b00100011
+    CENTER_I = 0b00100100
+    CENTER_IM = 0b00100101
+    CENTER_IB = 0b00100110
+    CENTER_IBM = 0b00100111
+    CENTER_U = 0b00101000
+    CENTER_UM = 0b00101001
+    CENTER_UB = 0b00101010
+    CENTER_UBM = 0b00101011
+    CENTER_UI = 0b00101100
+    CENTER_UIM = 0b00101101
+    CENTER_UIB = 0b00101110
+    CENTER_UIBM = 0b00101111
+    RIGHT = 0b00010000
+    RIGHT_M = 0b00010001
+    RIGHT_B = 0b00010010
+    RIGHT_BM = 0b00010011
+    RIGHT_I = 0b00010100
+    RIGHT_IM = 0b00010101
+    RIGHT_IB = 0b00010110
+    RIGHT_IBM = 0b00010111
+    RIGHT_U = 0b00011000
+    RIGHT_UM = 0b00011001
+    RIGHT_UB = 0b00011010
+    RIGHT_UBM = 0b00011011
+    RIGHT_UI = 0b00011100
+    RIGHT_UIM = 0b00011101
+    RIGHT_UIB = 0b00011110
+    RIGHT_UIBM = 0b00011111
+
+
+
+class BusyStatus(enum.Enum):
+    """
+    The availability of a use for the event described by the object.
+
+    OL_FREE: The user is available.
+    OL_TENTATIVE: The user has a tentative event scheduled.
+    OL_BUSY: The user is busy.
+    OL_OUT_OF_OFFICE: The user is Out of Office.
+    OL_WORKING_ELSEWHERE: The user is working from a location other than the
+        office.
+    """
+    OL_FREE = 0x00000000
+    OL_TENTATIVE = 0x00000001
+    OL_BUSY = 0x00000002
+    OL_OUT_OF_OFFICE = 0x00000003
+    OL_WORKING_ELSEWHERE = 0x00000004
+
+
+
+class ClientIntentFlag(enum.Enum):
+    """
+    An action a user has taken on a Meeting object.
+
+    MANAGER: The user is the owner of the Meeting object's Calendar folder. If
+        set, DELEGATE SHOULD NOT be set.
+    DELEGATE: The user is a delegate acting on a Meeting object in a delegator's
+        Calendar folder. If set, MANAGER SHOULD NOT be set.
+    DELETED_WITH_NO_RESPONSE: The user deleted the Meeting object with no
+        response sent to the organizer.
+    DELETED_EXCEPTION_WITH_NO_RESPONSE: The user deleted an exception to a
+        recurring series with no response sent to the organizer.
+    RESPONDED_TENTATIVE: The user tentatively accepted the meeting request.
+    RESPONSED_ACCEPT: The user accepted the meeting request.
+    RESPONDED_DECLINE: The user declined the meeting request.
+    MODIFIED_START_TIME: The user modified the start time.
+    MODIFIED_END_TIME: The user modified the end time.
+    MODIFIED_LOCATION: The user changed the location of the meeting.
+    RESPONDED_EXCEPTION_DECLINE: The user declined an exception to a recurring
+        series.
+    CANCELED: The user canceled a meeting request.
+    EXCEPTION_CANCELED: The user canceled an exception to a recurring series.
+    """
+    @classmethod
+    def fromBits(cls, value : int) -> Set['ClientIntentFlag']:
+        """
+        Takes an int and returns a set of the flags.
+        """
+        return {cls(1 << x) for x in range(13) if (value & (1 << x))}
+
+    MANAGER = 0b1
+    DELEGATE = 0b10
+    DELETED_WITH_NO_RESPONSE = 0b100
+    DELETED_EXCEPTION_WITH_NO_RESPONSE = 0b1000
+    RESPONDED_TENTATIVE = 0b10000
+    RESPONSED_ACCEPT = 0b100000
+    RESPONDED_DECLINE = 0b1000000
+    MODIFIED_START_TIME = 0b10000000
+    MODIFIED_END_TIME = 0b100000000
+    MODIFIED_LOCATION = 0b1000000000
+    RESPONDED_EXCEPTION_DECLINE = 0b10000000000
+    CANCELED = 0b100000000000
+    EXCEPTION_CANCELED = 0b1000000000000
+
+
+
+class Color(enum.IntEnum):
+    RED = 0
+    BLACK = 1
+
+
+class ContactAddressIndex(enum.Enum):
+    EMAIL_1 = 0
+    EMAIL_2 = 1
+    EMAIL_3 = 2
+    FAX_1 = 3
+    FAX_2 = 4
+    FAX_3 = 5
+
+
+
+class ContactLinkState(enum.Enum):
+    """
+    Values for PidLidContactLinkGlobalAddressListLinkState.
+
+    DUPLICATE_NOT_LINKED: The duplicate contact is not linked to the GAL contact
+        or the GAL contact is not downloaded.
+    DUPLICATE_LINKED: The duplicate contact is linked to the GAL contact.
+    DUPLICATE_CANNOT_LINK: The duplicate contact cannot be automatically linked
+        to the GAL contact.
+    """
+    DUPLICATE_NOT_LINKED = 0
+    DUPLICATE_LINKED = 1
+    DUPLICATE_CANNOT_LINK = 2
+
+
+
+class DeencapType(enum.Enum):
+    """
+    Enum to specify to custom deencapsulation functions the type of data being
+    requested.
+    """
+    PLAIN = 0
+    HTML = 1
+
+
+
+class DirectoryEntryType(enum.IntEnum):
+    UNALLOCATED = 0
+    UNKNOWN = 0
+    STORAGE = 1
+    STREAM = 2
+    ROOT_STORAGE = 5
+
+
+
+class DisplayType(enum.Enum):
+    MAILUSER = 0x0000
+    DISTLIST = 0x0001
+    FORUM = 0x0002
+    AGENT = 0x0003
+    ORGANIZATION = 0x0004
+    PRIVATE_DISTLIST = 0x0005
+    REMOTE_MAILUSER = 0x0006
+    CONTAINER = 0x0100
+    TEMPLATE = 0x0101
+    ADDRESS_TEMPLATE = 0x0102
+    SEARCH = 0x0200
+
+
+
+class ElectronicAddressProperties(enum.Enum):
+    @classmethod
+    def fromBits(cls, value : int) -> Set['ElectronicAddressProperties']:
+        """
+        Converts an int, with the left most bit referring to 0x00000000, to a
+        set of this enum.
+
+        :raises ValueError: The value was less than 0.
+        """
+        if value < 0:
+            raise ValueError('Value must not be negative.')
+        # This is a quick compressed way to convert the bits in the int into
+        # a tuple of instances of this class should any bit be a 1.
+        return {cls(int(index)) for index, val in enumerate(bin(value)[:1:-1]) if val == '1'}
+
+    EMAIL_1 = 0x00000000
+    EMAIL_2 = 0x00000001
+    EMAIL_3 = 0x00000002
+    BUSINESS_FAX = 0x00000003
+    HOME_FAX = 0x00000004
+    PRIMARY_FAX = 0x00000005
+
+
+
+class EntryIDType(enum.Enum):
+    """
+    Converts a UID to the type of Entry ID structure.
+    """
+    def toHex(self):
+        """
+        Converts an EntryIDType to it's hex equivelent.
+        """
+        return EntryIDTypeHex[self.name]
+
+    # This is the same as the one used for permanent IDs, and the strucutre is
+    # near identical too. Anything that needs a PermanentEntryID will need to
+    # specifically ask for it instead of autogenerating it.
+    ADDRESS_BOOK_RECIPIENT = b'\xDC\xA7\x40\xC8\xC0\x42\x10\x1A\xB4\xB9\x08\x00\x2B\x2F\xE1\x82'
+    # Contact address or personal distribution list recipient.
+    CA_OR_PDL_RECIPIENT = b'\xFE\x42\xAA\x0A\x18\xC7\x1A\x10\xE8\x85\x0B\x65\x1C\x24\x00\x00'
+    # This is also used for the Store Object EntryID structure.
+    NNTP_NEWSGROUP_FOLDER = b'\x38\xA1\xBB\x10\x05\xE5\x10\x1A\xA1\xBB\x08\x00\x2B\x2A\x56\xC2'
+    ONE_OFF_RECIPIENT = b'\x81\x2B\x1F\xA4\xBE\xA3\x10\x19\x9D\x6E\x00\xDD\x01\x0F\x54\x02'
+    PUBLIC_MESSAGE_STORE = b'\x1A\x44\x73\x90\xAA\x66\x11\xCD\x9B\xC8\x00\xAA\x00\x2F\xC4\x5A'
+    # [MS-OXOCNTC] WrappedEntryId Structure.
+    WRAPPED = b'\xC0\x91\xAD\xD3\x51\x9D\xCF\x11\xA4\xA9\x00\xAA\x00\x47\xFA\xA4'
+
+
+
+class EntryIDTypeHex(enum.Enum):
+    """
+    Converts a UID to the type of Entry ID structure. Uses a hex string instead
+    of bytes for the value.
+    """
+    def toRaw(self):
+        """
+        Converts and EntryIDTypeHex to it's raw equivelent.
+        """
+        return EntryIDType[self.name]
+
+    ADDRESS_BOOK_RECIPIENT = 'DCA740C8C042101AB4B908002B2FE182'
+    # Contact address or personal distribution list recipient.
+    CA_OR_PDL_RECIPIENT = 'FE42AA0A18C71A10E8850B651C240000'
+    NNTP_NEWSGROUP_FOLDER = '38A1BB1005E5101AA1BB08002B2A56C2'
+    ONE_OFF_RECIPIENT = '812B1FA4BEA310199D6E00DD010F5402'
+    PUBLIC_MESSAGE_STORE = '1A447390AA6611CD9BC800AA002FC45A'
+    # [MS-OXOCNTC] WrappedEntryId Structure.
+    WRAPPED = 'C091ADD3519DCF11A4A900AA0047FAA4'
+
+
+
+class ErrorBehavior(enum.IntFlag):
+    """
+    The behavior to follow when handling an error in an MSG file and it's 
+    attachments. This is an int flag enum, so the options you want will be ORed
+    with each other.
+
+    THROW: Throw the exception regardless of type.
+    ATTACH_NOT_IMPLEMENTED: Silence the exception for NotImplementedError.
+    ATTACH_BROKEN: Silence the exception for broken attachments.
+    ATTACH_SUPPRESS_ALL: Silence the exception for NotImplementedError and for broken
+        attachments.
+    STANDARDS_VIOLATION
+    """
+    THROW = 0b000
+    ATTACH_NOT_IMPLEMENTED = 0b001
+    ATTACH_BROKEN = 0b010
+    ATTACH_SUPPRESS_ALL = 0b011
+    STANDARDS_VIOLATION = 0b100
+    SUPPRESS_ALL = 0b111
+
+
+
+class ErrorCode(enum.Enum):
+    SUCCESS = 0x00000000
+    GENERAL_FAILURE = 0x80004005
+    OUT_OF_MEMORY = 0x8007000E
+    INVALID_PARAMETER = 0x80070057
+    NO_INTERFACE = 0x80004002
+    ACCESS_DENIED = 0x80070005
+    STORAGE_INVALID_FUNCTION = 0x80030001
+    STORAGE_ACCESS_DENIED = 0x80030005
+    STORAGE_INSUFFICIENT_MEMORY = 0x80030008
+    STORAGE_INVALID_POINTER = 0x80030009
+    STORAGE_READ_FAULT = 0x8003001E
+    STORAGE_LOCK_VIOLATION = 0x80030021
+    STORAGE_INVALID_PARAMETER = 0x80030057
+    STREAM_SIZE_ERROR = 0x80030070
+    STORAGE_INVALID_FLAG = 0x800300FF
+    STORAGE_CANNOT_SAVE = 0x80030103
+    NOT_SUPPORTED = 0x80040102
+    INVALID_CHARACTER_WIDTH = 0x80040103
+    STRING_TOO_LONG = 0x80040105
+    INVALID_FLAG = 0x80040106
+    INVALID_ENTRY_ID = 0x80040107
+    INVALID_OBJECT = 0x80040108
+    OBJECT_CHANGED = 0x80040109
+    OBJECT_DELETED = 0x8004010A
+    SERVER_BUSY = 0x8004010B
+    OUT_OF_DISK = 0x8004010D
+    OUT_OF_RESOURCES = 0x8004010E
+    NOT_FOUND = 0x8004010F
+    VERSION_MISMATCH = 0x80040110
+    LOGON_FAILED = 0x80040111
+    TOO_MANY_SESSIONS = 0x80040112
+    USER_CANCELED = 0x80040113
+    ABORT_FAILED = 0x80040114
+    NETWORK_ERROR = 0x80040115
+    DISK_ERROR = 0x80040116
+    TOO_COMPLEX = 0x80040117
+    INVALID_COLUMN = 0x80040118
+    COMPUTED_VALUE = 0x8004011A
+    CORRUPT_DATA = 0x8004011B
+    INVALID_CODEPAGE = 0x8004011E
+    INVALID_LOCALE = 0x8004011F
+    TIME_SKEW = 0x80040123
+    END_OF_SESSION = 0x80040200
+    UNKNOWN_ENTRY_ID = 0x80040201
+    NOT_COMPLETED = 0x80040400
+    TIMEOUT = 0x80040401
+    EMPTY_TABLE = 0x80040402
+    TABLE_TOO_BIG = 0x80040403
+    INVALID_BOOKMARK = 0x80040405
+    ERROR_WAIT = 0x80040500
+    ERROR_CANCEL = 0x80040501
+    NO_SUPPRESS = 0x80040602
+    COLLIDING_NAMES = 0x80040604
+    NOT_INITIALIZED = 0x80040605
+    NO_RECIPIENTS = 0x80040607
+    ALREADY_SENT = 0x80040608
+    HAS_FOLDERS = 0x80040609
+    HAS_MESSAGES = 0x8004060A
+    FOLDER_CYCLE = 0x8004060B
+    TOO_MANY_LOCKS = 0x8004060D
+    AMBIGUOUS_RECIPIENT = 0x80040700
+    SYNC_OBJECT_DELETED = 0x80040800
+    IGNORE_FAILURE = 0x80040801
+    SYNC_CONFLICT = 0x80040802
+    NO_PARENT_FOLDER = 0x80040803
+    CYCLE_DETECTED = 0x80040804
+    NOT_SYNCHRONIZED = 0x80040805
+    NAMED_PROPERTY_QUOTA = 0x80040900
+    NOT_IMPLEMENTED = 0x80040FFF
+
+
+
+class ErrorCodeType(enum.Enum):
+    """
+    Enum representing values for PtypErrorCode.
+
+    See "Additional Error Codes" in [MS-OXCDATA].
+    """
+    SUCCESS = 0x00000000
+    ISAM_ERROR = 0x000003EA
+    UNKNOWN_USER = 0x000003EB
+    EXITING = 0x000003ED
+    BAD_CONFIGURATION = 0x000003EE
+    UNKNOWN_CODE_PAGE = 0x000003EF
+    SERVER_MEMORY = 0x000003F0
+    LOGIN_PERMISSION = 0x000003F2
+    DATABASE_ROLLED_BACK = 0x000003F3
+    DATABASE_COPIED_ERROR = 0x000003F4
+    AUDIT_NOT_ALLOWED = 0x000003F5
+    ZOMBIE_USER = 0x000003F6
+    UNCONVERTABLE_ACL = 0x000003F7
+    NO_FREE_JET_SESSIONS = 0x0000044C
+    DIFFERENT_JET_SESSION = 0x0000044D
+    FILE_REMOVE = 0x0000044F
+    PARAMETER_OVERFLOW = 0x00000450
+    BAD_VERSION = 0x00000451
+    TOO_MANY_COLUMNS = 0x00000452
+    HAVE_MORE = 0x00000453
+    DATABASE_ERROR = 0x00000454
+    INDEX_NAME_TOO_BIG = 0x00000455
+    UNSUPPORTED_PROPERTY = 0x00000456
+    MESSAGE_NOT_SAVED = 0x00000457
+    UNPUBLISHED_NOTIFICATION = 0x00000459
+    DIFFERENT_ROOT = 0x0000045B
+    BAD_FOLDER_NAME = 0x0000045C
+    ATTACHMENT_OPEN = 0x0000045D
+    INVALID_COLLAPSE_STATE = 0x0000045E
+    SKIP_MY_CHILDREN = 0x0000045F
+    SEARCH_FOLDER = 0x00000460
+    NOT_SEARCH_FOLDER = 0x00000461
+    FOLDER_SET_RECEIVE = 0x00000462
+    NO_RECEIVE_FOLDER = 0x00000463
+    DELETE_SUBMITTED_MESSAGE = 0x00000465
+    INVALID_RECIPIENTS = 0x00000467
+    NO_REPLICA_HERE = 0x00000468
+    NO_REPLICA_AVAILABLE = 0x00000469
+    PUBLIC_DATABASE = 0x0000046A
+    NOT_PUBLIC_DATABASE = 0x0000046B
+    RECORD_NOT_FOUND = 0x0000046C
+    REPLICATION_CONFLICT = 0x0000046D
+    FX_BUFFER_OVERRUN = 0x00000470
+    FX_BUFFER_EMPTY = 0x00000471
+    FX_PARTIAL_VALUE = 0x00000472
+    FX_NO_ROOM = 0x00000473
+    TIME_EXPIRED = 0x00000474
+    DESTINATION_ERROR = 0x00000475
+    DATABASE_NOT_INITIALIZED = 0x00000476
+    WRONG_SERVER = 0x00000478
+    BUFFER_TOO_SMALL = 0x0000047D
+    ATTACHMENT_RESOLUTION_REQUIRED = 0x0000047E
+    SERVER_PAUSED = 0x0000047F
+    SERVER_BUSY = 0x00000480
+    NO_SUCH_LOGON = 0x00000481
+    LOAD_LIBRARY_FAILED = 0x00000482
+    ALREADY_CONFIGURED = 0x00000483
+    NOT_CONFIGURED = 0x00000484
+    DATA_LOSS = 0x00000485
+    MAXIMUM_SEND_THREAD_EXCEEDED = 0x00000488
+    FX_ERROR_MARKER = 0x00000489
+    NO_FREE_JTABS = 0x0000048A
+    NOT_PRIVATE_DATABASE = 0x0000048B
+    ISINTEG_MDB = 0x0000048C
+    RECOVERY_MISMATCH = 0x0000048D
+    TABLE_MAY_NOT_BE_DELETED = 0x0000048E
+    SEARCH_FOLDER_SCOPE_VIOLATION = 0x00000490
+    RPC_REGISTER_IF = 0x000004B1
+    RPC_LISTEN = 0x000004B2
+    RPC_FORMAT = 0x000004B6
+    NO_COPY_TO = 0x000004B7
+    NULL_OBJECT = 0x000004B9
+    RPC_AUTHENTICATION = 0x000004BC
+    RPC_BAD_AUTHENTICATION_LEVEL = 0x000004BD
+    NULL_COMMENT_RESTRICTION = 0x000004BE
+    RULES_LOAD_ERROR = 0x000004CC
+    RULES_DELIVER_ERR = 0x000004CD
+    RULES_PARSING_ERR = 0x000004CE
+    RULES_CREATE_DAE = 0x000004CF
+    RULES_CREATE_DAM = 0x000004D0
+    RULES_NO_MOVE_COPY_FOLDER = 0x000004D1
+    RULES_NO_FOLDER_RIGHTS = 0x000004D2
+    MESSAGE_TOO_BIG = 0x000004D4
+    FORM_NOT_VALID = 0x000004D5
+    NOT_AUTHORIZED = 0x000004D6
+    DELETE_MESSAGE = 0x000004D7
+    BOUNCE_MESSAGE = 0x000004D8
+    QUOTA_EXCEEDED = 0x000004D9
+    MAX_SUBMISSION_EXCEEDED = 0x000004DA
+    MAX_ATTACHMENT_EXCEEDED = 0x000004DB
+    SEND_AS_DENIED = 0x000004DC
+    SHUTOFF_QUOTA_EXCEEDED = 0x000004DD
+    TOO_MANY_OPEN_OBJECTS = 0x000004DE
+    CLIENT_VERSION_BLOCKED = 0x000004DF
+    RPC_HTTP_DISALLOWED = 0x000004E0
+    CACHED_MODE_REQUIRED = 0x000004E1
+    FOLDER_NOT_CLEANED_UP = 0x000004E3
+    FORMAT_ERROR = 0x000004ED
+    NOT_EXPANDED = 0x000004F7
+    NOT_COLLAPSED = 0x000004F8
+    NO_EXPAND_LEAF_ROW = 0x000004F9
+    UNREGISTERED_NAME_PROP = 0x000004FA
+    FOLDER_DISABLED = 0x000004FB
+    DOMAIN_ERROR = 0x000004FC
+    NO_CREATE_RIGHT = 0x000004FF
+    PUBLIC_ROOT = 0x00000500
+    NO_READ_RIGHT = 0x00000501
+    NO_CREATE_SUBFOLDER_RIGHT = 0x00000502
+    MESSAGE_CYCLE = 0x00000504
+    NULL_DESTINATION_OBJECT = 0x00000503
+    TOO_MANY_RECIPS = 0x00000505
+    VIRUS_SCAN_IN_PROGRESS = 0x0000050A
+    VIRUS_DETECTED = 0x0000050B
+    MAILBOX_IN_TRANSIT = 0x0000050C
+    BACKUP_IN_PROGRESS = 0x0000050D
+    VIRUS_MESSAGE_DELETED = 0x0000050E
+    INVALID_BACKUP_SEQUENCE = 0x0000050F
+    INVALID_BACKUP_TYPE = 0x00000510
+    TOO_MANY_BACKUPS = 0x00000511
+    RESTORE_IN_PROGRESS = 0x00000512
+    DUPLICATE_OBJECT = 0x00000579
+    OBJECT_NOT_FOUND = 0x0000057A
+    FIXUP_REPLY_RULE = 0x0000057B
+    TEMPLATE_NOT_FOUND = 0x0000057C
+    RULE_EXECUTION = 0x0000057D
+    DS_NO_SUCH_OBJECT = 0x0000057E
+    ALREADY_TOMBSTONED = 0x0000057F
+    READ_ONLY_TRANSACTION = 0x00000596
+    PAUSED = 0x0000060E
+    NOT_PAUSED = 0x0000060F
+    WRONG_MAILBOX = 0x00000648
+    CHANGE_PASSWORD = 0x0000064C
+    PASSWORD_EXPIRED = 0x0000064D
+    INVALID_WORKSTATION = 0x0000064E
+    INVALID_LOGON_HOURS = 0x0000064F
+    ACCOUNT_DISABLED = 0x00000650
+    RULE_VERSION = 0x000006A4
+    RULE_FORMAT = 0x000006A5
+    RULE_SEND_AS_DENIED = 0x000006A6
+    NO_SERVER_SUPPORT = 0x000006B9
+    LOCK_TIMED_OUT = 0x000006BA
+    OBJECT_LOCKED = 0x000006BB
+    INVALID_LOCK_NAMESPACE = 0x000006BD
+    MESSAGE_DELETED = 0x000007D6
+    PROTOCOL_DISABLED = 0x000007D8
+    CLEARTEXT_LOGON_DISABLED = 0x000007D9
+    REJECTED = 0x000007EE
+    AMBIGUOUS_ALIAS = 0x0000089A
+    UNKNOWN_MAILBOX = 0x0000089B
+    EXPRESSION_RESERVED = 0x000008FC
+    EXPRESSION_PARSE_DEPTH = 0x000008FD
+    EXPRESSION_ARGUMENT_TYPE = 0x000008FE
+    EXPRESSION_SYNTAX = 0x000008FF
+    EXPRESSION_BAD_STRING_TOKEN = 0x00000900
+    EXPRESSION_BAD_COL_TOKEN = 0x00000901
+    EXPRESSION_TYPE_MISMATCH = 0x00000902
+    EXPRESSION_OPERATOR_NOT_SUPPORTED = 0x00000903
+    EXPRESSION_DIVIDE_BY_ZERO = 0x00000904
+    EXPRESSION_UNARY_ARGUMENT = 0x00000905
+    NOT_LOCKED = 0x00000960
+    CLIENT_EVENT = 0x00000961
+    CORRUPT_EVENT = 0x00000965
+    CORRUPT_WATERMARK = 0x00000966
+    EVENT_ERROR = 0x00000967
+    WATERMARK_ERROR = 0x00000968
+    NON_CANONICAL_ACL = 0x00000969
+    MAILBOX_DISABLED = 0x0000096C
+    RULES_FOLDER_OVER_QUOTA = 0x0000096D
+    ADDRESS_BOOK_UNAVAILABLE = 0x0000096E
+    ADDRESS_BOOK_ERROR = 0x0000096F
+    ADDRESS_BOOK_OBJECT_NOT_FOUND = 0x00000971
+    ADDRESS_BOOK_PROPERTY_ERROR = 0x00000972
+    NOT_ENCRYPTED = 0x00000970
+    RPC_SERVER_TOO_BUSY = 0x00000973
+    RPC_OUT_OF_MEMORY = 0x00000974
+    RPC_SERVER_OUT_OF_MEMORY = 0x00000975
+    RPC_OUT_OF_RESOURCES = 0x00000976
+    RPC_SERVER_UNAVAILABLE = 0x00000977
+    SECURE_SUBMIT_ERROR = 0x0000097A
+    EVENTS_DELETED = 0x0000097C
+    SUBSYSTEM_STOPPING = 0x0000097D
+    ATTENDANT_UNAVAILABLE = 0x0000097E
+    CI_STOPPING = 0x00000A28
+    FX_INVALID_STATE = 0x00000A29
+    FX_UNEXPECTED_MARKER = 0x00000A2A
+    DUPLICATE_DELIVERY = 0x00000A2B
+    CONDITION_VIOLATION = 0x00000A2C
+    MAXIMUM_CONNECTION_POOLS_EXCEEDED = 0x00000A2D
+    INVALID_RPC_HANDLE = 0x00000A2E
+    EVENT_NOT_FOUND = 0x00000A2F
+    PROPERTY_NOT_PROMOTED = 0x00000A30
+    LOW_FREE_SPACE_FOR_DATABASE = 0x00000A31
+    LOW_FREE_SPACE_FOR_LOGS = 0x00000A32
+    MAILBOX_IS_QUARANTINED = 0x00000A33
+    DATABASE_MOUNT_IN_PROGRESS = 0x00000A34
+    DATABASE_DISMOUNT_IN_PROGRESS = 0x00000A35
+    CONNECTIONS_OVER_BUDGET = 0x00000A36
+    NOT_FOUND_IN_CONTAINER = 0x00000A37
+    CANNOT_REMOVE = 0x00000A38
+    INVALID_CONNECTION_POOL = 0x00000A39
+    VIRUS_SCAN_GENERAL_FAILURE = 0x00000A3A
+    ISAM_ERROR_RFS_FAILURE = 0xFFFFFF9C
+    ISAM_ERROR_RFS_NOT_ARMED = 0xFFFFFF9B
+    ISAM_ERROR_FILE_CLOSE = 0xFFFFFF9A
+    ISAM_ERROR_OUT_OF_THREADS = 0xFFFFFF99
+    ISAM_ERROR_TOO_MANY_IO = 0xFFFFFF97
+    ISAM_ERROR_TASK_DROPPED = 0xFFFFFF96
+    ISAM_ERROR_INTERNAL_ERROR = 0xFFFFFF95
+    ISAM_ERROR_DATABASE_BUFFER_DEPENDENCIES_CORRUPTED = 0xFFFFFF01
+    ISAM_ERROR_PREVIOUS_VERSION = 0xFFFFFEBE
+    ISAM_ERROR_PAGE_BOUNDARY = 0xFFFFFEBD
+    ISAM_ERROR_KEY_BOUNDARY = 0xFFFFFEBC
+    ISAM_ERROR_BAD_PAGE_LINK = 0xFFFFFEB9
+    ISAM_ERROR_BAD_BOOKMARK = 0xFFFFFEB8
+    ISAM_ERROR_NT_SYSTEM_CALL_FAILED = 0xFFFFFEB2
+    ISAM_ERROR_BAD_PARENT_PAGE_LINK = 0xFFFFFEAE
+    ISAM_ERROR_SP_AVAIL_EXT_CACHE_OUT_OF_SYNC = 0xFFFFFEAC
+    ISAM_ERROR_SP_AVAIL_EXT_CORRUPTED = 0xFFFFFEAB
+    ISAM_ERROR_SP_AVAIL_EXT_CACHE_OUT_OF_MEMORY = 0xFFFFFEAA
+    ISAM_ERROR_SP_OWN_EXT_CORRUPTED = 0xFFFFFEA9
+    ISAM_ERROR_DB_TIME_CORRUPTED = 0xFFFFFEA8
+    ISAM_ERROR_KEY_TRUNCATED = 0xFFFFFEA6
+    ISAM_ERROR_KEY_TOO_BIG = 0xFFFFFE68
+    ISAM_ERROR_INVALID_LOGGED_OPERATION = 0xFFFFFE0C
+    ISAM_ERROR_LOG_FILE_CORRUPT = 0xFFFFFE0B
+    ISAM_ERROR_NO_BACKUP_DIRECTORY = 0xFFFFFE09
+    ISAM_ERROR_BACKUP_DIRECTORY_NOT_EMPTY = 0xFFFFFE08
+    ISAM_ERROR_BACKUP_IN_PROGRESS = 0xFFFFFE07
+    ISAM_ERROR_RESTORE_IN_PROGRESS = 0xFFFFFE06
+    ISAM_ERROR_MISSING_PREVIOUS_LOG_FILE = 0xFFFFFE03
+    ISAM_ERROR_LOG_WRITE_FAIL = 0xFFFFFE02
+    ISAM_ERROR_LOG_DISABLED_DUE_TO_RECOVERY_FAILURE = 0xFFFFFE01
+    ISAM_ERROR_CANNOT_LOG_DURING_RECOVERY_REDO = 0xFFFFFE00
+    ISAM_ERROR_LOG_GENERATION_MISMATCH = 0xFFFFFDFF
+    ISAM_ERROR_BAD_LOG_VERSION = 0xFFFFFDFE
+    ISAM_ERROR_INVALID_LOG_SEQUENCE = 0xFFFFFDFD
+    ISAM_ERROR_LOGGING_DISABLED = 0xFFFFFDFC
+    ISAM_ERROR_LOG_BUFFER_TOO_SMALL = 0xFFFFFDFB
+    ISAM_ERROR_LOG_SEQUENCE_END = 0xFFFFFDF9
+    ISAM_ERROR_NO_BACKUP = 0xFFFFFDF8
+    ISAM_ERROR_INVALID_BACKUP_SEQUENCE = 0xFFFFFDF7
+    ISAM_ERROR_BACKUP_NOT_ALLOWED_YET = 0xFFFFFDF5
+    ISAM_ERROR_DELETE_BACKUP_FILE_FAIL = 0xFFFFFDF4
+    ISAM_ERROR_MAKE_BACKUP_DIRECTORY_FAIL = 0xFFFFFDF3
+    ISAM_ERROR_INVALID_BACKUP = 0xFFFFFDF2
+    ISAM_ERROR_RECOVERED_WITH_ERRORS = 0xFFFFFDF1
+    ISAM_ERROR_MISSING_LOG_FILE = 0xFFFFFDF0
+    ISAM_ERROR_LOG_DISK_FULL = 0xFFFFFDEF
+    ISAM_ERROR_BAD_LOG_SIGNATURE = 0xFFFFFDEE
+    ISAM_ERROR_BAD_DB_SIGNATURE = 0xFFFFFDED
+    ISAM_ERROR_BAD_CHECKPOINT_SIGNATURE = 0xFFFFFDEC
+    ISAM_ERROR_CHECKPOINT_CORRUPT = 0xFFFFFDEB
+    ISAM_ERROR_MISSING_PATCH_PAGE = 0xFFFFFDEA
+    ISAM_ERROR_BAD_PATCH_PAGE = 0xFFFFFDE9
+    ISAM_ERROR_REDO_ABRUPT_ENDED = 0xFFFFFDE8
+    ISAM_ERROR_BAD_SLV_SIGNATURE = 0xFFFFFDE7
+    ISAM_ERROR_PATCH_FILE_MISSING = 0xFFFFFDE6
+    ISAM_ERROR_DATABASE_LOG_SET_MISMATCH = 0xFFFFFDE5
+    ISAM_ERROR_DATABASE_STREAMING_FILE_MISMATCH = 0xFFFFFDE4
+    ISAM_ERROR_LOG_FILE_SIZE_MISMATCH = 0xFFFFFDE3
+    ISAM_ERROR_CHECKPOINT_FILE_NOT_FOUND = 0xFFFFFDE2
+    ISAM_ERROR_REQUIRED_LOG_FILES_MISSING = 0xFFFFFDE1
+    ISAM_ERROR_SOFT_RECOVERY_ON_BACKUP_DATABASE = 0xFFFFFDE0
+    ISAM_ERROR_LOG_FILE_SIZE_MISMATCH_DATABASES_CONSISTENT = 0xFFFFFDDF
+    ISAM_ERROR_LOG_SECTOR_SIZE_MISMATCH = 0xFFFFFDDE
+    ISAM_ERROR_LOG_SECTOR_SIZE_MISMATCH_DATABASES_CONSISTENT = 0xFFFFFDDD
+    ISAM_ERROR_LOG_SEQUENCE_END_DATABASES_CONSISTENT = 0xFFFFFDDC
+    ISAM_ERROR_STREAMING_DATA_NOT_LOGGED = 0xFFFFFDDB
+    ISAM_ERROR_DATABASE_DIRTY_SHUTDOWN = 0xFFFFFDDA
+    ISAM_ERROR_CONSISTENT_TIME_MISMATCH = 0xFFFFFDD9
+    ISAM_ERROR_DATABASE_PATCH_FILE_MISMATCH = 0xFFFFFDD8
+    ISAM_ERROR_ENDING_RESTORE_LOG_TOO_LOW = 0xFFFFFDD7
+    ISAM_ERROR_STARTING_RESTORE_LOG_TOO_HIGH = 0xFFFFFDD6
+    ISAM_ERROR_GIVEN_LOG_FILE_HAS_BAD_SIGNATURE = 0xFFFFFDD5
+    ISAM_ERROR_GIVEN_LOG_FILE_IS_NOT_CONTIGUOUS = 0xFFFFFDD4
+    ISAM_ERROR_MISSING_RESTORE_LOG_FILES = 0xFFFFFDD3
+    ISAM_ERROR_MISSING_FULL_BACKUP = 0xFFFFFDD0
+    ISAM_ERROR_BAD_BACKUP_DATABASE_SIZE = 0xFFFFFDCF
+    ISAM_ERROR_DATABASE_ALREADY_UPGRADED = 0xFFFFFDCE
+    ISAM_ERROR_DATABASE_INCOMPLETE_UPGRADE = 0xFFFFFDCD
+    ISAM_ERROR_MISSING_CURRENT_LOG_FILES = 0xFFFFFDCB
+    ISAM_ERROR_DB_TIME_TOO_OLD = 0xFFFFFDCA
+    ISAM_ERROR_DB_TIME_TOO_NEW = 0xFFFFFDC9
+    ISAM_ERROR_MISSING_FILE_TO_BACKUP = 0xFFFFFDC7
+    ISAM_ERROR_LOG_TORN_WRITE_DURING_HARD_RESTORE = 0xFFFFFDC6
+    ISAM_ERROR_LOG_TORN_WRITE_DURING_HARD_RECOVERY = 0xFFFFFDC5
+    ISAM_ERROR_LOG_CORRUPT_DURING_HARD_RESTORE = 0xFFFFFDC3
+    ISAM_ERROR_LOG_CORRUPT_DURING_HARD_RECOVERY = 0xFFFFFDC2
+    ISAM_ERROR_MUST_DISABLE_LOGGING_FOR_DB_UPGRADE = 0xFFFFFDC1
+    ISAM_ERROR_BAD_RESTORE_TARGET_INSTANCE = 0xFFFFFDBF
+    ISAM_ERROR_RECOVERED_WITHOUT_UNDO = 0xFFFFFDBD
+    ISAM_ERROR_DATABASES_NOT_FROM_SAME_SNAPSHOT = 0xFFFFFDBC
+    ISAM_ERROR_SOFT_RECOVERY_ON_SNAPSHOT = 0xFFFFFDBB
+    ISAM_ERROR_COMMITTED_LOG_FILES_MISSING = 0xFFFFFDBA
+    ISAM_ERROR_COMMITTED_LOG_FILES_CORRUPT = 0xFFFFFDB6
+    ISAM_ERROR_UNICODE_TRANSLATION_BUFFER_TOO_SMALL = 0xFFFFFDA7
+    ISAM_ERROR_UNICODE_TRANSLATION_FAIL = 0xFFFFFDA6
+    ISAM_ERROR_UNICODE_NORMALIZATION_NOT_SUPPORTED = 0xFFFFFDA5
+    ISAM_ERROR_EXISTING_LOG_FILE_HAS_BAD_SIGNATURE = 0xFFFFFD9E
+    ISAM_ERROR_EXISTING_LOG_FILE_IS_NOT_CONTIGUOUS = 0xFFFFFD9D
+    ISAM_ERROR_LOG_READ_VERIFY_FAILURE = 0xFFFFFD9C
+    ISAM_ERROR_SLV_READ_VERIFY_FAILURE = 0xFFFFFD9B
+    ISAM_ERROR_CHECKPOINT_DEPTH_TOO_DEEP = 0xFFFFFD9A
+    ISAM_ERROR_RESTORE_OF_NON_BACKUP_DATABASE = 0xFFFFFD99
+    ISAM_ERROR_INVALID_GRBIT = 0xFFFFFC7C
+    ISAM_ERROR_TERM_IN_PROGRESS = 0xFFFFFC18
+    ISAM_ERROR_FEATURE_NOT_AVAILABLE = 0xFFFFFC17
+    ISAM_ERROR_INVALID_NAME = 0xFFFFFC16
+    ISAM_ERROR_INVALID_PARAMETER = 0xFFFFFC15
+    ISAM_ERROR_DATABASE_FILE_READ_ONLY = 0xFFFFFC10
+    ISAM_ERROR_INVALID_DATABASE_ID = 0xFFFFFC0E
+    ISAM_ERROR_OUT_OF_MEMORY = 0xFFFFFC0D
+    ISAM_ERROR_OUT_OF_DATABASE_SPACE = 0xFFFFFC0C
+    ISAM_ERROR_OUT_OF_CURSORS = 0xFFFFFC0B
+    ISAM_ERROR_OUT_OF_BUFFERS = 0xFFFFFC0A
+    ISAM_ERROR_TOO_MANY_INDEXES = 0xFFFFFC09
+    ISAM_ERROR_TOO_MANY_KEYS = 0xFFFFFC08
+    ISAM_ERROR_RECORD_DELETED = 0xFFFFFC07
+    ISAM_ERROR_READ_VERIFY_FAILURE = 0xFFFFFC06
+    ISAM_ERROR_PAGE_NOT_INITIALIZED = 0xFFFFFC05
+    ISAM_ERROR_OUT_OF_FILE_HANDLES = 0xFFFFFC04
+    ISAM_ERROR_DISK_IO = 0xFFFFFC02
+    ISAM_ERROR_INVALID_PATH = 0xFFFFFC01
+    ISAM_ERROR_INVALID_SYSTEM_PATH = 0xFFFFFC00
+    ISAM_ERROR_INVALID_LOG_DIRECTORY = 0xFFFFFBFF
+    ISAM_ERROR_RECORD_TOO_BIG = 0xFFFFFBFE
+    ISAM_ERROR_TOO_MANY_OPEN_DATABASES = 0xFFFFFBFD
+    ISAM_ERROR_INVALID_DATABASE = 0xFFFFFBFC
+    ISAM_ERROR_NOT_INITIALIZED = 0xFFFFFBFB
+    ISAM_ERROR_ALREADY_INITIALIZED = 0xFFFFFBFA
+    ISAM_ERROR_INIT_IN_PROGRESS = 0xFFFFFBF9
+    ISAM_ERROR_FILE_ACCESS_DENIED = 0xFFFFFBF8
+    ISAM_ERROR_BUFFER_TOO_SMALL = 0xFFFFFBF2
+    ISAM_ERROR_TOO_MANY_COLUMNS = 0xFFFFFBF0
+    ISAM_ERROR_CONTAINER_NOT_EMPTY = 0xFFFFFBED
+    ISAM_ERROR_INVALID_FILENAME = 0xFFFFFBEC
+    ISAM_ERROR_INVALID_BOOKMARK = 0xFFFFFBEB
+    ISAM_ERROR_COLUMN_IN_USE = 0xFFFFFBEA
+    ISAM_ERROR_INVALID_BUFFER_SIZE = 0xFFFFFBE9
+    ISAM_ERROR_COLUMN_NOT_UPDATABLE = 0xFFFFFBE8
+    ISAM_ERROR_INDEX_IN_USE = 0xFFFFFBE5
+    ISAM_ERROR_LINK_NOT_SUPPORTED = 0xFFFFFBE4
+    ISAM_ERROR_NULL_KEY_DISALLOWED = 0xFFFFFBE3
+    ISAM_ERROR_NOT_IN_TRANSACTION = 0xFFFFFBE2
+    ISAM_ERROR_TOO_MANY_ACTIVE_USERS = 0xFFFFFBDD
+    ISAM_ERROR_INVALID_COUNTRY = 0xFFFFFBDB
+    ISAM_ERROR_INVALID_LANGUAGE_ID = 0xFFFFFBDA
+    ISAM_ERROR_INVALID_CODE_PAGE = 0xFFFFFBD9
+    ISAM_ERROR_INVALID_LC_MAP_STRING_FLAGS = 0xFFFFFBD8
+    ISAM_ERROR_VERSION_STORE_ENTRY_TOO_BIG = 0xFFFFFBD7
+    ISAM_ERROR_VERSION_STORE_OUT_OF_MEMORY_AND_CLEANUP_TIMED_OUT = 0xFFFFFBD6
+    ISAM_ERROR_VERSION_STORE_OUT_OF_MEMORY = 0xFFFFFBD3
+    ISAM_ERROR_CANNOT_INDEX = 0xFFFFFBD1
+    ISAM_ERROR_RECORD_NOT_DELETED = 0xFFFFFBD0
+    ISAM_ERROR_TOO_MANY_MEMPOOL_ENTRIES = 0xFFFFFBCF
+    ISAM_ERROR_OUT_OF_OBJECT_I_DS = 0xFFFFFBCE
+    ISAM_ERROR_OUT_OF_LONG_VALUE_I_DS = 0xFFFFFBCD
+    ISAM_ERROR_OUT_OF_AUTOINCREMENT_VALUES = 0xFFFFFBCC
+    ISAM_ERROR_OUT_OF_DBTIME_VALUES = 0xFFFFFBCB
+    ISAM_ERROR_OUT_OF_SEQUENTIAL_INDEX_VALUES = 0xFFFFFBCA
+    ISAM_ERROR_RUNNING_IN_ONE_INSTANCE_MODE = 0xFFFFFBC8
+    ISAM_ERROR_RUNNING_IN_MULTI_INSTANCE_MODE = 0xFFFFFBC7
+    ISAM_ERROR_SYSTEM_PARAMS_ALREADY_SET = 0xFFFFFBC6
+    ISAM_ERROR_SYSTEM_PATH_IN_USE = 0xFFFFFBC5
+    ISAM_ERROR_LOG_FILE_PATH_IN_USE = 0xFFFFFBC4
+    ISAM_ERROR_TEMP_PATH_IN_USE = 0xFFFFFBC3
+    ISAM_ERROR_INSTANCE_NAME_IN_USE = 0xFFFFFBC2
+    ISAM_ERROR_INSTANCE_UNAVAILABLE = 0xFFFFFBBE
+    ISAM_ERROR_DATABASE_UNAVAILABLE = 0xFFFFFBBD
+    ISAM_ERROR_INSTANCE_UNAVAILABLE_DUE_TO_FATAL_LOG_DISK_FULL = 0xFFFFFBBC
+    ISAM_ERROR_OUT_OF_SESSIONS = 0xFFFFFBB3
+    ISAM_ERROR_WRITE_CONFLICT = 0xFFFFFBB2
+    ISAM_ERROR_TRANS_TOO_DEEP = 0xFFFFFBB1
+    ISAM_ERROR_INVALID_SESID = 0xFFFFFBB0
+    ISAM_ERROR_WRITE_CONFLICT_PRIMARY_INDEX = 0xFFFFFBAF
+    ISAM_ERROR_IN_TRANSACTION = 0xFFFFFBAC
+    ISAM_ERROR_ROLLBACK_REQUIRED = 0xFFFFFBAB
+    ISAM_ERROR_TRANS_READ_ONLY = 0xFFFFFBAA
+    ISAM_ERROR_SESSION_WRITE_CONFLICT = 0xFFFFFBA9
+    ISAM_ERROR_RECORD_TOO_BIG_FOR_BACKWARD_COMPATIBILITY = 0xFFFFFBA8
+    ISAM_ERROR_CANNOT_MATERIALIZE_FORWARD_ONLY_SORT = 0xFFFFFBA7
+    ISAM_ERROR_SESID_TABLE_ID_MISMATCH = 0xFFFFFBA6
+    ISAM_ERROR_INVALID_INSTANCE = 0xFFFFFBA5
+    ISAM_ERROR_DATABASE_DUPLICATE = 0xFFFFFB4F
+    ISAM_ERROR_DATABASE_IN_USE = 0xFFFFFB4E
+    ISAM_ERROR_DATABASE_NOT_FOUND = 0xFFFFFB4D
+    ISAM_ERROR_DATABASE_INVALID_NAME = 0xFFFFFB4C
+    ISAM_ERROR_DATABASE_INVALID_PAGES = 0xFFFFFB4B
+    ISAM_ERROR_DATABASE_CORRUPTED = 0xFFFFFB4A
+    ISAM_ERROR_DATABASE_LOCKED = 0xFFFFFB49
+    ISAM_ERROR_CANNOT_DISABLE_VERSIONING = 0xFFFFFB48
+    ISAM_ERROR_INVALID_DATABASE_VERSION = 0xFFFFFB47
+    ISAM_ERROR_DATABASE200_FORMAT = 0xFFFFFB46
+    ISAM_ERROR_DATABASE400_FORMAT = 0xFFFFFB45
+    ISAM_ERROR_DATABASE500_FORMAT = 0xFFFFFB44
+    ISAM_ERROR_PAGE_SIZE_MISMATCH = 0xFFFFFB43
+    ISAM_ERROR_TOO_MANY_INSTANCES = 0xFFFFFB42
+    ISAM_ERROR_DATABASE_SHARING_VIOLATION = 0xFFFFFB41
+    ISAM_ERROR_ATTACHED_DATABASE_MISMATCH = 0xFFFFFB40
+    ISAM_ERROR_DATABASE_INVALID_PATH = 0xFFFFFB3F
+    ISAM_ERROR_DATABASE_ID_IN_USE = 0xFFFFFB3E
+    ISAM_ERROR_FORCE_DETACH_NOT_ALLOWED = 0xFFFFFB3D
+    ISAM_ERROR_CATALOG_CORRUPTED = 0xFFFFFB3C
+    ISAM_ERROR_PARTIALLY_ATTACHED_DB = 0xFFFFFB3B
+    ISAM_ERROR_DATABASE_SIGN_IN_USE = 0xFFFFFB3A
+    ISAM_ERROR_DATABASE_CORRUPTED_NO_REPAIR = 0xFFFFFB38
+    ISAM_ERROR_INVALID_CREATE_DB_VERSION = 0xFFFFFB37
+    ISAM_ERROR_TABLE_LOCKED = 0xFFFFFAEA
+    ISAM_ERROR_TABLE_DUPLICATE = 0xFFFFFAE9
+    ISAM_ERROR_TABLE_IN_USE = 0xFFFFFAE8
+    ISAM_ERROR_OBJECT_NOT_FOUND = 0xFFFFFAE7
+    ISAM_ERROR_DENSITY_INVALID = 0xFFFFFAE5
+    ISAM_ERROR_TABLE_NOT_EMPTY = 0xFFFFFAE4
+    ISAM_ERROR_INVALID_TABLE_ID = 0xFFFFFAE2
+    ISAM_ERROR_TOO_MANY_OPEN_TABLES = 0xFFFFFAE1
+    ISAM_ERROR_ILLEGAL_OPERATION = 0xFFFFFAE0
+    ISAM_ERROR_TOO_MANY_OPEN_TABLES_AND_CLEANUP_TIMED_OUT = 0xFFFFFADF
+    ISAM_ERROR_OBJECT_DUPLICATE = 0xFFFFFADE
+    ISAM_ERROR_INVALID_OBJECT = 0xFFFFFADC
+    ISAM_ERROR_CANNOT_DELETE_TEMP_TABLE = 0xFFFFFADB
+    ISAM_ERROR_CANNOT_DELETE_SYSTEM_TABLE = 0xFFFFFADA
+    ISAM_ERROR_CANNOT_DELETE_TEMPLATE_TABLE = 0xFFFFFAD9
+    ISAM_ERROR_EXCLUSIVE_TABLE_LOCK_REQUIRED = 0xFFFFFAD6
+    ISAM_ERROR_FIXED_DDL = 0xFFFFFAD5
+    ISAM_ERROR_FIXED_INHERITED_DDL = 0xFFFFFAD4
+    ISAM_ERROR_CANNOT_NEST_DDL = 0xFFFFFAD3
+    ISAM_ERROR_DDL_NOT_INHERITABLE = 0xFFFFFAD2
+    ISAM_ERROR_INVALID_SETTINGS = 0xFFFFFAD0
+    ISAM_ERROR_CLIENT_REQUEST_TO_STOP_JET_SERVICE = 0xFFFFFACF
+    ISAM_ERROR_CANNOT_ADD_FIXED_VAR_COLUMN_TO_DERIVED_TABLE = 0xFFFFFACE
+    ISAM_ERROR_INDEX_CANT_BUILD = 0xFFFFFA87
+    ISAM_ERROR_INDEX_HAS_PRIMARY = 0xFFFFFA86
+    ISAM_ERROR_INDEX_DUPLICATE = 0xFFFFFA85
+    ISAM_ERROR_INDEX_NOT_FOUND = 0xFFFFFA84
+    ISAM_ERROR_INDEX_MUST_STAY = 0xFFFFFA83
+    ISAM_ERROR_INDEX_INVALID_DEF = 0xFFFFFA82
+    ISAM_ERROR_INVALID_CREATE_INDEX = 0xFFFFFA7F
+    ISAM_ERROR_TOO_MANY_OPEN_INDEXES = 0xFFFFFA7E
+    ISAM_ERROR_MULTI_VALUED_INDEX_VIOLATION = 0xFFFFFA7D
+    ISAM_ERROR_INDEX_BUILD_CORRUPTED = 0xFFFFFA7C
+    ISAM_ERROR_PRIMARY_INDEX_CORRUPTED = 0xFFFFFA7B
+    ISAM_ERROR_SECONDARY_INDEX_CORRUPTED = 0xFFFFFA7A
+    ISAM_ERROR_INVALID_INDEX_ID = 0xFFFFFA78
+    ISAM_ERROR_INDEX_TUPLES_SECONDARY_INDEX_ONLY = 0xFFFFFA6A
+    ISAM_ERROR_INDEX_TUPLES_TOO_MANY_COLUMNS = 0xFFFFFA69
+    ISAM_ERROR_INDEX_TUPLES_NON_UNIQUE_ONLY = 0xFFFFFA68
+    ISAM_ERROR_INDEX_TUPLES_TEXT_BINARY_COLUMNS_ONLY = 0xFFFFFA67
+    ISAM_ERROR_INDEX_TUPLES_VAR_SEG_MAC_NOT_ALLOWED = 0xFFFFFA66
+    ISAM_ERROR_INDEX_TUPLES_INVALID_LIMITS = 0xFFFFFA65
+    ISAM_ERROR_INDEX_TUPLES_CANNOT_RETRIEVE_FROM_INDEX = 0xFFFFFA64
+    ISAM_ERROR_INDEX_TUPLES_KEY_TOO_SMALL = 0xFFFFFA63
+    ISAM_ERROR_COLUMN_LONG = 0xFFFFFA23
+    ISAM_ERROR_COLUMN_NO_CHUNK = 0xFFFFFA22
+    ISAM_ERROR_COLUMN_DOES_NOT_FIT = 0xFFFFFA21
+    ISAM_ERROR_NULL_INVALID = 0xFFFFFA20
+    ISAM_ERROR_COLUMN_INDEXED = 0xFFFFFA1F
+    ISAM_ERROR_COLUMN_TOO_BIG = 0xFFFFFA1E
+    ISAM_ERROR_COLUMN_NOT_FOUND = 0xFFFFFA1D
+    ISAM_ERROR_COLUMN_DUPLICATE = 0xFFFFFA1C
+    ISAM_ERROR_MULTI_VALUED_COLUMN_MUST_BE_TAGGED = 0xFFFFFA1B
+    ISAM_ERROR_COLUMN_REDUNDANT = 0xFFFFFA1A
+    ISAM_ERROR_INVALID_COLUMN_TYPE = 0xFFFFFA19
+    ISAM_ERROR_TAGGED_NOT_NULL = 0xFFFFFA16
+    ISAM_ERROR_NO_CURRENT_INDEX = 0xFFFFFA15
+    ISAM_ERROR_KEY_IS_MADE = 0xFFFFFA14
+    ISAM_ERROR_BAD_COLUMN_ID = 0xFFFFFA13
+    ISAM_ERROR_BAD_ITAG_SEQUENCE = 0xFFFFFA12
+    ISAM_ERROR_COLUMN_IN_RELATIONSHIP = 0xFFFFFA11
+    ISAM_ERROR_CANNOT_BE_TAGGED = 0xFFFFFA0F
+    ISAM_ERROR_DEFAULT_VALUE_TOO_BIG = 0xFFFFFA0C
+    ISAM_ERROR_MULTI_VALUED_DUPLICATE = 0xFFFFFA0B
+    ISAM_ERROR_LV_CORRUPTED = 0xFFFFFA0A
+    ISAM_ERROR_MULTI_VALUED_DUPLICATE_AFTER_TRUNCATION = 0xFFFFFA08
+    ISAM_ERROR_DERIVED_COLUMN_CORRUPTION = 0xFFFFFA07
+    ISAM_ERROR_INVALID_PLACEHOLDER_COLUMN = 0xFFFFFA06
+    ISAM_ERROR_RECORD_NOT_FOUND = 0xFFFFF9BF
+    ISAM_ERROR_RECORD_NO_COPY = 0xFFFFF9BE
+    ISAM_ERROR_NO_CURRENT_RECORD = 0xFFFFF9BD
+    ISAM_ERROR_RECORD_PRIMARY_CHANGED = 0xFFFFF9BC
+    ISAM_ERROR_KEY_DUPLICATE = 0xFFFFF9BB
+    ISAM_ERROR_ALREADY_PREPARED = 0xFFFFF9B9
+    ISAM_ERROR_KEY_NOT_MADE = 0xFFFFF9B8
+    ISAM_ERROR_UPDATE_NOT_PREPARED = 0xFFFFF9B7
+    ISAM_ERROR_DATA_HAS_CHANGED = 0xFFFFF9B5
+    ISAM_ERROR_LANGUAGE_NOT_SUPPORTED = 0xFFFFF9AD
+    ISAM_ERROR_TOO_MANY_SORTS = 0xFFFFF95B
+    ISAM_ERROR_INVALID_ON_SORT = 0xFFFFF95A
+    ISAM_ERROR_TEMP_FILE_OPEN_ERROR = 0xFFFFF8F5
+    ISAM_ERROR_TOO_MANY_ATTACHED_DATABASES = 0xFFFFF8F3
+    ISAM_ERROR_DISK_FULL = 0xFFFFF8F0
+    ISAM_ERROR_PERMISSION_DENIED = 0xFFFFF8EF
+    ISAM_ERROR_FILE_NOT_FOUND = 0xFFFFF8ED
+    ISAM_ERROR_FILE_INVALID_TYPE = 0xFFFFF8EC
+    ISAM_ERROR_AFTER_INITIALIZATION = 0xFFFFF8C6
+    ISAM_ERROR_LOG_CORRUPTED = 0xFFFFF8C4
+    ISAM_ERROR_INVALID_OPERATION = 0xFFFFF88E
+    ISAM_ERROR_ACCESS_DENIED = 0xFFFFF88D
+    ISAM_ERROR_TOO_MANY_SPLITS = 0xFFFFF88B
+    ISAM_ERROR_SESSION_SHARING_VIOLATION = 0xFFFFF88A
+    ISAM_ERROR_ENTRY_POINT_NOT_FOUND = 0xFFFFF889
+    ISAM_ERROR_SESSION_CONTEXT_ALREADY_SET = 0xFFFFF888
+    ISAM_ERROR_SESSION_CONTEXT_NOT_SET_BY_THIS_THREAD = 0xFFFFF887
+    ISAM_ERROR_SESSION_IN_USE = 0xFFFFF886
+    ISAM_ERROR_RECORD_FORMAT_CONVERSION_FAILED = 0xFFFFF885
+    ISAM_ERROR_ONE_DATABASE_PER_SESSION = 0xFFFFF884
+    ISAM_ERROR_ROLLBACK_ERROR = 0xFFFFF883
+    ISAM_ERROR_CALLBACK_FAILED = 0xFFFFF7CB
+    ISAM_ERROR_CALLBACK_NOT_RESOLVED = 0xFFFFF7CA
+    ISAM_ERROR_OS_SNAPSHOT_INVALID_SEQUENCE = 0xFFFFF69F
+    ISAM_ERROR_OS_SNAPSHOT_TIME_OUT = 0xFFFFF69E
+    ISAM_ERROR_OS_SNAPSHOT_NOT_ALLOWED = 0xFFFFF69D
+    ISAM_ERROR_OS_SNAPSHOT_INVALID_SNAP_ID = 0xFFFFF69C
+    ISAM_ERROR_LS_CALLBACK_NOT_SPECIFIED = 0xFFFFF448
+    ISAM_ERROR_LS_ALREADY_SET = 0xFFFFF447
+    ISAM_ERROR_LS_NOT_SET = 0xFFFFF446
+    ISAM_ERROR_FILE_IO_SPARSE = 0xFFFFF060
+    ISAM_ERROR_FILE_IO_BEYOND_EOF = 0xFFFFF05F
+    ISAM_ERROR_FILE_COMPRESSED = 0xFFFFF05B
+
+
+
+class Gender(enum.Enum):
+    # Seems rather binary, which is less than ideal. We are directly using the
+    # terms used by the documentation.
+    UNSPECIFIED = 0x0000
+    FEMALE = 0x0001
+    MALE = 0x0002
+
+
+
+class IconIndex(enum.Enum):
+    @classmethod
+    def tryMake(cls, value : int) -> Union['IconIndex', int]:
+        """
+        Try to make an instance, returning the value on failure.
+        """
+        try:
+            return cls(value)
+        except ValueError:
+            return value
+
+    UNSPECIFIED = 0xFFFFFFFF
+    SINGLE_INSTANCE_APPOINTMENT = 0x00000400
+    RECURRING_APPOINTMENT = 0x00000401
+    SINGLE_INSTANCE_MEETING = 0x00000402
+    RECURRING_MEETING = 0x00000403
+    MEETING_REQUEST_UPDATE = 0x00000404
+    ACCEPT_MEETING_REQUEST = 0x00000405
+    DECLINE_MEETING_REQUEST = 0x00000406
+    TENTATIVELY_ACCEPT_MEETING_REQUEST = 0x00000407
+    MEETING_CANCELLATION = 0x00000408
+    MEETING_UPDATE_INFORMATIONAL = 0x00000409
+    FORWARD_NOTIFICATION = 0x0000040B
+
+
+
+class Importance(enum.Enum):
+    LOW = 0
+    MEDIUM = 1
+    HIGH = 2
+
+
+
+class Intelligence(enum.Enum):
+    ERROR = -1
+    DUMB = 0
+    SMART = 1
+
+
+
+class MacintoshEncoding(enum.Enum):
+    """
+    The encoding to use for Macintosh-specific data attachments.
+    """
+    BIN_HEX = 0
+    UUENCODE = 1
+    APPLE_SINGLE = 2
+    APPLE_DOUBLE = 3
+
+
+
+class MeetingObjectChange(enum.Enum):
+    """
+    Indicates a property that has changed on a meeting object.
+
+    START: The start has changed.
+    END: The end has changed.
+    RECUR: The recurrence pattern has changed.
+    LOCATION: The location has changed.
+    SUBJECT: The subject has changed.
+    REQUIRED_ATTENDEE: One or more required attendees were added.
+    OPTIONAL_ATTENDEE: One or more optional attendees were added.
+    BODY: The body was modified.
+    RESPONSE: The responseRequested or replyRequested property has changed.
+    ALLOW_PROPOSE: The appointmentNotAllowPropose property has changed.
+    """
+    @classmethod
+    def fromBits(cls, value : int) -> Set['MeetingObjectChange']:
+        """
+        Takes an int and returns a set of the changes.
+        """
+        changes = set()
+        for x in range(32):
+            if x in (8, 11) or (12 < x < 31):
+                continue
+            bit = value & (1 << x)
+            if bit:
+                if x in (12, 31):
+                    raise ValueError('Reserved bit was set.')
+                changes.add(cls(bit))
+
+        return changes
+
+    START = 0b1
+    END = 0b10
+    RECUR = 0b100
+    LOCATION = 0b1000
+    SUBJECT = 0b10000
+    REQUIRED_ATTENDEE = 0b100000
+    OPTIONAL_ATTENDEE = 0b1000000
+    BODY = 0b10000000
+    RESPONSE = 0b1000000000
+    ALLOW_PROPOSE = 0b10000000000
+    DEPRECATED = 0b100000000000
+
+
+
+class MeetingRecipientType(enum.Enum):
+    ORGANIZER = 0x01
+    SENDABLE_REQUIRED_ATTENDEE = 0x01
+    SENDABLE_OPTIONAL_ATTENDEE = 0x02
+    SENDABLE_RESOURCE_OBJECT = 0x03
+
+
+
+class MeetingType(enum.Enum):
+    """
+    The type of Meeting Request object of Meeting Update object.
+
+    EMPTY: Unspecified.
+    REQUEST: The meeting request is the initial request.
+    FULL: Attendees were added, the meeting was cancelled and the organizer is
+        uncancelling it, and or the start, end, or recurrance property was
+        changed.
+    INFO: An informational update was made to the meeting and it is not one of
+        the conditions for FULL.
+    OUT_OF_DATE: A newer Meeting Request object or MeetingUpdate object was
+        received after this one.
+    DELEGATOR_COPY: Set on the delegator's copy when a delegate will handle
+        meeting-related objects.
+    """
+    EMPTY = 0x00000000
+    REQUEST = 0x00000001
+    FULL = 0x00010000
+    INFO = 0x00020000
+    OUT_OF_DATE = 0x00080000
+    DELEGATOR_COPY = 0x00100000
+
+
+
+class MessageFormat(enum.Enum):
+    TNEF = 0
+    MIME = 1
+
+
+
+class MessageType(enum.Enum):
+    PRIVATE_FOLDER = 0x0001
+    PUBLIC_FOLDER = 0x0003
+    MAPPED_PUBLIC_FOLDER = 0x0005
+    PRIVATE_MESSAGE = 0x0007
+    PUBLIC_MESSAGE = 0x0009
+    MAPPED_PUBLIC_MESSAGE = 0x000B
+    PUBLIC_NEWSGROUP_FOLDER = 0x000C
+
+
+
+class NamedPropertyType(enum.Enum):
+    NUMERICAL_NAMED = 0
+    STRING_NAMED = 1
+
+
+
+class OORBodyFormat(enum.Enum):
+    """
+    The body format for One Off Recipients.
+    """
+    TEXT_ONLY = 0b0011
+    HTML_ONLY = 0b0111
+    TEXT_AND_HTML = 0b1011
+    # This one isn't actually listed in the documentation, but I've seen it and
+    # this is my best guess for what a format of `0` is meant to mean. This will
+    # also prevent the code from failing on a 0 format.
+    UNSPECIFIED = 0b0000
+
+
+
+class PostalAddressID(enum.Enum):
+    UNSPECIFIED = 0x00000000
+    HOME = 0x00000001
+    WORK = 0x00000002
+    OTHER = 0x00000003
+
+
+
+class Priority(enum.Enum):
+    URGENT = 0x00000001
+    NORMAL = 0x00000000
+    NOT_URGENT = 0xFFFFFFFF
+
+
+
+class PropertiesType(enum.Enum):
+    """
+    The type of the properties instance.
+    """
+    MESSAGE = 0
+    MESSAGE_EMBED = 1
+    ATTACHMENT = 2
+    RECIPIENT = 3
+
+
+
+class RecipientRowFlagType(enum.Enum):
+    NOTYPE = 0x0
+    X500DN = 0x1
+    MSMAIL = 0x2
+    SMTP = 0x3
+    FAX = 0x4
+    PROFESSIONALOFFICESYSTEM = 0x5
+    PERSONALDESTRIBUTIONLIST1 = 0x6
+    PERSONALDESTRIBUTIONLIST2 = 0x7
+
+
+
+class RecipientType(enum.Enum):
+    """
+    The type of recipient.
+    """
+    SENDER = 0
+    TO = 1
+    CC = 2
+    BCC = 3
+
+
+
+class RecurCalendarType(enum.Enum):
+    DEFAULT = 0x0000
+    CAL_GREGORIAN = 0x0001
+    CAL_GREGORIAN_US = 0x0002
+    CAL_JAPAN = 0x0003
+    CAL_TAIWAN = 0x0004
+    CAL_KOREA = 0x0005
+    CAL_HIJRI = 0x0006
+    CAL_THAI = 0x0007
+    CAL_HEBREW = 0x0008
+    CAL_GREGORIAN_ME_FRENCH = 0x0009
+    CAL_GREGORIAN_ARABIC = 0x000A
+    CAL_GREGORIAN_XLIT_ENGLISH = 0x000B
+    CAL_GREGORIAN_XLIT_FRENCH = 0x000C
+    CAL_LUNAR_JAPANESE = 0x000E
+    CAL_CHINESE_LUNAR = 0x000F
+    CAL_SAKA = 0x0010
+    CAL_LUNAR_ETO_CHN = 0x0011
+    CAL_LUNAR_ETO_KOR = 0x0012
+    CAL_LUNAR_ROKUYOU = 0x0013
+    CAL_LUNAR_KOREAN = 0x0014
+    CAL_UMALQURA = 0x0017
+
+
+
+class RecurDOW(enum.Enum):
+    SUNDAY = 0x00000000
+    MONDAY = 0x00000001
+    TUESDAY = 0x00000002
+    WEDNESDAY = 0x00000003
+    THURSDAY = 0x00000004
+    FRIDAY = 0x00000005
+    SATURDAY = 0x00000006
+
+
+
+class RecurEndType(enum.Enum):
+    @classmethod
+    def fromInt(cls, value) -> 'RecurEndType':
+        """
+        Some enum values CAN be created from more than one int, so handle that.
+        """
+        return cls(0x00002023) if value == 0xFFFFFFFF else cls(value)
+
+    END_AFTER_DATE = 0x00002021
+    END_AFTER_N_OCCURRENCES = 0x00002022
+    NEVER_END = 0x00002023
+
+
+class RecurFrequency(enum.Enum):
+    """
+    See [MS-OXOCAL] for details.
+    """
+    DAILY = 0x200A
+    WEEKLY = 0x200B
+    MONTHLY = 0x200C
+    YEARLY = 0x200D
+
+
+
+class RecurMonthNthWeek(enum.Enum):
+    FIRST = 0x00000001
+    SECOND = 0x00000002
+    THIRD = 0x00000003
+    FOURTH = 0x00000004
+    LAST = 0x00000005
+
+
+
+class RecurPatternTypeSpecificWeekday(enum.Enum):
+    """
+    See [MS-OXOCAL] for details.
+    """
+    @classmethod
+    def fromBits(cls, value : int) -> Set['RecurPatternTypeSpecificWeekday']:
+        """
+        Takes an int and returns a set of the weekdays.
+        """
+        return {cls(1 << x) for x in range(1, 8) if (value & (1 << x))}
+
+    SATURDAY = 0b10
+    FRIDAY = 0b100
+    THURSDAY = 0b1000
+    WEDNESDAY = 0b10000
+    TUESDAY = 0b100000
+    MONDAY = 0b1000000
+    SUNDAY = 0b10000000
+
+
+
+class RecurPatternType(enum.Enum):
+    """
+    See [MS-OXOCAL] for details.
+    """
+    DAY = 0x0000
+    WEEK = 0x0001
+    MONTH = 0x0002
+    MONTH_NTH = 0x0003
+    MONTH_END = 0x0004
+    HJ_MONTH = 0x000A
+    HJ_MONTH_NTH = 0x000B
+    HJ_MONTH_END = 0x000C
+
+
+
+class ResponseStatus(enum.Enum):
+    """
+    The response status of an attendee.
+
+    NONE: No response is required for this object.
+    ORGANIZED: This Meeting object belongs to the organizer.
+    TENTATIVE: The attendee has tentatively accepted.
+    ACCEPTED: The attendee has accepted.
+    DECLINED: The attendee has declined.
+    NOT_RESPONDED: The attendee has not yet responded.
+    """
+    NONE = 0x00000000
+    ORGANIZED = 0x00000001
+    TENTATIVE = 0x00000002
+    ACCEPTED = 0x00000003
+    DECLINED = 0x00000004
+    NOT_RESPONDED = 0x00000005
+
+
+
+class ResponseType(enum.Enum):
+    """
+    The type of response for a Meeting Response object.
+    """
+    ACCEPT = 'pos'
+    DECLINE = 'neg'
+    TENTATIVE = 'tent'
+
+
+
+class RuleActionType(enum.Enum):
+    OP_MOVE = 0x01
+    OP_COPY = 0x02
+    OP_REPLY = 0x03
+    OP_OOF_REPLY = 0x04
+    OP_DEFER_ACTION = 0x05
+    OP_BOUNCE = 0x06
+    OP_FORWARD = 0x07
+    OP_DELEGATE = 0x08
+    OP_TAG = 0x09
+    OP_DELETE = 0x0A
+    OP_MARK_AS_READ = 0x0B
+
+
+
+class Sensitivity(enum.Enum):
+    NORMAL = 0
+    PERSONAL = 1
+    PRIVATE = 2
+    CONFIDENTIAL = 3
+
+
+
+class ServerProcessingAction(enum.Enum):
+    """
+    Actions taken on a meeting-related object.
+    """
+    @classmethod
+    def fromBits(cls, value : int) -> Set['ServerProcessingAction']:
+        """
+        Takes an int and returns a set of the weekdays.
+        """
+        return {cls(1 << x) for x in range(16) if (value & (1 << x))}
+
+    DELEGATOR_WANTS_COPY = 0x00000002
+    CREATED_ON_PRINCIPLE = 0x00000010
+    UPDATED_CAL_ITEM = 0x00000080
+    COPIED_OLD_PROPERTIES = 0x00000100
+    SEND_AUTO_RESPONSE = 0x00000400
+    REVIVED_EXCEPTION = 0x00000800
+    PROCESSED_MEETING_FORWARD_NOTIFICATION = 0x00001000
+
+
+
+class SideEffect(enum.Enum):
+    """
+    A flag for how a Message object is handled by the client in relation to
+    certain user interface actions.
+
+    OPEN_TO_DELETE: The client opens the Message object when deleting.
+    NO_FRAME: No UI is associated with the Message object.
+    COERCE_TO_INDEX: The client moves the Message object to the Inbox folder
+        when moving or copying to a Folder object with the PidTagContainerClass
+        property set to "IPF.Note".
+    OPEN_TO_COPY: The client opens the Message object when copying to another
+        folder.
+    OPEN_TO_MOVE: The client opens the Message object when moving to another
+        folder.
+    OPEN_FOR_CTX_MENU: The client opens the Message object when displaying
+        context-sensitive commands, such as a context menu, to the end user.
+    CANNOT_UNDO_DELETE: The client cannot undo a delete operation. Must not be
+        set unless the OPEN_TO_DELETE flag is set.
+    CANNOT_UNDO_COPY: The client cannot undo a copy operation. Must not be set
+        unless the OPEN_TO_COPY flag is set.
+    CANNOT_UNDO_MOVE: The client cannot undo a move operation. Must not be set
+        unless the OPEN_TO_MOVE flag is set.
+    HAS_SCRIPT: The Message object contains end-user script.
+    OPEN_TO_PERM_DELETE: The client opens the Message object to permanently
+        delete it.
+    """
+    @classmethod
+    def fromBits(cls, value : int) -> Set['SideEffect']:
+        """
+        Takes an int and returns a set of the side effects.
+        """
+        return {cls(1 << x) for x in range(15) if (value & (1 << x))}
+
+    OPEN_TO_DELETE = 0b1
+    NO_FRAME = 0b1000
+    COERCE_TO_INDEX = 0b10000
+    OPEN_TO_COPY = 0b100000
+    OPEN_TO_MOVE = 0b1000000
+    OPEN_FOR_CTX_MENU = 0b100000000
+    CANNOT_UNDO_DELETE = 0b10000000000
+    CANNOT_UNDO_COPY = 0b100000000000
+    CANNOT_UNDO_MOVE = 0b1000000000000
+    HAS_SCRIPT = 0b10000000000000
+    OPEN_TO_PERM_DELETE = 0b100000000000000
+
+
+
+class TaskAcceptance(enum.Enum):
+    """
+    The acceptance state of the task.
+    """
+    NOT_ASSIGNED = 0x00000000
+    UNKNOWN = 0x00000001
+    ACCEPTED = 0x00000002
+    REJECTED = 0x00000003
+
+
+
+class TaskHistory(enum.Enum):
+    """
+    The type of the last change to the Task object.
+    """
+    NONE = 0x00000000
+    ACCEPTED = 0x00000001
+    REJECTED = 0x00000002
+    OTHER = 0x00000003
+    DUE_DATE_CHANGED = 0x00000004
+    ASSIGNED = 0x00000005
+
+
+
+class TaskMode(enum.Enum):
+    """
+    The mode of the Task object used in task communication (PidLidTaskMode).
+
+    UNASSIGNED: The Task object is not assigned.
+    EMBEDDED_REQUEST: The Task object is embedded in a task request.
+    ACCEPTED: The Task object has been accepted by the task assignee.
+    REJECTED: The Task object was rejected by the task assignee.
+    EMBEDDED_UPDATE: The Task object is embedded in a task update.
+    SELF_ASSIGNED: The Task object was assigned to the task assigner
+        (self-delegation).
+    """
+    UNASSIGNED = 0
+    EMBEDDED_REQUEST = 1
+    ACCEPTED = 2
+    REJECTED = 3
+    EMBEDDED_UPDATE = 4
+    SELF_ASSIGNED = 5
+
+
+
+class TaskMultipleRecipients(enum.Enum):
+    @classmethod
+    def fromBits(cls, value : int) -> Set['TaskMultipleRecipients']:
+        """
+        Takes an int and returns a set of the flags.
+        """
+        return {cls(1 << x) for x in range(2) if (value & (1 << x))}
+
+    SENT = 0x00000001
+    RECEIVED = 0x00000002
+
+
+
+class TaskOwnership(enum.Enum):
+    """
+    The role of the current user relative to the Task object.
+
+    NOT_ASSIGNED: The Task object is not assigned.
+    ASSIGNERS_COPY: The Task object is the task assigner's copy of the Task
+        object.
+    ASSIGNEES_COPY: The Task object is the task assignee's copy of the Task
+        object.
+    """
+    NOT_ASSIGNED = 0x00000000
+    ASSIGNERS_COPY = 0x00000001
+    ASSIGNEES_COPY = 0x00000002
+
+
+
+class TaskRequestType(enum.Enum):
+    """
+    The type of task request.
+
+    REQUEST: A plain request.
+    ACCEPT: Task has been accepted.
+    DECLINE: Task has been declined.
+    UPDATE: Task has been updated.
+    """
+    @classmethod
+    def fromClassType(cls, classType : str) -> 'TaskRequestType':
+        """
+        Convert a class type string into a TaskRequestType.
+        """
+        classType = classType.lower()
+        if 'accept' in classType:
+            return cls(1)
+        if 'decline' in classType:
+            return cls(2)
+        if 'update' in classType:
+            return cls(3)
+        return cls(0)
+
+    REQUEST = 0
+    ACCEPT = 1
+    DECLINE = 2
+    UPDATE = 3
+
+
+
+class TaskState(enum.Enum):
+    """
+    NOT_ASSIGNED: The Task object is not assigned.
+    ASSIGNEES_COPY_ACCEPTED: The Task object is the task assignee's copy of an
+        assigned Task object.
+    ASSIGNERS_COPY_ACCEPTED: The Task object is the task assigner's copy of an
+        assigned Task object.
+    ASSIGNERS_COPY_REJECTED: The Task object is the task assigner's copy of a
+        rejected Task object.
+    EMBEDDED_REJECTION: This Task object was created to correspond to a Task
+        object that was embedded in a task rejection but could not be found
+        locally.
+    """
+    NOT_ASSIGNED = 0x00000001
+    ASSIGNEES_COPY_ACCEPTED = 0x00000002
+    ASSIGNERS_COPY_ACCEPTED = 0x00000003
+    ASSIGNERS_COPY_REJECTED = 0x00000004
+    EMBEDDED_REJECTION = 0x00000005
+
+
+
+class TaskStatus(enum.Enum):
+    """
+    The status of a task object (PidLidTaskStatus).
+
+    NOT_STARTED: The user has not started the task.
+    IN_PROGRESS: The users's work on the Task object is in progress.
+    COMPLETE: The user's work on the Task object is complete.
+    WAITING_ON_OTHER: The user is waiting on somebody else.
+    DEFERRED: The user has deferred work on the Task object.
+    """
+    NOT_STARTED = 0x00000000
+    IN_PROGRESS = 0x00000001
+    COMPLETE = 0x00000002
+    WAITING_ON_OTHER = 0x00000003
+    DEFERRED = 0x00000004
+
+
+
+class TZFlag(enum.Enum):
+    """
+    Flags for a TZRule object as defined in [MS-OXOCAL].
+
+    RECUR_CURRENT_TZREG: The rule is associated with a recurring series.
+    EFFECTIVE_TZREG: The rule is the effective rule.
+    """
+    @classmethod
+    def fromBits(cls, value : int) -> Set['TZFlag']:
+        """
+        Takes an int and returns a set of the flags.
+        """
+        return {cls(1 << x) for x in range(2) if (value & (1 << x))}
+
+    RECUR_CURRENT_TZREG = 0b1
+    EFFECTIVE_TZREG = 0b10
+
+
+
+class _EnumDeprecator:
+    """
+    Special class for handling deprecated enums in a way that shouldn't break 
+    existing code, including code for checking `is` on a member of the enum.
+    """
+    def __init__(self, oldClassName : str, newClass : enum.Enum, nameConversion : dict = {}, valueConversion : dict = {}):
+        """
+        :param oldClassName: The name to use in the deprecation message.
+        :param newClass: The new enum class to look for the value in.
+        :param nameConversion: A dictionary of old names to new names to
+            convert if needed. If a name is the same, it can be omitted.
+        :param valueConversion: A dictionary of old values to new values used
+            when getting a value from the enum.
+        """
+        self.__warnMessage = f'Enum `{oldClassName}` is deprecated and has been replaced with {newClass.__name__}. Please update your code.'
+        self.__new = newClass
+        self.__nameConv = nameConversion
+        self.__valConv = valueConversion
+
+    def __call__(self, val):
+        # Warn about the deprecation
+        import warnings
+        warnings.warn(self.__warnMessage, DeprecationWarning)
+
+        return self.__new(self.__valConv.get(val, val))
+
+    def __getattr__(self, key):
+        # Warn about the deprecation
+        import warnings
+        warnings.warn(self.__warnMessage, DeprecationWarning)
+
+        return getattr(self.__new, self.__nameConv.get(key, key))
+    
+    def __getitem__(self, name):
+        # Warn about the deprecation
+        import warnings
+        warnings.warn(self.__warnMessage, DeprecationWarning)
+
+        return self.__new.__getitem__(self.__nameConv.get(name, name))
+
+
+
+
+# Deprecated Enums
+AttachErrorBehavior = _EnumDeprecator(
+    'AttachErrorBehavior', 
+    ErrorBehavior,
+    {
+        'BROKEN': 'ATTACH_SUPPRESS_ALL',
+        'NOT_IMPLEMENTED': 'ATTACH_NOT_IMPLEMENTED',
+    },
+    {
+        2: 3
+    })
```

### Comparing `extract_msg-0.40.0/extract_msg/logging-config/logging-posix.json` & `extract_msg-0.41.0/extract_msg/logging-config/logging-nt.json`

 * *Files 23% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9976190476190476%*

 * *Differences: {"'handlers'": "{'info_file_handler': {'filename': '%LOCALAPPDATA%/extract_msg/extract_msg.log'}, "*

 * *               "'error_file_handler': {'filename': '%LOCALAPPDATA%/extract_msg/extract_msg.log'}, "*

 * *               "'warning_file_handler': {'filename': "*

 * *               "'%LOCALAPPDATA%/extract_msg/extract_msg.log'}, 'developer_file_handler': "*

 * *               "{'filename': '%LOCALAPPDATA%/extract_msg/extract_msg.log'}}"}*

```diff
@@ -12,42 +12,42 @@
             "level": "DEBUG",
             "stream": "ext://sys.stdout"
         },
         "developer_file_handler": {
             "backupCount": 20,
             "class": "logging.handlers.RotatingFileHandler",
             "encoding": "utf8",
-            "filename": "/var/log/extract_msg/extract_msg.log",
+            "filename": "%LOCALAPPDATA%/extract_msg/extract_msg.log",
             "formatter": "simple",
             "level": "DEVELOPER",
             "maxBytes": 10485760
         },
         "error_file_handler": {
             "backupCount": 20,
             "class": "logging.handlers.RotatingFileHandler",
             "encoding": "utf8",
-            "filename": "/var/log/extract_msg/extract_msg.log",
+            "filename": "%LOCALAPPDATA%/extract_msg/extract_msg.log",
             "formatter": "simple",
             "level": "ERROR",
             "maxBytes": 10485760
         },
         "info_file_handler": {
             "backupCount": 20,
             "class": "logging.handlers.RotatingFileHandler",
             "encoding": "utf8",
-            "filename": "/var/log/extract_msg/extract_msg.log",
+            "filename": "%LOCALAPPDATA%/extract_msg/extract_msg.log",
             "formatter": "simple",
             "level": "INFO",
             "maxBytes": 10485760
         },
         "warning_file_handler": {
             "backupCount": 20,
             "class": "logging.handlers.RotatingFileHandler",
             "encoding": "utf8",
-            "filename": "/var/log/extract_msg/extract_msg.log",
+            "filename": "%LOCALAPPDATA%/extract_msg/extract_msg.log",
             "formatter": "simple",
             "level": "WARNING",
             "maxBytes": 10485760
         }
     },
     "loggers": {
         "my_module": {
```

### Comparing `extract_msg-0.40.0/extract_msg/meeting_cancellation.py` & `extract_msg-0.41.0/extract_msg/meeting_cancellation.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,87 +1,92 @@
-from . import constants
-from .enums import RecurPatternType, ResponseStatus
-from .meeting_related import MeetingRelated
-
-
-# The documentation for this only specifies restrictions on existing properties,
-# so we just mostly leave this alone.
-class MeetingCancellation(MeetingRelated):
-    """
-    Class for a Meeting Cancellation object.
-    """
-
-    @property
-    def headerFormatProperties(self) -> constants.HEADER_FORMAT_TYPE:
-        """
-        Returns a dictionary of properties, in order, to be formatted into the
-        header. Keys are the names to use in the header while the values are one
-        of the following:
-        None: Signifies no data was found for the property and it should be
-            omitted from the header.
-        str: A string to be formatted into the header using the string encoding.
-        Tuple[Union[str, None], bool]: A string should be formatted into the
-            header. If the bool is True, then place an empty string if the value
-            is None, otherwise follow the same behavior as regular None.
-
-        Additional note: If the value is an empty string, it will be dropped as
-        well by default.
-
-        Additionally you can group members of a header together by placing them
-        in an embedded dictionary. Groups will be spaced out using a second
-        instance of the join string. If any member of a group is being printed,
-        it will be spaced apart from the next group/item.
-
-        If you class should not do *any* header injection, return None from this
-        property.
-        """
-        meetingStatusString = {
-            ResponseStatus.NONE: None,
-            ResponseStatus.ORGANIZED: 'Meeting organizer',
-            ResponseStatus.TENTATIVE: 'Tentatively accepted',
-            ResponseStatus.ACCEPTED: 'Accepted',
-            ResponseStatus.DECLINED: 'Declined',
-            ResponseStatus.NOT_RESPONDED: 'Not yet responded',
-        }[self.responseStatus]
-
-        # Get the recurrence string.
-        recur = '(none)'
-        if self.appointmentRecur:
-            recur = {
-                RecurPatternType.DAY: 'Daily',
-                RecurPatternType.WEEK: 'Weekly',
-                RecurPatternType.MONTH: 'Monthly',
-                RecurPatternType.MONTH_NTH: 'Monthly',
-                RecurPatternType.MONTH_END: 'Monthly',
-                RecurPatternType.HJ_MONTH: 'Monthly',
-                RecurPatternType.HJ_MONTH_NTH: 'Monthly',
-                RecurPatternType.HJ_MONTH_END: 'Monthly',
-            }[self.appointmentRecur.patternType]
-
-
-        return {
-            '-main info-': {
-                'Subject': self.subject,
-                'Location': self.location,
-            },
-            '-date-': {
-                'Start': self.startDate.__format__('%a, %d %b %Y %H:%M %z') if self.startDate else None,
-                'End': self.endDate.__format__('%a, %d %b %Y %H:%M %z') if self.endDate else None,
-                'Show Time As': 'Free',
-            },
-            '-recurrence-': {
-                'Recurrance': recur,
-                'Recurrence Pattern': self.recurrencePattern,
-            },
-            '-status-': {
-                'Meeting Status': meetingStatusString,
-            },
-            '-attendees-': {
-                'Organizer': self.organizer,
-                'Required Attendees': self.to,
-                'Optional Attendees': self.cc,
-                'Resources': self.bcc,
-            },
-            '-importance-': {
-                'Importance': self.importanceString,
-            },
-        }
+__all__ = [
+    'MeetingCancellation',
+]
+
+
+from . import constants
+from .enums import RecurPatternType, ResponseStatus
+from .meeting_related import MeetingRelated
+
+
+# The documentation for this only specifies restrictions on existing properties,
+# so we just mostly leave this alone.
+class MeetingCancellation(MeetingRelated):
+    """
+    Class for a Meeting Cancellation object.
+    """
+
+    @property
+    def headerFormatProperties(self) -> constants.HEADER_FORMAT_TYPE:
+        """
+        Returns a dictionary of properties, in order, to be formatted into the
+        header. Keys are the names to use in the header while the values are one
+        of the following:
+        None: Signifies no data was found for the property and it should be
+            omitted from the header.
+        str: A string to be formatted into the header using the string encoding.
+        Tuple[Union[str, None], bool]: A string should be formatted into the
+            header. If the bool is True, then place an empty string if the value
+            is None, otherwise follow the same behavior as regular None.
+
+        Additional note: If the value is an empty string, it will be dropped as
+        well by default.
+
+        Additionally you can group members of a header together by placing them
+        in an embedded dictionary. Groups will be spaced out using a second
+        instance of the join string. If any member of a group is being printed,
+        it will be spaced apart from the next group/item.
+
+        If you class should not do *any* header injection, return None from this
+        property.
+        """
+        meetingStatusString = {
+            ResponseStatus.NONE: None,
+            ResponseStatus.ORGANIZED: 'Meeting organizer',
+            ResponseStatus.TENTATIVE: 'Tentatively accepted',
+            ResponseStatus.ACCEPTED: 'Accepted',
+            ResponseStatus.DECLINED: 'Declined',
+            ResponseStatus.NOT_RESPONDED: 'Not yet responded',
+        }[self.responseStatus]
+
+        # Get the recurrence string.
+        recur = '(none)'
+        if self.appointmentRecur:
+            recur = {
+                RecurPatternType.DAY: 'Daily',
+                RecurPatternType.WEEK: 'Weekly',
+                RecurPatternType.MONTH: 'Monthly',
+                RecurPatternType.MONTH_NTH: 'Monthly',
+                RecurPatternType.MONTH_END: 'Monthly',
+                RecurPatternType.HJ_MONTH: 'Monthly',
+                RecurPatternType.HJ_MONTH_NTH: 'Monthly',
+                RecurPatternType.HJ_MONTH_END: 'Monthly',
+            }[self.appointmentRecur.patternType]
+
+
+        return {
+            '-main info-': {
+                'Subject': self.subject,
+                'Location': self.location,
+            },
+            '-date-': {
+                'Start': self.startDate.__format__('%a, %d %b %Y %H:%M %z') if self.startDate else None,
+                'End': self.endDate.__format__('%a, %d %b %Y %H:%M %z') if self.endDate else None,
+                'Show Time As': 'Free',
+            },
+            '-recurrence-': {
+                'Recurrance': recur,
+                'Recurrence Pattern': self.recurrencePattern,
+            },
+            '-status-': {
+                'Meeting Status': meetingStatusString,
+            },
+            '-attendees-': {
+                'Organizer': self.organizer,
+                'Required Attendees': self.to,
+                'Optional Attendees': self.cc,
+                'Resources': self.bcc,
+            },
+            '-importance-': {
+                'Importance': self.importanceString,
+            },
+        }
```

### Comparing `extract_msg-0.40.0/extract_msg/meeting_exception.py` & `extract_msg-0.41.0/extract_msg/meeting_exception.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,47 +1,52 @@
-import datetime
-
-from typing import Optional
-
-from . import constants
-from .meeting_related import MeetingRelated
-
-
-class MeetingException(MeetingRelated):
-    """
-    Class for handling Meeting Exceptions.
-    """
-
-    def save(self, *args, **kwargs):
-        """
-        Meeting Exceptions are hidden attachments with no save behaviors. As
-        such, for saving we literally just return the object and do nothing
-        else.
-
-        If you want something to happen for saving, you can call the save of a
-        parent class or write your own code.
-        """
-        return self
-
-    @property
-    def exceptionReplaceTime(self) -> Optional[datetime.datetime]:
-        """
-        The date and time within the recurrence pattern that the exception will
-        replace. The value is specified in UTC.
-        """
-        return self._ensureSetNamed('_exceptionReplaceTime', '8228', constants.PSETID_APPOINTMENT)
-
-    @property
-    def fExceptionalBody(self) -> bool:
-        """
-        Indicates that the Exception Embedded Message object has a body that
-        differs from the Recurring Calendar object. If True, the Exception MUST
-        have a body.
-        """
-        return self._ensureSetNamed('_fExceptionalBody', '8206', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
-
-    @property
-    def fInvited(self) -> bool:
-        """
-        Indicates if invitations have been sent for this exception.
-        """
-        return self._ensureSetNamed('_fInvited', '8229', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
+__all__ = [
+    'MeetingException',
+]
+
+
+import datetime
+
+from typing import Optional
+
+from . import constants
+from .meeting_related import MeetingRelated
+
+
+class MeetingException(MeetingRelated):
+    """
+    Class for handling Meeting Exceptions.
+    """
+
+    def save(self, *args, **kwargs):
+        """
+        Meeting Exceptions are hidden attachments with no save behaviors. As
+        such, for saving we literally just return the object and do nothing
+        else.
+
+        If you want something to happen for saving, you can call the save of a
+        parent class or write your own code.
+        """
+        return self
+
+    @property
+    def exceptionReplaceTime(self) -> Optional[datetime.datetime]:
+        """
+        The date and time within the recurrence pattern that the exception will
+        replace. The value is specified in UTC.
+        """
+        return self._ensureSetNamed('_exceptionReplaceTime', '8228', constants.PSETID_APPOINTMENT)
+
+    @property
+    def fExceptionalBody(self) -> bool:
+        """
+        Indicates that the Exception Embedded Message object has a body that
+        differs from the Recurring Calendar object. If True, the Exception MUST
+        have a body.
+        """
+        return self._ensureSetNamed('_fExceptionalBody', '8206', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
+
+    @property
+    def fInvited(self) -> bool:
+        """
+        Indicates if invitations have been sent for this exception.
+        """
+        return self._ensureSetNamed('_fInvited', '8229', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
```

### Comparing `extract_msg-0.40.0/extract_msg/meeting_forward.py` & `extract_msg-0.41.0/extract_msg/meeting_forward.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,92 +1,97 @@
-from typing import Optional
-
-from . import constants
-from .meeting_related import MeetingRelated
-from .enums import BusyStatus, MeetingObjectChange, MeetingType, RecurCalendarType, RecurPatternType, ResponseStatus
-
-
-class MeetingForwardNotification(MeetingRelated):
-    """
-    Class for handling Meeting Forward Notification objects.
-    """
-
-    @property
-    def forwardNotificationRecipients(self) -> Optional[bytes]:
-        """
-        Bytes containing a list of RecipientRow structures that indicate the
-        recipients of a meeting forward.
-
-        Incomplete, looks to be the same structure as
-        appointmentUnsendableRecipients, so we need more examples of this.
-        """
-        return self._ensureSetNamed('_forwardNotificationRecipients', '8261', constants.PSETID_APPOINTMENT)
-
-    @property
-    def headerFormatProperties(self) -> constants.HEADER_FORMAT_TYPE:
-        """
-        Returns a dictionary of properties, in order, to be formatted into the
-        header. Keys are the names to use in the header while the values are one
-        of the following:
-        None: Signifies no data was found for the property and it should be
-            omitted from the header.
-        str: A string to be formatted into the header using the string encoding.
-        Tuple[Union[str, None], bool]: A string should be formatted into the
-            header. If the bool is True, then place an empty string if the value
-            is None, otherwise follow the same behavior as regular None.
-
-        Additional note: If the value is an empty string, it will be dropped as
-        well by default.
-
-        Additionally you can group members of a header together by placing them
-        in an embedded dictionary. Groups will be spaced out using a second
-        instance of the join string. If any member of a group is being printed,
-        it will be spaced apart from the next group/item.
-
-        If you class should not do *any* header injection, return None from this
-        property.
-        """
-        # Get the recurrence string.
-        recur = '(none)'
-        if self.appointmentRecur:
-            recur = {
-                RecurPatternType.DAY: 'Daily',
-                RecurPatternType.WEEK: 'Weekly',
-                RecurPatternType.MONTH: 'Monthly',
-                RecurPatternType.MONTH_NTH: 'Monthly',
-                RecurPatternType.MONTH_END: 'Monthly',
-                RecurPatternType.HJ_MONTH: 'Monthly',
-                RecurPatternType.HJ_MONTH_NTH: 'Monthly',
-                RecurPatternType.HJ_MONTH_END: 'Monthly',
-            }[self.appointmentRecur.patternType]
-
-        return {
-            '-main info-': {
-                'Subject': self.subject,
-                'Location': self.location,
-            },
-            '-date-': {
-                'Start': self.startDate.__format__('%a, %d %b %Y %H:%M %z') if self.startDate else None,
-                'End': self.endDate.__format__('%a, %d %b %Y %H:%M %z') if self.endDate else None,
-            },
-            '-recurrence-': {
-                'Recurrance': recur,
-                'Recurrence Pattern': self.recurrencePattern,
-            },
-            '-attendees-': {
-                'Organizer': self.organizer,
-                'Required Attendees': self.to,
-                'Optional Attendees': self.cc,
-                'Resources': self.bcc,
-            },
-            '-importance-': {
-                'Importance': self.importanceString,
-            },
-        }
-
-    @property
-    def promptSendUpdate(self) -> bool:
-        """
-        Indicates that the Meeting Forward Notification object was out-of-date
-        when it was received.
-        """
-        return self._ensureSetNamed('_promptSendUpdate', '8045', constants.PSETID_COMMON, overrideClass = bool, preserveNone = False)
+__all__ = [
+    'MeetingForwardNotification',
+]
+
+
+from typing import Optional
+
+from . import constants
+from .meeting_related import MeetingRelated
+from .enums import RecurPatternType
+
+
+class MeetingForwardNotification(MeetingRelated):
+    """
+    Class for handling Meeting Forward Notification objects.
+    """
+
+    @property
+    def forwardNotificationRecipients(self) -> Optional[bytes]:
+        """
+        Bytes containing a list of RecipientRow structures that indicate the
+        recipients of a meeting forward.
+
+        Incomplete, looks to be the same structure as
+        appointmentUnsendableRecipients, so we need more examples of this.
+        """
+        return self._ensureSetNamed('_forwardNotificationRecipients', '8261', constants.PSETID_APPOINTMENT)
+
+    @property
+    def headerFormatProperties(self) -> constants.HEADER_FORMAT_TYPE:
+        """
+        Returns a dictionary of properties, in order, to be formatted into the
+        header. Keys are the names to use in the header while the values are one
+        of the following:
+        None: Signifies no data was found for the property and it should be
+            omitted from the header.
+        str: A string to be formatted into the header using the string encoding.
+        Tuple[Union[str, None], bool]: A string should be formatted into the
+            header. If the bool is True, then place an empty string if the value
+            is None, otherwise follow the same behavior as regular None.
+
+        Additional note: If the value is an empty string, it will be dropped as
+        well by default.
+
+        Additionally you can group members of a header together by placing them
+        in an embedded dictionary. Groups will be spaced out using a second
+        instance of the join string. If any member of a group is being printed,
+        it will be spaced apart from the next group/item.
+
+        If you class should not do *any* header injection, return None from this
+        property.
+        """
+        # Get the recurrence string.
+        recur = '(none)'
+        if self.appointmentRecur:
+            recur = {
+                RecurPatternType.DAY: 'Daily',
+                RecurPatternType.WEEK: 'Weekly',
+                RecurPatternType.MONTH: 'Monthly',
+                RecurPatternType.MONTH_NTH: 'Monthly',
+                RecurPatternType.MONTH_END: 'Monthly',
+                RecurPatternType.HJ_MONTH: 'Monthly',
+                RecurPatternType.HJ_MONTH_NTH: 'Monthly',
+                RecurPatternType.HJ_MONTH_END: 'Monthly',
+            }[self.appointmentRecur.patternType]
+
+        return {
+            '-main info-': {
+                'Subject': self.subject,
+                'Location': self.location,
+            },
+            '-date-': {
+                'Start': self.startDate.__format__('%a, %d %b %Y %H:%M %z') if self.startDate else None,
+                'End': self.endDate.__format__('%a, %d %b %Y %H:%M %z') if self.endDate else None,
+            },
+            '-recurrence-': {
+                'Recurrance': recur,
+                'Recurrence Pattern': self.recurrencePattern,
+            },
+            '-attendees-': {
+                'Organizer': self.organizer,
+                'Required Attendees': self.to,
+                'Optional Attendees': self.cc,
+                'Resources': self.bcc,
+            },
+            '-importance-': {
+                'Importance': self.importanceString,
+            },
+        }
+
+    @property
+    def promptSendUpdate(self) -> bool:
+        """
+        Indicates that the Meeting Forward Notification object was out-of-date
+        when it was received.
+        """
+        return self._ensureSetNamed('_promptSendUpdate', '8045', constants.PSETID_COMMON, overrideClass = bool, preserveNone = False)
```

### Comparing `extract_msg-0.40.0/extract_msg/meeting_related.py` & `extract_msg-0.41.0/extract_msg/meeting_related.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,59 +1,64 @@
-import datetime
-
-from typing import Optional, Set
-
-from . import constants
-from .calendar_base import CalendarBase
-from .enums import ServerProcessingAction
-
-
-class MeetingRelated(CalendarBase):
-    """
-    Base class for meeting-related objects.
-    """
-
-    @property
-    def attendeeCriticalChange(self) -> Optional[datetime.datetime]:
-        """
-        The date and time at which the meeting-related object was sent.
-        """
-        return self._ensureSetNamed('_attendeeCriticalChange', '0001', constants.PSETID_MEETING)
-
-    @property
-    def processed(self) -> bool:
-        """
-        Indicates whether a client has processed a meeting-related object.
-        """
-        return self._ensureSetProperty('_processed', '7D01000B', overrideClass = bool, preserveNone = False)
-
-    @property
-    def serverProcessed(self) -> bool:
-        """
-        Indicates that the Meeting Request object or Meeting Update object has
-        been processed.
-        """
-        return self._ensureSetNamed('_serverProcessed', '85CC', constants.PSETID_CALENDAR_ASSISTANT, overrideClass = bool, preserveNone = False)
-
-    @property
-    def serverProcessingActions(self) -> Optional[Set[ServerProcessingAction]]:
-        """
-        A set of which actions have been taken on the Meeting Request object or
-        Meeting Update object.
-        """
-        return self._ensureSetNamed('_serverProcessingActions', '85CD', constants.PSETID_CALENDAR_ASSISTANT, overrideClass = ServerProcessingAction.fromBits)
-
-    @property
-    def timeZone(self) -> Optional[int]:
-        """
-        Specifies information about the time zone of a recurring meeting.
-
-        See PidLidTimeZone in [MS-OXOCAL] for details.
-        """
-        return self._ensureSetNamed('_timeZone', '000C', constants.PSETID_MEETING)
-
-    @property
-    def where(self) -> Optional[str]:
-        """
-        PidLidWhere. Should be the same as location.
-        """
-        return self._ensureSetNamed('_where', '0002', constants.PSETID_MEETING)
+__all__ = [
+    'MeetingRelated',
+]
+
+
+import datetime
+
+from typing import Optional, Set
+
+from . import constants
+from .calendar_base import CalendarBase
+from .enums import ServerProcessingAction
+
+
+class MeetingRelated(CalendarBase):
+    """
+    Base class for meeting-related objects.
+    """
+
+    @property
+    def attendeeCriticalChange(self) -> Optional[datetime.datetime]:
+        """
+        The date and time at which the meeting-related object was sent.
+        """
+        return self._ensureSetNamed('_attendeeCriticalChange', '0001', constants.PSETID_MEETING)
+
+    @property
+    def processed(self) -> bool:
+        """
+        Indicates whether a client has processed a meeting-related object.
+        """
+        return self._ensureSetProperty('_processed', '7D01000B', overrideClass = bool, preserveNone = False)
+
+    @property
+    def serverProcessed(self) -> bool:
+        """
+        Indicates that the Meeting Request object or Meeting Update object has
+        been processed.
+        """
+        return self._ensureSetNamed('_serverProcessed', '85CC', constants.PSETID_CALENDAR_ASSISTANT, overrideClass = bool, preserveNone = False)
+
+    @property
+    def serverProcessingActions(self) -> Optional[Set[ServerProcessingAction]]:
+        """
+        A set of which actions have been taken on the Meeting Request object or
+        Meeting Update object.
+        """
+        return self._ensureSetNamed('_serverProcessingActions', '85CD', constants.PSETID_CALENDAR_ASSISTANT, overrideClass = ServerProcessingAction.fromBits)
+
+    @property
+    def timeZone(self) -> Optional[int]:
+        """
+        Specifies information about the time zone of a recurring meeting.
+
+        See PidLidTimeZone in [MS-OXOCAL] for details.
+        """
+        return self._ensureSetNamed('_timeZone', '000C', constants.PSETID_MEETING)
+
+    @property
+    def where(self) -> Optional[str]:
+        """
+        PidLidWhere. Should be the same as location.
+        """
+        return self._ensureSetNamed('_where', '0002', constants.PSETID_MEETING)
```

### Comparing `extract_msg-0.40.0/extract_msg/meeting_request.py` & `extract_msg-0.41.0/extract_msg/meeting_request.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,167 +1,172 @@
-import datetime
-
-from typing import List, Optional, Set
-
-from . import constants
-from .meeting_related import MeetingRelated
-from .enums import BusyStatus, MeetingObjectChange, MeetingType, RecurCalendarType, RecurPatternType, ResponseStatus
-
-
-class MeetingRequest(MeetingRelated):
-    """
-    Class for handling Meeting Request and Meeting Update objects.
-    """
-
-    @property
-    def appointmentMessageClass(self) -> Optional[str]:
-        """
-        Indicates the value of the PidTagMessageClass property of the Meeting
-        object that is to be generated from the Meeting Request object. MUST
-        start with "IPM.Appointment".
-        """
-        return self._ensureSetNamed('_appointmentMessageClass', '0024', constants.PSETID_MEETING)
-
-    @property
-    def calendarType(self) -> Optional[RecurCalendarType]:
-        """
-        The value of the CalendarType field from the PidLidAppointmentRecur
-        property if the Meeting Request object represents a recurring series or
-        an exception.
-        """
-        return self._ensureSetNamed('_calendarType', '001C', constants.PSETID_MEETING, overrideClass = RecurCalendarType)
-
-    @property
-    def changeHighlight(self) -> Optional[Set[MeetingObjectChange]]:
-        """
-        Soecifies a bit field that indicates how the Meeting object has been
-        changed.
-
-        Returns a set of flags.
-        """
-        return self._ensureSetNamed('_changeHighlight', '8204', constants.PSETID_APPOINTMENT, overrideClass = MeetingObjectChange.fromBits)
-
-    @property
-    def forwardInstance(self) -> bool:
-        """
-        Indicates that the Meeting Request object represents an exception to a
-        recurring series, and it was forwarded (even when forwarded by the
-        organizer) rather than being an invitation sent by the organizer.
-        """
-        return self._ensureSetNamed('_forwardInstance', '820A', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
-
-    @property
-    def headerFormatProperties(self) -> constants.HEADER_FORMAT_TYPE:
-        """
-        Returns a dictionary of properties, in order, to be formatted into the
-        header. Keys are the names to use in the header while the values are one
-        of the following:
-        None: Signifies no data was found for the property and it should be
-            omitted from the header.
-        str: A string to be formatted into the header using the string encoding.
-        Tuple[Union[str, None], bool]: A string should be formatted into the
-            header. If the bool is True, then place an empty string if the value
-            is None, otherwise follow the same behavior as regular None.
-
-        Additional note: If the value is an empty string, it will be dropped as
-        well by default.
-
-        Additionally you can group members of a header together by placing them
-        in an embedded dictionary. Groups will be spaced out using a second
-        instance of the join string. If any member of a group is being printed,
-        it will be spaced apart from the next group/item.
-
-        If you class should not do *any* header injection, return None from this
-        property.
-        """
-        meetingStatusString = {
-            ResponseStatus.NONE: None,
-            ResponseStatus.ORGANIZED: 'Meeting organizer',
-            ResponseStatus.TENTATIVE: 'Tentatively accepted',
-            ResponseStatus.ACCEPTED: 'Accepted',
-            ResponseStatus.DECLINED: 'Declined',
-            ResponseStatus.NOT_RESPONDED: 'Not yet responded',
-        }[self.responseStatus]
-
-        # Get the recurrence string.
-        recur = '(none)'
-        if self.appointmentRecur:
-            recur = {
-                RecurPatternType.DAY: 'Daily',
-                RecurPatternType.WEEK: 'Weekly',
-                RecurPatternType.MONTH: 'Monthly',
-                RecurPatternType.MONTH_NTH: 'Monthly',
-                RecurPatternType.MONTH_END: 'Monthly',
-                RecurPatternType.HJ_MONTH: 'Monthly',
-                RecurPatternType.HJ_MONTH_NTH: 'Monthly',
-                RecurPatternType.HJ_MONTH_END: 'Monthly',
-            }[self.appointmentRecur.patternType]
-
-        showTime = None if self.appointmentNotAllowPropose else 'Tentative'
-
-        return {
-            '-main info-': {
-                'Subject': self.subject,
-                'Location': self.location,
-            },
-            '-date-': {
-                'Start': self.startDate.__format__('%a, %d %b %Y %H:%M %z') if self.startDate else None,
-                'End': self.endDate.__format__('%a, %d %b %Y %H:%M %z') if self.endDate else None,
-                'Show Time As': showTime,
-            },
-            '-recurrence-': {
-                'Recurrance': recur,
-                'Recurrence Pattern': self.recurrencePattern,
-            },
-            '-status-': {
-                'Meeting Status': meetingStatusString,
-            },
-            '-attendees-': {
-                'Organizer': self.organizer,
-                'Required Attendees': self.to,
-                'Optional Attendees': self.cc,
-                'Resources': self.bcc,
-            },
-            '-importance-': {
-                'Importance': self.importanceString,
-            },
-        }
-
-
-    @property
-    def intendedBusyStatus(self) -> Optional[BusyStatus]:
-        """
-        The value of the busyStatus on the Meeting object in the organizer's
-        calendar at the time the Meeting Request object or Meeting Update object
-        was sent.
-        """
-        return self._ensureSetNamed('_intendedBusyStatus', '8224', constants.PSETID_APPOINTMENT, overrideClass = BusyStatus)
-
-    @property
-    def meetingType(self) -> Optional[MeetingType]:
-        """
-        The type of Meeting Request object or Meeting Update object.
-        """
-        return self._ensureSetNamed('_meetingType', '0026', constants.PSETID_MEETING, overrideClass = MeetingType)
-
-    @property
-    def oldLocation(self) -> Optional[str]:
-        """
-        The original value of the location property before a meeting update.
-        """
-        return self._ensureSetNamed('_oldLocation', '0028', constants.PSETID_MEETING)
-
-    @property
-    def oldWhenEndWhole(self) -> Optional[datetime.datetime]:
-        """
-        The original value of the appointmentEndWhole property before a meeting
-        update.
-        """
-        return self._ensureSetNamed('_oldWhenEndWhole', '002A', constants.PSETID_MEETING)
-
-    @property
-    def oldWhenStartWhole(self) -> Optional[datetime.datetime]:
-        """
-        The original value of the appointmentStartWhole property before a
-        meeting update.
-        """
-        return self._ensureSetNamed('_oldWhenStartWhole', '0029', constants.PSETID_MEETING)
+__all__ = [
+    'MeetingRequest',
+]
+
+
+import datetime
+
+from typing import List, Optional, Set
+
+from . import constants
+from .meeting_related import MeetingRelated
+from .enums import BusyStatus, MeetingObjectChange, MeetingType, RecurCalendarType, RecurPatternType, ResponseStatus
+
+
+class MeetingRequest(MeetingRelated):
+    """
+    Class for handling Meeting Request and Meeting Update objects.
+    """
+
+    @property
+    def appointmentMessageClass(self) -> Optional[str]:
+        """
+        Indicates the value of the PidTagMessageClass property of the Meeting
+        object that is to be generated from the Meeting Request object. MUST
+        start with "IPM.Appointment".
+        """
+        return self._ensureSetNamed('_appointmentMessageClass', '0024', constants.PSETID_MEETING)
+
+    @property
+    def calendarType(self) -> Optional[RecurCalendarType]:
+        """
+        The value of the CalendarType field from the PidLidAppointmentRecur
+        property if the Meeting Request object represents a recurring series or
+        an exception.
+        """
+        return self._ensureSetNamed('_calendarType', '001C', constants.PSETID_MEETING, overrideClass = RecurCalendarType)
+
+    @property
+    def changeHighlight(self) -> Optional[Set[MeetingObjectChange]]:
+        """
+        Soecifies a bit field that indicates how the Meeting object has been
+        changed.
+
+        Returns a set of flags.
+        """
+        return self._ensureSetNamed('_changeHighlight', '8204', constants.PSETID_APPOINTMENT, overrideClass = MeetingObjectChange.fromBits)
+
+    @property
+    def forwardInstance(self) -> bool:
+        """
+        Indicates that the Meeting Request object represents an exception to a
+        recurring series, and it was forwarded (even when forwarded by the
+        organizer) rather than being an invitation sent by the organizer.
+        """
+        return self._ensureSetNamed('_forwardInstance', '820A', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
+
+    @property
+    def headerFormatProperties(self) -> constants.HEADER_FORMAT_TYPE:
+        """
+        Returns a dictionary of properties, in order, to be formatted into the
+        header. Keys are the names to use in the header while the values are one
+        of the following:
+        None: Signifies no data was found for the property and it should be
+            omitted from the header.
+        str: A string to be formatted into the header using the string encoding.
+        Tuple[Union[str, None], bool]: A string should be formatted into the
+            header. If the bool is True, then place an empty string if the value
+            is None, otherwise follow the same behavior as regular None.
+
+        Additional note: If the value is an empty string, it will be dropped as
+        well by default.
+
+        Additionally you can group members of a header together by placing them
+        in an embedded dictionary. Groups will be spaced out using a second
+        instance of the join string. If any member of a group is being printed,
+        it will be spaced apart from the next group/item.
+
+        If you class should not do *any* header injection, return None from this
+        property.
+        """
+        meetingStatusString = {
+            ResponseStatus.NONE: None,
+            ResponseStatus.ORGANIZED: 'Meeting organizer',
+            ResponseStatus.TENTATIVE: 'Tentatively accepted',
+            ResponseStatus.ACCEPTED: 'Accepted',
+            ResponseStatus.DECLINED: 'Declined',
+            ResponseStatus.NOT_RESPONDED: 'Not yet responded',
+        }[self.responseStatus]
+
+        # Get the recurrence string.
+        recur = '(none)'
+        if self.appointmentRecur:
+            recur = {
+                RecurPatternType.DAY: 'Daily',
+                RecurPatternType.WEEK: 'Weekly',
+                RecurPatternType.MONTH: 'Monthly',
+                RecurPatternType.MONTH_NTH: 'Monthly',
+                RecurPatternType.MONTH_END: 'Monthly',
+                RecurPatternType.HJ_MONTH: 'Monthly',
+                RecurPatternType.HJ_MONTH_NTH: 'Monthly',
+                RecurPatternType.HJ_MONTH_END: 'Monthly',
+            }[self.appointmentRecur.patternType]
+
+        showTime = None if self.appointmentNotAllowPropose else 'Tentative'
+
+        return {
+            '-main info-': {
+                'Subject': self.subject,
+                'Location': self.location,
+            },
+            '-date-': {
+                'Start': self.startDate.__format__('%a, %d %b %Y %H:%M %z') if self.startDate else None,
+                'End': self.endDate.__format__('%a, %d %b %Y %H:%M %z') if self.endDate else None,
+                'Show Time As': showTime,
+            },
+            '-recurrence-': {
+                'Recurrance': recur,
+                'Recurrence Pattern': self.recurrencePattern,
+            },
+            '-status-': {
+                'Meeting Status': meetingStatusString,
+            },
+            '-attendees-': {
+                'Organizer': self.organizer,
+                'Required Attendees': self.to,
+                'Optional Attendees': self.cc,
+                'Resources': self.bcc,
+            },
+            '-importance-': {
+                'Importance': self.importanceString,
+            },
+        }
+
+
+    @property
+    def intendedBusyStatus(self) -> Optional[BusyStatus]:
+        """
+        The value of the busyStatus on the Meeting object in the organizer's
+        calendar at the time the Meeting Request object or Meeting Update object
+        was sent.
+        """
+        return self._ensureSetNamed('_intendedBusyStatus', '8224', constants.PSETID_APPOINTMENT, overrideClass = BusyStatus)
+
+    @property
+    def meetingType(self) -> Optional[MeetingType]:
+        """
+        The type of Meeting Request object or Meeting Update object.
+        """
+        return self._ensureSetNamed('_meetingType', '0026', constants.PSETID_MEETING, overrideClass = MeetingType)
+
+    @property
+    def oldLocation(self) -> Optional[str]:
+        """
+        The original value of the location property before a meeting update.
+        """
+        return self._ensureSetNamed('_oldLocation', '0028', constants.PSETID_MEETING)
+
+    @property
+    def oldWhenEndWhole(self) -> Optional[datetime.datetime]:
+        """
+        The original value of the appointmentEndWhole property before a meeting
+        update.
+        """
+        return self._ensureSetNamed('_oldWhenEndWhole', '002A', constants.PSETID_MEETING)
+
+    @property
+    def oldWhenStartWhole(self) -> Optional[datetime.datetime]:
+        """
+        The original value of the appointmentStartWhole property before a
+        meeting update.
+        """
+        return self._ensureSetNamed('_oldWhenStartWhole', '0029', constants.PSETID_MEETING)
```

### Comparing `extract_msg-0.40.0/extract_msg/meeting_response.py` & `extract_msg-0.41.0/extract_msg/meeting_response.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,68 +1,73 @@
-import datetime
-
-from typing import Optional
-
-from . import constants
-from .enums import ResponseType
-from .meeting_related import MeetingRelated
-
-
-class MeetingResponse(MeetingRelated):
-    """
-    Class for handling meeting response objects.
-    """
-
-    @property
-    def appointmentCounterProposal(self) -> bool:
-        """
-        Indicates if the response is a counter proposal.
-        """
-        return self._ensureSetNamed('_appointmentCounterProposal', '8257', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
-
-    @property
-    def appointmentProposedDuration(self) -> Optional[int]:
-        """
-        The proposed value for the appointmentDuration property for a counter
-        proposal.
-        """
-        return self._ensureSetNamed('_appointmentProposedDuration', '8256', constants.PSETID_APPOINTMENT)
-
-    @property
-    def appointmentProposedEndWhole(self) -> Optional[datetime.datetime]:
-        """
-        The proposal value for the appointmentEndWhole property for a counter
-        proposal.
-        """
-        return self._ensureSetNamed('_appointmentProposedEndWhole', '8251', constants.PSETID_APPOINTMENT)
-
-    @property
-    def appointmentProposedStartWhole(self) -> Optional[datetime.datetime]:
-        """
-        The proposal value for the appointmentStartWhole property for a counter
-        proposal.
-        """
-        return self._ensureSetNamed('_appointmentProposedStartWhole', '8250', constants.PSETID_APPOINTMENT)
-
-    @property
-    def isSilent(self) -> bool:
-        """
-        Indicates if the user did not include any text in the body of the
-        Meeting Response object.
-        """
-        return self._ensureSetNamed('_isSilent', '0004', constants.PSETID_MEETING, overrideClass = bool, preserveNone = False)
-
-    @property
-    def promptSendUpdate(self) -> bool:
-        """
-        Indicates that the Meeting Response object was out-of-date when it was
-        received.
-        """
-        return self._ensureSetNamed('_promptSendUpdate', '8045', constants.PSETID_COMMON, overrideClass = bool, preserveNone = False)
-
-    @property
-    def responseType(self) -> Optional[ResponseType]:
-        """
-        The type of Meeting Response object.
-        """
-        # The ending of the class type determines the type of response.
-        return ResponseType(self.classType.lower().split('.')[-1])
+__all__ = [
+    'MeetingResponse',
+]
+
+
+import datetime
+
+from typing import Optional
+
+from . import constants
+from .enums import ResponseType
+from .meeting_related import MeetingRelated
+
+
+class MeetingResponse(MeetingRelated):
+    """
+    Class for handling meeting response objects.
+    """
+
+    @property
+    def appointmentCounterProposal(self) -> bool:
+        """
+        Indicates if the response is a counter proposal.
+        """
+        return self._ensureSetNamed('_appointmentCounterProposal', '8257', constants.PSETID_APPOINTMENT, overrideClass = bool, preserveNone = False)
+
+    @property
+    def appointmentProposedDuration(self) -> Optional[int]:
+        """
+        The proposed value for the appointmentDuration property for a counter
+        proposal.
+        """
+        return self._ensureSetNamed('_appointmentProposedDuration', '8256', constants.PSETID_APPOINTMENT)
+
+    @property
+    def appointmentProposedEndWhole(self) -> Optional[datetime.datetime]:
+        """
+        The proposal value for the appointmentEndWhole property for a counter
+        proposal.
+        """
+        return self._ensureSetNamed('_appointmentProposedEndWhole', '8251', constants.PSETID_APPOINTMENT)
+
+    @property
+    def appointmentProposedStartWhole(self) -> Optional[datetime.datetime]:
+        """
+        The proposal value for the appointmentStartWhole property for a counter
+        proposal.
+        """
+        return self._ensureSetNamed('_appointmentProposedStartWhole', '8250', constants.PSETID_APPOINTMENT)
+
+    @property
+    def isSilent(self) -> bool:
+        """
+        Indicates if the user did not include any text in the body of the
+        Meeting Response object.
+        """
+        return self._ensureSetNamed('_isSilent', '0004', constants.PSETID_MEETING, overrideClass = bool, preserveNone = False)
+
+    @property
+    def promptSendUpdate(self) -> bool:
+        """
+        Indicates that the Meeting Response object was out-of-date when it was
+        received.
+        """
+        return self._ensureSetNamed('_promptSendUpdate', '8045', constants.PSETID_COMMON, overrideClass = bool, preserveNone = False)
+
+    @property
+    def responseType(self) -> Optional[ResponseType]:
+        """
+        The type of Meeting Response object.
+        """
+        # The ending of the class type determines the type of response.
+        return ResponseType(self.classType.lower().split('.')[-1])
```

### Comparing `extract_msg-0.40.0/extract_msg/message_base.py` & `extract_msg-0.41.0/extract_msg/message_base.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,1344 +1,1345 @@
-import base64
-import datetime
-import email.utils
-import html
-import json
-import logging
-import os
-import pathlib
-import re
-import subprocess
-import zipfile
-
-import bs4
-import chardet
-import compressed_rtf
-import RTFDE
-
-from email.parser import Parser as EmailParser
-from typing import Callable, Dict, List, Optional, Tuple, Union
-
-from . import constants
-from ._rtf.create_doc import createDocument
-from ._rtf.inject_rtf import injectStartRTF
-from .enums import DeencapType, RecipientType
-from .exceptions import (
-        DataNotFoundError, DeencapMalformedData, DeencapNotEncapsulated,
-        IncompatibleOptionsError, WKError
-    )
-from .msg import MSGFile
-from .structures.report_tag import ReportTag
-from .recipient import Recipient
-from .utils import (
-        addNumToDir, addNumToZipDir, createZipOpen, findWk, htmlSanitize,
-        inputToBytes, inputToString, isEncapsulatedRtf, prepareFilename,
-        rtfSanitizeHtml, rtfSanitizePlain, validateHtml
-    )
-from imapclient.imapclient import decode_utf7
-
-
-logger = logging.getLogger(__name__)
-logger.addHandler(logging.NullHandler())
-
-
-class MessageBase(MSGFile):
-    """
-    Base class for Message like msg files.
-    """
-
-    def __init__(self, path, **kwargs):
-        """
-        :param path: path to the msg file in the system or is the raw msg file.
-        :param prefix: used for extracting embeded msg files
-            inside the main one. Do not set manually unless
-            you know what you are doing.
-        :param parentMsg: Used for syncronizing named properties instances. Do
-            not set this unless you know what you are doing.
-        :param attachmentClass: Optional, the class the Message object
-            will use for attachments. You probably should
-            not change this value unless you know what you
-            are doing.
-        :param filename: Optional, the filename to be used by default when
-            saving.
-        :param delayAttachments: Optional, delays the initialization of
-            attachments until the user attempts to retrieve them. Allows MSG
-            files with bad attachments to be initialized so the other data can
-            be retrieved.
-        :param overrideEncoding: Optional, an encoding to use instead of the one
-            specified by the msg file. Do not report encoding errors caused by
-            this.
-        :param attachmentErrorBehavior: Optional, the behavior to use in the
-            event of an error when parsing the attachments.
-        :param recipientSeparator: Optional, separator string to use between
-            recipients.
-        :param ignoreRtfDeErrors: Optional, specifies that any errors that occur
-            from the usage of RTFDE should be ignored (default: False).
-        :param deencapsulationFunc: Optional, if specified must be a callable
-            that will override the way that HTML/text is deencapsulated from the
-            RTF body. This function must take exactly 2 arguments, the first
-            being the RTF body from the message and the second being an instance
-            of the enum DeencapType that will tell the function what type of
-            body is desired. The function should return a string for plain text
-            and bytes for HTML. If any problems occur, the function *must*
-            either return None or raise one of the appropriate functions from
-            extract_msg.exceptions. All other exceptions must be handled
-            internally or they will not be caught. The original deencapsulation
-            method will not run if this is set.
-        """
-        super().__init__(path, **kwargs)
-        recipientSeparator = ';'
-        self.__recipientSeparator = kwargs.get('recipientSeparator', ';')
-        self.__ignoreRtfDeErrors = kwargs.get('ignoreRtfDeErrors', False)
-        self.__deencap = kwargs.get('deencapsulationFunc')
-        # Initialize properties in the order that is least likely to cause bugs.
-        # TODO have each function check for initialization of needed data so
-        # these lines will be unnecessary.
-        self.props
-        self.header
-        self.recipients
-
-        self.to
-        self.cc
-        self.sender
-        self.date
-        # This variable keeps track of what the new line character should be.
-        self.__crlf = '\n'
-        try:
-            self.body
-        except Exception as e:
-            # Prevent an error in the body from preventing opening.
-            logger.exception('Critical error accessing the body. File opened but accessing the body will throw an exception.')
-        self.named
-        self.namedProperties
-
-    def _genRecipient(self, recipientType, recipientInt : RecipientType) -> Optional[str]:
-        """
-        Returns the specified recipient field.
-        """
-        private = '_' + recipientType
-        recipientInt = RecipientType(recipientInt)
-        try:
-            return getattr(self, private)
-        except AttributeError:
-            value = None
-            # Check header first.
-            if self.headerInit():
-                value = self.header[recipientType]
-                if value:
-                    value = value.replace(',', self.__recipientSeparator)
-
-            # If the header had a blank field or didn't have the field, generate
-            # it manually.
-            if not value:
-                # Check if the header has initialized.
-                if self.headerInit():
-                    logger.info(f'Header found, but "{recipientType}" is not included. Will be generated from other streams.')
-
-                # Get a list of the recipients of the specified type.
-                foundRecipients = tuple(recipient.formatted for recipient in self.recipients if recipient.type == recipientInt)
-
-                # If we found recipients, join them with the recipient separator
-                # and a space.
-                if len(foundRecipients) > 0:
-                    value = (self.__recipientSeparator + ' ').join(foundRecipients)
-
-            # Code to fix the formatting so it's all a single line. This allows
-            # the user to format it themself if they want. This should probably
-            # be redone to use re or something, but I can do that later. This
-            # shouldn't be a huge problem for now.
-            if value:
-                value = value.replace(' \r\n\t', ' ').replace('\r\n\t ', ' ').replace('\r\n\t', ' ')
-                value = value.replace('\r\n', ' ').replace('\r', ' ').replace('\n', ' ')
-                while value.find('  ') != -1:
-                    value = value.replace('  ', ' ')
-
-            # Set the field in the class.
-            setattr(self, private, value)
-
-            return value
-
-    def deencapsulateBody(self, rtfBody : bytes, bodyType : DeencapType) -> Optional[Union[bytes, str]]:
-        """
-        A function to deencapsulate the specified body from the rtfBody. Returns
-        a string for plain text and bytes for HTML. If specified, uses the
-        deencapsulation override function. Returns None if nothing could be
-        deencapsulated.
-
-        If you want to change the deencapsulation behaviour in a base class,
-        simply override this function.
-        """
-        if rtfBody:
-            bodyType = DeencapType(bodyType)
-            if bodyType == DeencapType.PLAIN:
-                if self.__deencap:
-                    try:
-                        return self.__deencap(rtfBody, DeencapType.PLAIN)
-                    except DeencapMalformedData:
-                        logger.exception('Custom deencapsulation function reported encapsulated data was malformed.')
-                    except DeencapNotEncapsulated:
-                        logger.exception('Custom deencapsulation function reported data is not encapsulated.')
-                else:
-                    if self.deencapsulatedRtf and self.deencapsulatedRtf.content_type == 'text':
-                        return self.deencapsulatedRtf.text
-            else:
-                if self.__deencap:
-                    try:
-                        return self.__deencap(rtfBody, DeencapType.HTML)
-                    except DeencapMalformedData:
-                        logger.exception('Custom deencapsulation function reported encapsulated data was malformed.')
-                    except DeencapNotEncapsulated:
-                        logger.exception('Custom deencapsulation function reported data is not encapsulated.')
-                else:
-                    if self.deencapsulatedRtf and self.deencapsulatedRtf.content_type == 'html':
-                        return self.deencapsulatedRtf.html.encode('utf-8')
-
-            if bodyType == DeencapType.PLAIN:
-                logger.info('Could not deencapsulate plain text from RTF body.')
-            else:
-                logger.info('Could not deencapsulate HTML from RTF body.')
-        else:
-            logger.info('No RTF body to deencapsulate from.')
-        return None
-
-    def dump(self) -> None:
-        """
-        Prints out a summary of the message.
-        """
-        print('Message')
-        print('Subject:', self.subject)
-        print('Date:', self.date)
-        print('Body:')
-        print(self.body)
-
-    def getInjectableHeader(self, prefix : str, joinStr : str, suffix : str, formatter : Callable[[str, str], str]) -> str:
-        """
-        Using the specified prefix, suffix, formatter, and join string,
-        generates the injectable header. Prefix is placed at the beginning,
-        followed by a series of format strings joined together with the join
-        string, with the suffix placed afterwards. Effectively makes this
-        structure:
-        {prefix}{formatter()}{joinStr}{formatter()}{joinStr}...{formatter()}{suffix}
-
-        Formatter be a function that takes first a name variable then a value
-        variable and formats the line.
-
-        If self.headerFormatProperties is None, immediately returns an empty
-        string.
-        """
-        formattedProps = []
-        allProps = self.headerFormatProperties
-
-        if allProps is None:
-            return ''
-
-        for entry in allProps:
-            isGroup = False
-            entryUsed = False
-            # This is how we handle the groups.
-            if isinstance(allProps[entry], dict):
-                props = allProps[entry]
-                isGroup = True
-            else:
-                props = {entry: allProps[entry]}
-
-            for name in props:
-                if props[name]:
-                    if isinstance(props[name], tuple):
-                        if props[name][1]:
-                            value = props[name][0] or ''
-                        elif props[name][0] is not None:
-                            value = props[name][0]
-                        else:
-                            continue
-                    else:
-                        value = props[name]
-
-                    entryUsed = True
-                    formattedProps.append(formatter(name, value))
-
-            # Now if we are working with a group, add an empty entry to get a
-            # second join string between this section and the last, but *only*
-            # if any of the entries were used.
-            if isGroup and entryUsed:
-                formattedProps.append('')
-
-        # If the last entry is empty, remove it. We don't want extra spacing at
-        # the end.
-        if formattedProps[-1] == '':
-            formattedProps.pop()
-
-        return prefix + joinStr.join(formattedProps) + suffix
-
-    def getJson(self) -> str:
-        """
-        Returns the JSON representation of the Message.
-        """
-        return json.dumps({
-            'from': inputToString(self.sender, self.stringEncoding),
-            'to': inputToString(self.to, self.stringEncoding),
-            'cc': inputToString(self.cc, self.stringEncoding),
-            'bcc': inputToString(self.bcc, self.stringEncoding),
-            'subject': inputToString(self.subject, self.stringEncoding),
-            'date': inputToString(self.date, self.stringEncoding),
-            'body': decode_utf7(self.body),
-        })
-
-    def getSaveBody(self, **kwargs) -> bytes:
-        """
-        Returns the plain text body that will be used in saving based on the
-        arguments.
-
-        :param kwargs: Used to allow kwargs expansion in the save function.
-            Arguments absorbed by this are simply ignored.
-        """
-        # Get the type of line endings.
-        crlf = inputToString(self.crlf, 'utf-8')
-
-        prefix = ''
-        suffix = crlf + '-----------------' + crlf + crlf
-        joinStr = crlf
-        formatter = (lambda name, value : f'{name}: {value}')
-
-        header = self.getInjectableHeader(prefix, joinStr, suffix, formatter).encode('utf-8')
-        return header + inputToBytes(self.body, 'utf-8')
-
-    def getSaveHtmlBody(self, preparedHtml : bool = False, charset : str = 'utf-8', **kwargs) -> bytes:
-        """
-        Returns the HTML body that will be used in saving based on the
-        arguments.
-
-        :param preparedHtml: Whether or not the HTML should be prepared for
-            standalone use (add tags, inject images, etc.).
-        :param charset: If the html is being prepared, the charset to use for
-            the Content-Type meta tag to insert. This exists to ensure that
-            something parsing the html can properly determine the encoding (as
-            not having this tag can cause errors in some programs). Set this to
-            `None` or an empty string to not insert the tag (Default: 'utf-8').
-        :param kwargs: Used to allow kwargs expansion in the save function.
-            Arguments absorbed by this are simply ignored.
-
-        :raises BadHtmlError: if :param preparedHtml: is False and the HTML
-            fails to validate.
-        """
-        if self.htmlBody:
-            # Inject the header into the data.
-            data = self.injectHtmlHeader(prepared = preparedHtml)
-
-            # If we are preparing the HTML, then we should
-            if preparedHtml and charset:
-                bs = bs4.BeautifulSoup(data, features = 'html.parser')
-                if not bs.find('meta', {'http-equiv': 'Content-Type'}):
-                    # Setup the attributes for the tag.
-                    tagAttrs = {
-                        'http-equiv': 'Content-Type',
-                        'content': f'text/html; charset={charset}',
-                    }
-                    # Create the tag.
-                    tag = bs4.Tag(parser = bs, name = 'meta', attrs = tagAttrs, can_be_empty_element = True)
-                    # Add the tag to the head section.
-                    if bs.find('head'):
-                        bs.find('head').insert(0, tag)
-                    else:
-                        # If we are here, the head doesn't exist, so let's add
-                        # it.
-                        if bs.find('html'):
-                            # This should always be true, but I want to be safe.
-                            head = bs4.Tag(parser = bs, name = 'head')
-                            head.insert(0, tag)
-                            bs.find('html').insert(0, head)
-
-                    data = bs.prettify('utf-8')
-
-            return data
-        else:
-            return self.htmlBody
-
-    def getSavePdfBody(self, **kwargs) -> bytes:
-        """
-        Returns the PDF body that will be used in saving based on the arguments.
-
-        :param wkPath: Used to manually specify the path of the wkhtmltopdf
-            executable. If not specified, the function will try to find it.
-            Useful if wkhtmltopdf is not on the path. If :param pdf: is False,
-            this argument is ignored.
-        :param wkOptions: Used to specify additional options to wkhtmltopdf.
-            this must be a list or list-like object composed of strings and
-            bytes.
-        :param kwargs: Used to allow kwargs expansion in the save function.
-            Arguments absorbed by this are simply ignored.
-
-        :raises ExecutableNotFound: The wkhtmltopdf executable could not be
-            found.
-        :raises WKError: Something went wrong in creating the PDF body.
-        """
-        # Immediately try to find the executable.
-        wkPath = findWk(kwargs.get('wkPath'))
-
-        # First thing is first, we need to parse our wkOptions if they exist.
-        wkOptions = kwargs.get('wkOptions')
-        if wkOptions:
-            try:
-                # Try to convert to a list, whatever it is, and fail if it is
-                # not possible.
-                parsedWkOptions = [*wkOptions]
-            except TypeError:
-                raise TypeError(f':param wkOptions: must be an iterable, not {type(wkOptions)}.')
-        else:
-            parsedWkOptions = []
-
-        # Confirm that all of our options we now have are either strings or
-        # bytes.
-        if not all(isinstance(option, (str, bytes)) for option in parsedWkOptions):
-            raise TypeError(':param wkOptions: must be an iterable of strings and bytes.')
-
-        processArgs = [wkPath, *parsedWkOptions, '-', '-']
-        # Log the arguments.
-        logger.info(f'Converting to PDF with the following arguments: {processArgs}')
-
-        # Get the html body *before* calling Popen.
-        htmlBody = self.getSaveHtmlBody(**kwargs)
-
-        # We call the program to convert the html, but give tell it the data
-        # will go in and come out through stdin and stdout, respectively. This
-        # way we don't have to write temporary files to the disk. We also ask
-        # that it be quiet about it.
-        process = subprocess.run(processArgs, input = htmlBody, stdout = subprocess.PIPE, stderr = subprocess.PIPE)
-        # Give the program the data and wait for the program to finish.
-        #output = process.communicate(htmlBody)
-
-        # If it errored, throw it as an exception.
-        if process.returncode != 0:
-            raise WKError(process.stderr.decode('utf-8'))
-
-        return process.stdout
-
-    def getSaveRtfBody(self, **kwargs) -> bytes:
-        """
-        Returns the RTF body that will be used in saving based on the arguments.
-
-        :param kwargs: Used to allow kwargs expansion in the save function.
-            Arguments absorbed by this are simply ignored.
-        """
-        # Inject the header into the data.
-        return self.injectRtfHeader()
-
-    def headerInit(self) -> bool:
-        """
-        Checks whether the header has been initialized.
-        """
-        try:
-            self._header
-            return True
-        except AttributeError:
-            return False
-
-    def injectHtmlHeader(self, prepared : bool = False) -> bytes:
-        """
-        Returns the HTML body from the MSG file (will check that it has one) with
-        the HTML header injected into it.
-
-        :param prepared: Determines whether to be using the standard HTML (False) or
-            the prepared HTML (True) body (Default: False).
-
-        :raises AttributeError: if the correct HTML body cannot be acquired.
-        :raises BadHtmlError: if :param preparedHtml: is False and the HTML fails to
-            validate.
-        """
-        if not self.htmlBody:
-            raise AttributeError('Cannot inject the HTML header without an HTML body attribute.')
-
-        body = None
-
-        # We don't do this all at once because the prepared body is not cached.
-        if prepared:
-            body = self.htmlBodyPrepared
-
-            # If the body is not valid or not found, raise an AttributeError.
-            if not body:
-                raise AttributeError('Cannot find a prepared HTML body to inject into.')
-        else:
-            body = self.htmlBody
-
-        # Validate the HTML.
-        if not validateHtml(body):
-            # If we are not preparing the HTML body, then raise an
-            # exception.
-            if not prepared:
-                raise BadHtmlError('HTML body failed to pass validation.')
-
-            # If we are here, then we need to do what we can to fix the HTML body.
-            # Unfortunately this gets complicated because of the various ways the
-            # body could be wrong. If only the <body> tag is missing, then we just
-            # need to insert it at the end and be done. If both the <html> and
-            # <body> tag are missing, we determine where to put the body tag (around
-            # everything if there is no <head> tag, otherwise at the end) and then
-            # wrap it all in the <html> tag.
-            parser = bs4.BeautifulSoup(body, features = 'html.parser')
-            if not parser.find('html') and not parser.find('body'):
-                if parser.find('head') or parser.find('footer'):
-                    # Create the parser we will be using for the corrections.
-                    correctedHtml = bs4.BeautifulSoup(b'<html></html>', features = 'html.parser')
-                    htmlTag = correctedHtml.find('html')
-
-                    # Iterate over each of the direct descendents of the parser and
-                    # add each to a new tag if they are not the head or footer.
-                    bodyTag = parser.new_tag('body')
-                    # What we are going to be doing will be causing some of the tags
-                    # to be moved out of the parser, and so the iterator will end up
-                    # pointing to the wrong place after that. To compensate we first
-                    # create a tuple and iterate over that.
-                    for tag in tuple(parser.children):
-                        if tag.name.lower() in ('head', 'footer'):
-                            correctedHtml.append(tag)
-                        else:
-                            bodyTag.append(tag)
-
-                    # All the tags should now be properly in the body, so let's
-                    # insert it.
-                    if correctedHtml.find('head'):
-                        correctedHtml.find('head').insert_after(bodyTag)
-                    elif correctedHtml.find('footer'):
-                        correctedHtml.find('footer').insert_before(bodyTag)
-                    else:
-                        # Neither a head or a body are present, so just append it to
-                        # the main tag.
-                        htmlTag.append(bodyTag)
-                else:
-                    # If there is no <html>, <head>, <footer>, or <body> tag, then
-                    # we just add the tags to the beginning and end of the data and
-                    # move on.
-                    body = b'<html><body>' + body + b'</body></html>'
-            elif parser.find('html'):
-                # Found <html> but not <body>.
-                # Iterate over each of the direct descendents of the parser and
-                # add each to a new tag if they are not the head or footer.
-                bodyTag = parser.new_tag('body')
-                # What we are going to be doing will be causing some of the tags
-                # to be moved out of the parser, and so the iterator will end up
-                # pointing to the wrong place after that. To compensate we first
-                # create a tuple and iterate over that.
-                for tag in tuple(parser.find('html').children):
-                    if tag.name and tag.name.lower() not in ('head', 'footer'):
-                        bodyTag.append(tag)
-
-                # All the tags should now be properly in the body, so let's
-                # insert it.
-                if parser.find('head'):
-                    parser.find('head').insert_after(bodyTag)
-                elif parser.find('footer'):
-                    parser.find('footer').insert_before(bodyTag)
-                else:
-                    parser.find('html').insert(0, bodyTag)
-            else:
-                # Found <body> but not <html>. Just wrap everything in the <html>
-                # tags.
-                body = b'<html>' + body + b'</html>'
-
-        def replace(bodyMarker):
-            """
-            Internal function to replace the body tag with itself plus the header.
-            """
-            # I recently had to change this and how it worked. Now we use a new
-            # property of `MSGFile` that returns a special tuple of tuples to define
-            # how to get all of the properties we are formatting. They are all
-            # processed in the same way, making everything neat. By defining them
-            # in each class, any class can specify a completely different set to be
-            # used.
-            return bodyMarker.group() + self.htmlInjectableHeader.encode('utf-8')
-
-        # Use the previously defined function to inject the HTML header.
-        return constants.RE_HTML_BODY_START.sub(replace, body, 1)
-
-    def injectRtfHeader(self) -> bytes:
-        """
-        Returns the RTF body from this MSG file (will check that it has one)
-        with the RTF header injected into it.
-
-        :raises AttributeError: if the RTF body cannot be acquired.
-        :raises RuntimeError: if all injection attempts fail.
-        """
-        if not self.rtfBody:
-            raise AttributeError('Cannot inject the RTF header without an RTF body attribute.')
-
-        # Try to determine which header to use. Also determines how to sanitize the
-        # rtf.
-        if isEncapsulatedRtf(self.rtfBody):
-            injectableHeader = self.rtfEncapInjectableHeader
-        else:
-            injectableHeader = self.rtfPlainInjectableHeader
-
-        def replace(bodyMarker):
-            """
-            Internal function to replace the body tag with itself plus the header.
-            """
-            return bodyMarker.group() + injectableHeader
-
-        # This first method only applies to documents with encapsulated HTML
-        # that is formatted in a nice way.
-        if isEncapsulatedRtf(self.rtfBody):
-            data = constants.RE_RTF_ENC_BODY_START.sub(replace, self.rtfBody, 1)
-            if data != self.rtfBody:
-                logger.debug('Successfully injected RTF header using encapsulation method.')
-                return data
-            logger.debug('RTF has encapsulated HTML, but injection method failed. It is likely dirty. Will use normal RTF injection method.')
-
-        # If the normal encapsulated HTML injection fails or it isn't
-        # encapsulated, use the internal _rtf module.
-        logger.debug('Using _rtf module to inject RTF text header.')
-        return createDocument(injectStartRTF(self.rtfBody, injectableHeader))
-
-    def save(self, **kwargs):
-        """
-        Saves the message body and attachments found in the message.
-
-        The body and attachments are stored in a folder in the current running
-        directory unless :param customPath: has been specified. The name of the
-        folder will be determined by 3 factors.
-           * If :param customFilename: has been set, the value provided for that
-             will be used.
-           * If :param useMsgFilename: has been set, the name of the file used
-             to create the Message instance will be used.
-           * If the file name has not been provided or :param useMsgFilename:
-             has not been set, the name of the folder will be created using the
-             `defaultFolderName` property.
-           * :param maxNameLength: will force all file names to be shortened
-             to fit in the space (with the extension included in the length). If
-             a number is added to the directory that will not be included in the
-             length, so it is recommended to plan for up to 5 characters extra
-             to be a part of the name. Default is 256.
-
-        It should be noted that regardless of the value for maxNameLength, the
-        name of the file containing the body will always have the name 'message'
-        followed by the full extension.
-
-        There are several parameters used to determine how the message will be
-        saved. By default, the message will be saved as plain text. Setting one
-        of the following parameters to True will change that:
-           * :param html: will output the message in HTML format.
-           * :param json: will output the message in JSON format.
-           * :param raw: will output the message in a raw format.
-           * :param rtf: will output the message in RTF format.
-
-        Usage of more than one formatting parameter will raise an exception.
-
-        Using HTML or RTF will raise an exception if they could not be retrieved
-        unless you have :param allowFallback: set to True. Fallback will go in
-        this order, starting at the top most format that is set:
-           * HTML
-           * RTF
-           * Plain text
-
-        If you want to save the contents into a ZipFile or similar object,
-        either pass a path to where you want to create one or pass an instance
-        to :param zip:. If :param zip: is set, :param customPath: will refer to
-        a location inside the zip file.
-
-        :param attachmentsOnly: Turns off saving the body and only saves the
-            attachments when set.
-        :param saveHeader: Turns on saving the header as a separate file when
-        set.
-        :param skipAttachments: Turns off saving attachments.
-        :param skipHidden: If True, skips attachments marked as hidden.
-            (Default: False)
-        :param skipBodyNotFound: Suppresses errors if no valid body could be
-            found, simply skipping the step of saving the body.
-        :param charset: If the html is being prepared, the charset to use for
-            the Content-Type meta tag to insert. This exists to ensure that
-            something parsing the html can properly determine the encoding (as
-            not having this tag can cause errors in some programs). Set this to
-            `None` or an empty string to not insert the tag (Default: 'utf-8').
-        :param kwargs: Used to allow kwargs expansion in the save function.
-        :param preparedHtml: When set, prepares the HTML body for standalone
-            usage, doing things like adding tags, injecting attachments, etc.
-            This is useful for things like trying to convert the HTML body
-            directly to PDF.
-        :param pdf: Used to enable saving the body as a PDF file.
-        :param wkPath: Used to manually specify the path of the wkhtmltopdf
-            executable. If not specified, the function will try to find it.
-            Useful if wkhtmltopdf is not on the path. If :param pdf: is False,
-            this argument is ignored.
-        :param wkOptions: Used to specify additional options to wkhtmltopdf.
-            this must be a list or list-like object composed of strings and
-            bytes.
-        """
-        # Move keyword arguments into variables.
-        _json = kwargs.get('json', False)
-        html = kwargs.get('html', False)
-        rtf = kwargs.get('rtf', False)
-        raw = kwargs.get('raw', False)
-        pdf = kwargs.get('pdf', False)
-        allowFallback = kwargs.get('allowFallback', False)
-        _zip = kwargs.get('zip')
-        maxNameLength = kwargs.get('maxNameLength', 256)
-
-        # Variables involved in the save location.
-        customFilename = kwargs.get('customFilename')
-        useMsgFilename = kwargs.get('useMsgFilename', False)
-        #maxPathLength = kwargs.get('maxPathLength', 255)
-
-        # Track if we are only saving the attachments.
-        attachOnly = kwargs.get('attachmentsOnly', False)
-        # Track if we are skipping attachments.
-        skipAttachments = kwargs.get('skipAttachments', False)
-        skipHidden = kwargs.get('skipHidden', False)
-        # Track if we should skip the body if no valid body is found instead of
-        # raising an exception.
-        skipBodyNotFound = kwargs.get('skipBodyNotFound', False)
-
-        if pdf:
-            kwargs['preparedHtml'] = True
-
-        # ZipFile handling.
-        if _zip:
-            # `raw` and `zip` are incompatible.
-            if raw:
-                raise IncompatibleOptionsError('The options `raw` and `zip` are incompatible.')
-            # If we are doing a zip file, first check that we have been given a
-            # path.
-            if isinstance(_zip, (str, pathlib.Path)):
-                # If we have a path then we use the zip file.
-                _zip = zipfile.ZipFile(_zip, 'a', zipfile.ZIP_DEFLATED)
-                kwargs['zip'] = _zip
-                createdZip = True
-            else:
-                createdZip = False
-            # Path needs to be done in a special way if we are in a zip file.
-            path = pathlib.Path(kwargs.get('customPath', ''))
-            # Set the open command to be that of the zip file.
-            _open = createZipOpen(_zip.open)
-            # Zip files use w for writing in binary.
-            mode = 'w'
-        else:
-            path = pathlib.Path(kwargs.get('customPath', '.')).absolute()
-            mode = 'wb'
-            _open = open
-
-        # Reset this for sub save calls.
-        kwargs['customFilename'] = None
-
-        # Check if incompatible options have been provided in any way.
-        if _json + html + rtf + raw + attachOnly + pdf > 1:
-            raise IncompatibleOptionsError('Only one of the following options may be used at a time: json, raw, html, rtf, attachmentsOnly, pdf.')
-
-        # TODO: insert code here that will handle checking all of the msg files
-        # to see if the path with overflow.
-
-        if customFilename:
-            # First we need to validate it. If there are invalid characters,
-            # this will detect it.
-            if constants.RE_INVALID_FILENAME_CHARACTERS.search(customFilename):
-                raise ValueError('Invalid character found in customFilename. Must not contain any of the following characters: \\/:*?"<>|')
-            # Quick fix to remove spaces from the end of the filename, if any
-            # are there.
-            customFilename = customFilename.strip()
-            path /= customFilename[:maxNameLength]
-        elif useMsgFilename:
-            if not self.filename:
-                raise ValueError(':param useMsgFilename: is only available if you are using an msg file on the disk or have provided a filename.')
-            # Get the actual name of the file.
-            filename = os.path.split(self.filename)[1]
-            # Remove the extensions.
-            filename = os.path.splitext(filename)[0]
-            # Prepare the filename by removing any special characters.
-            filename = prepareFilename(filename)
-            # Shorted the filename.
-            filename = filename[:maxNameLength]
-            # Check to make sure we actually have a filename to use.
-            if not filename:
-                raise ValueError(f'Invalid filename found in self.filename: "{self.filename}"')
-
-            # Add the file name to the path.
-            path /= filename[:maxNameLength]
-        else:
-            path /= self.defaultFolderName[:maxNameLength]
-
-        # Create the folders.
-        if not _zip:
-            try:
-                os.makedirs(path)
-            except Exception:
-                newDirName = addNumToDir(path)
-                if newDirName:
-                    path = newDirName
-                else:
-                    raise Exception(f'Failed to create directory "{path}". Does it already exist?')
-        else:
-            # In my testing I ended up with multiple files in a zip at the same
-            # location so let's try to handle that.
-            pathCompare = str(path).replace('\\', '/').rstrip('/') + '/'
-            if any(x.startswith(pathCompare) for x in _zip.namelist()):
-                newDirName = addNumToZipDir(path, _zip)
-                if newDirName:
-                    path = newDirName
-                else:
-                    raise Exception(f'Failed to create directory "{path}". Does it already exist?')
-
-        # Update the kwargs.
-        kwargs['customPath'] = path
-
-        if raw:
-            self.saveRaw(path)
-            return self
-
-        # If the user has requested the headers for this file, save it now.
-        if kwargs.get('saveHeader', False):
-            headerText = self._getStringStream('__substg1.0_007D')
-            if not headerText:
-                headerText = constants.HEADER_FORMAT.format(subject = self.subject, **self.header)
-
-            with _open(str(path / 'header.txt'), mode) as f:
-                f.write(headerText.encode('utf-8'))
-
-        try:
-            if not attachOnly:
-                # Check what to save the body with.
-                fext = 'json' if _json else 'txt'
-
-                fallbackToPlain = False
-                useHtml = False
-                usePdf = False
-                useRtf = False
-                if html:
-                    if self.htmlBody:
-                        useHtml = True
-                        fext = 'html'
-                    elif not allowFallback:
-                        if skipBodyNotFound:
-                            fext = None
-                        else:
-                            raise DataNotFoundError('Could not find the htmlBody.')
-
-                if pdf:
-                    if self.htmlBody:
-                        usePdf = True
-                        fext = 'pdf'
-                    elif not allowFallback:
-                        if skipBodyNotFound:
-                            fext = None
-                        else:
-                            raise DataNotFoundError('Count not find the htmlBody to convert to pdf.')
-
-                if rtf or (html and not useHtml) or (pdf and not usePdf):
-                    if self.rtfBody:
-                        useRtf = True
-                        fext = 'rtf'
-                    elif not allowFallback:
-                        if skipBodyNotFound:
-                            fext = None
-                        else:
-                            raise DataNotFoundError('Could not find the rtfBody.')
-                    else:
-                        # This was the last resort before plain text, so fall
-                        # back to that.
-                        fallbackToPlain = True
-
-                # After all other options, try to go with plain text if
-                # possible.
-                if not (rtf or html or pdf) or fallbackToPlain:
-                    # We need to check if the plain text body was found. If it
-                    # was found but was empty that is considered valid, so we
-                    # specifically check against None.
-                    if self.body is None:
-                        if skipBodyNotFound:
-                            fext = None
-                        else:
-                            if allowFallback:
-                                raise DataNotFoundError('Could not find a valid body using current options.')
-                            else:
-                                raise DataNotFoundError('Plain text body could not be found.')
-
-
-            if not skipAttachments:
-                # Save the attachments.
-                attachmentNames = [attachment.save(**kwargs) for attachment in self.attachments if not (skipHidden and attachment.hidden)]
-                # Remove skipped attachments.
-                attachmentNames = [x for x in attachmentNames if x and isinstance(x, str)]
-
-            if not attachOnly and fext:
-                with _open(str(path / ('message.' + fext)), mode) as f:
-                    if _json:
-                        emailObj = json.loads(self.getJson())
-                        if not skipAttachments:
-                            emailObj['attachments'] = attachmentNames
-
-                        f.write(inputToBytes(json.dumps(emailObj), 'utf-8'))
-                    elif useHtml:
-                        f.write(self.getSaveHtmlBody(**kwargs))
-                    elif usePdf:
-                        f.write(self.getSavePdfBody(**kwargs))
-                    elif useRtf:
-                        f.write(self.getSaveRtfBody(**kwargs))
-                    else:
-                        f.write(self.getSaveBody(**kwargs))
-
-        except Exception:
-            if not _zip:
-                self.saveRaw(path)
-            raise
-        finally:
-            # Close the ZipFile if this function created it.
-            if _zip and createdZip:
-                _zip.close()
-
-        # Return the instance so that functions can easily be chained.
-        return self
-
-    @property
-    def bcc(self) -> Optional[str]:
-        """
-        Returns the bcc field, if it exists.
-        """
-        return self._genRecipient('bcc', RecipientType.BCC)
-
-    @property
-    def body(self) -> Optional[str]:
-        """
-        Returns the message body, if it exists.
-        """
-        try:
-            return self._body
-        except AttributeError:
-            if self._ensureSet('_body', '__substg1.0_1000'):
-                pass
-            else:
-                # If the body doesn't exist, see if we can get it from the RTF
-                # body.
-                if self.rtfBody:
-                    self._body = self.deencapsulateBody(self.rtfBody, DeencapType.PLAIN)
-
-            if self._body:
-                self._body = inputToString(self._body, 'utf-8')
-                a = re.search('\n', self._body)
-                if a is not None:
-                    if re.search('\r\n', self._body) is not None:
-                        self.__crlf = '\r\n'
-            return self._body
-
-    @property
-    def cc(self) -> Optional[str]:
-        """
-        Returns the cc field, if it exists.
-        """
-        return self._genRecipient('cc', RecipientType.CC)
-
-    @property
-    def compressedRtf(self) -> Optional[bytes]:
-        """
-        Returns the compressed RTF stream, if it exists.
-        """
-        return self._ensureSet('_compressedRtf', '__substg1.0_10090102', False)
-
-    @property
-    def crlf(self) -> str:
-        """
-        Returns the value of self.__crlf, should you need it for whatever
-        reason.
-        """
-        self.body
-        return self.__crlf
-
-    @property
-    def date(self) -> Optional[str]:
-        """
-        Returns the send date, if it exists.
-        """
-        try:
-            return self._date
-        except AttributeError:
-            self._date = self._prop.date if self.isSent else None
-            return self._date
-
-    @property
-    def deencapsulatedRtf(self) -> Optional[RTFDE.DeEncapsulator]:
-        """
-        Returns the instance of the deencapsulated RTF body. If there is no RTF
-        body or the body is not encasulated, returns None.
-        """
-        try:
-            return self._deencapsultor
-        except AttributeError:
-            if self.rtfBody:
-                # If there is an RTF body, we try to deencapsulate it.
-                body = self.rtfBody
-                # Sometimes you get MSG files whose RTF body has stuff
-                # *after* the body, and RTFDE can't handle that. Here is
-                # how we compensate.
-                while body and body[-1] != 125:
-                    body = body[:-1]
-
-                try:
-                    try:
-                        self._deencapsultor = RTFDE.DeEncapsulator(body)
-                    except UnicodeDecodeError:
-                        # There is a known issue that bytes are not well decoded
-                        # by RTFDE right now, so let's see if we can't manually
-                        # decode it and see if that will work.
-                        #
-                        # There is also the fact that it is decoded *at all*
-                        # before binary data is stripped out. This data should
-                        # almost certainly be stripped out, so let's log it and
-                        # then log if we removed any of them before trying this.
-                        logger.warning(f'RTFDE failed to decode rtfBody for message with subject "{self.subject}". Attempting to cut out unnecessary data and override decoding.')
-
-                        match = constants.RE_BIN.search(body)
-                        # Because we are going to be actively removing things,
-                        # we want to search the entire thing over again.
-                        while match:
-                            logger.info(f'Found match to bin data starting at location {match.start()}. Replacing with nothing.')
-                            length = int(match.group(1))
-                            # Extract the entire binary section and replace it.
-                            body = body.replace(body[match.start():match.end() + length], b'', 1)
-                            match = constants.RE_BIN.search(body)
-
-                        self._deencapsultor = RTFDE.DeEncapsulator(body.decode(chardet.detect(body)['encoding']))
-                    self._deencapsultor.deencapsulate()
-                except RTFDE.exceptions.NotEncapsulatedRtf as e:
-                    logger.debug('RTF body is not encapsulated.')
-                    self._deencapsultor = None
-                except RTFDE.exceptions.MalformedEncapsulatedRtf as _e:
-                    logger.info('RTF body contains malformed encapsulated content.')
-                    self._deencapsultor = None
-                except Exception:
-                    # If we are just ignoring the errors, log it then set to
-                    # None. Otherwise, continue the exception.
-                    if not self.__ignoreRtfDeErrors:
-                        raise
-                    logger.exception('Unhandled error happened while using RTFDE. You have choosen to ignore these errors.')
-                    self._deencapsultor = None
-            else:
-                self._deencapsultor = None
-            return self._deencapsultor
-
-    @property
-    def defaultFolderName(self) -> str:
-        """
-        Generates the default name of the save folder.
-        """
-        try:
-            return self._defaultFolderName
-        except AttributeError:
-            d = self.parsedDate
-
-            dirName = '{0:02d}-{1:02d}-{2:02d}_{3:02d}{4:02d}'.format(*d) if d else 'UnknownDate'
-            dirName += ' ' + (prepareFilename(self.subject) if self.subject else '[No subject]')
-            dirName = dirName.strip()
-
-            self._defaultFolderName = dirName
-            return dirName
-
-    @property
-    def header(self):
-        """
-        Returns the message header, if it exists. Otherwise it will generate
-        one.
-        """
-        try:
-            return self._header
-        except AttributeError:
-            headerText = self._getStringStream('__substg1.0_007D')
-            if headerText:
-                self._header = EmailParser().parsestr(headerText)
-                self._header['date'] = self.date
-            else:
-                logger.info('Header is empty or was not found. Header will be generated from other streams.')
-                header = EmailParser().parsestr('')
-                header.add_header('Date', self.date)
-                header.add_header('From', self.sender)
-                header.add_header('To', self.to)
-                header.add_header('Cc', self.cc)
-                header.add_header('Bcc', self.bcc)
-                header.add_header('Message-Id', self.messageId)
-                # TODO find authentication results outside of header
-                header.add_header('Authentication-Results', None)
-                self._header = header
-            return self._header
-
-    @property
-    def headerDict(self) -> dict:
-        """
-        Returns a dictionary of the entries in the header
-        """
-        try:
-            return self._headerDict
-        except AttributeError:
-            self._headerDict = dict(self.header._headers)
-            try:
-                self._headerDict.pop('Received')
-            except KeyError:
-                pass
-            return self._headerDict
-
-    @property
-    def headerFormatProperties(self) -> constants.HEADER_FORMAT_TYPE:
-        """
-        Returns a dictionary of properties, in order, to be formatted into the
-        header. Keys are the names to use in the header while the values are one
-        of the following:
-        None: Signifies no data was found for the property and it should be
-            omitted from the header.
-        str: A string to be formatted into the header using the string encoding.
-        Tuple[Union[str, None], bool]: A string should be formatted into the
-            header. If the bool is True, then place an empty string if the value
-            is None, otherwise follow the same behavior as regular None.
-
-        Additional note: If the value is an empty string, it will be dropped as
-        well by default.
-
-        Additionally you can group members of a header together by placing them
-        in an embedded dictionary. Groups will be spaced out using a second
-        instance of the join string. If any member of a group is being printed,
-        it will be spaced apart from the next group/item.
-
-        If you class should not do *any* header injection, return None from this
-        property.
-        """
-        # Checking outlook printing, default behavior is to completely omit
-        # *any* field that is not present. So while for extensability the
-        # option exists to have it be present even if no data is found, we are
-        # specifically not doing that.
-        return {
-            '-basic info-': {
-                'From': self.sender,
-                'Sent': self.date,
-                'To': self.to,
-                'Cc': self.cc,
-                'Bcc': self.bcc,
-                'Subject': self.subject,
-            },
-            '-importance-': {
-                'Importance': self.importanceString,
-            },
-        }
-
-    @property
-    def htmlBody(self) -> Optional[bytes]:
-        """
-        Returns the html body, if it exists.
-        """
-        try:
-            return self._htmlBody
-        except AttributeError:
-            if self._ensureSet('_htmlBody', '__substg1.0_10130102', False):
-                # Reducing line repetition.
-                pass
-            elif self.rtfBody:
-                logger.info('HTML body was not found, attempting to generate from RTF.')
-                self._htmlBody = self.deencapsulateBody(self.rtfBody, DeencapType.HTML)
-            # This is it's own if statement so we can ensure it will generate
-            # even if there is an rtfBody, in the event it doesn't have HTML.
-            if not self._htmlBody and self.body:
-                # Convert the plain text body to html.
-                logger.info('HTML body was not found, attempting to generate from plain text body.')
-                correctedBody = html.escape(self.body).replace('\r', '').replace('\n', '<br />')
-                self._htmlBody = f'<html><body>{correctedBody}</body></head>'.encode('utf-8')
-
-            if not self._htmlBody:
-                logger.info('HTML body could not be found nor generated.')
-
-            return self._htmlBody
-
-    @property
-    def htmlBodyPrepared(self) -> Optional[bytes]:
-        """
-        Returns the HTML body that has (where possible) the embedded attachments
-        inserted into the body.
-        """
-        # If we can't get an HTML body then we have nothing to do.
-        if not self.htmlBody:
-            return self.htmlBody
-
-        # Create the BeautifulSoup instance to use.
-        soup = bs4.BeautifulSoup(self.htmlBody, 'html.parser')
-
-        # Get a list of image tags to see if we can inject into. If the source
-        # of an image starts with "cid:" that means it is one of the attachments
-        # and is using the content id of that attachment.
-        tags = (tag for tag in soup.findAll('img') if tag.get('src') and tag.get('src').startswith('cid:'))
-
-        for tag in tags:
-            # Iterate through the attachments until we get the right one.
-            cid = tag['src'][4:]
-            data = next((attachment.data for attachment in self.attachments if attachment.cid == cid), None)
-            # If we found anything, inject it.
-            if data:
-                tag['src'] = (b'data:image;base64,' + base64.b64encode(data)).decode('utf-8')
-
-        return soup.prettify('utf-8')
-
-    @property
-    def htmlInjectableHeader(self) -> str:
-        """
-        The header that can be formatted and injected into the html body.
-        """
-        prefix = '<div id="injectedHeader"><div><p class="MsoNormal">'
-        suffix = '<o:p></o:p></p></div></div>'
-        joinStr = '<br/>'
-        formatter = (lambda name, value : f'<b>{name}:</b>&nbsp;{inputToString(htmlSanitize(value), self.stringEncoding)}')
-
-        return self.getInjectableHeader(prefix, joinStr, suffix, formatter)
-
-    @property
-    def inReplyTo(self) -> Optional[str]:
-        """
-        Returns the message id that this message is in reply to.
-        """
-        return self._ensureSet('_in_reply_to', '__substg1.0_1042')
-
-    @property
-    def isRead(self) -> bool:
-        """
-        Returns if this email has been marked as read.
-        """
-        return bool(self.props['0E070003'].value & 1)
-
-    @property
-    def isSent(self) -> bool:
-        """
-        Returns if this email has been marked as sent. Assumes True if no flags
-        are found.
-        """
-        if not self.props.get('0E070003'):
-            return True
-        else:
-            return not bool(self.props['0E070003'].value & 8)
-
-    @property
-    def messageId(self) -> Optional[str]:
-        try:
-            return self._messageId
-        except AttributeError:
-            headerResult = None
-            if self.headerInit():
-                headerResult = self._header['message-id']
-            if headerResult is not None:
-                self._messageId = headerResult
-            else:
-                if self.headerInit():
-                    logger.info('Header found, but "Message-Id" is not included. Will be generated from other streams.')
-                self._messageId = self._getStringStream('__substg1.0_1035')
-            return self._messageId
-
-    @property
-    def parsedDate(self):
-        return email.utils.parsedate(self.date)
-
-    @property
-    def receivedTime(self) -> Optional[datetime.datetime]:
-        """
-        The date and time the message was received by the server.
-        """
-        return self._ensureSetProperty('_receivedTime', '0E060040')
-
-    @property
-    def recipientSeparator(self) -> str:
-        return self.__recipientSeparator
-
-    @property
-    def recipients(self) -> List[Recipient]:
-        """
-        Returns a list of all recipients.
-        """
-        try:
-            return self._recipients
-        except AttributeError:
-            # Get the recipients
-            recipientDirs = []
-            prefixLen = self.prefixLen
-            for dir_ in self.listDir():
-                if dir_[prefixLen].startswith('__recip') and\
-                        dir_[prefixLen] not in recipientDirs:
-                    recipientDirs.append(dir_[prefixLen])
-
-            self._recipients = []
-
-            for recipientDir in recipientDirs:
-                self._recipients.append(Recipient(recipientDir, self))
-
-            return self._recipients
-
-    @property
-    def reportTag(self) -> Optional[ReportTag]:
-        """
-        Data that is used to correlate the report and the original message.
-        """
-        return self._ensureSet('_reportTag', '__substg1.0_00310102', False, overrideClass = ReportTag)
-
-    @property
-    def rtfBody(self) -> Optional[bytes]:
-        """
-        Returns the decompressed Rtf body from the message.
-        """
-        try:
-            return self._rtfBody
-        except AttributeError:
-            self._rtfBody = compressed_rtf.decompress(self.compressedRtf) if self.compressedRtf else None
-            return self._rtfBody
-
-    @property
-    def rtfEncapInjectableHeader(self) -> bytes:
-        """
-        The header that can be formatted and injected into the plain RTF body.
-        """
-        prefix = r'\htmlrtf {\htmlrtf0 {\*\htmltag96 <div>}{\*\htmltag96 <div>}{\*\htmltag64 <p class=MsoNormal>}'
-        suffix = r'{\*\htmltag244 <o:p>}{\*\htmlrag252 </o:p>}\htmlrtf \par\par\htmlrtf0 {\*\htmltag72 </p>}{\*\htmltag104 </div>}{\*\htmltag104 </div>}\htmlrtf }\htmlrtf0 '
-        joinStr = r'{\*\htmltag116 <br />}\htmlrtf \line\htmlrtf0 '
-        formatter = (lambda name, value : fr'\htmlrtf {{\b\htmlrtf0{{\*\htmltag84 <b>}}{name}: {{\*\htmltag92 </b>}}\htmlrtf \b0\htmlrtf0 {inputToString(rtfSanitizeHtml(value), self.stringEncoding)}\htmlrtf }}\htmlrtf0')
-
-        return self.getInjectableHeader(prefix, joinStr, suffix, formatter).encode('utf-8')
-
-    @property
-    def rtfPlainInjectableHeader(self) -> bytes:
-        """
-        The header that can be formatted and injected into the encapsulated RTF
-        body.
-        """
-        prefix = '{'
-        suffix = r'\par\par}'
-        joinStr = r'\line'
-        formatter = (lambda name, value : fr'{{\b {name}: \b0 {inputToString(rtfSanitizePlain(value), self.stringEncoding)}}}')
-
-        return self.getInjectableHeader(prefix, joinStr, suffix, formatter).encode('utf-8')
-
-    @property
-    def sender(self) -> Optional[str]:
-        """
-        Returns the message sender, if it exists.
-        """
-        try:
-            return self._sender
-        except AttributeError:
-            # Check header first
-            if self.headerInit():
-                headerResult = self.header['from']
-                if headerResult is not None:
-                    self._sender = headerResult
-                    return headerResult
-                logger.info('Header found, but "sender" is not included. Will be generated from other streams.')
-            # Extract from other fields
-            text = self._getStringStream('__substg1.0_0C1A')
-            email = self._getStringStream('__substg1.0_5D01')
-            # Will not give an email address sometimes. Seems to exclude the email address if YOU are the sender.
-            result = None
-            if text is None:
-                result = email
-            else:
-                result = text
-                if email is not None:
-                    result += ' <' + email + '>'
-
-            self._sender = result
-            return result
-
-    @property
-    def subject(self) -> Optional[str]:
-        """
-        Returns the message subject, if it exists.
-        """
-        return self._ensureSet('_subject', '__substg1.0_0037')
-
-    @property
-    def to(self) -> Optional[str]:
-        """
-        Returns the to field, if it exists.
-        """
-        return self._genRecipient('to', RecipientType.TO)
+__all__ = [
+    'MessageBase',
+]
+
+
+import base64
+import datetime
+import email.utils
+import html
+import json
+import logging
+import os
+import pathlib
+import re
+import subprocess
+import zipfile
+
+import bs4
+import chardet
+import compressed_rtf
+import RTFDE
+
+from email.parser import Parser as EmailParser
+from typing import Callable, List, Optional, Union
+
+from . import constants
+from ._rtf.create_doc import createDocument
+from ._rtf.inject_rtf import injectStartRTF
+from .enums import DeencapType, RecipientType
+from .exceptions import (
+        BadHtmlError, DataNotFoundError, DeencapMalformedData,
+        DeencapNotEncapsulated, IncompatibleOptionsError, WKError
+    )
+from .msg import MSGFile
+from .structures.report_tag import ReportTag
+from .recipient import Recipient
+from .utils import (
+        addNumToDir, addNumToZipDir, createZipOpen, findWk, htmlSanitize,
+        inputToBytes, inputToString, isEncapsulatedRtf, prepareFilename,
+        rtfSanitizeHtml, rtfSanitizePlain, validateHtml
+    )
+
+from imapclient.imapclient import decode_utf7
+
+
+logger = logging.getLogger(__name__)
+logger.addHandler(logging.NullHandler())
+
+
+class MessageBase(MSGFile):
+    """
+    Base class for Message like msg files.
+    """
+
+    def __init__(self, path, **kwargs):
+        """
+        :param path: path to the msg file in the system or is the raw msg file.
+        :param prefix: used for extracting embeded msg files
+            inside the main one. Do not set manually unless
+            you know what you are doing.
+        :param parentMsg: Used for syncronizing named properties instances. Do
+            not set this unless you know what you are doing.
+        :param attachmentClass: Optional, the class the Message object
+            will use for attachments. You probably should
+            not change this value unless you know what you
+            are doing.
+        :param filename: Optional, the filename to be used by default when
+            saving.
+        :param delayAttachments: Optional, delays the initialization of
+            attachments until the user attempts to retrieve them. Allows MSG
+            files with bad attachments to be initialized so the other data can
+            be retrieved.
+        :param overrideEncoding: Optional, an encoding to use instead of the one
+            specified by the msg file. Do not report encoding errors caused by
+            this.
+        :param attachmentErrorBehavior: Optional, the behavior to use in the
+            event of an error when parsing the attachments.
+        :param recipientSeparator: Optional, separator string to use between
+            recipients.
+        :param ignoreRtfDeErrors: Optional, specifies that any errors that occur
+            from the usage of RTFDE should be ignored (default: False).
+        :param deencapsulationFunc: Optional, if specified must be a callable
+            that will override the way that HTML/text is deencapsulated from the
+            RTF body. This function must take exactly 2 arguments, the first
+            being the RTF body from the message and the second being an instance
+            of the enum DeencapType that will tell the function what type of
+            body is desired. The function should return a string for plain text
+            and bytes for HTML. If any problems occur, the function *must*
+            either return None or raise one of the appropriate functions from
+            extract_msg.exceptions. All other exceptions must be handled
+            internally or they will not be caught. The original deencapsulation
+            method will not run if this is set.
+        """
+        super().__init__(path, **kwargs)
+        recipientSeparator = ';'
+        self.__recipientSeparator = kwargs.get('recipientSeparator', ';')
+        self.__ignoreRtfDeErrors = kwargs.get('ignoreRtfDeErrors', False)
+        self.__deencap = kwargs.get('deencapsulationFunc')
+        # Initialize properties in the order that is least likely to cause bugs.
+        # TODO have each function check for initialization of needed data so
+        # these lines will be unnecessary.
+        self.props
+        self.header
+        self.recipients
+
+        self.to
+        self.cc
+        self.sender
+        self.date
+        # This variable keeps track of what the new line character should be.
+        self.__crlf = '\n'
+        try:
+            self.body
+        except Exception as e:
+            # Prevent an error in the body from preventing opening.
+            logger.exception('Critical error accessing the body. File opened but accessing the body will throw an exception.')
+        self.named
+        self.namedProperties
+
+    def _genRecipient(self, recipientType, recipientInt : RecipientType) -> Optional[str]:
+        """
+        Returns the specified recipient field.
+        """
+        private = '_' + recipientType
+        recipientInt = RecipientType(recipientInt)
+        try:
+            return getattr(self, private)
+        except AttributeError:
+            value = None
+            # Check header first.
+            if self.headerInit():
+                value = self.header[recipientType]
+                if value:
+                    value = value.replace(',', self.__recipientSeparator)
+
+            # If the header had a blank field or didn't have the field, generate
+            # it manually.
+            if not value:
+                # Check if the header has initialized.
+                if self.headerInit():
+                    logger.info(f'Header found, but "{recipientType}" is not included. Will be generated from other streams.')
+
+                # Get a list of the recipients of the specified type.
+                foundRecipients = tuple(recipient.formatted for recipient in self.recipients if recipient.type == recipientInt)
+
+                # If we found recipients, join them with the recipient separator
+                # and a space.
+                if len(foundRecipients) > 0:
+                    value = (self.__recipientSeparator + ' ').join(foundRecipients)
+
+            # Code to fix the formatting so it's all a single line. This allows
+            # the user to format it themself if they want. This should probably
+            # be redone to use re or something, but I can do that later. This
+            # shouldn't be a huge problem for now.
+            if value:
+                value = value.replace(' \r\n\t', ' ').replace('\r\n\t ', ' ').replace('\r\n\t', ' ')
+                value = value.replace('\r\n', ' ').replace('\r', ' ').replace('\n', ' ')
+                while value.find('  ') != -1:
+                    value = value.replace('  ', ' ')
+
+            # Set the field in the class.
+            setattr(self, private, value)
+
+            return value
+
+    def deencapsulateBody(self, rtfBody : bytes, bodyType : DeencapType) -> Optional[Union[bytes, str]]:
+        """
+        A function to deencapsulate the specified body from the rtfBody. Returns
+        a string for plain text and bytes for HTML. If specified, uses the
+        deencapsulation override function. Returns None if nothing could be
+        deencapsulated.
+
+        If you want to change the deencapsulation behaviour in a base class,
+        simply override this function.
+        """
+        if rtfBody:
+            bodyType = DeencapType(bodyType)
+            if bodyType == DeencapType.PLAIN:
+                if self.__deencap:
+                    try:
+                        return self.__deencap(rtfBody, DeencapType.PLAIN)
+                    except DeencapMalformedData:
+                        logger.exception('Custom deencapsulation function reported encapsulated data was malformed.')
+                    except DeencapNotEncapsulated:
+                        logger.exception('Custom deencapsulation function reported data is not encapsulated.')
+                else:
+                    if self.deencapsulatedRtf and self.deencapsulatedRtf.content_type == 'text':
+                        return self.deencapsulatedRtf.text
+            else:
+                if self.__deencap:
+                    try:
+                        return self.__deencap(rtfBody, DeencapType.HTML)
+                    except DeencapMalformedData:
+                        logger.exception('Custom deencapsulation function reported encapsulated data was malformed.')
+                    except DeencapNotEncapsulated:
+                        logger.exception('Custom deencapsulation function reported data is not encapsulated.')
+                else:
+                    if self.deencapsulatedRtf and self.deencapsulatedRtf.content_type == 'html':
+                        return self.deencapsulatedRtf.html.encode('utf-8')
+
+            if bodyType == DeencapType.PLAIN:
+                logger.info('Could not deencapsulate plain text from RTF body.')
+            else:
+                logger.info('Could not deencapsulate HTML from RTF body.')
+        else:
+            logger.info('No RTF body to deencapsulate from.')
+        return None
+
+    def dump(self) -> None:
+        """
+        Prints out a summary of the message.
+        """
+        print('Message')
+        print('Subject:', self.subject)
+        print('Date:', self.date)
+        print('Body:')
+        print(self.body)
+
+    def getInjectableHeader(self, prefix : str, joinStr : str, suffix : str, formatter : Callable[[str, str], str]) -> str:
+        """
+        Using the specified prefix, suffix, formatter, and join string,
+        generates the injectable header. Prefix is placed at the beginning,
+        followed by a series of format strings joined together with the join
+        string, with the suffix placed afterwards. Effectively makes this
+        structure:
+        {prefix}{formatter()}{joinStr}{formatter()}{joinStr}...{formatter()}{suffix}
+
+        Formatter be a function that takes first a name variable then a value
+        variable and formats the line.
+
+        If self.headerFormatProperties is None, immediately returns an empty
+        string.
+        """
+        formattedProps = []
+        allProps = self.headerFormatProperties
+
+        if allProps is None:
+            return ''
+
+        for entry in allProps:
+            isGroup = False
+            entryUsed = False
+            # This is how we handle the groups.
+            if isinstance(allProps[entry], dict):
+                props = allProps[entry]
+                isGroup = True
+            else:
+                props = {entry: allProps[entry]}
+
+            for name in props:
+                if props[name]:
+                    if isinstance(props[name], tuple):
+                        if props[name][1]:
+                            value = props[name][0] or ''
+                        elif props[name][0] is not None:
+                            value = props[name][0]
+                        else:
+                            continue
+                    else:
+                        value = props[name]
+
+                    entryUsed = True
+                    formattedProps.append(formatter(name, value))
+
+            # Now if we are working with a group, add an empty entry to get a
+            # second join string between this section and the last, but *only*
+            # if any of the entries were used.
+            if isGroup and entryUsed:
+                formattedProps.append('')
+
+        # If the last entry is empty, remove it. We don't want extra spacing at
+        # the end.
+        if formattedProps[-1] == '':
+            formattedProps.pop()
+
+        return prefix + joinStr.join(formattedProps) + suffix
+
+    def getJson(self) -> str:
+        """
+        Returns the JSON representation of the Message.
+        """
+        return json.dumps({
+            'from': inputToString(self.sender, self.stringEncoding),
+            'to': inputToString(self.to, self.stringEncoding),
+            'cc': inputToString(self.cc, self.stringEncoding),
+            'bcc': inputToString(self.bcc, self.stringEncoding),
+            'subject': inputToString(self.subject, self.stringEncoding),
+            'date': inputToString(self.date, self.stringEncoding),
+            'body': decode_utf7(self.body),
+        })
+
+    def getSaveBody(self, **kwargs) -> bytes:
+        """
+        Returns the plain text body that will be used in saving based on the
+        arguments.
+
+        :param kwargs: Used to allow kwargs expansion in the save function.
+            Arguments absorbed by this are simply ignored.
+        """
+        # Get the type of line endings.
+        crlf = inputToString(self.crlf, 'utf-8')
+
+        prefix = ''
+        suffix = crlf + '-----------------' + crlf + crlf
+        joinStr = crlf
+        formatter = (lambda name, value : f'{name}: {value}')
+
+        header = self.getInjectableHeader(prefix, joinStr, suffix, formatter).encode('utf-8')
+        return header + inputToBytes(self.body, 'utf-8')
+
+    def getSaveHtmlBody(self, preparedHtml : bool = False, charset : str = 'utf-8', **kwargs) -> bytes:
+        """
+        Returns the HTML body that will be used in saving based on the
+        arguments.
+
+        :param preparedHtml: Whether or not the HTML should be prepared for
+            standalone use (add tags, inject images, etc.).
+        :param charset: If the html is being prepared, the charset to use for
+            the Content-Type meta tag to insert. This exists to ensure that
+            something parsing the html can properly determine the encoding (as
+            not having this tag can cause errors in some programs). Set this to
+            `None` or an empty string to not insert the tag (Default: 'utf-8').
+        :param kwargs: Used to allow kwargs expansion in the save function.
+            Arguments absorbed by this are simply ignored.
+
+        :raises BadHtmlError: if :param preparedHtml: is False and the HTML
+            fails to validate.
+        """
+        if self.htmlBody:
+            # Inject the header into the data.
+            data = self.injectHtmlHeader(prepared = preparedHtml)
+
+            # If we are preparing the HTML, then we should
+            if preparedHtml and charset:
+                bs = bs4.BeautifulSoup(data, features = 'html.parser')
+                if not bs.find('meta', {'http-equiv': 'Content-Type'}):
+                    # Setup the attributes for the tag.
+                    tagAttrs = {
+                        'http-equiv': 'Content-Type',
+                        'content': f'text/html; charset={charset}',
+                    }
+                    # Create the tag.
+                    tag = bs4.Tag(parser = bs, name = 'meta', attrs = tagAttrs, can_be_empty_element = True)
+                    # Add the tag to the head section.
+                    if bs.find('head'):
+                        bs.find('head').insert(0, tag)
+                    else:
+                        # If we are here, the head doesn't exist, so let's add
+                        # it.
+                        if bs.find('html'):
+                            # This should always be true, but I want to be safe.
+                            head = bs4.Tag(parser = bs, name = 'head')
+                            head.insert(0, tag)
+                            bs.find('html').insert(0, head)
+
+                    data = bs.prettify('utf-8')
+
+            return data
+        else:
+            return self.htmlBody
+
+    def getSavePdfBody(self, **kwargs) -> bytes:
+        """
+        Returns the PDF body that will be used in saving based on the arguments.
+
+        :param wkPath: Used to manually specify the path of the wkhtmltopdf
+            executable. If not specified, the function will try to find it.
+            Useful if wkhtmltopdf is not on the path. If :param pdf: is False,
+            this argument is ignored.
+        :param wkOptions: Used to specify additional options to wkhtmltopdf.
+            this must be a list or list-like object composed of strings and
+            bytes.
+        :param kwargs: Used to allow kwargs expansion in the save function.
+            Arguments absorbed by this are simply ignored.
+
+        :raises ExecutableNotFound: The wkhtmltopdf executable could not be
+            found.
+        :raises WKError: Something went wrong in creating the PDF body.
+        """
+        # Immediately try to find the executable.
+        wkPath = findWk(kwargs.get('wkPath'))
+
+        # First thing is first, we need to parse our wkOptions if they exist.
+        wkOptions = kwargs.get('wkOptions')
+        if wkOptions:
+            try:
+                # Try to convert to a list, whatever it is, and fail if it is
+                # not possible.
+                parsedWkOptions = [*wkOptions]
+            except TypeError:
+                raise TypeError(f':param wkOptions: must be an iterable, not {type(wkOptions)}.')
+        else:
+            parsedWkOptions = []
+
+        # Confirm that all of our options we now have are either strings or
+        # bytes.
+        if not all(isinstance(option, (str, bytes)) for option in parsedWkOptions):
+            raise TypeError(':param wkOptions: must be an iterable of strings and bytes.')
+
+        processArgs = [wkPath, *parsedWkOptions, '-', '-']
+        # Log the arguments.
+        logger.info(f'Converting to PDF with the following arguments: {processArgs}')
+
+        # Get the html body *before* calling Popen.
+        htmlBody = self.getSaveHtmlBody(**kwargs)
+
+        # We call the program to convert the html, but give tell it the data
+        # will go in and come out through stdin and stdout, respectively. This
+        # way we don't have to write temporary files to the disk. We also ask
+        # that it be quiet about it.
+        process = subprocess.run(processArgs, input = htmlBody, stdout = subprocess.PIPE, stderr = subprocess.PIPE)
+        # Give the program the data and wait for the program to finish.
+        #output = process.communicate(htmlBody)
+
+        # If it errored, throw it as an exception.
+        if process.returncode != 0:
+            raise WKError(process.stderr.decode('utf-8'))
+
+        return process.stdout
+
+    def getSaveRtfBody(self, **kwargs) -> bytes:
+        """
+        Returns the RTF body that will be used in saving based on the arguments.
+
+        :param kwargs: Used to allow kwargs expansion in the save function.
+            Arguments absorbed by this are simply ignored.
+        """
+        # Inject the header into the data.
+        return self.injectRtfHeader()
+
+    def headerInit(self) -> bool:
+        """
+        Checks whether the header has been initialized.
+        """
+        try:
+            self._header
+            return True
+        except AttributeError:
+            return False
+
+    def injectHtmlHeader(self, prepared : bool = False) -> bytes:
+        """
+        Returns the HTML body from the MSG file (will check that it has one) with
+        the HTML header injected into it.
+
+        :param prepared: Determines whether to be using the standard HTML (False) or
+            the prepared HTML (True) body (Default: False).
+
+        :raises AttributeError: if the correct HTML body cannot be acquired.
+        :raises BadHtmlError: if :param preparedHtml: is False and the HTML fails to
+            validate.
+        """
+        if not self.htmlBody:
+            raise AttributeError('Cannot inject the HTML header without an HTML body attribute.')
+
+        body = None
+
+        # We don't do this all at once because the prepared body is not cached.
+        if prepared:
+            body = self.htmlBodyPrepared
+
+            # If the body is not valid or not found, raise an AttributeError.
+            if not body:
+                raise AttributeError('Cannot find a prepared HTML body to inject into.')
+        else:
+            body = self.htmlBody
+
+        # Validate the HTML.
+        if not validateHtml(body):
+            # If we are not preparing the HTML body, then raise an
+            # exception.
+            if not prepared:
+                raise BadHtmlError('HTML body failed to pass validation.')
+
+            # If we are here, then we need to do what we can to fix the HTML body.
+            # Unfortunately this gets complicated because of the various ways the
+            # body could be wrong. If only the <body> tag is missing, then we just
+            # need to insert it at the end and be done. If both the <html> and
+            # <body> tag are missing, we determine where to put the body tag (around
+            # everything if there is no <head> tag, otherwise at the end) and then
+            # wrap it all in the <html> tag.
+            parser = bs4.BeautifulSoup(body, features = 'html.parser')
+            if not parser.find('html') and not parser.find('body'):
+                if parser.find('head') or parser.find('footer'):
+                    # Create the parser we will be using for the corrections.
+                    correctedHtml = bs4.BeautifulSoup(b'<html></html>', features = 'html.parser')
+                    htmlTag = correctedHtml.find('html')
+
+                    # Iterate over each of the direct descendents of the parser and
+                    # add each to a new tag if they are not the head or footer.
+                    bodyTag = parser.new_tag('body')
+                    # What we are going to be doing will be causing some of the tags
+                    # to be moved out of the parser, and so the iterator will end up
+                    # pointing to the wrong place after that. To compensate we first
+                    # create a tuple and iterate over that.
+                    for tag in tuple(parser.children):
+                        if tag.name.lower() in ('head', 'footer'):
+                            correctedHtml.append(tag)
+                        else:
+                            bodyTag.append(tag)
+
+                    # All the tags should now be properly in the body, so let's
+                    # insert it.
+                    if correctedHtml.find('head'):
+                        correctedHtml.find('head').insert_after(bodyTag)
+                    elif correctedHtml.find('footer'):
+                        correctedHtml.find('footer').insert_before(bodyTag)
+                    else:
+                        # Neither a head or a body are present, so just append it to
+                        # the main tag.
+                        htmlTag.append(bodyTag)
+                else:
+                    # If there is no <html>, <head>, <footer>, or <body> tag, then
+                    # we just add the tags to the beginning and end of the data and
+                    # move on.
+                    body = b'<html><body>' + body + b'</body></html>'
+            elif parser.find('html'):
+                # Found <html> but not <body>.
+                # Iterate over each of the direct descendents of the parser and
+                # add each to a new tag if they are not the head or footer.
+                bodyTag = parser.new_tag('body')
+                # What we are going to be doing will be causing some of the tags
+                # to be moved out of the parser, and so the iterator will end up
+                # pointing to the wrong place after that. To compensate we first
+                # create a tuple and iterate over that.
+                for tag in tuple(parser.find('html').children):
+                    if tag.name and tag.name.lower() not in ('head', 'footer'):
+                        bodyTag.append(tag)
+
+                # All the tags should now be properly in the body, so let's
+                # insert it.
+                if parser.find('head'):
+                    parser.find('head').insert_after(bodyTag)
+                elif parser.find('footer'):
+                    parser.find('footer').insert_before(bodyTag)
+                else:
+                    parser.find('html').insert(0, bodyTag)
+            else:
+                # Found <body> but not <html>. Just wrap everything in the <html>
+                # tags.
+                body = b'<html>' + body + b'</html>'
+
+        def replace(bodyMarker):
+            """
+            Internal function to replace the body tag with itself plus the header.
+            """
+            # I recently had to change this and how it worked. Now we use a new
+            # property of `MSGFile` that returns a special tuple of tuples to define
+            # how to get all of the properties we are formatting. They are all
+            # processed in the same way, making everything neat. By defining them
+            # in each class, any class can specify a completely different set to be
+            # used.
+            return bodyMarker.group() + self.htmlInjectableHeader.encode('utf-8')
+
+        # Use the previously defined function to inject the HTML header.
+        return constants.RE_HTML_BODY_START.sub(replace, body, 1)
+
+    def injectRtfHeader(self) -> bytes:
+        """
+        Returns the RTF body from this MSG file (will check that it has one)
+        with the RTF header injected into it.
+
+        :raises AttributeError: if the RTF body cannot be acquired.
+        :raises RuntimeError: if all injection attempts fail.
+        """
+        if not self.rtfBody:
+            raise AttributeError('Cannot inject the RTF header without an RTF body attribute.')
+
+        # Try to determine which header to use. Also determines how to sanitize the
+        # rtf.
+        if isEncapsulatedRtf(self.rtfBody):
+            injectableHeader = self.rtfEncapInjectableHeader
+        else:
+            injectableHeader = self.rtfPlainInjectableHeader
+
+        def replace(bodyMarker):
+            """
+            Internal function to replace the body tag with itself plus the header.
+            """
+            return bodyMarker.group() + injectableHeader
+
+        # This first method only applies to documents with encapsulated HTML
+        # that is formatted in a nice way.
+        if isEncapsulatedRtf(self.rtfBody):
+            data = constants.RE_RTF_ENC_BODY_START.sub(replace, self.rtfBody, 1)
+            if data != self.rtfBody:
+                logger.debug('Successfully injected RTF header using encapsulation method.')
+                return data
+            logger.debug('RTF has encapsulated HTML, but injection method failed. It is likely dirty. Will use normal RTF injection method.')
+
+        # If the normal encapsulated HTML injection fails or it isn't
+        # encapsulated, use the internal _rtf module.
+        logger.debug('Using _rtf module to inject RTF text header.')
+        return createDocument(injectStartRTF(self.rtfBody, injectableHeader))
+
+    def save(self, **kwargs):
+        """
+        Saves the message body and attachments found in the message.
+
+        The body and attachments are stored in a folder in the current running
+        directory unless :param customPath: has been specified. The name of the
+        folder will be determined by 3 factors.
+           * If :param customFilename: has been set, the value provided for that
+             will be used.
+           * If :param useMsgFilename: has been set, the name of the file used
+             to create the Message instance will be used.
+           * If the file name has not been provided or :param useMsgFilename:
+             has not been set, the name of the folder will be created using the
+             `defaultFolderName` property.
+           * :param maxNameLength: will force all file names to be shortened
+             to fit in the space (with the extension included in the length). If
+             a number is added to the directory that will not be included in the
+             length, so it is recommended to plan for up to 5 characters extra
+             to be a part of the name. Default is 256.
+
+        It should be noted that regardless of the value for maxNameLength, the
+        name of the file containing the body will always have the name 'message'
+        followed by the full extension.
+
+        There are several parameters used to determine how the message will be
+        saved. By default, the message will be saved as plain text. Setting one
+        of the following parameters to True will change that:
+           * :param html: will output the message in HTML format.
+           * :param json: will output the message in JSON format.
+           * :param raw: will output the message in a raw format.
+           * :param rtf: will output the message in RTF format.
+
+        Usage of more than one formatting parameter will raise an exception.
+
+        Using HTML or RTF will raise an exception if they could not be retrieved
+        unless you have :param allowFallback: set to True. Fallback will go in
+        this order, starting at the top most format that is set:
+           * HTML
+           * RTF
+           * Plain text
+
+        If you want to save the contents into a ZipFile or similar object,
+        either pass a path to where you want to create one or pass an instance
+        to :param zip:. If :param zip: is set, :param customPath: will refer to
+        a location inside the zip file.
+
+        :param attachmentsOnly: Turns off saving the body and only saves the
+            attachments when set.
+        :param saveHeader: Turns on saving the header as a separate file when
+        set.
+        :param skipAttachments: Turns off saving attachments.
+        :param skipHidden: If True, skips attachments marked as hidden.
+            (Default: False)
+        :param skipBodyNotFound: Suppresses errors if no valid body could be
+            found, simply skipping the step of saving the body.
+        :param charset: If the html is being prepared, the charset to use for
+            the Content-Type meta tag to insert. This exists to ensure that
+            something parsing the html can properly determine the encoding (as
+            not having this tag can cause errors in some programs). Set this to
+            `None` or an empty string to not insert the tag (Default: 'utf-8').
+        :param kwargs: Used to allow kwargs expansion in the save function.
+        :param preparedHtml: When set, prepares the HTML body for standalone
+            usage, doing things like adding tags, injecting attachments, etc.
+            This is useful for things like trying to convert the HTML body
+            directly to PDF.
+        :param pdf: Used to enable saving the body as a PDF file.
+        :param wkPath: Used to manually specify the path of the wkhtmltopdf
+            executable. If not specified, the function will try to find it.
+            Useful if wkhtmltopdf is not on the path. If :param pdf: is False,
+            this argument is ignored.
+        :param wkOptions: Used to specify additional options to wkhtmltopdf.
+            this must be a list or list-like object composed of strings and
+            bytes.
+        """
+        # Move keyword arguments into variables.
+        _json = kwargs.get('json', False)
+        html = kwargs.get('html', False)
+        rtf = kwargs.get('rtf', False)
+        raw = kwargs.get('raw', False)
+        pdf = kwargs.get('pdf', False)
+        allowFallback = kwargs.get('allowFallback', False)
+        _zip = kwargs.get('zip')
+        maxNameLength = kwargs.get('maxNameLength', 256)
+
+        # Variables involved in the save location.
+        customFilename = kwargs.get('customFilename')
+        useMsgFilename = kwargs.get('useMsgFilename', False)
+        #maxPathLength = kwargs.get('maxPathLength', 255)
+
+        # Track if we are only saving the attachments.
+        attachOnly = kwargs.get('attachmentsOnly', False)
+        # Track if we are skipping attachments.
+        skipAttachments = kwargs.get('skipAttachments', False)
+        skipHidden = kwargs.get('skipHidden', False)
+        # Track if we should skip the body if no valid body is found instead of
+        # raising an exception.
+        skipBodyNotFound = kwargs.get('skipBodyNotFound', False)
+
+        if pdf:
+            kwargs['preparedHtml'] = True
+
+        # ZipFile handling.
+        if _zip:
+            # `raw` and `zip` are incompatible.
+            if raw:
+                raise IncompatibleOptionsError('The options `raw` and `zip` are incompatible.')
+            # If we are doing a zip file, first check that we have been given a
+            # path.
+            if isinstance(_zip, (str, pathlib.Path)):
+                # If we have a path then we use the zip file.
+                _zip = zipfile.ZipFile(_zip, 'a', zipfile.ZIP_DEFLATED)
+                kwargs['zip'] = _zip
+                createdZip = True
+            else:
+                createdZip = False
+            # Path needs to be done in a special way if we are in a zip file.
+            path = pathlib.Path(kwargs.get('customPath', ''))
+            # Set the open command to be that of the zip file.
+            _open = createZipOpen(_zip.open)
+            # Zip files use w for writing in binary.
+            mode = 'w'
+        else:
+            path = pathlib.Path(kwargs.get('customPath', '.')).absolute()
+            mode = 'wb'
+            _open = open
+
+        # Reset this for sub save calls.
+        kwargs['customFilename'] = None
+
+        # Check if incompatible options have been provided in any way.
+        if _json + html + rtf + raw + attachOnly + pdf > 1:
+            raise IncompatibleOptionsError('Only one of the following options may be used at a time: json, raw, html, rtf, attachmentsOnly, pdf.')
+
+        # TODO: insert code here that will handle checking all of the msg files
+        # to see if the path with overflow.
+
+        if customFilename:
+            # First we need to validate it. If there are invalid characters,
+            # this will detect it.
+            if constants.RE_INVALID_FILENAME_CHARACTERS.search(customFilename):
+                raise ValueError('Invalid character found in customFilename. Must not contain any of the following characters: \\/:*?"<>|')
+            # Quick fix to remove spaces from the end of the filename, if any
+            # are there.
+            customFilename = customFilename.strip()
+            path /= customFilename[:maxNameLength]
+        elif useMsgFilename:
+            if not self.filename:
+                raise ValueError(':param useMsgFilename: is only available if you are using an msg file on the disk or have provided a filename.')
+            # Get the actual name of the file.
+            filename = os.path.split(self.filename)[1]
+            # Remove the extensions.
+            filename = os.path.splitext(filename)[0]
+            # Prepare the filename by removing any special characters.
+            filename = prepareFilename(filename)
+            # Shorted the filename.
+            filename = filename[:maxNameLength]
+            # Check to make sure we actually have a filename to use.
+            if not filename:
+                raise ValueError(f'Invalid filename found in self.filename: "{self.filename}"')
+
+            # Add the file name to the path.
+            path /= filename[:maxNameLength]
+        else:
+            path /= self.defaultFolderName[:maxNameLength]
+
+        # Create the folders.
+        if not _zip:
+            try:
+                os.makedirs(path)
+            except Exception:
+                newDirName = addNumToDir(path)
+                if newDirName:
+                    path = newDirName
+                else:
+                    raise Exception(f'Failed to create directory "{path}". Does it already exist?')
+        else:
+            # In my testing I ended up with multiple files in a zip at the same
+            # location so let's try to handle that.
+            pathCompare = str(path).replace('\\', '/').rstrip('/') + '/'
+            if any(x.startswith(pathCompare) for x in _zip.namelist()):
+                newDirName = addNumToZipDir(path, _zip)
+                if newDirName:
+                    path = newDirName
+                else:
+                    raise Exception(f'Failed to create directory "{path}". Does it already exist?')
+
+        # Update the kwargs.
+        kwargs['customPath'] = path
+
+        if raw:
+            self.saveRaw(path)
+            return self
+
+        # If the user has requested the headers for this file, save it now.
+        if kwargs.get('saveHeader', False):
+            headerText = self._getStringStream('__substg1.0_007D')
+            if not headerText:
+                headerText = constants.HEADER_FORMAT.format(subject = self.subject, **self.header)
+
+            with _open(str(path / 'header.txt'), mode) as f:
+                f.write(headerText.encode('utf-8'))
+
+        try:
+            if not attachOnly:
+                # Check what to save the body with.
+                fext = 'json' if _json else 'txt'
+
+                fallbackToPlain = False
+                useHtml = False
+                usePdf = False
+                useRtf = False
+                if html:
+                    if self.htmlBody:
+                        useHtml = True
+                        fext = 'html'
+                    elif not allowFallback:
+                        if skipBodyNotFound:
+                            fext = None
+                        else:
+                            raise DataNotFoundError('Could not find the htmlBody.')
+
+                if pdf:
+                    if self.htmlBody:
+                        usePdf = True
+                        fext = 'pdf'
+                    elif not allowFallback:
+                        if skipBodyNotFound:
+                            fext = None
+                        else:
+                            raise DataNotFoundError('Count not find the htmlBody to convert to pdf.')
+
+                if rtf or (html and not useHtml) or (pdf and not usePdf):
+                    if self.rtfBody:
+                        useRtf = True
+                        fext = 'rtf'
+                    elif not allowFallback:
+                        if skipBodyNotFound:
+                            fext = None
+                        else:
+                            raise DataNotFoundError('Could not find the rtfBody.')
+                    else:
+                        # This was the last resort before plain text, so fall
+                        # back to that.
+                        fallbackToPlain = True
+
+                # After all other options, try to go with plain text if
+                # possible.
+                if not (rtf or html or pdf) or fallbackToPlain:
+                    # We need to check if the plain text body was found. If it
+                    # was found but was empty that is considered valid, so we
+                    # specifically check against None.
+                    if self.body is None:
+                        if skipBodyNotFound:
+                            fext = None
+                        else:
+                            if allowFallback:
+                                raise DataNotFoundError('Could not find a valid body using current options.')
+                            else:
+                                raise DataNotFoundError('Plain text body could not be found.')
+
+
+            if not skipAttachments:
+                # Save the attachments.
+                attachmentNames = [attachment.save(**kwargs) for attachment in self.attachments if not (skipHidden and attachment.hidden)]
+                # Remove skipped attachments.
+                attachmentNames = [x for x in attachmentNames if x and isinstance(x, str)]
+
+            if not attachOnly and fext:
+                with _open(str(path / ('message.' + fext)), mode) as f:
+                    if _json:
+                        emailObj = json.loads(self.getJson())
+                        if not skipAttachments:
+                            emailObj['attachments'] = attachmentNames
+
+                        f.write(inputToBytes(json.dumps(emailObj), 'utf-8'))
+                    elif useHtml:
+                        f.write(self.getSaveHtmlBody(**kwargs))
+                    elif usePdf:
+                        f.write(self.getSavePdfBody(**kwargs))
+                    elif useRtf:
+                        f.write(self.getSaveRtfBody(**kwargs))
+                    else:
+                        f.write(self.getSaveBody(**kwargs))
+        finally:
+            # Close the ZipFile if this function created it.
+            if _zip and createdZip:
+                _zip.close()
+
+        # Return the instance so that functions can easily be chained.
+        return self
+
+    @property
+    def bcc(self) -> Optional[str]:
+        """
+        Returns the bcc field, if it exists.
+        """
+        return self._genRecipient('bcc', RecipientType.BCC)
+
+    @property
+    def body(self) -> Optional[str]:
+        """
+        Returns the message body, if it exists.
+        """
+        try:
+            return self._body
+        except AttributeError:
+            if self._ensureSet('_body', '__substg1.0_1000'):
+                pass
+            else:
+                # If the body doesn't exist, see if we can get it from the RTF
+                # body.
+                if self.rtfBody:
+                    self._body = self.deencapsulateBody(self.rtfBody, DeencapType.PLAIN)
+
+            if self._body:
+                self._body = inputToString(self._body, 'utf-8')
+                a = re.search('\n', self._body)
+                if a is not None:
+                    if re.search('\r\n', self._body) is not None:
+                        self.__crlf = '\r\n'
+            return self._body
+
+    @property
+    def cc(self) -> Optional[str]:
+        """
+        Returns the cc field, if it exists.
+        """
+        return self._genRecipient('cc', RecipientType.CC)
+
+    @property
+    def compressedRtf(self) -> Optional[bytes]:
+        """
+        Returns the compressed RTF stream, if it exists.
+        """
+        return self._ensureSet('_compressedRtf', '__substg1.0_10090102', False)
+
+    @property
+    def crlf(self) -> str:
+        """
+        Returns the value of self.__crlf, should you need it for whatever
+        reason.
+        """
+        self.body
+        return self.__crlf
+
+    @property
+    def date(self) -> Optional[str]:
+        """
+        Returns the send date, if it exists.
+        """
+        try:
+            return self._date
+        except AttributeError:
+            self._date = self._prop.date if self.isSent else None
+            return self._date
+
+    @property
+    def deencapsulatedRtf(self) -> Optional[RTFDE.DeEncapsulator]:
+        """
+        Returns the instance of the deencapsulated RTF body. If there is no RTF
+        body or the body is not encasulated, returns None.
+        """
+        try:
+            return self._deencapsultor
+        except AttributeError:
+            if self.rtfBody:
+                # If there is an RTF body, we try to deencapsulate it.
+                body = self.rtfBody
+                # Sometimes you get MSG files whose RTF body has stuff
+                # *after* the body, and RTFDE can't handle that. Here is
+                # how we compensate.
+                while body and body[-1] != 125:
+                    body = body[:-1]
+
+                try:
+                    try:
+                        self._deencapsultor = RTFDE.DeEncapsulator(body)
+                    except UnicodeDecodeError:
+                        # There is a known issue that bytes are not well decoded
+                        # by RTFDE right now, so let's see if we can't manually
+                        # decode it and see if that will work.
+                        #
+                        # There is also the fact that it is decoded *at all*
+                        # before binary data is stripped out. This data should
+                        # almost certainly be stripped out, so let's log it and
+                        # then log if we removed any of them before trying this.
+                        logger.warning(f'RTFDE failed to decode rtfBody for message with subject "{self.subject}". Attempting to cut out unnecessary data and override decoding.')
+
+                        match = constants.RE_BIN.search(body)
+                        # Because we are going to be actively removing things,
+                        # we want to search the entire thing over again.
+                        while match:
+                            logger.info(f'Found match to bin data starting at location {match.start()}. Replacing with nothing.')
+                            length = int(match.group(1))
+                            # Extract the entire binary section and replace it.
+                            body = body.replace(body[match.start():match.end() + length], b'', 1)
+                            match = constants.RE_BIN.search(body)
+
+                        self._deencapsultor = RTFDE.DeEncapsulator(body.decode(chardet.detect(body)['encoding']))
+                    self._deencapsultor.deencapsulate()
+                except RTFDE.exceptions.NotEncapsulatedRtf as e:
+                    logger.debug('RTF body is not encapsulated.')
+                    self._deencapsultor = None
+                except RTFDE.exceptions.MalformedEncapsulatedRtf as _e:
+                    logger.info('RTF body contains malformed encapsulated content.')
+                    self._deencapsultor = None
+                except Exception:
+                    # If we are just ignoring the errors, log it then set to
+                    # None. Otherwise, continue the exception.
+                    if not self.__ignoreRtfDeErrors:
+                        raise
+                    logger.exception('Unhandled error happened while using RTFDE. You have choosen to ignore these errors.')
+                    self._deencapsultor = None
+            else:
+                self._deencapsultor = None
+            return self._deencapsultor
+
+    @property
+    def defaultFolderName(self) -> str:
+        """
+        Generates the default name of the save folder.
+        """
+        try:
+            return self._defaultFolderName
+        except AttributeError:
+            d = self.parsedDate
+
+            dirName = '{0:02d}-{1:02d}-{2:02d}_{3:02d}{4:02d}'.format(*d) if d else 'UnknownDate'
+            dirName += ' ' + (prepareFilename(self.subject) if self.subject else '[No subject]')
+            dirName = dirName.strip()
+
+            self._defaultFolderName = dirName
+            return dirName
+
+    @property
+    def header(self):
+        """
+        Returns the message header, if it exists. Otherwise it will generate
+        one.
+        """
+        try:
+            return self._header
+        except AttributeError:
+            headerText = self._getStringStream('__substg1.0_007D')
+            if headerText:
+                self._header = EmailParser().parsestr(headerText)
+                self._header['date'] = self.date
+            else:
+                logger.info('Header is empty or was not found. Header will be generated from other streams.')
+                header = EmailParser().parsestr('')
+                header.add_header('Date', self.date)
+                header.add_header('From', self.sender)
+                header.add_header('To', self.to)
+                header.add_header('Cc', self.cc)
+                header.add_header('Bcc', self.bcc)
+                header.add_header('Message-Id', self.messageId)
+                # TODO find authentication results outside of header
+                header.add_header('Authentication-Results', None)
+                self._header = header
+            return self._header
+
+    @property
+    def headerDict(self) -> dict:
+        """
+        Returns a dictionary of the entries in the header
+        """
+        try:
+            return self._headerDict
+        except AttributeError:
+            self._headerDict = dict(self.header._headers)
+            try:
+                self._headerDict.pop('Received')
+            except KeyError:
+                pass
+            return self._headerDict
+
+    @property
+    def headerFormatProperties(self) -> constants.HEADER_FORMAT_TYPE:
+        """
+        Returns a dictionary of properties, in order, to be formatted into the
+        header. Keys are the names to use in the header while the values are one
+        of the following:
+        None: Signifies no data was found for the property and it should be
+            omitted from the header.
+        str: A string to be formatted into the header using the string encoding.
+        Tuple[Union[str, None], bool]: A string should be formatted into the
+            header. If the bool is True, then place an empty string if the value
+            is None, otherwise follow the same behavior as regular None.
+
+        Additional note: If the value is an empty string, it will be dropped as
+        well by default.
+
+        Additionally you can group members of a header together by placing them
+        in an embedded dictionary. Groups will be spaced out using a second
+        instance of the join string. If any member of a group is being printed,
+        it will be spaced apart from the next group/item.
+
+        If you class should not do *any* header injection, return None from this
+        property.
+        """
+        # Checking outlook printing, default behavior is to completely omit
+        # *any* field that is not present. So while for extensability the
+        # option exists to have it be present even if no data is found, we are
+        # specifically not doing that.
+        return {
+            '-basic info-': {
+                'From': self.sender,
+                'Sent': self.date,
+                'To': self.to,
+                'Cc': self.cc,
+                'Bcc': self.bcc,
+                'Subject': self.subject,
+            },
+            '-importance-': {
+                'Importance': self.importanceString,
+            },
+        }
+
+    @property
+    def htmlBody(self) -> Optional[bytes]:
+        """
+        Returns the html body, if it exists.
+        """
+        try:
+            return self._htmlBody
+        except AttributeError:
+            if self._ensureSet('_htmlBody', '__substg1.0_10130102', False):
+                # Reducing line repetition.
+                pass
+            elif self.rtfBody:
+                logger.info('HTML body was not found, attempting to generate from RTF.')
+                self._htmlBody = self.deencapsulateBody(self.rtfBody, DeencapType.HTML)
+            # This is it's own if statement so we can ensure it will generate
+            # even if there is an rtfBody, in the event it doesn't have HTML.
+            if not self._htmlBody and self.body:
+                # Convert the plain text body to html.
+                logger.info('HTML body was not found, attempting to generate from plain text body.')
+                correctedBody = html.escape(self.body).replace('\r', '').replace('\n', '<br />')
+                self._htmlBody = f'<html><body>{correctedBody}</body></head>'.encode('utf-8')
+
+            if not self._htmlBody:
+                logger.info('HTML body could not be found nor generated.')
+
+            return self._htmlBody
+
+    @property
+    def htmlBodyPrepared(self) -> Optional[bytes]:
+        """
+        Returns the HTML body that has (where possible) the embedded attachments
+        inserted into the body.
+        """
+        # If we can't get an HTML body then we have nothing to do.
+        if not self.htmlBody:
+            return self.htmlBody
+
+        # Create the BeautifulSoup instance to use.
+        soup = bs4.BeautifulSoup(self.htmlBody, 'html.parser')
+
+        # Get a list of image tags to see if we can inject into. If the source
+        # of an image starts with "cid:" that means it is one of the attachments
+        # and is using the content id of that attachment.
+        tags = (tag for tag in soup.findAll('img') if tag.get('src') and tag.get('src').startswith('cid:'))
+
+        for tag in tags:
+            # Iterate through the attachments until we get the right one.
+            cid = tag['src'][4:]
+            data = next((attachment.data for attachment in self.attachments if attachment.cid == cid), None)
+            # If we found anything, inject it.
+            if data:
+                tag['src'] = (b'data:image;base64,' + base64.b64encode(data)).decode('utf-8')
+
+        return soup.prettify('utf-8')
+
+    @property
+    def htmlInjectableHeader(self) -> str:
+        """
+        The header that can be formatted and injected into the html body.
+        """
+        prefix = '<div id="injectedHeader"><div><p class="MsoNormal">'
+        suffix = '<o:p></o:p></p></div></div>'
+        joinStr = '<br/>'
+        formatter = (lambda name, value : f'<b>{name}:</b>&nbsp;{inputToString(htmlSanitize(value), self.stringEncoding)}')
+
+        return self.getInjectableHeader(prefix, joinStr, suffix, formatter)
+
+    @property
+    def inReplyTo(self) -> Optional[str]:
+        """
+        Returns the message id that this message is in reply to.
+        """
+        return self._ensureSet('_in_reply_to', '__substg1.0_1042')
+
+    @property
+    def isRead(self) -> bool:
+        """
+        Returns if this email has been marked as read.
+        """
+        return bool(self.props['0E070003'].value & 1)
+
+    @property
+    def isSent(self) -> bool:
+        """
+        Returns if this email has been marked as sent. Assumes True if no flags
+        are found.
+        """
+        if not self.props.get('0E070003'):
+            return True
+        else:
+            return not bool(self.props['0E070003'].value & 8)
+
+    @property
+    def messageId(self) -> Optional[str]:
+        try:
+            return self._messageId
+        except AttributeError:
+            headerResult = None
+            if self.headerInit():
+                headerResult = self._header['message-id']
+            if headerResult is not None:
+                self._messageId = headerResult
+            else:
+                if self.headerInit():
+                    logger.info('Header found, but "Message-Id" is not included. Will be generated from other streams.')
+                self._messageId = self._getStringStream('__substg1.0_1035')
+            return self._messageId
+
+    @property
+    def parsedDate(self):
+        return email.utils.parsedate(self.date)
+
+    @property
+    def receivedTime(self) -> Optional[datetime.datetime]:
+        """
+        The date and time the message was received by the server.
+        """
+        return self._ensureSetProperty('_receivedTime', '0E060040')
+
+    @property
+    def recipientSeparator(self) -> str:
+        return self.__recipientSeparator
+
+    @property
+    def recipients(self) -> List[Recipient]:
+        """
+        Returns a list of all recipients.
+        """
+        try:
+            return self._recipients
+        except AttributeError:
+            # Get the recipients
+            recipientDirs = []
+            prefixLen = self.prefixLen
+            for dir_ in self.listDir():
+                if dir_[prefixLen].startswith('__recip') and\
+                        dir_[prefixLen] not in recipientDirs:
+                    recipientDirs.append(dir_[prefixLen])
+
+            self._recipients = []
+
+            for recipientDir in recipientDirs:
+                self._recipients.append(Recipient(recipientDir, self))
+
+            return self._recipients
+
+    @property
+    def reportTag(self) -> Optional[ReportTag]:
+        """
+        Data that is used to correlate the report and the original message.
+        """
+        return self._ensureSet('_reportTag', '__substg1.0_00310102', False, overrideClass = ReportTag)
+
+    @property
+    def rtfBody(self) -> Optional[bytes]:
+        """
+        Returns the decompressed Rtf body from the message.
+        """
+        try:
+            return self._rtfBody
+        except AttributeError:
+            self._rtfBody = compressed_rtf.decompress(self.compressedRtf) if self.compressedRtf else None
+            return self._rtfBody
+
+    @property
+    def rtfEncapInjectableHeader(self) -> bytes:
+        """
+        The header that can be formatted and injected into the plain RTF body.
+        """
+        prefix = r'\htmlrtf {\htmlrtf0 {\*\htmltag96 <div>}{\*\htmltag96 <div>}{\*\htmltag64 <p class=MsoNormal>}'
+        suffix = r'{\*\htmltag244 <o:p>}{\*\htmlrag252 </o:p>}\htmlrtf \par\par\htmlrtf0 {\*\htmltag72 </p>}{\*\htmltag104 </div>}{\*\htmltag104 </div>}\htmlrtf }\htmlrtf0 '
+        joinStr = r'{\*\htmltag116 <br />}\htmlrtf \line\htmlrtf0 '
+        formatter = (lambda name, value : fr'\htmlrtf {{\b\htmlrtf0{{\*\htmltag84 <b>}}{name}: {{\*\htmltag92 </b>}}\htmlrtf \b0\htmlrtf0 {inputToString(rtfSanitizeHtml(value), self.stringEncoding)}\htmlrtf }}\htmlrtf0')
+
+        return self.getInjectableHeader(prefix, joinStr, suffix, formatter).encode('utf-8')
+
+    @property
+    def rtfPlainInjectableHeader(self) -> bytes:
+        """
+        The header that can be formatted and injected into the encapsulated RTF
+        body.
+        """
+        prefix = '{'
+        suffix = r'\par\par}'
+        joinStr = r'\line'
+        formatter = (lambda name, value : fr'{{\b {name}: \b0 {inputToString(rtfSanitizePlain(value), self.stringEncoding)}}}')
+
+        return self.getInjectableHeader(prefix, joinStr, suffix, formatter).encode('utf-8')
+
+    @property
+    def sender(self) -> Optional[str]:
+        """
+        Returns the message sender, if it exists.
+        """
+        try:
+            return self._sender
+        except AttributeError:
+            # Check header first
+            if self.headerInit():
+                headerResult = self.header['from']
+                if headerResult is not None:
+                    self._sender = headerResult
+                    return headerResult
+                logger.info('Header found, but "sender" is not included. Will be generated from other streams.')
+            # Extract from other fields
+            text = self._getStringStream('__substg1.0_0C1A')
+            email = self._getStringStream('__substg1.0_5D01')
+            # Will not give an email address sometimes. Seems to exclude the email address if YOU are the sender.
+            result = None
+            if text is None:
+                result = email
+            else:
+                result = text
+                if email is not None:
+                    result += ' <' + email + '>'
+
+            self._sender = result
+            return result
+
+    @property
+    def subject(self) -> Optional[str]:
+        """
+        Returns the message subject, if it exists.
+        """
+        return self._ensureSet('_subject', '__substg1.0_0037')
+
+    @property
+    def to(self) -> Optional[str]:
+        """
+        Returns the to field, if it exists.
+        """
+        return self._genRecipient('to', RecipientType.TO)
```

### Comparing `extract_msg-0.40.0/extract_msg/message_signed_base.py` & `extract_msg-0.41.0/extract_msg/message_signed_base.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,174 +1,189 @@
-import email.utils
-import html
-import logging
-import re
-
-from typing import List, Optional
-
-from .exceptions import StandardViolationError
-from .message_base import MessageBase
-from .signed_attachment import SignedAttachment
-from .utils import inputToBytes, inputToString, unwrapMultipart
-
-
-logger = logging.getLogger(__name__)
-logger.addHandler(logging.NullHandler())
-
-
-class MessageSignedBase(MessageBase):
-    """
-    Base class for Message like msg files.
-    """
-
-    def __init__(self, path, **kwargs):
-        """
-        :param path: path to the msg file in the system or is the raw msg file.
-        :param prefix: used for extracting embeded msg files
-            inside the main one. Do not set manually unless
-            you know what you are doing.
-        :param attachmentClass: optional, the class the Message object
-            will use for attachments. You probably should
-            not change this value unless you know what you
-            are doing.
-        :param signedAttachmentClass: optional, the class the object will use
-            for signed attachments.
-        :param filename: optional, the filename to be used by default when
-            saving.
-        :param delayAttachments: optional, delays the initialization of
-            attachments until the user attempts to retrieve them. Allows MSG
-            files with bad attachments to be initialized so the other data can
-            be retrieved.
-        :param overrideEncoding: optional, an encoding to use instead of the one
-            specified by the msg file. Do not report encoding errors caused by
-            this.
-        :param attachmentErrorBehavior: Optional, the behavior to use in the
-            event of an error when parsing the attachments.
-        :param recipientSeparator: Optional, Separator string to use between
-            recipients.
-        """
-        self.__recipientSeparator = kwargs.get('recipientSeparator', ';')
-        self.__signedAttachmentClass = kwargs.get('signedAttachmentClass', SignedAttachment)
-        super().__init__(path, **kwargs)
-        # Initialize properties in the order that is least likely to cause bugs.
-        # TODO have each function check for initialization of needed data so these
-        # lines will be unnecessary.
-        if not kwargs.get('delayAttachments', False):
-            self.attachments
-
-    @property
-    def attachments(self) -> List:
-        """
-        Returns a list of all attachments.
-
-        :raises StandardViolationError: The standard for signed messages was
-            blatantly violated.
-        """
-        try:
-            return self._sAttachments
-        except AttributeError:
-            atts = super().attachments
-
-            if len(atts) != 1:
-                raise StandardViolationError('Signed messages without exactly 1 (regular) attachment constitue a violation of the standard.')
-
-            # We need to unwrap the multipart stream.
-            unwrapped = unwrapMultipart(atts[0].data)
-
-            # Now store everything where it needs to be and make the
-            # attachments.
-            self._sAttachments = [self.__signedAttachmentClass(self, **att) for att in unwrapped['attachments']]
-            self._signedBody = unwrapped['plain_body']
-            self._signedHtmlBody = inputToBytes(unwrapped['html_body'], 'utf-8')
-
-            return self._sAttachments
-
-    @property
-    def body(self) -> Optional[str]:
-        """
-        Returns the message body, if it exists.
-        """
-        try:
-            return self._body
-        except AttributeError:
-            if self._ensureSet('_body', '__substg1.0_1000'):
-                pass
-            elif self.signedBody:
-                self._body = self.signedBody
-            else:
-                # If the body doesn't exist, see if we can get it from the RTF
-                # body.
-                if self.deencapsulatedRtf and self.deencapsulatedRtf.content_type == 'text':
-                    self._body = self.deencapsulatedRtf.text
-
-            if self._body:
-                self._body = inputToString(self._body, 'utf-8')
-                a = re.search('\n', self._body)
-                if a is not None:
-                    if re.search('\r\n', self._body) is not None:
-                        self.__crlf = '\r\n'
-            return self._body
-
-    @property
-    def htmlBody(self) -> Optional[bytes]:
-        """
-        Returns the html body, if it exists.
-        """
-        try:
-            return self._htmlBody
-        except AttributeError:
-            if self._ensureSet('_htmlBody', '__substg1.0_10130102', False):
-                # Reducing line repetition.
-                pass
-            elif self.signedHtmlBody:
-                self._htmlBody = self.signedHtmlBody
-            elif self.rtfBody:
-                logger.info('HTML body was not found, attempting to generate from RTF.')
-                if self.deencapsulatedRtf and self.deencapsulatedRtf.content_type == 'html':
-                    self._htmlBody = self.deencapsulatedRtf.html.encode('utf-8')
-                else:
-                    logger.info('Could not deencapsulate HTML from RTF body.')
-            elif self.body:
-                # Convert the plain text body to html.
-                logger.info('HTML body was not found, attempting to generate from plain text body.')
-                correctedBody = html.escpae(self.body).replace('\r', '').replace('\n', '<br />')
-                self._htmlBody = f'<html><body>{correctedBody}</body></head>'.encode('utf-8')
-            else:
-                logger.info('HTML body could not be found nor generated.')
-
-            return self._htmlBody
-
-    @property
-    def _rawAttachments(self) -> List:
-        """
-        A property to allow access to the non-signed attachments.
-        """
-        return super().attachments
-
-    @property
-    def signedAttachmentClass(self):
-        """
-        The attachment class used for signed attachments.
-        """
-        return self.__signedAttachmentClass
-
-    @property
-    def signedBody(self) -> Optional[str]:
-        """
-        Returns the body from the signed message if it exists.
-        """
-        try:
-            return self._signedBody
-        except AttributeError:
-            self.attachments
-            return self._signedBody
-
-    @property
-    def signedHtmlBody(self) -> Optional[bytes]:
-        """
-        Returns the HTML body from the signed message if it exists.
-        """
-        try:
-            return self._signedHtmlBody
-        except AttributeError:
-            self.attachments
-            return self._signedHtmlBody
+__all__ = [
+    'MessageSignedBase',
+]
+
+
+import html
+import logging
+import re
+
+from typing import List, Optional
+
+from .enums import ErrorBehavior
+from .exceptions import StandardViolationError
+from .message_base import MessageBase
+from .signed_attachment import SignedAttachment
+from .utils import inputToBytes, inputToString, unwrapMultipart
+
+
+logger = logging.getLogger(__name__)
+logger.addHandler(logging.NullHandler())
+
+
+class MessageSignedBase(MessageBase):
+    """
+    Base class for Message like msg files.
+    """
+
+    def __init__(self, path, **kwargs):
+        """
+        :param path: path to the msg file in the system or is the raw msg file.
+        :param prefix: used for extracting embeded msg files
+            inside the main one. Do not set manually unless
+            you know what you are doing.
+        :param attachmentClass: optional, the class the Message object
+            will use for attachments. You probably should
+            not change this value unless you know what you
+            are doing.
+        :param signedAttachmentClass: optional, the class the object will use
+            for signed attachments.
+        :param filename: optional, the filename to be used by default when
+            saving.
+        :param delayAttachments: optional, delays the initialization of
+            attachments until the user attempts to retrieve them. Allows MSG
+            files with bad attachments to be initialized so the other data can
+            be retrieved.
+        :param overrideEncoding: optional, an encoding to use instead of the one
+            specified by the msg file. Do not report encoding errors caused by
+            this.
+        :param attachmentErrorBehavior: Optional, the behavior to use in the
+            event of an error when parsing the attachments.
+        :param recipientSeparator: Optional, Separator string to use between
+            recipients.
+        """
+        self.__recipientSeparator = kwargs.get('recipientSeparator', ';')
+        self.__signedAttachmentClass = kwargs.get('signedAttachmentClass', SignedAttachment)
+        super().__init__(path, **kwargs)
+        # Initialize properties in the order that is least likely to cause bugs.
+        # TODO have each function check for initialization of needed data so these
+        # lines will be unnecessary.
+        if not kwargs.get('delayAttachments', False):
+            self.attachments
+
+    @property
+    def attachments(self) -> List:
+        """
+        Returns a list of all attachments.
+
+        :raises StandardViolationError: The standard for signed messages was
+            blatantly violated.
+        """
+        try:
+            return self._sAttachments
+        except AttributeError:
+            atts = super().attachments
+
+            if len(atts) != 1:
+                if self.errorBehavior & ErrorBehavior.STANDARDS_VIOLATION:
+                    if len(atts) == 0:
+                        logger.error('Signed message has no attachments, a violation of the standard.')
+                        self._sAttachments = None
+                        self._signedBody = None
+                        self._signedHtmlBody = None
+                        return
+                    # If there is at least one attachment, just try to use the
+                    # first.
+                else:
+                    raise StandardViolationError('Signed messages without exactly 1 (regular) attachment constitue a violation of the standard.')
+
+            # We need to unwrap the multipart stream.
+            unwrapped = unwrapMultipart(atts[0].data)
+
+            # Now store everything where it needs to be and make the
+            # attachments.
+            self._sAttachments = [self.__signedAttachmentClass(self, **att) for att in unwrapped['attachments']]
+            self._signedBody = unwrapped['plain_body']
+            self._signedHtmlBody = inputToBytes(unwrapped['html_body'], 'utf-8')
+
+            return self._sAttachments
+
+    @property
+    def body(self) -> Optional[str]:
+        """
+        Returns the message body, if it exists.
+        """
+        try:
+            return self._body
+        except AttributeError:
+            if self._ensureSet('_body', '__substg1.0_1000'):
+                pass
+            elif self.signedBody:
+                self._body = self.signedBody
+            else:
+                # If the body doesn't exist, see if we can get it from the RTF
+                # body.
+                if self.deencapsulatedRtf and self.deencapsulatedRtf.content_type == 'text':
+                    self._body = self.deencapsulatedRtf.text
+
+            if self._body:
+                self._body = inputToString(self._body, 'utf-8')
+                a = re.search('\n', self._body)
+                if a is not None:
+                    if re.search('\r\n', self._body) is not None:
+                        self.__crlf = '\r\n'
+            return self._body
+
+    @property
+    def htmlBody(self) -> Optional[bytes]:
+        """
+        Returns the html body, if it exists.
+        """
+        try:
+            return self._htmlBody
+        except AttributeError:
+            if self._ensureSet('_htmlBody', '__substg1.0_10130102', False):
+                # Reducing line repetition.
+                pass
+            elif self.signedHtmlBody:
+                self._htmlBody = self.signedHtmlBody
+            elif self.rtfBody:
+                logger.info('HTML body was not found, attempting to generate from RTF.')
+                if self.deencapsulatedRtf and self.deencapsulatedRtf.content_type == 'html':
+                    self._htmlBody = self.deencapsulatedRtf.html.encode('utf-8')
+                else:
+                    logger.info('Could not deencapsulate HTML from RTF body.')
+            elif self.body:
+                # Convert the plain text body to html.
+                logger.info('HTML body was not found, attempting to generate from plain text body.')
+                correctedBody = html.escpae(self.body).replace('\r', '').replace('\n', '<br />')
+                self._htmlBody = f'<html><body>{correctedBody}</body></head>'.encode('utf-8')
+            else:
+                logger.info('HTML body could not be found nor generated.')
+
+            return self._htmlBody
+
+    @property
+    def _rawAttachments(self) -> List:
+        """
+        A property to allow access to the non-signed attachments.
+        """
+        return super().attachments
+
+    @property
+    def signedAttachmentClass(self):
+        """
+        The attachment class used for signed attachments.
+        """
+        return self.__signedAttachmentClass
+
+    @property
+    def signedBody(self) -> Optional[str]:
+        """
+        Returns the body from the signed message if it exists.
+        """
+        try:
+            return self._signedBody
+        except AttributeError:
+            self.attachments
+            return self._signedBody
+
+    @property
+    def signedHtmlBody(self) -> Optional[bytes]:
+        """
+        Returns the HTML body from the signed message if it exists.
+        """
+        try:
+            return self._signedHtmlBody
+        except AttributeError:
+            self.attachments
+            return self._signedHtmlBody
```

### Comparing `extract_msg-0.40.0/extract_msg/msg.py` & `extract_msg-0.41.0/extract_msg/msg.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,921 +1,947 @@
-import codecs
-import copy
-import datetime
-import io
-import logging
-import os
-import pathlib
-import zipfile
-
-import olefile
-
-from typing import List, Optional, Set, Tuple, Union
-from warnings import warn
-
-from . import constants
-from .attachment import Attachment, BrokenAttachment, UnsupportedAttachment
-from .enums import AttachErrorBehavior, Importance, Priority, PropertiesType, Sensitivity, SideEffect
-from .exceptions import InvalidFileFormatError, UnrecognizedMSGTypeError
-from .named import Named, NamedProperties
-from .prop import FixedLengthProp
-from .properties import Properties
-from .utils import divide, getEncodingName, hasLen, inputToMsgPath, inputToString, msgPathToString, parseType, properHex, verifyPropertyId, verifyType, windowsUnicode
-
-
-logger = logging.getLogger(__name__)
-logger.addHandler(logging.NullHandler())
-
-
-class MSGFile:
-    """
-    Parser for .msg files.
-    """
-
-    def __init__(self, path, **kwargs):
-        """
-        :param path: path to the msg file in the system or is the raw msg file.
-        :param prefix: Used for extracting embedded msg files inside the main
-            one. Do not set manually unless you know what you are doing.
-        :param parentMsg: Used for synchronizing named properties instances. Do
-            not set this unless you know what you are doing.
-        :param attachmentClass: Optional, the class the MSGFile object will use
-            for attachments. You probably should not change this value unless
-            you know what you are doing.
-        :param delayAttachments: Optional, delays the initialization of
-            attachments until the user attempts to retrieve them. Allows MSG
-            files with bad attachments to be initialized so the other data can
-            be retrieved.
-        :param filename: Optional, the filename to be used by default when
-            saving.
-        :param attachmentErrorBehavior: Optional, the behavior to use in the
-            event of an error when parsing the attachments.
-        :param overrideEncoding: Optional, an encoding to use instead of the one
-            specified by the msg file. Do not report encoding errors caused by
-            this.
-        :param treePath: Internal variable used for giving representation of the
-            path, as a tuple of objects, of the MSGFile. When passing, this is
-            the path to the parent object of this instance.
-
-        :raises InvalidFileFormatError: If the file is not an OleFile or could
-            not be parsed as an MSG file.
-        :raises IOError: If there is an issue opening the MSG file.
-        :raises NameError: If the encoding provided is not supported.
-        :raises TypeError: If the prefix is not a supported type.
-        :raises TypeError: If the parent is not an instance of MSGFile or a
-            subclass.
-        :raises ValueError: If the attachment error behavior is not valid.
-
-        It's recommended to check the error message to ensure you know why a
-        specific exceptions was raised.
-        """
-        # Retrieve all the kwargs that we need.
-        prefix = kwargs.get('prefix', '')
-        self.__parentMsg = kwargs.get('parentMsg')
-        self.__treePath = kwargs.get('treePath', tuple()) + (self,)
-        # Verify it is a valid class.
-        if self.__parentMsg is not None and not isinstance(self.__parentMsg, MSGFile):
-            raise TypeError(':param parentMsg: must be an instance of MSGFile or a subclass.')
-        filename = kwargs.get('filename', None)
-        overrideEncoding = kwargs.get('overrideEncoding', None)
-
-        # WARNING DO NOT MANUALLY MODIFY PREFIX. Let the program set it.
-        self.__path = path
-        self.__attachmentClass = kwargs.get('attachmentClass', Attachment)
-        self.__attachmentsDelayed = kwargs.get('delayAttachments', False)
-        self.__attachmentsReady = False
-        self.__attachmentErrorBehavior = AttachErrorBehavior(kwargs.get('attachmentErrorBehavior', AttachErrorBehavior.THROW))
-        self.__waitingProperties = []
-        if overrideEncoding is not None:
-            codecs.lookup(overrideEncoding)
-            logger.warning('You have chosen to override the string encoding. Do not report encoding errors caused by this.')
-            self.__stringEncoding = overrideEncoding
-        self.__overrideEncoding = overrideEncoding
-
-        self.__listDirRes = {}
-
-        # This is a variable that tells whether we own the olefile. Used for
-        # closing.
-        self.__oleOwner = True
-        if self.__parentMsg:
-            # We should be able to directly access the private variables of
-            # another instance with no issue.
-            self.__ole = self.__parentMsg.__ole
-            self.__oleOwner = False
-        else:
-            try:
-                self.__ole = olefile.OleFileIO(path)
-            except OSError as e:
-                logger.error(e)
-                if str(e) == 'not an OLE2 structured storage file':
-                    raise InvalidFileFormatError(e)
-                else:
-                    raise
-
-        kwargsCopy = copy.copy(kwargs)
-        if 'prefix' in kwargsCopy:
-            del kwargsCopy['prefix']
-        if 'parentMsg' in kwargsCopy:
-            del kwargsCopy['parentMsg']
-        if 'filename' in kwargsCopy:
-            del kwargsCopy['filename']
-        if 'treePath' in kwargsCopy:
-            del kwargsCopy['treePath']
-        self.__kwargs = kwargsCopy
-
-        prefixl = []
-        if prefix:
-            try:
-                prefix = inputToString(prefix, 'utf-8')
-            except Exception:
-                try:
-                    prefix = '/'.join(prefix)
-                except Exception:
-                    raise TypeError(f'Invalid prefix type: {type(prefix)}\n' +
-                                    '(This was probably caused by you setting it manually).')
-            prefix = prefix.replace('\\', '/')
-            g = prefix.split('/')
-            if g[-1] == '':
-                g.pop()
-            prefixl = g
-            if prefix[-1] != '/':
-                prefix += '/'
-        self.__prefix = prefix
-        self.__prefixList = prefixl
-        self.__prefixLen = len(prefixl)
-        if prefix and not filename:
-            filename = self._getStringStream(prefixl[:-1] + ['__substg1.0_3001'], prefix = False)
-        if filename:
-            self.filename = filename
-        elif hasLen(path):
-            if len(path) < 1536:
-                self.filename = str(path)
-            else:
-                self.filename = None
-        elif isinstance(path, pathlib.Path):
-            self.filename = str(path)
-        else:
-            self.filename = None
-
-        self.__open = True
-
-        # Now, load the attachments if we are not delaying them.
-        if not self.__attachmentsDelayed:
-            self.attachments
-
-    def __enter__(self):
-        self.__ole.__enter__()
-        return self
-
-    def __exit__(self, *args, **kwargs):
-        self.close()
-
-    def _ensureSet(self, variable : str, streamID, stringStream : bool = True, **kwargs):
-        """
-        Ensures that the variable exists, otherwise will set it using the
-        specified stream. After that, return said variable.
-
-        If the specified stream is not a string stream, make sure to set
-        :param stringStream: to False.
-
-        :param overrideClass: Class/function to use to morph the data that was
-            read. The data will be the first argument to the class's __init__
-            function or the function itself, if that is what is provided. By
-            default, this will be completely ignored if the value was not found.
-        :param preserveNone: If true (default), causes the function to ignore
-            :param overrideClass: when the value could not be found (is None).
-            If this is changed to False, then the value will be used regardless.
-        """
-        try:
-            return getattr(self, variable)
-        except AttributeError:
-            if stringStream:
-                value = self._getStringStream(streamID)
-            else:
-                value = self._getStream(streamID)
-            # Check if we should be overriding the data type for this instance.
-            if kwargs:
-                overrideClass = kwargs.get('overrideClass')
-                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
-                    value = overrideClass(value)
-            setattr(self, variable, value)
-            return value
-
-    def _ensureSetNamed(self, variable : str, propertyName : str, guid : str, **kwargs):
-        """
-        Ensures that the variable exists, otherwise will set it using the named
-        property. After that, return said variable.
-
-        :param overrideClass: Class/function to use to morph the data that was
-            read. The data will be the first argument to the class's __init__
-            function or the function itself, if that is what is provided. By
-            default, this will be completely ignored if the value was not found.
-        :param preserveNone: If true (default), causes the function to ignore
-            :param overrideClass: when the value could not be found (is None).
-            If this is changed to False, then the value will be used regardless.
-        """
-        try:
-            return getattr(self, variable)
-        except AttributeError:
-            value = self.namedProperties.get((propertyName, guid))
-            # Check if we should be overriding the data type for this instance.
-            if kwargs:
-                overrideClass = kwargs.get('overrideClass')
-                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
-                    value = overrideClass(value)
-            setattr(self, variable, value)
-            return value
-
-    def _ensureSetProperty(self, variable : str, propertyName, **kwargs):
-        """
-        Ensures that the variable exists, otherwise will set it using the
-        property. After that, return said variable.
-
-        :param overrideClass: Class/function to use to morph the data that was
-            read. The data will be the first argument to the class's __init__
-            function or the function itself, if that is what is provided. By
-            default, this will be completely ignored if the value was not found.
-        :param preserveNone: If true (default), causes the function to ignore
-            :param overrideClass: when the value could not be found (is None).
-            If this is changed to False, then the value will be used regardless.
-        """
-        try:
-            return getattr(self, variable)
-        except AttributeError:
-            try:
-                value = self.props[propertyName].value
-            except (KeyError, AttributeError):
-                value = None
-            # Check if we should be overriding the data type for this instance.
-            if kwargs:
-                overrideClass = kwargs.get('overrideClass')
-                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
-                    value = overrideClass(value)
-            setattr(self, variable, value)
-            return value
-
-    def _ensureSetTyped(self, variable : str, _id, **kwargs):
-        """
-        Like the other ensure set functions, but designed for when something
-        could be multiple types (where only one will be present). This way you
-        have no need to set the type, it will be handled for you.
-
-        :param overrideClass: Class/function to use to morph the data that was
-            read. The data will be the first argument to the class's __init__
-            function or the function itself, if that is what is provided. By
-            default, this will be completely ignored if the value was not found.
-        :param preserveNone: If true (default), causes the function to ignore
-            :param overrideClass: when the value could not be found (is None).
-            If this is changed to False, then the value will be used regardless.
-        """
-        try:
-            return getattr(self, variable)
-        except AttributeError:
-            value = self._getTypedData(_id)
-            # Check if we should be overriding the data type for this instance.
-            if kwargs:
-                overrideClass = kwargs.get('overrideClass')
-                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
-                    value = overrideClass(value)
-            setattr(self, variable, value)
-            return value
-
-    def _getOleEntry(self, filename, prefix : bool = True) -> olefile.olefile.OleDirectoryEntry:
-        """
-        Finds the directory entry from the olefile for the stream or storage
-        specified. Use '/' to get the root entry.
-        """
-        sid = -1
-        if filename == '/':
-            if prefix and self.__prefix:
-                sid = self.__ole._find(self.__prefixList)
-            else:
-                return self.__ole.direntries[0]
-        else:
-            sid = self.__ole._find(self.fixPath(filename, prefix))
-
-        return self.__ole.direntries[sid]
-
-    def _getStream(self, filename, prefix : bool = True) -> Optional[bytes]:
-        """
-        Gets a binary representation of the requested filename.
-
-        This should ALWAYS return a bytes object if it was found, otherwise
-        returns None.
-        """
-        filename = self.fixPath(filename, prefix)
-        if self.exists(filename, False):
-            with self.__ole.openstream(filename) as stream:
-                return stream.read() or b''
-        else:
-            logger.info(f'Stream "{filename}" was requested but could not be found. Returning `None`.')
-            return None
-
-    def _getStringStream(self, filename, prefix : bool = True) -> Optional[str]:
-        """
-        Gets a string representation of the requested filename.
-
-        Rather than the full filename, you should only feed this function the
-        filename sans the type. So if the full name is "__substg1.0_001A001F",
-        the filename this function should receive should be "__substg1.0_001A".
-
-        This should ALWAYS return a string if it was found, otherwise returns
-        None.
-        """
-        filename = self.fixPath(filename, prefix)
-        if self.areStringsUnicode:
-            return windowsUnicode(self._getStream(filename + '001F', prefix = False))
-        else:
-            tmp = self._getStream(filename + '001E', prefix = False)
-            return None if tmp is None else tmp.decode(self.stringEncoding)
-
-    def _getTypedData(self, _id : str, _type = None, prefix : bool = True):
-        """
-        Gets the data for the specified id as the type that it is supposed to
-        be. :param id: MUST be a 4 digit hexadecimal string.
-
-        If you know for sure what type the data is before hand, you can specify
-        it as being one of the strings in the constant FIXED_LENGTH_PROPS_STRING
-        or VARIABLE_LENGTH_PROPS_STRING.
-        """
-        verifyPropertyId(_id)
-        _id = _id.upper()
-        found, result = self._getTypedStream('__substg1.0_' + _id, prefix, _type)
-        if found:
-            return result
-        else:
-            found, result = self._getTypedProperty(_id, _type)
-            return result if found else None
-
-    def _getTypedProperty(self, propertyID : str, _type = None):
-        """
-        Gets the property with the specified id as the type that it is supposed
-        to be. :param id: MUST be a 4 digit hexadecimal string.
-
-        If you know for sure what type the property is before hand, you can
-        specify it as being one of the strings in the constant
-        FIXED_LENGTH_PROPS_STRING or VARIABLE_LENGTH_PROPS_STRING.
-        """
-        verifyPropertyId(propertyID)
-        verifyType(_type)
-        propertyID = propertyID.upper()
-        for x in (propertyID + _type,) if _type is not None else self.props:
-            if x.startswith(propertyID):
-                prop = self.props[x]
-                return True, (prop.value if isinstance(prop, FixedLengthProp) else prop)
-        return False, None
-
-    def _getTypedStream(self, filename, prefix : bool = True, _type = None):
-        """
-        Gets the contents of the specified stream as the type that it is
-        supposed to be.
-
-        Rather than the full filename, you should only feed this function the
-        filename sans the type. So if the full name is "__substg1.0_001A001F",
-        the filename this function should receive should be "__substg1.0_001A".
-
-        If you know for sure what type the stream is before hand, you can
-        specify it as being one of the strings in the constant
-        FIXED_LENGTH_PROPS_STRING or VARIABLE_LENGTH_PROPS_STRING.
-
-        If you have not specified the type, the type this function returns in
-        many cases cannot be predicted. As such, when using this function it is
-        best for you to check the type that it returns. If the function returns
-        None, that means it could not find the stream specified.
-        """
-        verifyType(_type)
-        filename = self.fixPath(filename, prefix)
-        for x in (filename + _type,) if _type is not None else self.slistDir():
-            if x.startswith(filename) and x.find('-') == -1:
-                contents = self._getStream(x, False)
-                if contents is None:
-                    continue
-                if len(contents) == 0:
-                    return True, None # We found the file, but it was empty.
-                extras = []
-                _type = x[-4:]
-                if x[-4] == '1': # It's a multiple
-                    if _type in ('101F', '101E'):
-                        streams = len(contents) // 4 # These lengths are normal.
-                    elif _type == '1102':
-                        streams = len(contents) // 8 # These lengths have 4 0x00 bytes at the end for seemingly no reason. They are "reserved" bytes
-                    elif _type in ('1002', '1003', '1004', '1005', '1007', '1014', '1040', '1048'):
-                        try:
-                            streams = self.props[x[-8:]].realLength
-                        except Exception:
-                            logger.error(f'Could not find matching VariableLengthProp for stream {x}')
-                            streams = len(contents) // (2 if _type in constants.MULTIPLE_2_BYTES else 4 if _type in constants.MULTIPLE_4_BYTES else 8 if _type in constants.MULTIPLE_8_BYTES else 16)
-                    else:
-                        raise NotImplementedError(f'The stream specified is of type {_type}. We don\'t currently understand exactly how this type works. If it is mandatory that you have the contents of this stream, please create an issue labled "NotImplementedError: _getTypedStream {_type}".')
-                    if _type in ('101F', '101E', '1102'):
-                        if self.exists(x + '-00000000', False):
-                            for y in range(streams):
-                                if self.exists(x + '-' + properHex(y, 8), False):
-                                    extras.append(self._getStream(x + '-' + properHex(y, 8), False))
-                    elif _type in ('1002', '1003', '1004', '1005', '1007', '1014', '1040', '1048'):
-                        extras = divide(contents, (2 if _type in constants.MULTIPLE_2_BYTES else 4 if _type in constants.MULTIPLE_4_BYTES else 8 if _type in constants.MULTIPLE_8_BYTES else 16))
-                        contents = streams
-                return True, parseType(int(_type, 16), contents, self.stringEncoding, extras)
-        return False, None # We didn't find the stream.
-
-    def _oleListDir(self, streams : bool = True, storages : bool = False) -> List:
-        """
-        Calls :method OleFileIO.listdir: from the OleFileIO instance associated
-        with this MSG file. Useful for if you need access to all the top level
-        streams if this is an embedded MSG file.
-
-        Returns a list of the streams and or storages depending on the arguments
-        given.
-        """
-        return self.__ole.listdir(streams, storages)
-
-    def close(self) -> None:
-        if self.__open:
-            try:
-                # If this throws an AttributeError then we have not loaded the attachments.
-                self._attachments
-                for attachment in self.attachments:
-                    if attachment.type == 'msg':
-                        attachment.data.close()
-            except AttributeError:
-                pass
-            if self.__oleOwner:
-                self.__ole.close()
-
-            self.__open = False
-
-    def debug(self) -> None:
-        for dir_ in self.listDir():
-            if dir_[-1].endswith('001E') or dir_[-1].endswith('001F'):
-                print('Directory: ' + str(dir_[:-1]))
-                print(f'Contents: {self._getStream(dir_)}')
-
-    def exists(self, inp, prefix : bool = True) -> bool:
-        """
-        Checks if :param inp: exists in the msg file.
-        """
-        inp = self.fixPath(inp, prefix)
-        return self.__ole.exists(inp)
-
-    def sExists(self, inp, prefix : bool = True) -> bool:
-        """
-        Checks if string stream :param inp: exists in the msg file.
-        """
-        inp = self.fixPath(inp, prefix)
-        return self.exists(inp + '001F') or self.exists(inp + '001E')
-
-    def existsTypedProperty(self, _id, location = None, _type = None, prefix = True, propertiesInstance = None):
-        """
-        Determines if the stream with the provided id exists in the location
-        specified. If no location is specified, the root directory is searched.
-        The return of this function is 2 values, the first being a boolean for
-        if anything was found, and the second being how many were found.
-
-        Because of how this function works, any folder that contains it's own
-        "__properties_version1.0" file should have this function called from
-        it's class.
-        """
-        verifyPropertyId(_id)
-        verifyType(_type)
-        _id = _id.upper()
-        if propertiesInstance is None:
-            propertiesInstance = self.props
-        prefixList = self.prefixList if prefix else []
-        if location is not None:
-            prefixList.append(location)
-        prefixList = inputToMsgPath(prefixList)
-        usableId = _id + _type if _type else _id
-        foundNumber = 0
-        foundStreams = []
-        for item in self.listDir():
-            if len(item) > self.__prefixLen:
-                if item[self.__prefixLen].startswith('__substg1.0_' + usableId) and item[self.__prefixLen] not in foundStreams:
-                    foundNumber += 1
-                    foundStreams.append(item[self.__prefixLen])
-        for x in propertiesInstance:
-            if x.startswith(usableId):
-                for y in foundStreams:
-                    if y.endswith(x):
-                        break
-                else:
-                    foundNumber += 1
-        return (foundNumber > 0), foundNumber
-
-    def export(self, path) -> None:
-        """
-        Exports the contents of this MSG file to a new MSG files specified by
-        the path given. If this is an embedded MSG file, the embedded streams
-        and directories will be added to it as if they were at the root,
-        allowing you to save it as it's own MSG file.
-
-        :param path: An IO device with a write method which accepts bytes or a
-            path-like object (including strings and pathlib.Path objects).
-        """
-        from .ole_writer import OleWriter
-
-        # Create an instance of the class used for writing a new OLE file.
-        writer = OleWriter()
-        # Add all file and directory entries to it. If this
-        writer.fromMsg(self)
-        writer.write(path)
-
-    def exportBytes(self) -> bytes:
-        """
-        Saves a new copy of the MSG file, returning the bytes.
-        """
-        out = io.BytesIO()
-        self.export(out)
-        return out.getvalue()
-
-    def fixPath(self, inp, prefix : bool = True) -> str:
-        """
-        Changes paths so that they have the proper prefix (should :param prefix:
-        be True) and are strings rather than lists or tuples.
-        """
-        inp = msgPathToString(inp)
-        if prefix:
-            inp = self.__prefix + inp
-        return inp
-
-    def listDir(self, streams : bool = True, storages : bool = False, includePrefix : bool = True) -> List[List]:
-        """
-        Replacement for OleFileIO.listdir that runs at the current prefix
-        directory.
-
-        :param includePrefix: If false, removed the part of the path that is the
-            prefix.
-        """
-        # Get the items from OleFileIO.
-        try:
-            return self.__listDirRes[(streams, storages, includePrefix)]
-        except KeyError:
-            entries = self.__ole.listdir(streams, storages)
-            if not self.__prefix:
-                return entries
-            prefix = self.__prefix.split('/')
-            if prefix[-1] == '':
-                prefix.pop()
-
-            prefixLength = self.__prefixLen
-            entries = [x for x in entries if len(x) > prefixLength and x[:prefixLength] == prefix]
-            if not includePrefix:
-                entries = [x[prefixLength:] for x in entries]
-            self.__listDirRes[(streams, storages, includePrefix)] = entries
-
-            return self.__listDirRes[(streams, storages, includePrefix)]
-
-    def slistDir(self, streams : bool = True, storages : bool = False) -> List[str]:
-        """
-        Replacement for OleFileIO.listdir that runs at the current prefix
-        directory. Returns a list of strings instead of lists.
-        """
-        return [msgPathToString(x) for x in self.listDir(streams, storages)]
-
-    def save(self, *args, **kwargs):
-        raise NotImplementedError(f'Saving is not yet supported for the {self.__class__.__name__} class.')
-
-    def saveAttachments(self, **kwargs) -> None:
-        """
-        Saves only attachments in the same folder.
-
-        :params skipHidden: If True, skips attachments marked as hidden.
-            (Default: False)
-        """
-        skipHidden = kwargs.get('skipHidden', False)
-        for attachment in self.attachments:
-            if not (skipHidden and attachment.hidden):
-                attachment.save(**kwargs)
-
-    def saveRaw(self, path):
-        # Create a 'raw' folder.
-        path = pathlib.Path(path)
-        # Make the location.
-        os.makedirs(path, exist_ok = True)
-        # Create the zipfile.
-        path /= 'raw.zip'
-        if path.exists():
-            raise FileExistsError(f'File "{path}" already exists.')
-        with zipfile.ZipFile(path, 'w', zipfile.ZIP_DEFLATED) as zfile:
-            # Loop through all the directories
-            for dir_ in self.listDir():
-                sysdir = '/'.join(dir_)
-                code = dir_[-1][-8:]
-                if constants.PROPERTIES.get(code):
-                    sysdir += ' - ' + constants.PROPERTIES[code]
-
-                # Generate appropriate filename.
-                if dir_[-1].endswith('001E') or dir_[-1].endswith('001F'):
-                    filename = 'contents.txt'
-                else:
-                    filename = 'contents.bin'
-
-                # Save contents of directory.
-                with zfile.open(sysdir + '/' + filename, 'w') as f:
-                    data = self._getStream(dir_)
-                    # Specifically check for None. If this is bytes we still want to do this line.
-                    # There was actually this weird issue where for some reason data would be bytes
-                    # but then also simultaneously register as None?
-                    if data is not None:
-                        f.write(data)
-
-    @property
-    def areStringsUnicode(self) -> bool:
-        """
-        Returns a boolean telling if the strings are unicode encoded.
-        """
-        try:
-            return self.__bStringsUnicode
-        except AttributeError:
-            if self.props.has_key('340D0003'):
-                if (self.props['340D0003'].value & 0x40000) != 0:
-                    self.__bStringsUnicode = True
-                    return self.__bStringsUnicode
-            self.__bStringsUnicode = False
-            return self.__bStringsUnicode
-
-    @property
-    def attachments(self) -> List:
-        """
-        Returns a list of all attachments.
-        """
-        try:
-            return self._attachments
-        except AttributeError:
-            # Get the attachments.
-            attachmentDirs = []
-            prefixLen = self.prefixLen
-            for dir_ in self.listDir(False, True):
-                if dir_[prefixLen].startswith('__attach') and \
-                        dir_[prefixLen] not in attachmentDirs:
-                    attachmentDirs.append(dir_[prefixLen])
-
-            self._attachments = []
-
-            for attachmentDir in attachmentDirs:
-                try:
-                    self._attachments.append(self.attachmentClass(self, attachmentDir))
-                except (NotImplementedError, UnrecognizedMSGTypeError) as e:
-                    print("Hello")
-                    if self.attachmentErrorBehavior != AttachErrorBehavior.THROW:
-                        logger.error(f'Error processing attachment at {attachmentDir}')
-                        logger.exception(e)
-                        self._attachments.append(UnsupportedAttachment(self, attachmentDir))
-                    else:
-                        raise
-                except Exception as e:
-                    if self.attachmentErrorBehavior == AttachErrorBehavior.BROKEN:
-                        logger.error(f'Error processing attachment at {attachmentDir}')
-                        logger.exception(e)
-                        self._attachments.append(BrokenAttachment(self, attachmentDir))
-                    else:
-                        raise
-
-            self.__attachmentsReady = True
-
-            return self._attachments
-
-    @property
-    def attachmentClass(self):
-        """
-        Returns the Attachment class being used, should you need to use it
-        externally for whatever reason.
-        """
-        return self.__attachmentClass
-
-    @property
-    def attachmentsDelayed(self) -> bool:
-        """
-        Returns True if the attachment initialization was delayed.
-        """
-        return self.__attachmentsDelayed
-
-    @property
-    def attachmentErrorBehavior(self) -> AttachErrorBehavior:
-        """
-        The behavior to follow when an attachment raises an exception. Will be
-        one of the following values:
-        ATTACHMENT_ERROR_THROW: Don't catch exceptions.
-        ATTACHMENT_ERROR_NOT_IMPLEMENTED: Catch NotImplementedError exceptions.
-        ATTACHMENT_ERROR_BROKEN: Catch all exceptions.
-        """
-        return self.__attachmentErrorBehavior
-
-    @property
-    def attachmentsReady(self) -> bool:
-        """
-        Returns True if the attachments are ready to be used.
-        """
-        return self.__attachmentsReady
-
-    @property
-    def classified(self) -> bool:
-        """
-        Indicates whether the contents of this message are regarded as
-        classified information.
-        """
-        return self._ensureSetNamed('_classified', '85B5', constants.PSETID_COMMON, overrideClass = bool, preserveNone = False)
-
-    @property
-    def classType(self) -> Optional[str]:
-        """
-        The class type of the MSG file.
-        """
-        return self._ensureSet('_classType', '__substg1.0_001A')
-
-    @property
-    def commonEnd(self) -> Optional[datetime.datetime]:
-        """
-        The end time for the object.
-        """
-        return self._ensureSetNamed('_commonEnd', '8517', constants.PSETID_COMMON)
-
-    @property
-    def commonStart(self) -> Optional[datetime.datetime]:
-        """
-        The start time for the object.
-        """
-        return self._ensureSetNamed('_commonStart', '8516', constants.PSETID_COMMON)
-
-    @property
-    def currentVersion(self) -> Optional[int]:
-        """
-        Specifies the build number of the client application that sent the
-        message.
-        """
-        return self._ensureSetNamed('_currentVersion', '8552', constants.PSETID_COMMON)
-
-    @property
-    def currentVersionName(self) -> Optional[str]:
-        """
-        Specifies the name of the client application that sent the message.
-        """
-        return self._ensureSetNamed('_currentVersionName', '8554', constants.PSETID_COMMON)
-
-    @property
-    def importance(self) -> Optional[Importance]:
-        """
-        The specified importance of the msg file.
-        """
-        return self._ensureSetProperty('_importance', '00170003', overrideClass = Importance)
-
-    @property
-    def importanceString(self) -> Union[str, None]:
-        """
-        Returns the string to use for saving. If the importance is medium then
-        it returns None. Mainly used for saving.
-        """
-        return {
-            Importance.HIGH: 'High',
-            Importance.MEDIUM: None,
-            Importance.LOW: 'low',
-            None: None,
-        }[self.importance]
-
-    @property
-    def kwargs(self) -> dict:
-        """
-        The kwargs used to initialize this message, excluding the prefix. This
-        is used for initializing embedded msg files.
-        """
-        return self.__kwargs
-
-    @property
-    def named(self) -> Named:
-        """
-        The main named properties storage. This is not usable to access the data
-        of the properties directly.
-        """
-        try:
-            return self.__named
-        except AttributeError:
-            self.__named = None
-            # Handle the parent msg file existing.
-            if self.__parentMsg:
-                # Try to get the named properties and use that for our main
-                # instance.
-                try:
-                    self.__named = self.__parentMsg.named
-                except Exception:
-                    pass
-            if not self.__named:
-                self.__named = Named(self)
-            return self.__named
-
-    @property
-    def namedProperties(self) -> NamedProperties:
-        """
-        The NamedProperties instances usable to access the data for named
-        properties.
-        """
-        try:
-            return self.__namedProperties
-        except AttributeError:
-            self.__namedProperties = NamedProperties(self.named, self)
-            return self.__namedProperties
-
-    @property
-    def overrideEncoding(self):
-        """
-        Returns None is the encoding has not been overriden, otherwise returns
-        the encoding.
-        """
-        return self.__overrideEncoding
-
-    @property
-    def path(self):
-        """
-        Returns the message path if generated from a file, otherwise returns the
-        data used to generate the Message instance.
-        """
-        return self.__path
-
-    @property
-    def prefix(self):
-        """
-        Returns the prefix of the Message instance. Intended for developer use.
-        """
-        return self.__prefix
-
-    @property
-    def prefixLen(self) -> int:
-        """
-        Returns the number of elements in the prefix.
-        """
-        return self.__prefixLen
-
-    @property
-    def prefixList(self):
-        """
-        Returns the prefix list of the Message instance. Intended for developer
-        use.
-        """
-        return copy.deepcopy(self.__prefixList)
-
-    @property
-    def priority(self) -> Optional[Priority]:
-        """
-        The specified priority of the msg file.
-        """
-        return self._ensureSetProperty('_priority', '00260003', overrideClass = Priority)
-
-    @property
-    def props(self) -> Properties:
-        """
-        Returns the Properties instance used by the MSGFile instance.
-        """
-        try:
-            return self._prop
-        except AttributeError:
-            stream = self._getStream('__properties_version1.0')
-            if not stream:
-                # Raise the exception from None so we don't get all the "during
-                # the handling of the above exception" stuff.
-                raise InvalidFileFormatError('File does not contain a properties stream.') from None
-            self._prop = Properties(stream,
-                                    PropertiesType.MESSAGE if self.prefix == '' else PropertiesType.MESSAGE_EMBED)
-            return self._prop
-
-    @property
-    def sensitivity(self) -> Optional[Sensitivity]:
-        """
-        The specified sensitivity of the msg file.
-        """
-        return self._ensureSetProperty('_sensitivity', '00360003', overrideClass = Sensitivity)
-
-    @property
-    def sideEffects(self) -> Optional[Set[SideEffect]]:
-        """
-        Controls how a Message object is handled by the client in relation to
-        certain user interface actions by the user, such as deleting a message.
-        """
-        return self._ensureSetNamed('_sideEffects', '8510', constants.PSETID_COMMON, overrideClass = SideEffect.fromBits)
-
-    @property
-    def stringEncoding(self):
-        try:
-            return self.__stringEncoding
-        except AttributeError:
-            # We need to calculate the encoding.
-            # Let's first check if the encoding will be unicode:
-            if self.areStringsUnicode:
-                self.__stringEncoding = "utf-16-le"
-                return self.__stringEncoding
-            else:
-                # Well, it's not unicode. Now we have to figure out what it IS.
-                if not self.props.has_key('3FFD0003'):
-                    # If this property is not set by the client, we SHOULD set
-                    # it to ISO-8859-15, but MAY set it to ISO-8859-1.
-                    logger.warning('Encoding property not found. Defaulting to ISO-8859-15.')
-                    self.__stringEncoding = 'iso-8859-15'
-                else:
-                    enc = self.props['3FFD0003'].value
-                    # Now we just need to translate that value.
-                    self.__stringEncoding = getEncodingName(enc)
-                return self.__stringEncoding
-
-    @property
-    def treePath(self) -> Tuple:
-        """
-        A path, as a tuple of instances, needed to get to this instance through
-        the MSGFile-Attachment tree.
-        """
-        return self.__treePath
+__all__ = [
+    'MSGFile',
+]
+
+
+import codecs
+import copy
+import datetime
+import io
+import logging
+import os
+import pathlib
+import zipfile
+
+import olefile
+
+from typing import List, Optional, Set, Tuple, Union
+
+from . import constants
+from .attachment import Attachment, BrokenAttachment, UnsupportedAttachment
+from .enums import (
+        AttachErrorBehavior, ErrorBehavior, Importance, Priority,
+        PropertiesType, Sensitivity, SideEffect
+    )
+from .exceptions import (
+        InvalidFileFormatError, StandardViolationError, UnrecognizedMSGTypeError
+    )
+from .named import Named, NamedProperties
+from .prop import FixedLengthProp
+from .properties import Properties
+from .utils import  (
+        divide, getEncodingName, hasLen, inputToMsgPath, inputToString,
+        msgPathToString, parseType, properHex, verifyPropertyId, verifyType,
+        windowsUnicode
+    )
+
+
+logger = logging.getLogger(__name__)
+logger.addHandler(logging.NullHandler())
+
+
+class MSGFile:
+    """
+    Parser for .msg files.
+    """
+
+    def __init__(self, path, **kwargs):
+        """
+        :param path: path to the msg file in the system or is the raw msg file.
+        :param prefix: Used for extracting embedded msg files inside the main
+            one. Do not set manually unless you know what you are doing.
+        :param parentMsg: Used for synchronizing named properties instances. Do
+            not set this unless you know what you are doing.
+        :param attachmentClass: Optional, the class the MSGFile object will use
+            for attachments. You probably should not change this value unless
+            you know what you are doing.
+        :param delayAttachments: Optional, delays the initialization of
+            attachments until the user attempts to retrieve them. Allows MSG
+            files with bad attachments to be initialized so the other data can
+            be retrieved.
+        :param filename: Optional, the filename to be used by default when
+            saving.
+        :param errorBehavior: Optional, the behavior to use in the event of an
+            certain types of errors.
+        :param overrideEncoding: Optional, an encoding to use instead of the one
+            specified by the msg file. Do not report encoding errors caused by
+            this.
+        :param treePath: Internal variable used for giving representation of the
+            path, as a tuple of objects, of the MSGFile. When passing, this is
+            the path to the parent object of this instance.
+
+        :raises InvalidFileFormatError: If the file is not an OleFile or could
+            not be parsed as an MSG file.
+        :raises StandardViolationError: If some part of the file badly violates 
+            the standard.
+        :raises IOError: If there is an issue opening the MSG file.
+        :raises NameError: If the encoding provided is not supported.
+        :raises TypeError: If the prefix is not a supported type.
+        :raises TypeError: If the parent is not an instance of MSGFile or a
+            subclass.
+        :raises ValueError: If the attachment error behavior is not valid.
+
+        It's recommended to check the error message to ensure you know why a
+        specific exceptions was raised.
+        """
+        # Retrieve all the kwargs that we need.
+        prefix = kwargs.get('prefix', '')
+        self.__parentMsg = kwargs.get('parentMsg')
+        self.__treePath = kwargs.get('treePath', tuple()) + (self,)
+        # Verify it is a valid class.
+        if self.__parentMsg is not None and not isinstance(self.__parentMsg, MSGFile):
+            raise TypeError(':param parentMsg: must be an instance of MSGFile or a subclass.')
+        filename = kwargs.get('filename', None)
+        overrideEncoding = kwargs.get('overrideEncoding', None)
+
+        # WARNING DO NOT MANUALLY MODIFY PREFIX. Let the program set it.
+        self.__path = path
+        self.__attachmentClass = kwargs.get('attachmentClass', Attachment)
+        self.__attachmentsDelayed = kwargs.get('delayAttachments', False)
+        self.__attachmentsReady = False
+        self.__errorBehavior = ErrorBehavior(kwargs.get('errorBehavior', ErrorBehavior.THROW))
+        if self.__errorBehavior is None:
+            if 'attachmentErrorBehavior' in kwargs:
+                import warnings
+                warnings.warn(':param attachmentErrorsBehavior: is deprecated. Use :param ErrorBehavior: instead.', DeprecationWarning)
+
+                # Get the error behavior and call the old class to convert it if
+                # necessary.
+                self.__errorBehavior = AttachErrorBehavior(kwargs['attachmentErrorBehavior'])
+
+        self.__waitingProperties = []
+        if overrideEncoding is not None:
+            codecs.lookup(overrideEncoding)
+            logger.warning('You have chosen to override the string encoding. Do not report encoding errors caused by this.')
+            self.__stringEncoding = overrideEncoding
+        self.__overrideEncoding = overrideEncoding
+
+        self.__listDirRes = {}
+
+        # This is a variable that tells whether we own the olefile. Used for
+        # closing.
+        self.__oleOwner = True
+        if self.__parentMsg:
+            # We should be able to directly access the private variables of
+            # another instance with no issue.
+            self.__ole = self.__parentMsg.__ole
+            self.__oleOwner = False
+        else:
+            try:
+                self.__ole = olefile.OleFileIO(path)
+            except OSError as e:
+                logger.error(e)
+                if str(e) == 'not an OLE2 structured storage file':
+                    raise InvalidFileFormatError(e)
+                else:
+                    raise
+
+        kwargsCopy = copy.copy(kwargs)
+        if 'prefix' in kwargsCopy:
+            del kwargsCopy['prefix']
+        if 'parentMsg' in kwargsCopy:
+            del kwargsCopy['parentMsg']
+        if 'filename' in kwargsCopy:
+            del kwargsCopy['filename']
+        if 'treePath' in kwargsCopy:
+            del kwargsCopy['treePath']
+        self.__kwargs = kwargsCopy
+
+        prefixl = []
+        if prefix:
+            try:
+                prefix = inputToString(prefix, 'utf-8')
+            except Exception:
+                try:
+                    prefix = '/'.join(prefix)
+                except Exception:
+                    raise TypeError(f'Invalid prefix type: {type(prefix)}\n' +
+                                    '(This was probably caused by you setting it manually).')
+            prefix = prefix.replace('\\', '/')
+            g = prefix.split('/')
+            if g[-1] == '':
+                g.pop()
+            prefixl = g
+            if prefix[-1] != '/':
+                prefix += '/'
+        self.__prefix = prefix
+        self.__prefixList = prefixl
+        self.__prefixLen = len(prefixl)
+        if prefix and not filename:
+            filename = self._getStringStream(prefixl[:-1] + ['__substg1.0_3001'], prefix = False)
+        if filename:
+            self.filename = filename
+        elif hasLen(path):
+            if len(path) < 1536:
+                self.filename = str(path)
+            else:
+                self.filename = None
+        elif isinstance(path, pathlib.Path):
+            self.filename = str(path)
+        else:
+            self.filename = None
+
+        self.__open = True
+
+        # Now, load the attachments if we are not delaying them.
+        if not self.__attachmentsDelayed:
+            self.attachments
+
+    def __enter__(self):
+        self.__ole.__enter__()
+        return self
+
+    def __exit__(self, *args, **kwargs):
+        self.close()
+
+    def _ensureSet(self, variable : str, streamID, stringStream : bool = True, **kwargs):
+        """
+        Ensures that the variable exists, otherwise will set it using the
+        specified stream. After that, return said variable.
+
+        If the specified stream is not a string stream, make sure to set
+        :param stringStream: to False.
+
+        :param overrideClass: Class/function to use to morph the data that was
+            read. The data will be the first argument to the class's __init__
+            function or the function itself, if that is what is provided. By
+            default, this will be completely ignored if the value was not found.
+        :param preserveNone: If true (default), causes the function to ignore
+            :param overrideClass: when the value could not be found (is None).
+            If this is changed to False, then the value will be used regardless.
+        """
+        try:
+            return getattr(self, variable)
+        except AttributeError:
+            if stringStream:
+                value = self._getStringStream(streamID)
+            else:
+                value = self._getStream(streamID)
+            # Check if we should be overriding the data type for this instance.
+            if kwargs:
+                overrideClass = kwargs.get('overrideClass')
+                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
+                    value = overrideClass(value)
+            setattr(self, variable, value)
+            return value
+
+    def _ensureSetNamed(self, variable : str, propertyName : str, guid : str, **kwargs):
+        """
+        Ensures that the variable exists, otherwise will set it using the named
+        property. After that, return said variable.
+
+        :param overrideClass: Class/function to use to morph the data that was
+            read. The data will be the first argument to the class's __init__
+            function or the function itself, if that is what is provided. By
+            default, this will be completely ignored if the value was not found.
+        :param preserveNone: If true (default), causes the function to ignore
+            :param overrideClass: when the value could not be found (is None).
+            If this is changed to False, then the value will be used regardless.
+        """
+        try:
+            return getattr(self, variable)
+        except AttributeError:
+            value = self.namedProperties.get((propertyName, guid))
+            # Check if we should be overriding the data type for this instance.
+            if kwargs:
+                overrideClass = kwargs.get('overrideClass')
+                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
+                    value = overrideClass(value)
+            setattr(self, variable, value)
+            return value
+
+    def _ensureSetProperty(self, variable : str, propertyName, **kwargs):
+        """
+        Ensures that the variable exists, otherwise will set it using the
+        property. After that, return said variable.
+
+        :param overrideClass: Class/function to use to morph the data that was
+            read. The data will be the first argument to the class's __init__
+            function or the function itself, if that is what is provided. By
+            default, this will be completely ignored if the value was not found.
+        :param preserveNone: If true (default), causes the function to ignore
+            :param overrideClass: when the value could not be found (is None).
+            If this is changed to False, then the value will be used regardless.
+        """
+        try:
+            return getattr(self, variable)
+        except AttributeError:
+            try:
+                value = self.props[propertyName].value
+            except (KeyError, AttributeError):
+                value = None
+            # Check if we should be overriding the data type for this instance.
+            if kwargs:
+                overrideClass = kwargs.get('overrideClass')
+                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
+                    value = overrideClass(value)
+            setattr(self, variable, value)
+            return value
+
+    def _ensureSetTyped(self, variable : str, _id, **kwargs):
+        """
+        Like the other ensure set functions, but designed for when something
+        could be multiple types (where only one will be present). This way you
+        have no need to set the type, it will be handled for you.
+
+        :param overrideClass: Class/function to use to morph the data that was
+            read. The data will be the first argument to the class's __init__
+            function or the function itself, if that is what is provided. By
+            default, this will be completely ignored if the value was not found.
+        :param preserveNone: If true (default), causes the function to ignore
+            :param overrideClass: when the value could not be found (is None).
+            If this is changed to False, then the value will be used regardless.
+        """
+        try:
+            return getattr(self, variable)
+        except AttributeError:
+            value = self._getTypedData(_id)
+            # Check if we should be overriding the data type for this instance.
+            if kwargs:
+                overrideClass = kwargs.get('overrideClass')
+                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
+                    value = overrideClass(value)
+            setattr(self, variable, value)
+            return value
+
+    def _getOleEntry(self, filename, prefix : bool = True) -> olefile.olefile.OleDirectoryEntry:
+        """
+        Finds the directory entry from the olefile for the stream or storage
+        specified. Use '/' to get the root entry.
+        """
+        sid = -1
+        if filename == '/':
+            if prefix and self.__prefix:
+                sid = self.__ole._find(self.__prefixList)
+            else:
+                return self.__ole.direntries[0]
+        else:
+            sid = self.__ole._find(self.fixPath(filename, prefix))
+
+        return self.__ole.direntries[sid]
+
+    def _getStream(self, filename, prefix : bool = True) -> Optional[bytes]:
+        """
+        Gets a binary representation of the requested filename.
+
+        This should ALWAYS return a bytes object if it was found, otherwise
+        returns None.
+        """
+        filename = self.fixPath(filename, prefix)
+        if self.exists(filename, False):
+            with self.__ole.openstream(filename) as stream:
+                return stream.read() or b''
+        else:
+            logger.info(f'Stream "{filename}" was requested but could not be found. Returning `None`.')
+            return None
+
+    def _getStringStream(self, filename, prefix : bool = True) -> Optional[str]:
+        """
+        Gets a string representation of the requested filename.
+
+        Rather than the full filename, you should only feed this function the
+        filename sans the type. So if the full name is "__substg1.0_001A001F",
+        the filename this function should receive should be "__substg1.0_001A".
+
+        This should ALWAYS return a string if it was found, otherwise returns
+        None.
+        """
+        filename = self.fixPath(filename, prefix)
+        if self.areStringsUnicode:
+            return windowsUnicode(self._getStream(filename + '001F', prefix = False))
+        else:
+            tmp = self._getStream(filename + '001E', prefix = False)
+            return None if tmp is None else tmp.decode(self.stringEncoding)
+
+    def _getTypedData(self, _id : str, _type = None, prefix : bool = True):
+        """
+        Gets the data for the specified id as the type that it is supposed to
+        be. :param id: MUST be a 4 digit hexadecimal string.
+
+        If you know for sure what type the data is before hand, you can specify
+        it as being one of the strings in the constant FIXED_LENGTH_PROPS_STRING
+        or VARIABLE_LENGTH_PROPS_STRING.
+        """
+        verifyPropertyId(_id)
+        _id = _id.upper()
+        found, result = self._getTypedStream('__substg1.0_' + _id, prefix, _type)
+        if found:
+            return result
+        else:
+            found, result = self._getTypedProperty(_id, _type)
+            return result if found else None
+
+    def _getTypedProperty(self, propertyID : str, _type = None):
+        """
+        Gets the property with the specified id as the type that it is supposed
+        to be. :param id: MUST be a 4 digit hexadecimal string.
+
+        If you know for sure what type the property is before hand, you can
+        specify it as being one of the strings in the constant
+        FIXED_LENGTH_PROPS_STRING or VARIABLE_LENGTH_PROPS_STRING.
+        """
+        verifyPropertyId(propertyID)
+        verifyType(_type)
+        propertyID = propertyID.upper()
+        for x in (propertyID + _type,) if _type is not None else self.props:
+            if x.startswith(propertyID):
+                prop = self.props[x]
+                return True, (prop.value if isinstance(prop, FixedLengthProp) else prop)
+        return False, None
+
+    def _getTypedStream(self, filename, prefix : bool = True, _type = None):
+        """
+        Gets the contents of the specified stream as the type that it is
+        supposed to be.
+
+        Rather than the full filename, you should only feed this function the
+        filename sans the type. So if the full name is "__substg1.0_001A001F",
+        the filename this function should receive should be "__substg1.0_001A".
+
+        If you know for sure what type the stream is before hand, you can
+        specify it as being one of the strings in the constant
+        FIXED_LENGTH_PROPS_STRING or VARIABLE_LENGTH_PROPS_STRING.
+
+        If you have not specified the type, the type this function returns in
+        many cases cannot be predicted. As such, when using this function it is
+        best for you to check the type that it returns. If the function returns
+        None, that means it could not find the stream specified.
+        """
+        verifyType(_type)
+        filename = self.fixPath(filename, prefix)
+        for x in (filename + _type,) if _type is not None else self.slistDir():
+            if x.startswith(filename) and x.find('-') == -1:
+                contents = self._getStream(x, False)
+                if contents is None:
+                    continue
+                if len(contents) == 0:
+                    return True, None # We found the file, but it was empty.
+                extras = []
+                _type = x[-4:]
+                if x[-4] == '1': # It's a multiple
+                    if _type in ('101F', '101E'):
+                        streams = len(contents) // 4 # These lengths are normal.
+                    elif _type == '1102':
+                        streams = len(contents) // 8 # These lengths have 4 0x00 bytes at the end for seemingly no reason. They are "reserved" bytes
+                    elif _type in ('1002', '1003', '1004', '1005', '1007', '1014', '1040', '1048'):
+                        try:
+                            streams = self.props[x[-8:]].realLength
+                        except Exception:
+                            logger.error(f'Could not find matching VariableLengthProp for stream {x}')
+                            streams = len(contents) // (2 if _type in constants.MULTIPLE_2_BYTES else 4 if _type in constants.MULTIPLE_4_BYTES else 8 if _type in constants.MULTIPLE_8_BYTES else 16)
+                    else:
+                        raise NotImplementedError(f'The stream specified is of type {_type}. We don\'t currently understand exactly how this type works. If it is mandatory that you have the contents of this stream, please create an issue labled "NotImplementedError: _getTypedStream {_type}".')
+                    if _type in ('101F', '101E', '1102'):
+                        if self.exists(x + '-00000000', False):
+                            for y in range(streams):
+                                if self.exists(x + '-' + properHex(y, 8), False):
+                                    extras.append(self._getStream(x + '-' + properHex(y, 8), False))
+                    elif _type in ('1002', '1003', '1004', '1005', '1007', '1014', '1040', '1048'):
+                        extras = divide(contents, (2 if _type in constants.MULTIPLE_2_BYTES else 4 if _type in constants.MULTIPLE_4_BYTES else 8 if _type in constants.MULTIPLE_8_BYTES else 16))
+                        contents = streams
+                return True, parseType(int(_type, 16), contents, self.stringEncoding, extras)
+        return False, None # We didn't find the stream.
+
+    def _oleListDir(self, streams : bool = True, storages : bool = False) -> List:
+        """
+        Calls :method OleFileIO.listdir: from the OleFileIO instance associated
+        with this MSG file. Useful for if you need access to all the top level
+        streams if this is an embedded MSG file.
+
+        Returns a list of the streams and or storages depending on the arguments
+        given.
+        """
+        return self.__ole.listdir(streams, storages)
+
+    def close(self) -> None:
+        if self.__open:
+            try:
+                # If this throws an AttributeError then we have not loaded the attachments.
+                self._attachments
+                for attachment in self.attachments:
+                    if attachment.type == 'msg':
+                        attachment.data.close()
+            except AttributeError:
+                pass
+            if self.__oleOwner:
+                self.__ole.close()
+
+            self.__open = False
+
+    def debug(self) -> None:
+        for dir_ in self.listDir():
+            if dir_[-1].endswith('001E') or dir_[-1].endswith('001F'):
+                print('Directory: ' + str(dir_[:-1]))
+                print(f'Contents: {self._getStream(dir_)}')
+
+    def exists(self, inp, prefix : bool = True) -> bool:
+        """
+        Checks if :param inp: exists in the msg file.
+        """
+        inp = self.fixPath(inp, prefix)
+        return self.__ole.exists(inp)
+
+    def sExists(self, inp, prefix : bool = True) -> bool:
+        """
+        Checks if string stream :param inp: exists in the msg file.
+        """
+        inp = self.fixPath(inp, prefix)
+        return self.exists(inp + '001F') or self.exists(inp + '001E')
+
+    def existsTypedProperty(self, _id, location = None, _type = None, prefix = True, propertiesInstance = None):
+        """
+        Determines if the stream with the provided id exists in the location
+        specified. If no location is specified, the root directory is searched.
+        The return of this function is 2 values, the first being a boolean for
+        if anything was found, and the second being how many were found.
+
+        Because of how this function works, any folder that contains it's own
+        "__properties_version1.0" file should have this function called from
+        it's class.
+        """
+        verifyPropertyId(_id)
+        verifyType(_type)
+        _id = _id.upper()
+        if propertiesInstance is None:
+            propertiesInstance = self.props
+        prefixList = self.prefixList if prefix else []
+        if location is not None:
+            prefixList.append(location)
+        prefixList = inputToMsgPath(prefixList)
+        usableId = _id + _type if _type else _id
+        foundNumber = 0
+        foundStreams = []
+        for item in self.listDir():
+            if len(item) > self.__prefixLen:
+                if item[self.__prefixLen].startswith('__substg1.0_' + usableId) and item[self.__prefixLen] not in foundStreams:
+                    foundNumber += 1
+                    foundStreams.append(item[self.__prefixLen])
+        for x in propertiesInstance:
+            if x.startswith(usableId):
+                for y in foundStreams:
+                    if y.endswith(x):
+                        break
+                else:
+                    foundNumber += 1
+        return (foundNumber > 0), foundNumber
+
+    def export(self, path) -> None:
+        """
+        Exports the contents of this MSG file to a new MSG files specified by
+        the path given. If this is an embedded MSG file, the embedded streams
+        and directories will be added to it as if they were at the root,
+        allowing you to save it as it's own MSG file.
+
+        :param path: An IO device with a write method which accepts bytes or a
+            path-like object (including strings and pathlib.Path objects).
+        """
+        from .ole_writer import OleWriter
+
+        # Create an instance of the class used for writing a new OLE file.
+        writer = OleWriter()
+        # Add all file and directory entries to it. If this
+        writer.fromMsg(self)
+        writer.write(path)
+
+    def exportBytes(self) -> bytes:
+        """
+        Saves a new copy of the MSG file, returning the bytes.
+        """
+        out = io.BytesIO()
+        self.export(out)
+        return out.getvalue()
+
+    def fixPath(self, inp, prefix : bool = True) -> str:
+        """
+        Changes paths so that they have the proper prefix (should :param prefix:
+        be True) and are strings rather than lists or tuples.
+        """
+        inp = msgPathToString(inp)
+        if prefix:
+            inp = self.__prefix + inp
+        return inp
+
+    def listDir(self, streams : bool = True, storages : bool = False, includePrefix : bool = True) -> List[List]:
+        """
+        Replacement for OleFileIO.listdir that runs at the current prefix
+        directory.
+
+        :param includePrefix: If false, removed the part of the path that is the
+            prefix.
+        """
+        # Get the items from OleFileIO.
+        try:
+            return self.__listDirRes[(streams, storages, includePrefix)]
+        except KeyError:
+            entries = self.__ole.listdir(streams, storages)
+            if not self.__prefix:
+                return entries
+            prefix = self.__prefix.split('/')
+            if prefix[-1] == '':
+                prefix.pop()
+
+            prefixLength = self.__prefixLen
+            entries = [x for x in entries if len(x) > prefixLength and x[:prefixLength] == prefix]
+            if not includePrefix:
+                entries = [x[prefixLength:] for x in entries]
+            self.__listDirRes[(streams, storages, includePrefix)] = entries
+
+            return self.__listDirRes[(streams, storages, includePrefix)]
+
+    def slistDir(self, streams : bool = True, storages : bool = False) -> List[str]:
+        """
+        Replacement for OleFileIO.listdir that runs at the current prefix
+        directory. Returns a list of strings instead of lists.
+        """
+        return [msgPathToString(x) for x in self.listDir(streams, storages)]
+
+    def save(self, *args, **kwargs):
+        raise NotImplementedError(f'Saving is not yet supported for the {self.__class__.__name__} class.')
+
+    def saveAttachments(self, **kwargs) -> None:
+        """
+        Saves only attachments in the same folder.
+
+        :params skipHidden: If True, skips attachments marked as hidden.
+            (Default: False)
+        """
+        skipHidden = kwargs.get('skipHidden', False)
+        for attachment in self.attachments:
+            if not (skipHidden and attachment.hidden):
+                attachment.save(**kwargs)
+
+    def saveRaw(self, path):
+        # Create a 'raw' folder.
+        path = pathlib.Path(path)
+        # Make the location.
+        os.makedirs(path, exist_ok = True)
+        # Create the zipfile.
+        path /= 'raw.zip'
+        if path.exists():
+            raise FileExistsError(f'File "{path}" already exists.')
+        with zipfile.ZipFile(path, 'w', zipfile.ZIP_DEFLATED) as zfile:
+            # Loop through all the directories
+            for dir_ in self.listDir():
+                sysdir = '/'.join(dir_)
+                code = dir_[-1][-8:]
+                if constants.PROPERTIES.get(code):
+                    sysdir += ' - ' + constants.PROPERTIES[code]
+
+                # Generate appropriate filename.
+                if dir_[-1].endswith('001E') or dir_[-1].endswith('001F'):
+                    filename = 'contents.txt'
+                else:
+                    filename = 'contents.bin'
+
+                # Save contents of directory.
+                with zfile.open(sysdir + '/' + filename, 'w') as f:
+                    data = self._getStream(dir_)
+                    # Specifically check for None. If this is bytes we still want to do this line.
+                    # There was actually this weird issue where for some reason data would be bytes
+                    # but then also simultaneously register as None?
+                    if data is not None:
+                        f.write(data)
+
+    @property
+    def areStringsUnicode(self) -> bool:
+        """
+        Returns a boolean telling if the strings are unicode encoded.
+        """
+        try:
+            return self.__bStringsUnicode
+        except AttributeError:
+            if '340D0003' in self.props:
+                if (self.props['340D0003'].value & 0x40000) != 0:
+                    self.__bStringsUnicode = True
+                    return self.__bStringsUnicode
+            self.__bStringsUnicode = False
+            return self.__bStringsUnicode
+
+    @property
+    def attachments(self) -> List:
+        """
+        Returns a list of all attachments.
+        """
+        try:
+            return self._attachments
+        except AttributeError:
+            # Get the attachments.
+            attachmentDirs = []
+            prefixLen = self.prefixLen
+            for dir_ in self.listDir(False, True):
+                if dir_[prefixLen].startswith('__attach') and \
+                        dir_[prefixLen] not in attachmentDirs:
+                    attachmentDirs.append(dir_[prefixLen])
+
+            self._attachments = []
+
+            for attachmentDir in attachmentDirs:
+                try:
+                    self._attachments.append(self.attachmentClass(self, attachmentDir))
+                except (NotImplementedError, UnrecognizedMSGTypeError) as e:
+                    if self.errorBehavior & ErrorBehavior.ATTACH_NOT_IMPLEMENTED:
+                        logger.exception(f'Error processing attachment at {attachmentDir}')
+                        self._attachments.append(UnsupportedAttachment(self, attachmentDir))
+                    else:
+                        raise
+                except StandardViolationError as e:
+                    if self.errorBehavior & ErrorBehavior.STANDARDS_VIOLATION:
+                        logger.exception(f'Unresolvable standards violation in  {attachmentDir}')
+                        self._attachments.append(BrokenAttachment(self, attachmentDir))
+                    else:
+                        raise
+                except Exception as e:
+                    if self.errorBehavior & ErrorBehavior.ATTACH_BROKEN:
+                        logger.exception(f'Error processing attachment at {attachmentDir}')
+                        self._attachments.append(BrokenAttachment(self, attachmentDir))
+                    else:
+                        raise
+
+            self.__attachmentsReady = True
+
+            return self._attachments
+
+    @property
+    def attachmentClass(self):
+        """
+        Returns the Attachment class being used, should you need to use it
+        externally for whatever reason.
+        """
+        return self.__attachmentClass
+
+    @property
+    def attachmentsDelayed(self) -> bool:
+        """
+        Returns True if the attachment initialization was delayed.
+        """
+        return self.__attachmentsDelayed
+
+    @property
+    def attachmentsReady(self) -> bool:
+        """
+        Returns True if the attachments are ready to be used.
+        """
+        return self.__attachmentsReady
+
+    @property
+    def classified(self) -> bool:
+        """
+        Indicates whether the contents of this message are regarded as
+        classified information.
+        """
+        return self._ensureSetNamed('_classified', '85B5', constants.PSETID_COMMON, overrideClass = bool, preserveNone = False)
+
+    @property
+    def classType(self) -> Optional[str]:
+        """
+        The class type of the MSG file.
+        """
+        return self._ensureSet('_classType', '__substg1.0_001A')
+
+    @property
+    def commonEnd(self) -> Optional[datetime.datetime]:
+        """
+        The end time for the object.
+        """
+        return self._ensureSetNamed('_commonEnd', '8517', constants.PSETID_COMMON)
+
+    @property
+    def commonStart(self) -> Optional[datetime.datetime]:
+        """
+        The start time for the object.
+        """
+        return self._ensureSetNamed('_commonStart', '8516', constants.PSETID_COMMON)
+
+    @property
+    def currentVersion(self) -> Optional[int]:
+        """
+        Specifies the build number of the client application that sent the
+        message.
+        """
+        return self._ensureSetNamed('_currentVersion', '8552', constants.PSETID_COMMON)
+
+    @property
+    def currentVersionName(self) -> Optional[str]:
+        """
+        Specifies the name of the client application that sent the message.
+        """
+        return self._ensureSetNamed('_currentVersionName', '8554', constants.PSETID_COMMON)
+    
+    @property
+    def errorBehavior(self) -> ErrorBehavior:
+        """
+        The behavior to follow when an attachment raises an exception. Will be
+        a member of the ErrorBehavior enum.
+        """
+        return self.__errorBehavior
+
+    @property
+    def importance(self) -> Optional[Importance]:
+        """
+        The specified importance of the msg file.
+        """
+        return self._ensureSetProperty('_importance', '00170003', overrideClass = Importance)
+
+    @property
+    def importanceString(self) -> Union[str, None]:
+        """
+        Returns the string to use for saving. If the importance is medium then
+        it returns None. Mainly used for saving.
+        """
+        return {
+            Importance.HIGH: 'High',
+            Importance.MEDIUM: None,
+            Importance.LOW: 'low',
+            None: None,
+        }[self.importance]
+
+    @property
+    def kwargs(self) -> dict:
+        """
+        The kwargs used to initialize this message, excluding the prefix. This
+        is used for initializing embedded msg files.
+        """
+        return self.__kwargs
+
+    @property
+    def named(self) -> Named:
+        """
+        The main named properties storage. This is not usable to access the data
+        of the properties directly.
+        """
+        try:
+            return self.__named
+        except AttributeError:
+            self.__named = None
+            # Handle the parent msg file existing.
+            if self.__parentMsg:
+                # Try to get the named properties and use that for our main
+                # instance.
+                try:
+                    self.__named = self.__parentMsg.named
+                except Exception:
+                    pass
+            if not self.__named:
+                self.__named = Named(self)
+            return self.__named
+
+    @property
+    def namedProperties(self) -> NamedProperties:
+        """
+        The NamedProperties instances usable to access the data for named
+        properties.
+        """
+        try:
+            return self.__namedProperties
+        except AttributeError:
+            self.__namedProperties = NamedProperties(self.named, self)
+            return self.__namedProperties
+
+    @property
+    def overrideEncoding(self):
+        """
+        Returns None is the encoding has not been overriden, otherwise returns
+        the encoding.
+        """
+        return self.__overrideEncoding
+
+    @property
+    def path(self):
+        """
+        Returns the message path if generated from a file, otherwise returns the
+        data used to generate the Message instance.
+        """
+        return self.__path
+
+    @property
+    def prefix(self):
+        """
+        Returns the prefix of the Message instance. Intended for developer use.
+        """
+        return self.__prefix
+
+    @property
+    def prefixLen(self) -> int:
+        """
+        Returns the number of elements in the prefix.
+        """
+        return self.__prefixLen
+
+    @property
+    def prefixList(self):
+        """
+        Returns the prefix list of the Message instance. Intended for developer
+        use.
+        """
+        return copy.deepcopy(self.__prefixList)
+
+    @property
+    def priority(self) -> Optional[Priority]:
+        """
+        The specified priority of the msg file.
+        """
+        return self._ensureSetProperty('_priority', '00260003', overrideClass = Priority)
+
+    @property
+    def props(self) -> Properties:
+        """
+        Returns the Properties instance used by the MSGFile instance.
+        """
+        try:
+            return self._prop
+        except AttributeError:
+            if not (stream := self._getStream('__properties_version1.0')):
+                if self.__errorBehavior & ErrorBehavior.STANDARDS_VIOLATION:
+                    logger.error('File does not contain a property stream.')
+                else:
+                    # Raise the exception from None so we don't get all the "during
+                    # the handling of the above exception" stuff.
+                    raise StandardViolationError('File does not contain a property stream.') from None
+            self._prop = Properties(stream,
+                                    PropertiesType.MESSAGE if self.prefix == '' else PropertiesType.MESSAGE_EMBED)
+            return self._prop
+
+    @property
+    def sensitivity(self) -> Optional[Sensitivity]:
+        """
+        The specified sensitivity of the msg file.
+        """
+        return self._ensureSetProperty('_sensitivity', '00360003', overrideClass = Sensitivity)
+
+    @property
+    def sideEffects(self) -> Optional[Set[SideEffect]]:
+        """
+        Controls how a Message object is handled by the client in relation to
+        certain user interface actions by the user, such as deleting a message.
+        """
+        return self._ensureSetNamed('_sideEffects', '8510', constants.PSETID_COMMON, overrideClass = SideEffect.fromBits)
+
+    @property
+    def stringEncoding(self):
+        try:
+            return self.__stringEncoding
+        except AttributeError:
+            # We need to calculate the encoding.
+            # Let's first check if the encoding will be unicode:
+            if self.areStringsUnicode:
+                self.__stringEncoding = "utf-16-le"
+                return self.__stringEncoding
+            else:
+                # Well, it's not unicode. Now we have to figure out what it IS.
+                if '3FFD0003' not in self.props:
+                    # If this property is not set by the client, we SHOULD set
+                    # it to ISO-8859-15, but MAY set it to ISO-8859-1.
+                    logger.warning('Encoding property not found. Defaulting to ISO-8859-15.')
+                    self.__stringEncoding = 'iso-8859-15'
+                else:
+                    enc = self.props['3FFD0003'].value
+                    # Now we just need to translate that value.
+                    self.__stringEncoding = getEncodingName(enc)
+                return self.__stringEncoding
+
+    @property
+    def treePath(self) -> Tuple:
+        """
+        A path, as a tuple of instances, needed to get to this instance through
+        the MSGFile-Attachment tree.
+        """
+        return self.__treePath
```

### Comparing `extract_msg-0.40.0/extract_msg/named.py` & `extract_msg-0.41.0/extract_msg/named.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,344 +1,363 @@
-import copy
-import logging
-import pprint
-
-from typing import Dict, Optional
-
-from . import constants
-from .enums import NamedPropertyType
-from .utils import bytesToGuid, divide, properHex, roundUp
-from compressed_rtf.crc32 import crc32
-
-
-logger = logging.getLogger(__name__)
-logger.addHandler(logging.NullHandler())
-
-
-class Named:
-    __dir = '__nameid_version1.0'
-    def __init__(self, msg):
-        self.__msg = msg
-        # Get the basic streams. If all are emtpy, then nothing to do.
-        guidStream = self._getStream('__substg1.0_00020102') or self._getStream('__substg1.0_00020102', False)
-        entryStream = self._getStream('__substg1.0_00030102') or self._getStream('__substg1.0_00030102', False)
-        self.guidStream = guidStream
-        self.entryStream = entryStream
-        self.namesStream = self._getStream('__substg1.0_00040102') or self._getStream('__substg1.0_00040102', False)
-        # The if else stuff is for protection against None.
-        guidStreamLength = len(guidStream) if guidStream else 0
-        entryStreamLength = len(entryStream) if entryStream else 0
-
-        self.__propertiesDict = {}
-        self.__properties = []
-        self.__guids = tuple()
-        self.__names = {}
-
-        # Check that we even have any entries. If there are none, nothing to do.
-        if entryStream:
-            guids = tuple([None, constants.PS_MAPI, constants.PS_PUBLIC_STRINGS] + [bytesToGuid(x) for x in divide(guidStream, 16)])
-            entries = []
-            for rawStream in divide(entryStream, 8):
-                tmp = constants.STNP_ENT.unpack(rawStream)
-                entry = {
-                    'id': tmp[0],
-                    'pid': tmp[2],
-                    'guid_index': tmp[1] >> 1,
-                    'pkind': NamedPropertyType(tmp[1] & 1), # 0 if numerical, 1 if string.
-                    'rawStream': rawStream,
-                }
-                entry['guid'] = guids[entry['guid_index']]
-                entries.append(entry)
-
-            self.entries = entries
-            self.__guids = guids
-
-            for entry in entries:
-                self.__properties.append(StringNamedProperty(entry, self.__getName(entry['id'])) if entry['pkind'] == NamedPropertyType.STRING_NAMED else NumericalNamedProperty(entry))
-
-            for property in self.__properties:
-                name = property.name if isinstance(property, StringNamedProperty) else property.propertyID
-                self.__propertiesDict[(name, property.guid)] = property
-
-    def __getitem__(self, key):
-        return self.__propertiesDict[key]
-
-    def __iter__(self):
-        return self.__propertiesDict.__iter__()
-
-    def __len__(self) -> int:
-        return self.__propertiesDict.__len__()
-
-    def __getName(self, offset : int) -> str:
-        """
-        Parses the offset into the named stream and returns the name found.
-        """
-        # We used to parse names by handing it as an array, as specified by the
-        # documentation, but this new method allows for a little bit more wiggle
-        # room in terms of what is accepted by the module.
-        if offset & 3 != 0:
-            # If the offset is not a multiple of 4, that is an error, but we are
-            # reducing it to a warning.
-            logger.warning(f'Malformed named properties detected due to bad offset ({offset}). Ignoring.')
-        # Check that offset is in string stream.
-        if offset > len(self.namesStream):
-            raise ValueError('Failed to parse named property: offset was not in string stream.')
-
-        # Get the length, in bytes, of the string.
-        length = constants.STNP_NAM.unpack(self.namesStream[offset:offset + 4])[0]
-        offset += 4
-
-        # Make sure the string can be read entirely. If it can't, something was
-        # corrupt.
-        if offset + length > len(self.namesStream):
-            raise ValueError(f'Failed to parse named property: length ({length}) of string overflows the string stream. This is probably due to a bad offset.')
-
-        return self.namesStream[offset:offset + length].decode('utf-16-le')
-
-    def _getStream(self, filename, prefix = True) -> Optional[bytes]:
-        return self.__msg._getStream([self.__dir, filename], prefix = prefix)
-
-    def _getStringStream(self, filename, prefix = True) -> Optional[str]:
-        """
-        Gets a string representation of the requested filename.
-        Checks for both ASCII and Unicode representations and returns
-        a value if possible.  If there are both ASCII and Unicode
-        versions, then :param prefer: specifies which will be
-        returned.
-        """
-        return self.__msg._getStringStream([self.__dir, filename], prefix = prefix)
-
-    def exists(self, filename) -> bool:
-        """
-        Checks if stream exists inside the named properties folder.
-        """
-        return self.__msg.exists([self.__dir, filename])
-
-    def sExists(self, filename) -> bool:
-        """
-        Checks if the string stream exists inside the named properties folder.
-        """
-        return self.__msg.sExists([self.__dir, filename])
-
-    def get(self, propertyName, default = None):
-        """
-        Tries to get a named property based on its key. Returns :param default:
-        if not found. Key is a tuple of the name and the property set GUID.
-        """
-        try:
-            return self.__propertiesDict[propertyName]
-        except KeyError:
-            propertyName = propertyName.upper()
-            for key in self.__propertiesDict.keys():
-                if propertyName == key.upper():
-                    return self.__propertiesDict[key]
-            return default
-
-    def keys(self):
-        return self.__propertiesDict.keys()
-
-    def pprintKeys(self):
-        """
-        Uses the pprint function on a sorted list of keys.
-        """
-        pprint.pprint(sorted(self.__propertiesDict.keys()))
-
-    def values(self):
-        return self.__propertiesDict.values()
-
-    @property
-    def dir(self):
-        """
-        Returns the directory inside the msg file where the named properties are located.
-        """
-        return self.__dir
-
-    @property
-    def msg(self) -> 'MSGFile':
-        """
-        Returns the Message instance the attachment belongs to.
-        """
-        return self.__msg
-
-    @property
-    def namedProperties(self) -> Dict:
-        """
-        Returns a copy of the dictionary containing all the named properties.
-        """
-        return copy.deepcopy(self.__propertiesDict)
-
-
-
-class NamedProperties:
-    """
-    An instance that uses a Named instance and an extract-msg class to read the
-    data of named properties.
-    """
-    def __init__(self, named, streamSource):
-        """
-        :param named: The named instance to refer to for named properties
-            entries.
-        :param streamSource: The source to use for acquiring the data of a named
-            property.
-        """
-        self.__named = named
-        self.__streamSource = streamSource
-
-    def __getitem__(self, item):
-        """
-        Get a named property using the [] operator. Item must be a named
-        property instance or a tuple with 2 items: the name and the GUID string.
-        """
-        if isinstance(item, NamedPropertyBase):
-            return self.__streamSource._getTypedData(item.propertyStreamID)
-        else:
-            return self.__streamSource._getTypedData(self.__named[item].propertyStreamID)
-
-    def get(self, item, default = None):
-        """
-        Get a named property, returning the value of :param default: if not
-        found. Item must be a tuple with 2 items: the name and the GUID string.
-        """
-        try:
-            return self[item]
-        except KeyError:
-            return default
-
-
-
-class NamedPropertyBase:
-    def __init__(self, entry):
-        self.__entry = entry
-        self.__guidIndex = entry['guid_index']
-        self.__namedPropertyID = entry['pid']
-        self.__guid = entry['guid']
-        self.__propertyStreamID = f'{0x8000 + self.__namedPropertyID:04X}'
-
-    @property
-    def guid(self) -> str:
-        """
-        The guid of the property's property set.
-        """
-        return self.__guid
-
-    @property
-    def guidIndex(self) -> int:
-        """
-        The guid index of the property's property set.
-        """
-        return self.__guidIndex
-
-    @property
-    def namedPropertyID(self) -> int:
-        """
-        The named property id.
-        """
-        return self.__namedPropertyID
-
-    @property
-    def propertyStreamID(self) -> str:
-        """
-        An ID usable for grabbing the value stream.
-        """
-        return self.__propertyStreamID
-
-    @property
-    def rawEntry(self) -> dict:
-        return copy.deepcopy(entry)
-
-    @property
-    def rawEntryStream(self) -> bytes:
-        """
-        The raw data used for the entry.
-        """
-        return self.__entry['rawStream']
-
-    @property
-    def type(self) -> NamedPropertyType:
-        """
-        The type of named property.
-        """
-        raise NotImplementedError('NamedPropertyBase cannot be used directly. Subclass it before using it.')
-
-
-
-class StringNamedProperty(NamedPropertyBase):
-    def __init__(self, entry, name):
-        super().__init__(entry)
-        self.__name = name
-
-        # Finally got this to be correct after asking about it on a Microsoft
-        # forum. Apparently it uses the same CRC-32 as the Compressed RTF
-        # standard does, so we can just use the function defined in the
-        # compressed-rtf Python module.
-        #
-        # First thing to note is that the name should only ever be lowered if it
-        # is part of the PS_INTERNET_HEADERS property set **AND** it is
-        # generated by certain versions of Outlook. As such, a little bit of
-        # additional code will need to run to determine exactly what the stream
-        # ID should be if it is in that property set.
-        if self.guid == constants.PS_INTERNET_HEADERS:
-            # To be sure if it needs to be lower the most effective method would
-            # be to just get the Stream ID and then check if the entry is in
-            # there. If it isn't, then check the regular case and see. If it is
-            # not in either... well, we don't use it for anything so it will
-            # just be a warning, and the Stream ID will be set to 0.
-            #
-            # TODO: Unfortunately, doing this will need to be put off until a
-            # different version, preferably after Python 2 support is removed,
-            # as this will require restructuring a lot of internal code. For now
-            # we just assume that it is lowercase.
-            self.__streamID = 0x1000 + (crc32(name.lower().encode('utf-16-le')) ^ (self.guidIndex << 1 | 1)) % 0x1F
-
-        else:
-            # No special logic here to determine what to do.
-            self.__streamID = 0x1000 + (crc32(name.encode('utf-16-le')) ^ (self.guidIndex << 1 | 1)) % 0x1F
-
-    @property
-    def name(self) -> str:
-        """
-        The name of the property.
-        """
-        return self.__name
-
-    @property
-    def streamID(self) -> int:
-        """
-        Returns the streamID of the named property. This may not be accurate.
-        """
-        return self.__streamID
-
-    @property
-    def type(self) -> NamedPropertyType:
-        """
-        Returns the type of the named property. This will either be NUMERICAL_NAMED or STRING_NAMED.
-        """
-        return NamedPropertyType.STRING_NAMED
-
-
-
-class NumericalNamedProperty(NamedPropertyBase):
-    def __init__(self, entry):
-        super().__init__(entry)
-        self.__propertyID = properHex(entry['id'], 4).upper()
-        self.__streamID = 0x1000 + (entry['id'] ^ (self.guidIndex << 1)) % 0x1F
-
-    @property
-    def propertyID(self) -> str:
-        """
-        The actualy property id of the named property.
-        """
-        return self.__propertyID
-
-    @property
-    def streamID(self) -> int:
-        """
-        Returns the streamID of the named property. This may not be accurate
-        """
-        return self.__streamID
-
-    @property
-    def type(self) -> NamedPropertyType:
-        """
-        Returns the type of the named property. This will either be NUMERICAL_NAMED or STRING_NAMED.
-        """
-        return NamedPropertyType.NUMERICAL_NAMED
+from __future__ import annotations
+
+
+__all__ = [
+    'Named',
+    'NamedProperties',
+    'NamedPropertyBase',
+    'NumericalNamedProperty',
+    'StringNamedProperty',
+]
+
+
+import copy
+import logging
+import pprint
+
+from typing import Dict, Optional, TYPE_CHECKING
+
+from . import constants
+from .enums import NamedPropertyType
+from .utils import bytesToGuid, divide, properHex
+from compressed_rtf.crc32 import crc32
+
+
+# Allow for nice type checking.
+if TYPE_CHECKING:
+    from .msg import MSGFile
+
+logger = logging.getLogger(__name__)
+logger.addHandler(logging.NullHandler())
+
+
+class Named:
+    __dir = '__nameid_version1.0'
+    def __init__(self, msg):
+        self.__msg = msg
+        # Get the basic streams. If all are emtpy, then nothing to do.
+        guidStream = self._getStream('__substg1.0_00020102') or self._getStream('__substg1.0_00020102', False)
+        entryStream = self._getStream('__substg1.0_00030102') or self._getStream('__substg1.0_00030102', False)
+        self.guidStream = guidStream
+        self.entryStream = entryStream
+        self.namesStream = self._getStream('__substg1.0_00040102') or self._getStream('__substg1.0_00040102', False)
+        # The if else stuff is for protection against None.
+        guidStreamLength = len(guidStream) if guidStream else 0
+        entryStreamLength = len(entryStream) if entryStream else 0
+
+        self.__propertiesDict = {}
+        self.__properties = []
+        self.__guids = tuple()
+        self.__names = {}
+
+        # Check that we even have any entries. If there are none, nothing to do.
+        if entryStream:
+            guids = tuple([None, constants.PS_MAPI, constants.PS_PUBLIC_STRINGS] + [bytesToGuid(x) for x in divide(guidStream, 16)])
+            entries = []
+            for rawStream in divide(entryStream, 8):
+                tmp = constants.STNP_ENT.unpack(rawStream)
+                entry = {
+                    'id': tmp[0],
+                    'pid': tmp[2],
+                    'guid_index': tmp[1] >> 1,
+                    'pkind': NamedPropertyType(tmp[1] & 1), # 0 if numerical, 1 if string.
+                    'rawStream': rawStream,
+                }
+                entry['guid'] = guids[entry['guid_index']]
+                entries.append(entry)
+
+            self.entries = entries
+            self.__guids = guids
+
+            for entry in entries:
+                self.__properties.append(StringNamedProperty(entry, self.__getName(entry['id'])) if entry['pkind'] == NamedPropertyType.STRING_NAMED else NumericalNamedProperty(entry))
+
+            for property in self.__properties:
+                name = property.name if isinstance(property, StringNamedProperty) else property.propertyID
+                self.__propertiesDict[(name, property.guid)] = property
+
+    def __contains__(self, key) -> bool:
+        return key in self.__propertiesDict
+
+    def __getitem__(self, key):
+        return self.__propertiesDict[key]
+
+    def __iter__(self):
+        return self.__propertiesDict.__iter__()
+
+    def __len__(self) -> int:
+        return self.__propertiesDict.__len__()
+
+    def __getName(self, offset : int) -> str:
+        """
+        Parses the offset into the named stream and returns the name found.
+        """
+        # We used to parse names by handing it as an array, as specified by the
+        # documentation, but this new method allows for a little bit more wiggle
+        # room in terms of what is accepted by the module.
+        if offset & 3 != 0:
+            # If the offset is not a multiple of 4, that is an error, but we are
+            # reducing it to a warning.
+            logger.warning(f'Malformed named properties detected due to bad offset ({offset}). Ignoring.')
+        # Check that offset is in string stream.
+        if offset > len(self.namesStream):
+            raise ValueError('Failed to parse named property: offset was not in string stream.')
+
+        # Get the length, in bytes, of the string.
+        length = constants.STNP_NAM.unpack(self.namesStream[offset:offset + 4])[0]
+        offset += 4
+
+        # Make sure the string can be read entirely. If it can't, something was
+        # corrupt.
+        if offset + length > len(self.namesStream):
+            raise ValueError(f'Failed to parse named property: length ({length}) of string overflows the string stream. This is probably due to a bad offset.')
+
+        return self.namesStream[offset:offset + length].decode('utf-16-le')
+
+    def _getStream(self, filename, prefix = True) -> Optional[bytes]:
+        return self.__msg._getStream([self.__dir, filename], prefix = prefix)
+
+    def _getStringStream(self, filename, prefix = True) -> Optional[str]:
+        """
+        Gets a string representation of the requested filename.
+        Checks for both ASCII and Unicode representations and returns
+        a value if possible.  If there are both ASCII and Unicode
+        versions, then :param prefer: specifies which will be
+        returned.
+        """
+        return self.__msg._getStringStream([self.__dir, filename], prefix = prefix)
+
+    def exists(self, filename) -> bool:
+        """
+        Checks if stream exists inside the named properties folder.
+        """
+        return self.__msg.exists([self.__dir, filename])
+
+    def sExists(self, filename) -> bool:
+        """
+        Checks if the string stream exists inside the named properties folder.
+        """
+        return self.__msg.sExists([self.__dir, filename])
+
+    def get(self, propertyName, default = None):
+        """
+        Tries to get a named property based on its key. Returns :param default:
+        if not found. Key is a tuple of the name and the property set GUID.
+        """
+        try:
+            return self.__propertiesDict[propertyName]
+        except KeyError:
+            propertyName = propertyName.upper()
+            for key in self.__propertiesDict.keys():
+                if propertyName == key.upper():
+                    return self.__propertiesDict[key]
+            return default
+
+    def keys(self):
+        return self.__propertiesDict.keys()
+
+    def pprintKeys(self):
+        """
+        Uses the pprint function on a sorted list of keys.
+        """
+        pprint.pprint(sorted(self.__propertiesDict.keys()))
+
+    def values(self):
+        return self.__propertiesDict.values()
+
+    @property
+    def dir(self):
+        """
+        Returns the directory inside the msg file where the named properties are located.
+        """
+        return self.__dir
+
+    @property
+    def msg(self) -> MSGFile:
+        """
+        Returns the Message instance the attachment belongs to.
+        """
+        return self.__msg
+
+    @property
+    def namedProperties(self) -> Dict:
+        """
+        Returns a copy of the dictionary containing all the named properties.
+        """
+        return copy.deepcopy(self.__propertiesDict)
+
+
+
+class NamedProperties:
+    """
+    An instance that uses a Named instance and an extract-msg class to read the
+    data of named properties.
+    """
+    def __init__(self, named, streamSource):
+        """
+        :param named: The named instance to refer to for named properties
+            entries.
+        :param streamSource: The source to use for acquiring the data of a named
+            property.
+        """
+        self.__named = named
+        self.__streamSource = streamSource
+
+    def __getitem__(self, item):
+        """
+        Get a named property using the [] operator. Item must be a named
+        property instance or a tuple with 2 items: the name and the GUID string.
+        """
+        if isinstance(item, NamedPropertyBase):
+            return self.__streamSource._getTypedData(item.propertyStreamID)
+        else:
+            return self.__streamSource._getTypedData(self.__named[item].propertyStreamID)
+
+    def get(self, item, default = None):
+        """
+        Get a named property, returning the value of :param default: if not
+        found. Item must be a tuple with 2 items: the name and the GUID string.
+        """
+        try:
+            return self[item]
+        except KeyError:
+            return default
+
+
+
+class NamedPropertyBase:
+    def __init__(self, entry):
+        self.__entry = entry
+        self.__guidIndex = entry['guid_index']
+        self.__namedPropertyID = entry['pid']
+        self.__guid = entry['guid']
+        self.__propertyStreamID = f'{0x8000 + self.__namedPropertyID:04X}'
+
+    @property
+    def guid(self) -> str:
+        """
+        The guid of the property's property set.
+        """
+        return self.__guid
+
+    @property
+    def guidIndex(self) -> int:
+        """
+        The guid index of the property's property set.
+        """
+        return self.__guidIndex
+
+    @property
+    def namedPropertyID(self) -> int:
+        """
+        The named property id.
+        """
+        return self.__namedPropertyID
+
+    @property
+    def propertyStreamID(self) -> str:
+        """
+        An ID usable for grabbing the value stream.
+        """
+        return self.__propertyStreamID
+
+    @property
+    def rawEntry(self) -> dict:
+        return copy.deepcopy(self.__entry)
+
+    @property
+    def rawEntryStream(self) -> bytes:
+        """
+        The raw data used for the entry.
+        """
+        return self.__entry['rawStream']
+
+    @property
+    def type(self) -> NamedPropertyType:
+        """
+        The type of named property.
+        """
+        raise NotImplementedError('NamedPropertyBase cannot be used directly. Subclass it before using it.')
+
+
+
+class StringNamedProperty(NamedPropertyBase):
+    def __init__(self, entry, name):
+        super().__init__(entry)
+        self.__name = name
+
+        # Finally got this to be correct after asking about it on a Microsoft
+        # forum. Apparently it uses the same CRC-32 as the Compressed RTF
+        # standard does, so we can just use the function defined in the
+        # compressed-rtf Python module.
+        #
+        # First thing to note is that the name should only ever be lowered if it
+        # is part of the PS_INTERNET_HEADERS property set **AND** it is
+        # generated by certain versions of Outlook. As such, a little bit of
+        # additional code will need to run to determine exactly what the stream
+        # ID should be if it is in that property set.
+        if self.guid == constants.PS_INTERNET_HEADERS:
+            # To be sure if it needs to be lower the most effective method would
+            # be to just get the Stream ID and then check if the entry is in
+            # there. If it isn't, then check the regular case and see. If it is
+            # not in either... well, we don't use it for anything so it will
+            # just be a warning, and the Stream ID will be set to 0.
+            #
+            # TODO: Unfortunately, doing this will need to be put off until a
+            # different version, preferably after Python 2 support is removed,
+            # as this will require restructuring a lot of internal code. For now
+            # we just assume that it is lowercase.
+            self.__streamID = 0x1000 + (crc32(name.lower().encode('utf-16-le')) ^ (self.guidIndex << 1 | 1)) % 0x1F
+
+        else:
+            # No special logic here to determine what to do.
+            self.__streamID = 0x1000 + (crc32(name.encode('utf-16-le')) ^ (self.guidIndex << 1 | 1)) % 0x1F
+
+    @property
+    def name(self) -> str:
+        """
+        The name of the property.
+        """
+        return self.__name
+
+    @property
+    def streamID(self) -> int:
+        """
+        Returns the streamID of the named property. This may not be accurate.
+        """
+        return self.__streamID
+
+    @property
+    def type(self) -> NamedPropertyType:
+        """
+        Returns the type of the named property. This will either be NUMERICAL_NAMED or STRING_NAMED.
+        """
+        return NamedPropertyType.STRING_NAMED
+
+
+
+class NumericalNamedProperty(NamedPropertyBase):
+    def __init__(self, entry):
+        super().__init__(entry)
+        self.__propertyID = properHex(entry['id'], 4).upper()
+        self.__streamID = 0x1000 + (entry['id'] ^ (self.guidIndex << 1)) % 0x1F
+
+    @property
+    def propertyID(self) -> str:
+        """
+        The actualy property id of the named property.
+        """
+        return self.__propertyID
+
+    @property
+    def streamID(self) -> int:
+        """
+        Returns the streamID of the named property. This may not be accurate
+        """
+        return self.__streamID
+
+    @property
+    def type(self) -> NamedPropertyType:
+        """
+        Returns the type of the named property. This will either be NUMERICAL_NAMED or STRING_NAMED.
+        """
+        return NamedPropertyType.NUMERICAL_NAMED
```

### Comparing `extract_msg-0.40.0/extract_msg/ole_writer.py` & `extract_msg-0.41.0/extract_msg/ole_writer.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,989 +1,1005 @@
-import copy
-import io
-import pathlib
-import re
-
-from typing import Dict, Iterator, List, Optional, Tuple, Union
-
-from . import constants
-from .enums import Color, DirectoryEntryType
-from .utils import ceilDiv, dictGetCasedKey, inputToMsgPath
-from olefile.olefile import OleDirectoryEntry, OleFileIO
-from red_black_dict_mod import RedBlackTree
-
-
-class DirectoryEntry:
-    """
-    An internal representation of a stream or storage in the OleWriter.
-    Originals should be inaccessible outside of the class.
-    """
-    name : str = ''
-    rightChild : 'DirectoryEntry' = None
-    leftChild : 'DirectoryEntry' = None
-    childTreeRoot : 'DirectoryEntry' = None
-    stateBits : int = 0
-    creationTime : int = 0
-    modifiedTime : int = 0
-    type : DirectoryEntryType = DirectoryEntryType.UNALLOCATED
-
-    # These get set after things have been sorted by the red black tree.
-    id : int = -1
-    # This is the ID for the left child. The terminology in the docs is really
-    # annoying.
-    leftSiblingID : int = 0xFFFFFFFF
-    rightSiblingID : int = 0xFFFFFFFF
-    # This is the ID for the root of the child tree, if any.
-    childID : int = 0xFFFFFFFF
-    startingSectorLocation : int = 0
-    color : Color = Color.BLACK
-
-    clsid : bytes = b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
-    data : bytes = b''
-
-    def __init__(self):
-        pass
-
-    def toBytes(self):
-        """
-        Converts the entry to bytes to be writen to a file.
-        """
-        # First write the name and the name length.
-        if len(self.name) > 31:
-            raise ValueError('Name is too long for directory entry.')
-        if len(self.name) < 1:
-            raise ValueError('Directory entry must have a name.')
-        if re.search('/\\\\:!', self.name):
-            raise ValueError('Directory entry name contains an illegal character.')
-
-        nameBytes = self.name.encode('utf-16-le')
-
-        return constants.ST_CF_DIR_ENTRY.pack(
-                                              nameBytes,
-                                              len(nameBytes) + 2,
-                                              self.type,
-                                              self.color,
-                                              self.leftSiblingID,
-                                              self.rightSiblingID,
-                                              self.childID,
-                                              self.clsid,
-                                              self.stateBits,
-                                              self.creationTime,
-                                              self.modifiedTime,
-                                              self.startingSectorLocation,
-                                              getattr(self, 'streamSize', len(self.data)),
-                                             )
-
-
-
-class OleWriter:
-    """
-    Takes data to write to a compound binary format file, as specified in
-    [MS-CFB].
-    """
-    def __init__(self, rootClsid : bytes = constants.DEFAULT_CLSID):
-        self.__rootEntry = DirectoryEntry()
-        self.__rootEntry.name = "Root Entry"
-        self.__rootEntry.type = DirectoryEntryType.ROOT_STORAGE
-        self.__rootEntry.clsid = rootClsid
-        # The root entry will always exist, so this must be at least 1.
-        self.__dirEntryCount = 1
-        self.__dirEntries = {}
-        self.__largeEntries = []
-        self.__largeEntrySectors = 0
-        self.__numMinifatSectors = 0
-
-    def __getContainingStorage(self, path : List[str], entryExists : bool = True, create : bool = False) -> Dict:
-        """
-        Finds the storage dict internally where the entry specified by
-        :param path: would be created. If :param create: is True, missing
-        storages will be created with default settings.
-
-        :param entryExists: If True, throws an error when the requested entry
-            does not yet exist.
-        :param create: If True, creates missing storages with default settings.
-
-        :raises OSError: If :param create: is False and the path could not be
-            found. Also raised if :param entryExists: is True and the requested
-            entry does not exist.
-        :raises ValueError: Tried to access an interal stream or tried to use
-            both the create option and the entryExists option as True.
-
-        :returns: The storage dict that the entry is in.
-        """
-        # Quick check for incompatability between create and entryExists.
-        if create and entryExists:
-            raise ValueError(':param create: and :param entryExists: cannot both be True (an entry cannot exist if it is being created).')
-
-        # Check that the path is not an internal entry. Given the validation on
-        # paths that most functions should do because of the call to
-        # inputToMsgPath, this shouldn't actually be necessary.
-        if any(x.startswith('::') for x in path):
-            raise ValueError('Found internal name in path.')
-
-        _dir = self.__dirEntries
-
-        for index, name in enumerate(path[:-1]):
-            # If no entry in the current stream matches the path, raise an
-            # OSError, *unless* the option to create storages is True.
-            if name.lower() not in map(str.lower, _dir.keys()):
-                if create:
-                    self.addEntry(path[:index + 1], storage = True)
-                else:
-                    raise OSError(f'Entry not found: {name}')
-            _dir = _dir[dictGetCasedKey(_dir, name)]
-
-            # If the current item is not a storage and we have more to the path,
-            # raise an OSError.
-            if not isinstance(_dir, dict):
-                raise OSError('Attempted to access children of a stream.')
-
-        if entryExists and path[-1].lower() not in map(str.lower, _dir.keys()):
-            raise OSError(f'Entry not found: {path[-1]}')
-
-        return _dir
-
-    def __getEntry(self, path : List[str]) -> DirectoryEntry:
-        """
-        Finds and returns an existing DirectoryEntry instance in the writer.
-
-        :raises OSError: If the entry does not exist.
-        :raises ValueError: If access to an internal item is attempted.
-        """
-        _dir = self.__getContainingStorage(path)
-        item = _dir[dictGetCasedKey(_dir, path[-1])]
-        if isinstance(item, dict):
-            return item['::DirectoryEntry']
-        else:
-            return item
-
-    def __modifyEntry(self, entry : DirectoryEntry, **kwargs):
-        """
-        Edits the DirectoryEntry with the data provided. Common code used for
-        :method addEntry: and :method editEntry:.
-
-        :raises ValueError: Some part of the data given to modify the various
-            properties was invalid. See the the listed methods for details.
-        """
-        # Extract the arguments.
-        data = kwargs.get('data')
-        clsid = kwargs.get('clsid')
-        creationTime = kwargs.get('creationTime')
-        modifiedTime = kwargs.get('modifiedTime')
-        stateBits = kwargs.get('stateBits')
-
-        # I don't like that I have repeated if statements for checking each of
-        # the arguments, but I need to make sure nothing changes if something is
-        # invalid.
-        if data is not None:
-            if entry.type is not DirectoryEntryType.STREAM:
-                raise ValueError('Cannot set the data of a storage object.')
-            if not isinstance(data, bytes):
-                raise ValueError('Data must be a bytes instance if set.')
-
-        if clsid is not None:
-            if not isinstance(clsid, bytes):
-                raise ValueError('CLSID must be bytes.')
-            if len(clsid) != 16:
-                raise ValueError('CLSID must be 16 bytes.')
-
-        if creationTime is not None:
-            if entry.type is DirectoryEntryType.STREAM:
-                raise ValueError('Modification of creation time cannot be done on a stream.')
-            if not isinstance(creationTime, int) or creationTime < 0 or creationTime > 0xFFFFFFFFFFFFFFFF:
-                raise ValueError('Creation time must be a positive 8 byte int.')
-
-        if modifiedTime is not None:
-            if entry.type is DirectoryEntryType.STREAM:
-                raise ValueError('Modification of modified time cannot be done on a stream.')
-            if not isinstance(modifiedTime, int) or modifiedTime < 0 or modifiedTime > 0xFFFFFFFFFFFFFFFF:
-                raise ValueError('Modified time must be a positive 8 byte int.')
-
-        if stateBits is not None:
-            if not isinstance(stateBits, int) or stateBits < 0 or stateBits > 0xFFFFFFFF:
-                raise ValueError('State bits must be a positive 4 byte int.')
-
-
-        # Now that all our checks have passed, let's set our data.
-        if data is not None:
-            entry.data = data
-        if clsid is not None:
-            entry.clsid = clsid
-        if creationTime is not None:
-            entry.creationTime = creationTime
-        if modifiedTime is not None:
-            entry.modifiedTime = modifiedTime
-        if stateBits is not None:
-            entry.stateBits = stateBits
-
-    def __recalculateSectors(self) -> None:
-        """
-        Recalculates several of the internal variables used for saving that
-        specify the number of sectors and where things should go.
-        """
-        self.__dirEntryCount = 0
-        self.__numMinifatSectors = 0
-        self.__largeEntries.clear()
-        self.__largeEntrySectors = 0
-
-        count = 0
-        for entry in self.__walkEntries():
-            self.__dirEntryCount += 1
-            if entry.type == DirectoryEntryType.STREAM:
-                if len(entry.data) < 4096:
-                    self.__numMinifatSectors += ceilDiv(len(entry.data), 64)
-                else:
-                    self.__largeEntries.append(entry)
-                    self.__largeEntrySectors += ceilDiv(len(entry.data), 512)
-
-    def __walkEntries(self) -> Iterator[DirectoryEntry]:
-        """
-        Returns a generator that will walk the entires recursively. Each item
-        returned by it will be a DirectoryEntry instance.
-        """
-        toProcess = [self.__dirEntries]
-        yield self.__rootEntry
-
-        while len(toProcess) > 0:
-            for name, item in toProcess.pop(0).items():
-                if not name.startswith('::'):
-                    if isinstance(item, dict):
-                        yield item['::DirectoryEntry']
-                        toProcess.append(item)
-                    else:
-                        yield item
-
-    @property
-    def __numberOfSectors(self) -> int:
-        """
-        TODO: finish the calculation needed. For now this just notes how many
-        sectors are needed for the directory entries.
-        """
-        return ceilDiv(self.__dirEntryCount, 4) + \
-               self.__numMinifat + \
-               ceilDiv(self.__numMinifat, 16) + \
-               self.__largeEntrySectors
-
-    @property
-    def __numMinifat(self) -> int:
-        """
-        The number of FAT sectors needed to store the mini FAT.
-        """
-        return ceilDiv(self.__numMinifatSectors, 8)
-
-    def _cleanupEntries(self) -> None:
-        """
-        Cleans up the node connections by walking the tree and removing
-        references that were added during writing.
-        """
-        self.__largeEntries.clear()
-        for entry in self.__walkEntries():
-            entry.id = -1
-            entry.leftChild = None
-            entry.rightChild = None
-            entry.childTreeRoot = None
-            entry.leftSiblingID = 0xFFFFFFFF
-            entry.rightSiblingID = 0xFFFFFFFF
-            entry.childID = 0xFFFFFFFF
-
-    def _getFatSectors(self) -> Tuple[int, int, int]:
-        """
-        Returns a tuple containing the number of FAT sectors, the number of
-        DIFAT sectors, and the total number of sectors the saved file will have.
-        """
-        # Right now we just use an annoying while loop to get the numbers.
-        numDifat = 0
-        # All divisions are ceiling divisions, so we leave them as
-        numFat = ceilDiv(self.__numberOfSectors, 127) or 1
-        newNumFat = 1
-        while numFat != newNumFat:
-            numFat = newNumFat
-            numDifat = ceilDiv(max(numFat - 109, 0), 127)
-            newNumFat = ceilDiv(self.__numberOfSectors + numDifat, 127)
-
-        return (numFat, numDifat, self.__numberOfSectors + numDifat + numFat)
-
-    def _treeSort(self, startingSector : int) -> List[DirectoryEntry]:
-        """
-        Uses red-black trees to sort the internal data in preparation for
-        writing the file, returning a list, in order, of the entries to write.
-        """
-        # First, create the root entry.
-        root = copy.copy(self.__rootEntry)
-
-        # Add the location of the start of the mini stream.
-        root.startingSectorLocation = (startingSector + ceilDiv(self.__dirEntryCount, 4) + ceilDiv(self.__numMinifatSectors, 128)) if self.__numMinifat > 0 else 0xFFFFFFFE
-        root.streamSize = self.__numMinifatSectors * 64
-        root.childTreeRoot = None
-        root.childID = 0xFFFFFFFF
-        entries = [root]
-
-        toProcess = [(root, self.__dirEntries)]
-        # Continue looping while there is more to process.
-        while toProcess:
-            entry, currentItem = toProcess.pop()
-            if not currentItem:
-                continue
-            # If the current item *only* has the directory's entry and no stream
-            # entries, we are actually done.
-            # Create a tree and add all the items to it. We add it with a key
-            # that is a tuple of the length (as shorter is *always* less than
-            # longer) and the uppercase name, and the value is the actual entry.
-            tree = RedBlackTree()
-            for name in currentItem:
-                if not name.startswith('::'):
-                    val = currentItem[name]
-                    # If we find a directory entry, then we need to add it to
-                    # the processing list.
-                    if isinstance(val, dict):
-                        toProcess.append((val['::DirectoryEntry'], val))
-                        val = val['::DirectoryEntry']
-
-                    entries.append(val)
-
-                    # Add the data to the tree.
-                    tree.add((len(name), name.upper()), val)
-
-            # Now that everything is added, we need to take our root and add it
-            # as the child of the current entry.
-            entry.childTreeRoot = tree.value
-
-            # Now we need to go through each node and set it's data based on
-            # it's sort position.
-            for node in tree.in_order():
-                item = node.value
-                # Set the color immediately.
-                item.color = Color.BLACK if node.is_black else Color.RED
-
-                if node.left:
-                    item.leftChild = node.left.value
-                else:
-                    item.leftChild = None
-
-                if node.right:
-                    item.rightChild = node.right.value
-                else:
-                    item.rightChild = None
-
-        # Now that everything is connected, we loop over the entries list a few
-        # times and set the data values.
-        for _id, entry in enumerate(entries):
-            entry.id = _id
-
-        for entry in entries:
-            entry.leftSiblingID = entry.leftChild.id if entry.leftChild else 0xFFFFFFFF
-            entry.childID = entry.childTreeRoot.id if entry.childTreeRoot else 0xFFFFFFFF
-            entry.rightSiblingID = entry.rightChild.id if entry.rightChild else 0xFFFFFFFF
-
-        # Finally, let's figure out the sector IDs to be used for the mini data.
-        # We only need to do this for streams with a size less than 4096.
-
-        # Use this to track where the next thing goes in the mini FAT.
-        miniFATLocation = 0
-
-        for entry in entries:
-            if len(entry.data) == 0 and entry != entries[0]:
-                # If there is no data, just set the starting location to none.
-                entry.startingSectorLocation = 0xFFFFFFFE
-            elif entry.type == DirectoryEntryType.STREAM and len(entry.data) < 4096:
-                entry.startingSectorLocation = miniFATLocation
-                miniFATLocation += ceilDiv(len(entry.data), 64)
-
-        return entries
-
-    def _writeBeginning(self, f) -> int:
-        """
-        Writes the beginning to the file :param f:. This includes the header,
-        DIFAT, and FAT blocks.
-
-        :returns: The current sector number after all the data is written.
-        """
-        # Recalculate some things needed for saving.
-        self.__recalculateSectors()
-        # Since we are going to need these multiple times, get them now.
-        numFat, numDifat, totalSectors = self._getFatSectors()
-
-        # Header signature.
-        f.write(b'\xD0\xCF\x11\xE0\xA1\xB1\x1A\xE1')
-        # Header CLSID.
-        f.write(b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00')
-        # Minor version.
-        f.write(b'\x3E\x00')
-        # Major version. For now, we only support version 3.
-        f.write(b'\x03\x00')
-        # Byte order. Specifies that it is little endian.
-        f.write(b'\xFE\xFF')
-        # Sector shift.
-        f.write(b'\x09\x00')
-        # Mini sector shift.
-        f.write(b'\x06\x00')
-        # Reserved.
-        f.write(b'\x00\x00\x00\x00\x00\x00')
-        # Number of directory sectors. Version 3 says this *must* be 0.
-        f.write(constants.ST_LE_UI32.pack(0))
-        # Number of FAT sectors.
-        f.write(constants.ST_LE_UI32.pack(numFat))
-        # First directory sector location (Sector for the directory stream).
-        # We place that right after the DIFAT and FAT.
-        f.write(constants.ST_LE_UI32.pack(numFat + numDifat))
-        # Transation signature number.
-        f.write(b'\x00\x00\x00\x00')
-        # Mini stream cutoff size.
-        f.write(b'\x00\x10\x00\x00')
-        # First mini FAT sector location.
-        f.write(constants.ST_LE_UI32.pack((numFat + numDifat + ceilDiv(self.__dirEntryCount, 4)) if self.__numMinifat > 0 else 0xFFFFFFFE))
-        # Number of mini FAT sectors.
-        f.write(constants.ST_LE_UI32.pack(ceilDiv(self.__numMinifatSectors, 128)))
-        # First DIFAT sector location. If there are none, set to 0xFFFFFFFE (End
-        # of chain).
-        f.write(constants.ST_LE_UI32.pack(0 if numDifat else 0xFFFFFFFE))
-        # Number of DIFAT sectors.
-        f.write(constants.ST_LE_UI32.pack(numDifat))
-
-        # To make life easier on me, I'm having the code start with the DIFAT
-        # followed by the FAT sectors, as I can write them all at once before
-        # writing the actual contents of the file.
-
-        # Write the DIFAT sectors.
-        for x in range(numFat):
-            # This kind of sucks to code, ngl.
-            if x > 109 and (x - 109) % 127 == 0:
-                # If we are at the end of a DIFAT sector, write the jump.
-                f.write(constants.ST_LE_UI32.pack((x - 109) // 127))
-            # Write the next FAT sector location.
-            f.write(constants.ST_LE_UI32.pack(x + numDifat))
-
-        # Finally, fill out the last DIFAT sector with null entries.
-        if numFat > 109:
-            print(numFat)
-            f.write(b'\xFF\xFF\xFF\xFF' * (127 - ((numFat - 109) % 127)))
-            # Finally, make sure to write the end of chain marker for the DIFAT.
-            f.write(b'\xFE\xFF\xFF\xFF')
-        else:
-            f.write(b'\xFF\xFF\xFF\xFF' * (109 - numFat))
-
-        ### FAT.
-
-        # First, if we had any DIFAT sectors, write that the previous sectors
-        # were all a part of it.
-        f.write(b'\xFC\xFF\xFF\xFF' * numDifat)
-        # Second write that the next x sectors are all FAT sectors.
-        f.write(b'\xFD\xFF\xFF\xFF' * numFat)
-
-        offset = numDifat + numFat
-
-        # Fill in the values for the directory stream.
-        for x in range(offset + 1, offset + ceilDiv(self.__dirEntryCount, 4)):
-            f.write(constants.ST_LE_UI32.pack(x))
-
-        # Write the end of chain marker.
-        f.write(b'\xFE\xFF\xFF\xFF')
-
-        offset += ceilDiv(self.__dirEntryCount, 4)
-
-        # Check if we have minifat *at all* first.
-        if self.__numMinifatSectors > 0:
-            # Mini FAT chain.
-            for x in range(offset + 1, offset + ceilDiv(self.__numMinifat, 16)):
-                f.write(constants.ST_LE_UI32.pack(x))
-
-            # Write the end of chain marker.
-            f.write(b'\xFE\xFF\xFF\xFF')
-
-            offset += ceilDiv(self.__numMinifat, 16)
-
-            # The mini stream sectors.
-            for x in range(offset + 1, offset + self.__numMinifat):
-                f.write(constants.ST_LE_UI32.pack(x))
-
-            # Write the end of chain marker.
-            f.write(b'\xFE\xFF\xFF\xFF')
-
-            offset += self.__numMinifat
-
-        # Regular stream chains. These are the most complex to handle. We handle
-        # them by checking a list that was make of entries which were only added
-        # to that list if the size was more than 4096. The order in the list is
-        # how they will eventually be stored into the file correctly.
-        for entry in self.__largeEntries:
-            size = ceilDiv(len(entry.data), 512)
-            entry.startingSectorLocation = offset
-            for x in range(offset + 1, offset + size):
-                f.write(constants.ST_LE_UI32.pack(x))
-
-            # Write the end of chain marker.
-            f.write(b'\xFE\xFF\xFF\xFF')
-
-            offset += size
-
-        # Finally, fill fat with markers to specify no block exists.
-        freeSectors = totalSectors & 0x7F
-        if freeSectors:
-            f.write(b'\xFF\xFF\xFF\xFF' * (128 - freeSectors))
-
-        # Finally, return the current sector index for use in other places.
-        return numDifat + numFat
-
-    def _writeDirectoryEntries(self, f, startingSector : int) -> List[DirectoryEntry]:
-        """
-        Writes out all the directory entries. Returns the list generated.
-        """
-        entries = self._treeSort(startingSector)
-        for x in entries:
-            self._writeDirectoryEntry(f, x)
-        if len(entries) & 3:
-            f.write(((b'\x00\x00' * 34) + (b'\xFF\xFF' * 6) + (b'\x00\x00' * 24)) * (4 - (len(entries) & 3)))
-
-        return entries
-
-    def _writeDirectoryEntry(self, f, entry : DirectoryEntry) -> None:
-        """
-        Writes the directory entry to the file f.
-        """
-        f.write(entry.toBytes())
-
-    def _writeFinal(self, f) -> None:
-        """
-        Writes the final sectors of the file, consisting of the streams too
-        large for the mini FAT.
-        """
-        for x in self.__largeEntries:
-            f.write(x.data)
-            if len(x.data) & 511:
-                f.write(b'\x00' * (512 - (len(x.data) & 511)))
-
-    def _writeMini(self, f, entries : List[DirectoryEntry]) -> None:
-        """
-        Writes the mini FAT followed by the full mini stream.
-        """
-        # For each of the entires that are streams and less than 4096.
-        currentSector = 0
-        for x in entries:
-            if x.type == DirectoryEntryType.STREAM and len(x.data) < 4096:
-                size = ceilDiv(len(x.data), 64)
-                for x in range(currentSector + 1, currentSector + size):
-                    f.write(constants.ST_LE_UI32.pack(x))
-                if size > 0:
-                    f.write(b'\xFE\xFF\xFF\xFF')
-                currentSector += size
-
-        # Finally, write the remaining slots.
-        if currentSector & 127:
-            f.write(b'\xFF\xFF\xFF\xFF' * (128 - (currentSector & 127)))
-
-        # Write the mini stream.
-        for x in entries:
-            if len(x.data) > 0 and len(x.data) < 4096:
-                f.write(x.data)
-                if len(x.data) & 63:
-                    f.write(b'\x00' * (64 - (len(x.data) & 63)))
-
-        # Pad the final mini stream block.
-        if self.__numMinifatSectors & 7:
-            f.write((b'\x00' * 64) * (8 - (self.__numMinifatSectors & 7)))
-
-    def addEntry(self, path, data : bytes = None, storage : bool = False, **kwargs) -> None:
-        """
-        Adds an entry to the OleWriter instance at the path specified, adding
-        storages with default settings where necessary. If the entry is not a
-        storage, :param data: *must* be set.
-
-        :param path: The path to add the entry at. Must not contain a path part
-            that is an already added stream.
-        :param data: The bytes for a stream.
-        :param storage: If True, the entry to add is a storage. Otherwise, the
-            entry is a stream.
-        :param clsid: The CLSID for the stream/storage. Must a a bytes instance
-            that is 16 bytes long.
-        :param creationTime: An 8 byte filetime int. Sets the creation time of
-            the entry. Not applicable to streams.
-        :param modifiedTime: An 8 byte filetime int. Sets the modification time
-            of the entry. Not applicable to streams.
-        :param stateBits: A 4 byte int. Sets the state bits, user-defined flags,
-            of the entry. For a stream, this *SHOULD* be unset.
-
-        :raises OSError: A stream was found on the path before the end.
-        :raises ValueError: Attempts to access an internal item.
-        """
-        path = inputToMsgPath(path)
-        # First, find the current place in our dict to add the item.
-        _dir = self.__getContainingStorage(path, False, True)
-        # Now, check that the item *is not* already in our dict, as that would
-        # cause problems.
-        if path[-1].lower() in map(str.lower, _dir.keys()):
-            raise OSError('Cannot add an entry that already exists.')
-
-        # Create a new entry with basic data and insert it.
-        entry = DirectoryEntry()
-        entry.type = DirectoryEntryType.STORAGE if storage else DirectoryEntryType.STREAM
-        entry.name = path[-1]
-        self.__modifyEntry(entry, data = data, **kwargs)
-        if storage:
-            _dir[path[-1]] = {'::DirectoryEntry': entry}
-        else:
-            _dir[path[-1]] = entry
-
-    def addOleEntry(self, path, entry : OleDirectoryEntry, data : Optional[bytes] = None) -> None:
-        """
-        Uses the entry provided to add the data to the writer.
-
-        :raises OSError: Tried to add an entry to a path that has not yet
-            been added, tried to add as a child of a stream, or tried to add an
-            entry where one already exists under the same name.
-        """
-        path = inputToMsgPath(path)
-        # First, find the current place in our dict to add the item.
-        _dir = self.__getContainingStorage(path, False)
-        # Now, check that the item *is not* already in our dict, as that would
-        # cause problems.
-        if path[-1].lower() in map(str.lower, _dir.keys()):
-            raise OSError('Cannot add an entry that already exists.')
-
-        # Now that we are in the right place, add our data.
-        newEntry = DirectoryEntry()
-        if entry.entry_type == DirectoryEntryType.STORAGE:
-            # Handle a storage entry.
-            # First add the dict to our tree of items.
-            _dir[path[-1]] = {'::DirectoryEntry': newEntry}
-
-            # Finally, setup the values for the stream.
-            newEntry.name = entry.name
-            newEntry.type = DirectoryEntryType.STORAGE
-            newEntry.clsid = _unClsid(entry.clsid)
-            newEntry.stateBits = entry.dwUserFlags
-            newEntry.creationTime = entry.createTime
-            newEntry.modifiedTime = entry.modifyTime
-        else:
-            # Handle a stream entry.
-            # First add the entry to out dict of entries.
-            _dir[path[-1]] = newEntry
-            newEntry.name = entry.name
-            newEntry.type = DirectoryEntryType.STREAM
-            newEntry.clsid = _unClsid(entry.clsid)
-            newEntry.stateBits = entry.dwUserFlags
-
-            # Finally, handle the data.
-            newEntry.data = data or b''
-
-        self.__dirEntryCount += 1
-
-    def deleteEntry(self, path) -> None:
-        """
-        Deletes the entry specified by :param path:, including all children.
-
-        :raises OSError: If the entry does not exist or a part of the path that
-            is not the last was a stream.
-        :raises ValueError: Attempted to delete an internal data stream.
-        """
-        path = inputToMsgPath(path)
-        # Get the containing storage for the entry.
-        _dir = self.__getContainingStorage(path)
-
-        # The garbage collector will take care of all the loose items, so just
-        # remove the entry. Also, once again we deal with the case insensitive
-        # nature of the path. Even though comparisons are case insensitive, the
-        # path does remember the case used.
-        del _dir[dictGetCasedKey(_dir, path[-1])]
-
-    def editEntry(self, path, **kwargs) -> None:
-        """
-        Used to edit values of an entry by setting the specific kwargs. Set a
-        value to something other than None to set it.
-
-        :param data: The data of a stream. Will error if used for something
-            other than a stream.
-        :param clsid: The CLSID for the stream/storage. Must a a bytes instance
-            that is 16 bytes long.
-        :param creationTime: An 8 byte filetime int. Sets the creation time of
-            the entry. Not applicable to streams.
-        :param modifiedTime: An 8 byte filetime int. Sets the modification time
-            of the entry. Not applicable to streams.
-        :param stateBits: A 4 byte int. Sets the state bits, user-defined flags,
-            of the entry. For a stream, this *SHOULD* be unset.
-
-
-        To convert a 32 character hexadecial CLSID into the bytes for this
-        function, the _unClsid function in the ole_writer submodule can be used.
-
-        :raises OSError: The entry does not exist in the file.
-        :raises TypeError: Attempted to modify the bytes of a storage.
-        :raises ValueError: The type of a parameter was wrong, or the data of a
-            parameter was invalid.
-        """
-        # First, find our entry to edit.
-        entry = self.__getEntry(inputToMsgPath(path))
-
-        # Send it to be modified using the arguments given.
-        self.__modifyEntry(entry, **kwargs)
-
-    def fromMsg(self, msg : 'MSGFile') -> None:
-        """
-        Copies the streams and stream information necessary from the MSG file.
-        """
-        # Get the root OLE entry's CLSID.
-        self.__rootEntry.clsid = _unClsid(msg._getOleEntry('/').clsid)
-
-        # List both storages and directories, but sort them by shortest length
-        # first to prevent errors.
-        entries = msg.listDir(True, True, False)
-        entries.sort(key = len)
-
-        for x in entries:
-            entry = msg._getOleEntry(x)
-            data = msg._getStream(x) if entry.entry_type == DirectoryEntryType.STREAM else None
-            # THe properties stream on embedded messages actualy needs to be
-            # transformed a little (*why* it is like that is a mystery to me).
-            # Basically we just need to add a "reserved" section to it in a
-            # specific place. So let's check if we are doing the properties
-            # stream and then if we are embedded.
-            if x[0] == '__properties_version1.0' and msg.prefixLen > 0:
-                data = data[:24] + b'\x00\x00\x00\x00\x00\x00\x00\x00' + data[24:]
-            self.addOleEntry(x, entry, data)
-
-        # Now check if it is an embedded file. If so, we need to copy the named
-        # properties streams (the metadata, not the values).
-        if msg.prefixLen > 0:
-            # Get the entry for the named properties directory and add it
-            # immediately if it exists. If it doesn't exist, this whole
-            # section will be skipped.
-            self.addOleEntry('__nameid_version1.0', msg._getOleEntry('__nameid_version1.0', False), None)
-
-            # Now that we know it exists, grab all the file inside and copy
-            # them to our root.
-            # Create our generator.
-            gen = (x for x in msg._oleListDir() if len(x) > 1 and x[0] == '__nameid_version1.0')
-            for x in gen:
-                self.addOleEntry(x, msg._getOleEntry(x, prefix = False), msg._getStream(x, prefix = False))
-
-    def fromOleFile(self, ole : OleFileIO, rootPath = []) -> None:
-        """
-        Copies all the streams from the proided OLE file into this writer.
-
-        NOTE: This method does *not* handle any special rule that may be
-        required by a format that uses the compound binary file format as a base
-        when extracting an embedded directory. For example, MSG files require
-        modification of an embedded properties stream when extracting an
-        embedded MSG file.
-
-        :param rootPath: A path (accepted by olefile.OleFileIO) to the directory
-            to use as the root of the file. If not provided, the file root will
-            be used.
-
-        :raises OSError: If :param rootPath: does not exist in the file.
-        """
-        rootPath = inputToMsgPath(rootPath)
-
-        # Check if the root path is simply the top of the file.
-        if rootPath == []:
-            # Copy the clsid of the root entry.
-            self.__rootEntry.clsid = _unClsid(ole.direntries[0].clsid)
-            paths = {tuple(x): (x, ole.direntries[ole._find(x)]) for x in ole.listdir(True, True)}
-        else:
-            # If it is not the top of the file, we need to do some filtering.
-            # First get the CLSID from the entry the path points to.
-            try:
-                entry = ole.direntries[ole._find(rootPath)]
-                self.__rootEntry.clsid = _unClsid(entry.clsid)
-
-            except OSError as e:
-                if str(e) == 'file not found':
-                    # Get the cause/context for the original exception and use
-                    # it for the new exception. This hides the exception from
-                    # OleFileIO.
-                    context = e.__cause__ or e.__context__
-                    raise OSError('Root path was not found in the OLE file.') from context
-                else:
-                    raise
-
-            paths = {tuple(x[len(rootPath):]): (x, ole.direntries[ole._find(x)])
-                     for x in ole.listdir(True, True) if len(x) > len(rootPath)}
-
-
-        # Copy all of the other entries. Ensure that directories come before
-        # their streams by sorting the paths.
-        for x in sorted(paths.keys()):
-            fullPath, entry = paths[x]
-
-            if entry.entry_type == DirectoryEntryType.STREAM:
-                with ole.openstream(fullPath) as f:
-                    data = f.read()
-            else:
-                data = None
-
-            self.addOleEntry(x, entry, data)
-
-    def getEntry(self, path) -> DirectoryEntry:
-        """
-        Finds and returns a copy of an existing DirectoryEntry instance in the
-        writer. Use this method to check the internal status of an entry.
-
-        :raises OSError: If the entry does not exist.
-        :raises ValueError: If access to an internal item is attempted.
-        """
-        return copy.copy(self.__getEntry(inputToMsgPath(path)))
-
-    def listItems(self, streams = True, storages = False) -> List[List[str]]:
-        """
-        Returns a list of the specified items currently in the writter.
-
-        :param streams: If True, includes the path for each stream in the list.
-        :param storages: If True, includes the path for each storage in the
-            list.
-        """
-        # We are actually abusing the walk function a bit here to life much
-        # easier. The way we do this is to look at the current directory that
-        # the walk function is giving information about and then deciding what
-        # parts of it we want to use. Once we have all the paths created, we
-        # will then sort and return it to give an output similar, if not
-        # identical, to OleFileIO.listdir. The mentioned method sorts keeping
-        # case in mind.
-        if not streams and not storages:
-            return []
-
-        paths = []
-        for currentDir, stor, stre in self.walk():
-            if storages:
-                for name in stor:
-                    paths.append(currentDir + [name])
-            if streams:
-                for name in stre:
-                    paths.append(currentDir + [name])
-
-        paths.sort()
-        return paths
-
-    def renameEntry(self, path, newName : str) -> None:
-        """
-        Changes the name of an entry, leaving it in it's current position.
-
-        :raises OSError: If the entry does not exist or an entry with the new
-            name already exists,
-        :raises ValueError: If access to an internal item is attempted or the
-            new name provided is invalid.
-        """
-        # First, validate the new name.
-        if not isinstance(newName, str):
-            raise ValueError('New name must be a string.')
-        if constants.RE_INVALID_OLE_PATH.search(newName):
-            raise ValueError('Invalid character(s) in new name. Must not contain the following characters: \\//!:')
-        if len(newName) > 31:
-            raise ValueError('New name must be less than 32 characters.')
-
-        # Get the storage for our entry. Entry *must* exist.
-        _dir = self.__getContainingStorage(inputToMsgPath(path))
-
-        # See if an item in the storage already has that new name.
-        if newName.lower() in map(str.lower, _dir.keys()):
-            raise OSError('An entry with the new name already exists.')
-
-        # Get the original name.
-        originalName = dictGetCasedKey(_dir, path[-1])
-
-        # Get the entry to change.
-        entry = _dir[originalName]
-        if isinstance(entry, dict):
-            dirData = entry
-            entry = entry['::DirectoryEntry']
-        else:
-            dirData = None
-
-        # Change the name on the entry first.
-        entry.name = newName
-
-        # Now, we need to remove the item from the current storage and add it
-        # back with the new name.
-        del _dir[originalName]
-
-        if dirData is None:
-            _dir[newName] = entry
-        else:
-            _dir[newName] = dirData
-
-    def walk(self) -> Iterator[Tuple[List[str], List[str], List[str]]]:
-        """
-        Functional equivelent to :function os.walk:, but for going over the file
-        structure of the OLE file to be written. Unlike :function os.walk:, it
-        takes no arguments.
-
-        :returns: A tuple of three lists. The first is the path, as a list of
-            strings, for the directory (or an empty list for the root), the
-            second is a list of the storages in the current directory, and the
-            last is a list of the streams. Streams and storages are sorted
-            caselessly.
-        """
-        toProcess = [([], self.__dirEntries)]
-
-        # Go through the toProcess list, removing the last item every time to
-        # mimic the behavior of os.walk.
-        while toProcess:
-            currentDir, dirDict = toProcess.pop()
-            storages = []
-            streams = []
-            for name in sorted(dirDict.keys(), key = str.lower):
-                if not name.startswith('::'):
-                    if isinstance(dirDict[name], dict):
-                        storages.append(name)
-                        toProcess.append((currentDir + [name], dirDict[name]))
-                    else:
-                        streams.append(name)
-
-            yield (currentDir, storages, streams)
-
-    def write(self, path) -> None:
-        """
-        Writes the data to the path specified. If :param path: has a write
-        method it will use the object directly.
-        """
-        opened = False
-
-        # First, let's open the file if it is not a writable object.
-        if hasattr(path, 'write') and hasattr(path.write, '__call__'):
-            f = path
-        else:
-            f = open(path, 'wb')
-            opened = True
-
-        # Make sure we close the file after everything, especially if there is
-        # an error.
-        try:
-            # Write each section, transferring data between functions where
-            # necessary.
-            offset = self._writeBeginning(f)
-            entries = self._writeDirectoryEntries(f, offset)
-            self._writeMini(f, entries)
-            self._writeFinal(f)
-        finally:
-            self._cleanupEntries()
-
-            if opened:
-                f.close()
-
-
-
-def _unClsid(clsid : str) -> bytes:
-    """
-    Converts the clsid from olefile.olefile._clsid back to bytes.
-    """
-    if not clsid:
-        return b''
-    clsid = clsid.replace('-', '')
-    try:
-        return bytes((
-            int(clsid[6:8], 16),
-            int(clsid[4:6], 16),
-            int(clsid[2:4], 16),
-            int(clsid[0:2], 16),
-            int(clsid[10:12], 16),
-            int(clsid[8:10], 16),
-            int(clsid[14:16], 16),
-            int(clsid[12:14], 16),
-            int(clsid[16:18], 16),
-            int(clsid[18:20], 16),
-            int(clsid[20:22], 16),
-            int(clsid[22:24], 16),
-            int(clsid[24:26], 16),
-            int(clsid[26:28], 16),
-            int(clsid[28:30], 16),
-            int(clsid[30:32], 16),
-        ))
-    except Exception:
-        raise
+from __future__ import annotations
+
+
+__all__ = [
+    'DirectoryEntry',
+    'OleWriter',
+]
+
+
+import copy
+import re
+
+from typing import Dict, Iterator, List, Optional, Tuple, TYPE_CHECKING
+
+from . import constants
+from .enums import Color, DirectoryEntryType
+from .utils import ceilDiv, dictGetCasedKey, inputToMsgPath
+from olefile.olefile import OleDirectoryEntry, OleFileIO
+from red_black_dict_mod import RedBlackTree
+
+
+# Allow for nice type checking.
+if TYPE_CHECKING:
+    from .msg import MSGFile
+
+
+
+class DirectoryEntry:
+    """
+    An internal representation of a stream or storage in the OleWriter.
+    Originals should be inaccessible outside of the class.
+    """
+    name : str = ''
+    rightChild : 'DirectoryEntry' = None
+    leftChild : 'DirectoryEntry' = None
+    childTreeRoot : 'DirectoryEntry' = None
+    stateBits : int = 0
+    creationTime : int = 0
+    modifiedTime : int = 0
+    type : DirectoryEntryType = DirectoryEntryType.UNALLOCATED
+
+    # These get set after things have been sorted by the red black tree.
+    id : int = -1
+    # This is the ID for the left child. The terminology in the docs is really
+    # annoying.
+    leftSiblingID : int = 0xFFFFFFFF
+    rightSiblingID : int = 0xFFFFFFFF
+    # This is the ID for the root of the child tree, if any.
+    childID : int = 0xFFFFFFFF
+    startingSectorLocation : int = 0
+    color : Color = Color.BLACK
+
+    clsid : bytes = b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
+    data : bytes = b''
+
+    def __init__(self):
+        pass
+
+    def toBytes(self):
+        """
+        Converts the entry to bytes to be writen to a file.
+        """
+        # First write the name and the name length.
+        if len(self.name) > 31:
+            raise ValueError('Name is too long for directory entry.')
+        if len(self.name) < 1:
+            raise ValueError('Directory entry must have a name.')
+        if re.search('/\\\\:!', self.name):
+            raise ValueError('Directory entry name contains an illegal character.')
+
+        nameBytes = self.name.encode('utf-16-le')
+
+        return constants.ST_CF_DIR_ENTRY.pack(
+                                              nameBytes,
+                                              len(nameBytes) + 2,
+                                              self.type,
+                                              self.color,
+                                              self.leftSiblingID,
+                                              self.rightSiblingID,
+                                              self.childID,
+                                              self.clsid,
+                                              self.stateBits,
+                                              self.creationTime,
+                                              self.modifiedTime,
+                                              self.startingSectorLocation,
+                                              getattr(self, 'streamSize', len(self.data)),
+                                             )
+
+
+
+class OleWriter:
+    """
+    Takes data to write to a compound binary format file, as specified in
+    [MS-CFB].
+    """
+    def __init__(self, rootClsid : bytes = constants.DEFAULT_CLSID):
+        self.__rootEntry = DirectoryEntry()
+        self.__rootEntry.name = "Root Entry"
+        self.__rootEntry.type = DirectoryEntryType.ROOT_STORAGE
+        self.__rootEntry.clsid = rootClsid
+        # The root entry will always exist, so this must be at least 1.
+        self.__dirEntryCount = 1
+        self.__dirEntries = {}
+        self.__largeEntries = []
+        self.__largeEntrySectors = 0
+        self.__numMinifatSectors = 0
+
+    def __getContainingStorage(self, path : List[str], entryExists : bool = True, create : bool = False) -> Dict:
+        """
+        Finds the storage dict internally where the entry specified by
+        :param path: would be created. If :param create: is True, missing
+        storages will be created with default settings.
+
+        :param entryExists: If True, throws an error when the requested entry
+            does not yet exist.
+        :param create: If True, creates missing storages with default settings.
+
+        :raises OSError: If :param create: is False and the path could not be
+            found. Also raised if :param entryExists: is True and the requested
+            entry does not exist.
+        :raises ValueError: Tried to access an interal stream or tried to use
+            both the create option and the entryExists option as True.
+
+        :returns: The storage dict that the entry is in.
+        """
+        if not path:
+            raise OSError('Path cannot be empty.')
+
+        # Quick check for incompatability between create and entryExists.
+        if create and entryExists:
+            raise ValueError(':param create: and :param entryExists: cannot both be True (an entry cannot exist if it is being created).')
+
+        # Check that the path is not an internal entry. Given the validation on
+        # paths that most functions should do because of the call to
+        # inputToMsgPath, this shouldn't actually be necessary.
+        if any(x.startswith('::') for x in path):
+            raise ValueError('Found internal name in path.')
+
+        _dir = self.__dirEntries
+
+        for index, name in enumerate(path[:-1]):
+            # If no entry in the current stream matches the path, raise an
+            # OSError, *unless* the option to create storages is True.
+            if name.lower() not in map(str.lower, _dir.keys()):
+                if create:
+                    self.addEntry(path[:index + 1], storage = True)
+                else:
+                    raise OSError(f'Entry not found: {name}')
+            _dir = _dir[dictGetCasedKey(_dir, name)]
+
+            # If the current item is not a storage and we have more to the path,
+            # raise an OSError.
+            if not isinstance(_dir, dict):
+                raise OSError('Attempted to access children of a stream.')
+
+        if entryExists and path[-1].lower() not in map(str.lower, _dir.keys()):
+            raise OSError(f'Entry not found: {path[-1]}')
+
+        return _dir
+
+    def __getEntry(self, path : List[str]) -> DirectoryEntry:
+        """
+        Finds and returns an existing DirectoryEntry instance in the writer.
+
+        :raises OSError: If the entry does not exist.
+        :raises ValueError: If access to an internal item is attempted.
+        """
+        _dir = self.__getContainingStorage(path)
+        item = _dir[dictGetCasedKey(_dir, path[-1])]
+        if isinstance(item, dict):
+            return item['::DirectoryEntry']
+        else:
+            return item
+
+    def __modifyEntry(self, entry : DirectoryEntry, **kwargs):
+        """
+        Edits the DirectoryEntry with the data provided. Common code used for
+        :method addEntry: and :method editEntry:.
+
+        :raises TypeError: Attempted to modify the data of a storage.
+        :raises ValueError: Some part of the data given to modify the various
+            properties was invalid. See the the listed methods for details.
+        """
+        # Extract the arguments.
+        data = kwargs.get('data')
+        clsid = kwargs.get('clsid')
+        creationTime = kwargs.get('creationTime')
+        modifiedTime = kwargs.get('modifiedTime')
+        stateBits = kwargs.get('stateBits')
+
+        # I don't like that I have repeated if statements for checking each of
+        # the arguments, but I need to make sure nothing changes if something is
+        # invalid.
+        if data is not None:
+            if entry.type is not DirectoryEntryType.STREAM:
+                raise TypeError('Cannot set the data of a storage object.')
+            if not isinstance(data, bytes):
+                raise ValueError('Data must be a bytes instance if set.')
+
+        if clsid is not None:
+            if not isinstance(clsid, bytes):
+                raise ValueError('CLSID must be bytes.')
+            if len(clsid) != 16:
+                raise ValueError('CLSID must be 16 bytes.')
+
+        if creationTime is not None:
+            if entry.type is DirectoryEntryType.STREAM:
+                raise ValueError('Modification of creation time cannot be done on a stream.')
+            if not isinstance(creationTime, int) or creationTime < 0 or creationTime > 0xFFFFFFFFFFFFFFFF:
+                raise ValueError('Creation time must be a positive 8 byte int.')
+
+        if modifiedTime is not None:
+            if entry.type is DirectoryEntryType.STREAM:
+                raise ValueError('Modification of modified time cannot be done on a stream.')
+            if not isinstance(modifiedTime, int) or modifiedTime < 0 or modifiedTime > 0xFFFFFFFFFFFFFFFF:
+                raise ValueError('Modified time must be a positive 8 byte int.')
+
+        if stateBits is not None:
+            if not isinstance(stateBits, int) or stateBits < 0 or stateBits > 0xFFFFFFFF:
+                raise ValueError('State bits must be a positive 4 byte int.')
+
+
+        # Now that all our checks have passed, let's set our data.
+        if data is not None:
+            entry.data = data
+        if clsid is not None:
+            entry.clsid = clsid
+        if creationTime is not None:
+            entry.creationTime = creationTime
+        if modifiedTime is not None:
+            entry.modifiedTime = modifiedTime
+        if stateBits is not None:
+            entry.stateBits = stateBits
+
+    def __recalculateSectors(self) -> None:
+        """
+        Recalculates several of the internal variables used for saving that
+        specify the number of sectors and where things should go.
+        """
+        self.__dirEntryCount = 0
+        self.__numMinifatSectors = 0
+        self.__largeEntries.clear()
+        self.__largeEntrySectors = 0
+
+        count = 0
+        for entry in self.__walkEntries():
+            self.__dirEntryCount += 1
+            if entry.type == DirectoryEntryType.STREAM:
+                if len(entry.data) < 4096:
+                    self.__numMinifatSectors += ceilDiv(len(entry.data), 64)
+                else:
+                    self.__largeEntries.append(entry)
+                    self.__largeEntrySectors += ceilDiv(len(entry.data), 512)
+
+    def __walkEntries(self) -> Iterator[DirectoryEntry]:
+        """
+        Returns a generator that will walk the entires recursively. Each item
+        returned by it will be a DirectoryEntry instance.
+        """
+        toProcess = [self.__dirEntries]
+        yield self.__rootEntry
+
+        while len(toProcess) > 0:
+            for name, item in toProcess.pop(0).items():
+                if not name.startswith('::'):
+                    if isinstance(item, dict):
+                        yield item['::DirectoryEntry']
+                        toProcess.append(item)
+                    else:
+                        yield item
+
+    @property
+    def __numberOfSectors(self) -> int:
+        """
+        TODO: finish the calculation needed. For now this just notes how many
+        sectors are needed for the directory entries.
+        """
+        return ceilDiv(self.__dirEntryCount, 4) + \
+               self.__numMinifat + \
+               ceilDiv(self.__numMinifat, 16) + \
+               self.__largeEntrySectors
+
+    @property
+    def __numMinifat(self) -> int:
+        """
+        The number of FAT sectors needed to store the mini FAT.
+        """
+        return ceilDiv(self.__numMinifatSectors, 8)
+
+    def _cleanupEntries(self) -> None:
+        """
+        Cleans up the node connections by walking the tree and removing
+        references that were added during writing.
+        """
+        self.__largeEntries.clear()
+        for entry in self.__walkEntries():
+            entry.id = -1
+            entry.leftChild = None
+            entry.rightChild = None
+            entry.childTreeRoot = None
+            entry.leftSiblingID = 0xFFFFFFFF
+            entry.rightSiblingID = 0xFFFFFFFF
+            entry.childID = 0xFFFFFFFF
+
+    def _getFatSectors(self) -> Tuple[int, int, int]:
+        """
+        Returns a tuple containing the number of FAT sectors, the number of
+        DIFAT sectors, and the total number of sectors the saved file will have.
+        """
+        # Right now we just use an annoying while loop to get the numbers.
+        numDifat = 0
+        # All divisions are ceiling divisions, so we leave them as
+        numFat = ceilDiv(self.__numberOfSectors, 127) or 1
+        newNumFat = 1
+        while numFat != newNumFat:
+            numFat = newNumFat
+            numDifat = ceilDiv(max(numFat - 109, 0), 127)
+            newNumFat = ceilDiv(self.__numberOfSectors + numDifat, 127)
+
+        return (numFat, numDifat, self.__numberOfSectors + numDifat + numFat)
+
+    def _treeSort(self, startingSector : int) -> List[DirectoryEntry]:
+        """
+        Uses red-black trees to sort the internal data in preparation for
+        writing the file, returning a list, in order, of the entries to write.
+        """
+        # First, create the root entry.
+        root = copy.copy(self.__rootEntry)
+
+        # Add the location of the start of the mini stream.
+        root.startingSectorLocation = (startingSector + ceilDiv(self.__dirEntryCount, 4) + ceilDiv(self.__numMinifatSectors, 128)) if self.__numMinifat > 0 else 0xFFFFFFFE
+        root.streamSize = self.__numMinifatSectors * 64
+        root.childTreeRoot = None
+        root.childID = 0xFFFFFFFF
+        entries = [root]
+
+        toProcess = [(root, self.__dirEntries)]
+        # Continue looping while there is more to process.
+        while toProcess:
+            entry, currentItem = toProcess.pop()
+            if not currentItem:
+                continue
+            # If the current item *only* has the directory's entry and no stream
+            # entries, we are actually done.
+            # Create a tree and add all the items to it. We add it with a key
+            # that is a tuple of the length (as shorter is *always* less than
+            # longer) and the uppercase name, and the value is the actual entry.
+            tree = RedBlackTree()
+            for name in currentItem:
+                if not name.startswith('::'):
+                    val = currentItem[name]
+                    # If we find a directory entry, then we need to add it to
+                    # the processing list.
+                    if isinstance(val, dict):
+                        toProcess.append((val['::DirectoryEntry'], val))
+                        val = val['::DirectoryEntry']
+
+                    entries.append(val)
+
+                    # Add the data to the tree.
+                    tree.add((len(name), name.upper()), val)
+
+            # Now that everything is added, we need to take our root and add it
+            # as the child of the current entry.
+            entry.childTreeRoot = tree.value
+
+            # Now we need to go through each node and set it's data based on
+            # it's sort position.
+            for node in tree.in_order():
+                item = node.value
+                # Set the color immediately.
+                item.color = Color.BLACK if node.is_black else Color.RED
+
+                if node.left:
+                    item.leftChild = node.left.value
+                else:
+                    item.leftChild = None
+
+                if node.right:
+                    item.rightChild = node.right.value
+                else:
+                    item.rightChild = None
+
+        # Now that everything is connected, we loop over the entries list a few
+        # times and set the data values.
+        for _id, entry in enumerate(entries):
+            entry.id = _id
+
+        for entry in entries:
+            entry.leftSiblingID = entry.leftChild.id if entry.leftChild else 0xFFFFFFFF
+            entry.childID = entry.childTreeRoot.id if entry.childTreeRoot else 0xFFFFFFFF
+            entry.rightSiblingID = entry.rightChild.id if entry.rightChild else 0xFFFFFFFF
+
+        # Finally, let's figure out the sector IDs to be used for the mini data.
+        # We only need to do this for streams with a size less than 4096.
+
+        # Use this to track where the next thing goes in the mini FAT.
+        miniFATLocation = 0
+
+        for entry in entries:
+            if len(entry.data) == 0 and entry != entries[0]:
+                # If there is no data, just set the starting location to none.
+                entry.startingSectorLocation = 0xFFFFFFFE
+            elif entry.type == DirectoryEntryType.STREAM and len(entry.data) < 4096:
+                entry.startingSectorLocation = miniFATLocation
+                miniFATLocation += ceilDiv(len(entry.data), 64)
+
+        return entries
+
+    def _writeBeginning(self, f) -> int:
+        """
+        Writes the beginning to the file :param f:. This includes the header,
+        DIFAT, and FAT blocks.
+
+        :returns: The current sector number after all the data is written.
+        """
+        # Recalculate some things needed for saving.
+        self.__recalculateSectors()
+        # Since we are going to need these multiple times, get them now.
+        numFat, numDifat, totalSectors = self._getFatSectors()
+
+        # Header signature.
+        f.write(b'\xD0\xCF\x11\xE0\xA1\xB1\x1A\xE1')
+        # Header CLSID.
+        f.write(b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00')
+        # Minor version.
+        f.write(b'\x3E\x00')
+        # Major version. For now, we only support version 3.
+        f.write(b'\x03\x00')
+        # Byte order. Specifies that it is little endian.
+        f.write(b'\xFE\xFF')
+        # Sector shift.
+        f.write(b'\x09\x00')
+        # Mini sector shift.
+        f.write(b'\x06\x00')
+        # Reserved.
+        f.write(b'\x00\x00\x00\x00\x00\x00')
+        # Number of directory sectors. Version 3 says this *must* be 0.
+        f.write(constants.ST_LE_UI32.pack(0))
+        # Number of FAT sectors.
+        f.write(constants.ST_LE_UI32.pack(numFat))
+        # First directory sector location (Sector for the directory stream).
+        # We place that right after the DIFAT and FAT.
+        f.write(constants.ST_LE_UI32.pack(numFat + numDifat))
+        # Transation signature number.
+        f.write(b'\x00\x00\x00\x00')
+        # Mini stream cutoff size.
+        f.write(b'\x00\x10\x00\x00')
+        # First mini FAT sector location.
+        f.write(constants.ST_LE_UI32.pack((numFat + numDifat + ceilDiv(self.__dirEntryCount, 4)) if self.__numMinifat > 0 else 0xFFFFFFFE))
+        # Number of mini FAT sectors.
+        f.write(constants.ST_LE_UI32.pack(ceilDiv(self.__numMinifatSectors, 128)))
+        # First DIFAT sector location. If there are none, set to 0xFFFFFFFE (End
+        # of chain).
+        f.write(constants.ST_LE_UI32.pack(0 if numDifat else 0xFFFFFFFE))
+        # Number of DIFAT sectors.
+        f.write(constants.ST_LE_UI32.pack(numDifat))
+
+        # To make life easier on me, I'm having the code start with the DIFAT
+        # followed by the FAT sectors, as I can write them all at once before
+        # writing the actual contents of the file.
+
+        # Write the DIFAT sectors.
+        for x in range(numFat):
+            # This kind of sucks to code, ngl.
+            if x > 109 and (x - 109) % 127 == 0:
+                # If we are at the end of a DIFAT sector, write the jump.
+                f.write(constants.ST_LE_UI32.pack((x - 109) // 127))
+            # Write the next FAT sector location.
+            f.write(constants.ST_LE_UI32.pack(x + numDifat))
+
+        # Finally, fill out the last DIFAT sector with null entries.
+        if numFat > 109:
+            f.write(b'\xFF\xFF\xFF\xFF' * (127 - ((numFat - 109) % 127)))
+            # Finally, make sure to write the end of chain marker for the DIFAT.
+            f.write(b'\xFE\xFF\xFF\xFF')
+        else:
+            f.write(b'\xFF\xFF\xFF\xFF' * (109 - numFat))
+
+        ### FAT.
+
+        # First, if we had any DIFAT sectors, write that the previous sectors
+        # were all a part of it.
+        f.write(b'\xFC\xFF\xFF\xFF' * numDifat)
+        # Second write that the next x sectors are all FAT sectors.
+        f.write(b'\xFD\xFF\xFF\xFF' * numFat)
+
+        offset = numDifat + numFat
+
+        # Fill in the values for the directory stream.
+        for x in range(offset + 1, offset + ceilDiv(self.__dirEntryCount, 4)):
+            f.write(constants.ST_LE_UI32.pack(x))
+
+        # Write the end of chain marker.
+        f.write(b'\xFE\xFF\xFF\xFF')
+
+        offset += ceilDiv(self.__dirEntryCount, 4)
+
+        # Check if we have minifat *at all* first.
+        if self.__numMinifatSectors > 0:
+            # Mini FAT chain.
+            for x in range(offset + 1, offset + ceilDiv(self.__numMinifat, 16)):
+                f.write(constants.ST_LE_UI32.pack(x))
+
+            # Write the end of chain marker.
+            f.write(b'\xFE\xFF\xFF\xFF')
+
+            offset += ceilDiv(self.__numMinifat, 16)
+
+            # The mini stream sectors.
+            for x in range(offset + 1, offset + self.__numMinifat):
+                f.write(constants.ST_LE_UI32.pack(x))
+
+            # Write the end of chain marker.
+            f.write(b'\xFE\xFF\xFF\xFF')
+
+            offset += self.__numMinifat
+
+        # Regular stream chains. These are the most complex to handle. We handle
+        # them by checking a list that was make of entries which were only added
+        # to that list if the size was more than 4096. The order in the list is
+        # how they will eventually be stored into the file correctly.
+        for entry in self.__largeEntries:
+            size = ceilDiv(len(entry.data), 512)
+            entry.startingSectorLocation = offset
+            for x in range(offset + 1, offset + size):
+                f.write(constants.ST_LE_UI32.pack(x))
+
+            # Write the end of chain marker.
+            f.write(b'\xFE\xFF\xFF\xFF')
+
+            offset += size
+
+        # Finally, fill fat with markers to specify no block exists.
+        freeSectors = totalSectors & 0x7F
+        if freeSectors:
+            f.write(b'\xFF\xFF\xFF\xFF' * (128 - freeSectors))
+
+        # Finally, return the current sector index for use in other places.
+        return numDifat + numFat
+
+    def _writeDirectoryEntries(self, f, startingSector : int) -> List[DirectoryEntry]:
+        """
+        Writes out all the directory entries. Returns the list generated.
+        """
+        entries = self._treeSort(startingSector)
+        for x in entries:
+            self._writeDirectoryEntry(f, x)
+        if len(entries) & 3:
+            f.write(((b'\x00\x00' * 34) + (b'\xFF\xFF' * 6) + (b'\x00\x00' * 24)) * (4 - (len(entries) & 3)))
+
+        return entries
+
+    def _writeDirectoryEntry(self, f, entry : DirectoryEntry) -> None:
+        """
+        Writes the directory entry to the file f.
+        """
+        f.write(entry.toBytes())
+
+    def _writeFinal(self, f) -> None:
+        """
+        Writes the final sectors of the file, consisting of the streams too
+        large for the mini FAT.
+        """
+        for x in self.__largeEntries:
+            f.write(x.data)
+            if len(x.data) & 511:
+                f.write(b'\x00' * (512 - (len(x.data) & 511)))
+
+    def _writeMini(self, f, entries : List[DirectoryEntry]) -> None:
+        """
+        Writes the mini FAT followed by the full mini stream.
+        """
+        # For each of the entires that are streams and less than 4096.
+        currentSector = 0
+        for x in entries:
+            if x.type == DirectoryEntryType.STREAM and len(x.data) < 4096:
+                size = ceilDiv(len(x.data), 64)
+                for x in range(currentSector + 1, currentSector + size):
+                    f.write(constants.ST_LE_UI32.pack(x))
+                if size > 0:
+                    f.write(b'\xFE\xFF\xFF\xFF')
+                currentSector += size
+
+        # Finally, write the remaining slots.
+        if currentSector & 127:
+            f.write(b'\xFF\xFF\xFF\xFF' * (128 - (currentSector & 127)))
+
+        # Write the mini stream.
+        for x in entries:
+            if len(x.data) > 0 and len(x.data) < 4096:
+                f.write(x.data)
+                if len(x.data) & 63:
+                    f.write(b'\x00' * (64 - (len(x.data) & 63)))
+
+        # Pad the final mini stream block.
+        if self.__numMinifatSectors & 7:
+            f.write((b'\x00' * 64) * (8 - (self.__numMinifatSectors & 7)))
+
+    def addEntry(self, path, data : bytes = None, storage : bool = False, **kwargs) -> None:
+        """
+        Adds an entry to the OleWriter instance at the path specified, adding
+        storages with default settings where necessary. If the entry is not a
+        storage, :param data: *must* be set.
+
+        :param path: The path to add the entry at. Must not contain a path part
+            that is an already added stream.
+        :param data: The bytes for a stream.
+        :param storage: If True, the entry to add is a storage. Otherwise, the
+            entry is a stream.
+        :param clsid: The CLSID for the stream/storage. Must a a bytes instance
+            that is 16 bytes long.
+        :param creationTime: An 8 byte filetime int. Sets the creation time of
+            the entry. Not applicable to streams.
+        :param modifiedTime: An 8 byte filetime int. Sets the modification time
+            of the entry. Not applicable to streams.
+        :param stateBits: A 4 byte int. Sets the state bits, user-defined flags,
+            of the entry. For a stream, this *SHOULD* be unset.
+
+        :raises OSError: A stream was found on the path before the end or an entry with the same name already exists.
+        :raises ValueError: Attempts to access an internal item.
+        """
+        path = inputToMsgPath(path)
+        # First, find the current place in our dict to add the item.
+        _dir = self.__getContainingStorage(path, False, True)
+        # Now, check that the item *is not* already in our dict, as that would
+        # cause problems.
+        if path[-1].lower() in map(str.lower, _dir.keys()):
+            raise OSError('Cannot add an entry that already exists.')
+
+        # Create a new entry with basic data and insert it.
+        entry = DirectoryEntry()
+        entry.type = DirectoryEntryType.STORAGE if storage else DirectoryEntryType.STREAM
+        entry.name = path[-1]
+        self.__modifyEntry(entry, data = data, **kwargs)
+        if storage:
+            _dir[path[-1]] = {'::DirectoryEntry': entry}
+        else:
+            _dir[path[-1]] = entry
+
+    def addOleEntry(self, path, entry : OleDirectoryEntry, data : Optional[bytes] = None) -> None:
+        """
+        Uses the entry provided to add the data to the writer.
+
+        :raises OSError: Tried to add an entry to a path that has not yet
+            been added, tried to add as a child of a stream, or tried to add an
+            entry where one already exists under the same name.
+        """
+        path = inputToMsgPath(path)
+        # First, find the current place in our dict to add the item.
+        _dir = self.__getContainingStorage(path, False)
+        # Now, check that the item *is not* already in our dict, as that would
+        # cause problems.
+        if path[-1].lower() in map(str.lower, _dir.keys()):
+            raise OSError('Cannot add an entry that already exists.')
+
+        # Now that we are in the right place, add our data.
+        newEntry = DirectoryEntry()
+        if entry.entry_type == DirectoryEntryType.STORAGE:
+            # Handle a storage entry.
+            # First add the dict to our tree of items.
+            _dir[path[-1]] = {'::DirectoryEntry': newEntry}
+
+            # Finally, setup the values for the stream.
+            newEntry.name = entry.name
+            newEntry.type = DirectoryEntryType.STORAGE
+            newEntry.clsid = _unClsid(entry.clsid)
+            newEntry.stateBits = entry.dwUserFlags
+            newEntry.creationTime = entry.createTime
+            newEntry.modifiedTime = entry.modifyTime
+        else:
+            # Handle a stream entry.
+            # First add the entry to out dict of entries.
+            _dir[path[-1]] = newEntry
+            newEntry.name = entry.name
+            newEntry.type = DirectoryEntryType.STREAM
+            newEntry.clsid = _unClsid(entry.clsid)
+            newEntry.stateBits = entry.dwUserFlags
+
+            # Finally, handle the data.
+            newEntry.data = data or b''
+
+        self.__dirEntryCount += 1
+
+    def deleteEntry(self, path) -> None:
+        """
+        Deletes the entry specified by :param path:, including all children.
+
+        :raises OSError: If the entry does not exist or a part of the path that
+            is not the last was a stream.
+        :raises ValueError: Attempted to delete an internal data stream.
+        """
+        path = inputToMsgPath(path)
+        # Get the containing storage for the entry.
+        _dir = self.__getContainingStorage(path)
+
+        # The garbage collector will take care of all the loose items, so just
+        # remove the entry. Also, once again we deal with the case insensitive
+        # nature of the path. Even though comparisons are case insensitive, the
+        # path does remember the case used.
+        del _dir[dictGetCasedKey(_dir, path[-1])]
+
+    def editEntry(self, path, **kwargs) -> None:
+        """
+        Used to edit values of an entry by setting the specific kwargs. Set a
+        value to something other than None to set it.
+
+        :param data: The data of a stream. Will error if used for something
+            other than a stream.
+        :param clsid: The CLSID for the stream/storage. Must a a bytes instance
+            that is 16 bytes long.
+        :param creationTime: An 8 byte filetime int. Sets the creation time of
+            the entry. Not applicable to streams.
+        :param modifiedTime: An 8 byte filetime int. Sets the modification time
+            of the entry. Not applicable to streams.
+        :param stateBits: A 4 byte int. Sets the state bits, user-defined flags,
+            of the entry. For a stream, this *SHOULD* be unset.
+
+
+        To convert a 32 character hexadecial CLSID into the bytes for this
+        function, the _unClsid function in the ole_writer submodule can be used.
+
+        :raises OSError: The entry does not exist in the file.
+        :raises TypeError: Attempted to modify the bytes of a storage.
+        :raises ValueError: The type of a parameter was wrong, or the data of a
+            parameter was invalid.
+        """
+        # First, find our entry to edit.
+        entry = self.__getEntry(inputToMsgPath(path))
+
+        # Send it to be modified using the arguments given.
+        self.__modifyEntry(entry, **kwargs)
+
+    def fromMsg(self, msg : MSGFile) -> None:
+        """
+        Copies the streams and stream information necessary from the MSG file.
+        """
+        # Get the root OLE entry's CLSID.
+        self.__rootEntry.clsid = _unClsid(msg._getOleEntry('/').clsid)
+
+        # List both storages and directories, but sort them by shortest length
+        # first to prevent errors.
+        entries = msg.listDir(True, True, False)
+        entries.sort(key = len)
+
+        for x in entries:
+            entry = msg._getOleEntry(x)
+            data = msg._getStream(x) if entry.entry_type == DirectoryEntryType.STREAM else None
+            # THe properties stream on embedded messages actualy needs to be
+            # transformed a little (*why* it is like that is a mystery to me).
+            # Basically we just need to add a "reserved" section to it in a
+            # specific place. So let's check if we are doing the properties
+            # stream and then if we are embedded.
+            if x[0] == '__properties_version1.0' and msg.prefixLen > 0:
+                data = data[:24] + b'\x00\x00\x00\x00\x00\x00\x00\x00' + data[24:]
+            self.addOleEntry(x, entry, data)
+
+        # Now check if it is an embedded file. If so, we need to copy the named
+        # properties streams (the metadata, not the values).
+        if msg.prefixLen > 0:
+            # Get the entry for the named properties directory and add it
+            # immediately if it exists. If it doesn't exist, this whole
+            # section will be skipped.
+            self.addOleEntry('__nameid_version1.0', msg._getOleEntry('__nameid_version1.0', False), None)
+
+            # Now that we know it exists, grab all the file inside and copy
+            # them to our root.
+            # Create our generator.
+            gen = (x for x in msg._oleListDir() if len(x) > 1 and x[0] == '__nameid_version1.0')
+            for x in gen:
+                self.addOleEntry(x, msg._getOleEntry(x, prefix = False), msg._getStream(x, prefix = False))
+
+    def fromOleFile(self, ole : OleFileIO, rootPath = []) -> None:
+        """
+        Copies all the streams from the proided OLE file into this writer.
+
+        NOTE: This method does *not* handle any special rule that may be
+        required by a format that uses the compound binary file format as a base
+        when extracting an embedded directory. For example, MSG files require
+        modification of an embedded properties stream when extracting an
+        embedded MSG file.
+
+        :param rootPath: A path (accepted by olefile.OleFileIO) to the directory
+            to use as the root of the file. If not provided, the file root will
+            be used.
+
+        :raises OSError: If :param rootPath: does not exist in the file.
+        """
+        rootPath = inputToMsgPath(rootPath)
+
+        # Check if the root path is simply the top of the file.
+        if rootPath == []:
+            # Copy the clsid of the root entry.
+            self.__rootEntry.clsid = _unClsid(ole.direntries[0].clsid)
+            paths = {tuple(x): (x, ole.direntries[ole._find(x)]) for x in ole.listdir(True, True)}
+        else:
+            # If it is not the top of the file, we need to do some filtering.
+            # First get the CLSID from the entry the path points to.
+            try:
+                entry = ole.direntries[ole._find(rootPath)]
+                self.__rootEntry.clsid = _unClsid(entry.clsid)
+
+            except OSError as e:
+                if str(e) == 'file not found':
+                    # Get the cause/context for the original exception and use
+                    # it for the new exception. This hides the exception from
+                    # OleFileIO.
+                    context = e.__cause__ or e.__context__
+                    raise OSError('Root path was not found in the OLE file.') from context
+                else:
+                    raise
+
+            paths = {tuple(x[len(rootPath):]): (x, ole.direntries[ole._find(x)])
+                     for x in ole.listdir(True, True) if len(x) > len(rootPath)}
+
+
+        # Copy all of the other entries. Ensure that directories come before
+        # their streams by sorting the paths.
+        for x in sorted(paths.keys()):
+            fullPath, entry = paths[x]
+
+            if entry.entry_type == DirectoryEntryType.STREAM:
+                with ole.openstream(fullPath) as f:
+                    data = f.read()
+            else:
+                data = None
+
+            self.addOleEntry(x, entry, data)
+
+    def getEntry(self, path) -> DirectoryEntry:
+        """
+        Finds and returns a copy of an existing DirectoryEntry instance in the
+        writer. Use this method to check the internal status of an entry.
+
+        :raises OSError: If the entry does not exist.
+        :raises ValueError: If access to an internal item is attempted.
+        """
+        return copy.copy(self.__getEntry(inputToMsgPath(path)))
+
+    def listItems(self, streams = True, storages = False) -> List[List[str]]:
+        """
+        Returns a list of the specified items currently in the writter.
+
+        :param streams: If True, includes the path for each stream in the list.
+        :param storages: If True, includes the path for each storage in the
+            list.
+        """
+        # We are actually abusing the walk function a bit here to life much
+        # easier. The way we do this is to look at the current directory that
+        # the walk function is giving information about and then deciding what
+        # parts of it we want to use. Once we have all the paths created, we
+        # will then sort and return it to give an output similar, if not
+        # identical, to OleFileIO.listdir. The mentioned method sorts keeping
+        # case in mind.
+        if not streams and not storages:
+            return []
+
+        paths = []
+        for currentDir, stor, stre in self.walk():
+            if storages:
+                for name in stor:
+                    paths.append(currentDir + [name])
+            if streams:
+                for name in stre:
+                    paths.append(currentDir + [name])
+
+        paths.sort()
+        return paths
+
+    def renameEntry(self, path, newName : str) -> None:
+        """
+        Changes the name of an entry, leaving it in it's current position.
+
+        :raises OSError: If the entry does not exist or an entry with the new
+            name already exists,
+        :raises ValueError: If access to an internal item is attempted or the
+            new name provided is invalid.
+        """
+        # First, validate the new name.
+        if not isinstance(newName, str):
+            raise ValueError('New name must be a string.')
+        if constants.RE_INVALID_OLE_PATH.search(newName):
+            raise ValueError('Invalid character(s) in new name. Must not contain the following characters: \\//!:')
+        if len(newName) > 31:
+            raise ValueError('New name must be less than 32 characters.')
+
+        # Get the storage for our entry. Entry *must* exist.
+        _dir = self.__getContainingStorage(inputToMsgPath(path))
+
+        # See if an item in the storage already has that new name.
+        if newName.lower() in map(str.lower, _dir.keys()):
+            raise OSError('An entry with the new name already exists.')
+
+        # Get the original name.
+        originalName = dictGetCasedKey(_dir, path[-1])
+
+        # Get the entry to change.
+        entry = _dir[originalName]
+        if isinstance(entry, dict):
+            dirData = entry
+            entry = entry['::DirectoryEntry']
+        else:
+            dirData = None
+
+        # Change the name on the entry first.
+        entry.name = newName
+
+        # Now, we need to remove the item from the current storage and add it
+        # back with the new name.
+        del _dir[originalName]
+
+        if dirData is None:
+            _dir[newName] = entry
+        else:
+            _dir[newName] = dirData
+
+    def walk(self) -> Iterator[Tuple[List[str], List[str], List[str]]]:
+        """
+        Functional equivelent to :function os.walk:, but for going over the file
+        structure of the OLE file to be written. Unlike :function os.walk:, it
+        takes no arguments.
+
+        :returns: A tuple of three lists. The first is the path, as a list of
+            strings, for the directory (or an empty list for the root), the
+            second is a list of the storages in the current directory, and the
+            last is a list of the streams. Streams and storages are sorted
+            caselessly.
+        """
+        toProcess = [([], self.__dirEntries)]
+
+        # Go through the toProcess list, removing the last item every time to
+        # mimic the behavior of os.walk.
+        while toProcess:
+            currentDir, dirDict = toProcess.pop()
+            storages = []
+            streams = []
+            for name in sorted(dirDict.keys(), key = str.lower):
+                if not name.startswith('::'):
+                    if isinstance(dirDict[name], dict):
+                        storages.append(name)
+                        toProcess.append((currentDir + [name], dirDict[name]))
+                    else:
+                        streams.append(name)
+
+            yield (currentDir, storages, streams)
+
+    def write(self, path) -> None:
+        """
+        Writes the data to the path specified. If :param path: has a write
+        method it will use the object directly.
+        """
+        opened = False
+
+        # First, let's open the file if it is not a writable object.
+        if hasattr(path, 'write') and hasattr(path.write, '__call__'):
+            f = path
+        else:
+            f = open(path, 'wb')
+            opened = True
+
+        # Make sure we close the file after everything, especially if there is
+        # an error.
+        try:
+            # Write each section, transferring data between functions where
+            # necessary.
+            offset = self._writeBeginning(f)
+            entries = self._writeDirectoryEntries(f, offset)
+            self._writeMini(f, entries)
+            self._writeFinal(f)
+        finally:
+            self._cleanupEntries()
+
+            if opened:
+                f.close()
+
+
+
+def _unClsid(clsid : str) -> bytes:
+    """
+    Converts the clsid from olefile.olefile._clsid back to bytes.
+    """
+    if not clsid:
+        return b''
+    clsid = clsid.replace('-', '')
+    try:
+        return bytes((
+            int(clsid[6:8], 16),
+            int(clsid[4:6], 16),
+            int(clsid[2:4], 16),
+            int(clsid[0:2], 16),
+            int(clsid[10:12], 16),
+            int(clsid[8:10], 16),
+            int(clsid[14:16], 16),
+            int(clsid[12:14], 16),
+            int(clsid[16:18], 16),
+            int(clsid[18:20], 16),
+            int(clsid[20:22], 16),
+            int(clsid[22:24], 16),
+            int(clsid[24:26], 16),
+            int(clsid[26:28], 16),
+            int(clsid[28:30], 16),
+            int(clsid[30:32], 16),
+        ))
+    except Exception:
+        raise
```

### Comparing `extract_msg-0.40.0/extract_msg/post.py` & `extract_msg-0.41.0/extract_msg/post.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,68 +1,77 @@
-from typing import Optional
-
-from . import constants
-from .message_base import MessageBase
-from .utils import inputToBytes, inputToString
-
-
-class Post(MessageBase):
-    """
-    Class for parsing Post messages.
-    """
-
-    def getJson(self) -> str:
-        """
-        Returns the JSON representation of the Post.
-        """
-        return json.dumps({
-            'from': inputToString(self.sender, self.stringEncoding),
-            'subject': inputToString(self.subject, self.stringEncoding),
-            'date': inputToString(self.date, self.stringEncoding),
-            'conversation': inputTostring(self.conversation, self.stringEncoding),
-            'body': decode_utf7(self.body),
-        })
-
-    @property
-    def conversation(self) -> Optional[str]:
-        """
-        The name of the conversation being posted to.
-        """
-        return self._ensureSet('_convo', '__substg1.0_0070')
-
-    @property
-    def headerFormatProperties(self) -> constants.HEADER_FORMAT_TYPE:
-        """
-        Returns a dictionary of properties, in order, to be formatted into the
-        header. Keys are the names to use in the header while the values are one
-        of the following:
-        None: Signifies no data was found for the property and it should be
-            omitted from the header.
-        str: A string to be formatted into the header using the string encoding.
-        Tuple[Union[str, None], bool]: A string should be formatted into the
-            header. If the bool is True, then place an empty string if the value
-            is None, otherwise follow the same behavior as regular None.
-
-        Additional note: If the value is an empty string, it will be dropped as
-        well by default.
-
-        Additionally you can group members of a header together by placing them
-        in an embedded dictionary. Groups will be spaced out using a second
-        instance of the join string. If any member of a group is being printed,
-        it will be spaced apart from the next group/item.
-
-        If you class should not do *any* header injection, return None from this
-        property.
-        """
-        return {
-            '-main details-': {
-                'From': self.sender,
-                'Posted At': self.date,
-                'Conversation': self.conversation,
-            },
-            '-subject-': {
-                'Subject': self.subject,
-            },
-            '-importance-': {
-                'Importance': self.importanceString,
-            },
-        }
+__all__ = [
+    'Post',
+]
+
+
+import json
+
+from typing import Optional
+
+from . import constants
+from .message_base import MessageBase
+from .utils import inputToString
+
+from imapclient.imapclient import decode_utf7
+
+
+class Post(MessageBase):
+    """
+    Class for parsing Post messages.
+    """
+
+    def getJson(self) -> str:
+        """
+        Returns the JSON representation of the Post.
+        """
+        return json.dumps({
+            'from': inputToString(self.sender, self.stringEncoding),
+            'subject': inputToString(self.subject, self.stringEncoding),
+            'date': inputToString(self.date, self.stringEncoding),
+            'conversation': inputToString(self.conversation, self.stringEncoding),
+            'body': decode_utf7(self.body),
+        })
+
+    @property
+    def conversation(self) -> Optional[str]:
+        """
+        The name of the conversation being posted to.
+        """
+        return self._ensureSet('_convo', '__substg1.0_0070')
+
+    @property
+    def headerFormatProperties(self) -> constants.HEADER_FORMAT_TYPE:
+        """
+        Returns a dictionary of properties, in order, to be formatted into the
+        header. Keys are the names to use in the header while the values are one
+        of the following:
+        None: Signifies no data was found for the property and it should be
+            omitted from the header.
+        str: A string to be formatted into the header using the string encoding.
+        Tuple[Union[str, None], bool]: A string should be formatted into the
+            header. If the bool is True, then place an empty string if the value
+            is None, otherwise follow the same behavior as regular None.
+
+        Additional note: If the value is an empty string, it will be dropped as
+        well by default.
+
+        Additionally you can group members of a header together by placing them
+        in an embedded dictionary. Groups will be spaced out using a second
+        instance of the join string. If any member of a group is being printed,
+        it will be spaced apart from the next group/item.
+
+        If you class should not do *any* header injection, return None from this
+        property.
+        """
+        return {
+            '-main details-': {
+                'From': self.sender,
+                'Posted At': self.date,
+                'Conversation': self.conversation,
+            },
+            '-subject-': {
+                'Subject': self.subject,
+            },
+            '-importance-': {
+                'Importance': self.importanceString,
+            },
+        }
```

### Comparing `extract_msg-0.40.0/extract_msg/prop.py` & `extract_msg-0.41.0/extract_msg/prop.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,213 +1,222 @@
-import datetime
-import logging
-
-import olefile
-
-from typing import Any
-
-from . import constants
-from .enums import ErrorCode, ErrorCodeType
-from .utils import filetimeToDatetime, properHex
-
-
-logger = logging.getLogger(__name__)
-logger.addHandler(logging.NullHandler())
-
-
-def createProp(data : bytes) -> 'PropBase':
-    temp = constants.ST2.unpack(data)[0]
-    if temp in constants.FIXED_LENGTH_PROPS:
-        return FixedLengthProp(data)
-    else:
-        if temp not in constants.VARIABLE_LENGTH_PROPS:
-            # DEBUG
-            logger.warning(f'Unknown property type: {properHex(temp)}')
-        return VariableLengthProp(data)
-
-
-class PropBase:
-    """
-    Base class for Prop instances.
-    """
-
-    def __init__(self, data : bytes):
-        self.__rawData = data
-        self.__name = properHex(data[3::-1]).upper()
-        self.__type, self.__flags = constants.ST2.unpack(data)
-        self.__fm = self.__flags & 1 == 1
-        self.__fr = self.__flags & 2 == 2
-        self.__fw = self.__flags & 4 == 4
-
-    @property
-    def flagMandatory(self) -> bool:
-        """
-        Boolean, is the "mandatory" flag set?
-        """
-        return self.__fm
-
-    @property
-    def flagReadable(self) -> bool:
-        """
-        Boolean, is the "readable" flag set?
-        """
-        return self.__fr
-
-    @property
-    def flagWritable(self) -> bool:
-        """
-        Boolean, is the "writable" flag set?
-        """
-        return self.__fw
-
-    @property
-    def flags(self) -> int:
-        """
-        Integer that contains property flags.
-        """
-        return self.__flags
-
-    @property
-    def name(self) -> str:
-        """
-        Property "name".
-        """
-        return self.__name
-
-    @property
-    def rawData(self) -> bytes:
-        """
-        The raw bytes used to create this object.
-        """
-        return self.__raw
-
-    @property
-    def type(self) -> int:
-        """
-        The type of property.
-        """
-        return self.__type
-
-
-class FixedLengthProp(PropBase):
-    """
-    Class to contain the data for a single fixed length property.
-
-    Currently a work in progress.
-    """
-
-    def __init__(self, data : bytes):
-        super().__init__(data)
-        self.__value = self.parseType(self.type, constants.STFIX.unpack(data)[0])
-
-    def parseType(self, _type : int, stream : bytes) -> Any:
-        """
-        Converts the data in :param stream: to a much more accurate type,
-        specified by :param _type:, if possible.
-        :param stream: The data that the value is extracted from.
-
-        WARNING: Not done.
-        """
-        # WARNING Not done.
-        value = stream
-        if _type == 0x0000: # PtypUnspecified
-            pass
-        elif _type == 0x0001: # PtypNull
-            if value != b'\x00\x00\x00\x00\x00\x00\x00\x00':
-                # DEBUG.
-                logger.warning('Property type is PtypNull, but is not equal to 0.')
-            value = None
-        elif _type == 0x0002: # PtypInteger16
-            value = constants.STI16.unpack(value)[0]
-        elif _type == 0x0003: # PtypInteger32
-            value = constants.STI32.unpack(value)[0]
-        elif _type == 0x0004: # PtypFloating32
-            value = constants.STF32.unpack(value)[0]
-        elif _type == 0x0005: # PtypFloating64
-            value = constants.STF64.unpack(value)[0]
-        elif _type == 0x0006: # PtypCurrency
-            value = (constants.STI64.unpack(value))[0] / 10000.0
-        elif _type == 0x0007: # PtypFloatingTime
-            value = constants.STF64.unpack(value)[0]
-            return constants.PYTPFLOATINGTIME_START + datetime.timedelta(days = value)
-        elif _type == 0x000A: # PtypErrorCode
-            value = constants.STI32.unpack(value)[0]
-            try:
-                value = ErrorCodeType(value)
-            except ValueError:
-                logger.warning(f'Error type found that was not from Additional Error Codes. Value was {value}. You should report this to the developers.')
-                # So here, the value should be from Additional Error Codes, but it
-                # wasn't. So we are just returning the int. However, we want to see
-                # if it is a normal error type.
-                try:
-                    logger.warning(f'REPORT TO DEVELOPERS: Error type of {ErrorType(value)} was found.')
-                except ValueError:
-                    pass
-        elif _type == 0x000B:  # PtypBoolean
-            value = constants.ST3.unpack(value)[0] == 1
-        elif _type == 0x0014:  # PtypInteger64
-            value = constants.STI64.unpack(value)[0]
-        elif _type == 0x0040:  # PtypTime
-            rawTime = constants.ST3.unpack(value)[0]
-            try:
-                value = filetimeToDatetime(rawTime)
-            except ValueError as e:
-                logger.exception(e)
-                logger.error(self.raw)
-        elif _type == 0x0048:  # PtypGuid
-            # TODO parsing for this
-            pass
-        return value
-
-    @property
-    def value(self) -> Any:
-        """
-        Property value.
-        """
-        return self.__value
-
-
-class VariableLengthProp(PropBase):
-    """
-    Class to contain the data for a single variable length property.
-    """
-
-    def __init__(self, data : bytes):
-        super().__init__(data)
-        self.__length, self.__reserved = constants.STVAR.unpack(data)
-        if self.type == 0x001E:
-            self.__realLength = self.__length - 1
-        elif self.type == 0x001F:
-            self.__realLength = self.__length - 2
-        elif self.type in constants.MULTIPLE_2_BYTES_HEX:
-            self.__realLength = self.__length // 2
-        elif self.type in constants.MULTIPLE_4_BYTES_HEX:
-            self.__realLength = self.__length // 4
-        elif self.type in constants.MULTIPLE_8_BYTES_HEX:
-            self.__realLength = self.__length // 8
-        elif self.type in constants.MULTIPLE_16_BYTES_HEX:
-            self.__realLength = self.__length // 16
-        elif self.type == 0x000D:
-            self.__realLength = None
-        else:
-            self.__realLength = self.__length
-
-    @property
-    def length(self) -> int:
-        """
-        The length field of the variable length property.
-        """
-        return self.__length
-
-    @property
-    def realLength(self) -> int:
-        """
-        The ACTUAL length of the stream that this property corresponds to.
-        """
-        return self.__realLength
-
-    @property
-    def reservedFlags(self) -> int:
-        """
-        The reserved flags field of the variable length property.
-        """
-        return self.__reserved
+__all__ = [
+    # Classes.
+    'FixedLengthProp'
+    'PropBase',
+    'VariableLengthProp',
+
+    # Functions.
+    'createProp',
+]
+
+
+import datetime
+import logging
+
+from typing import Any
+
+from . import constants
+from .enums import ErrorCode, ErrorCodeType
+from .utils import filetimeToDatetime, properHex
+
+
+logger = logging.getLogger(__name__)
+logger.addHandler(logging.NullHandler())
+
+
+def createProp(data : bytes) -> 'PropBase':
+    temp = constants.ST2.unpack(data)[0]
+    if temp in constants.FIXED_LENGTH_PROPS:
+        return FixedLengthProp(data)
+    else:
+        if temp not in constants.VARIABLE_LENGTH_PROPS:
+            # DEBUG
+            logger.warning(f'Unknown property type: {properHex(temp)}')
+        return VariableLengthProp(data)
+
+
+class PropBase:
+    """
+    Base class for Prop instances.
+    """
+
+    def __init__(self, data : bytes):
+        self.__rawData = data
+        self.__name = properHex(data[3::-1]).upper()
+        self.__type, self.__flags = constants.ST2.unpack(data)
+        self.__fm = self.__flags & 1 == 1
+        self.__fr = self.__flags & 2 == 2
+        self.__fw = self.__flags & 4 == 4
+
+    @property
+    def flagMandatory(self) -> bool:
+        """
+        Boolean, is the "mandatory" flag set?
+        """
+        return self.__fm
+
+    @property
+    def flagReadable(self) -> bool:
+        """
+        Boolean, is the "readable" flag set?
+        """
+        return self.__fr
+
+    @property
+    def flagWritable(self) -> bool:
+        """
+        Boolean, is the "writable" flag set?
+        """
+        return self.__fw
+
+    @property
+    def flags(self) -> int:
+        """
+        Integer that contains property flags.
+        """
+        return self.__flags
+
+    @property
+    def name(self) -> str:
+        """
+        Property "name".
+        """
+        return self.__name
+
+    @property
+    def rawData(self) -> bytes:
+        """
+        The raw bytes used to create this object.
+        """
+        return self.__rawData
+
+    @property
+    def type(self) -> int:
+        """
+        The type of property.
+        """
+        return self.__type
+
+
+class FixedLengthProp(PropBase):
+    """
+    Class to contain the data for a single fixed length property.
+
+    Currently a work in progress.
+    """
+
+    def __init__(self, data : bytes):
+        super().__init__(data)
+        self.__value = self.parseType(self.type, constants.STFIX.unpack(data)[0])
+
+    def parseType(self, _type : int, stream : bytes) -> Any:
+        """
+        Converts the data in :param stream: to a much more accurate type,
+        specified by :param _type:, if possible.
+        :param stream: The data that the value is extracted from.
+
+        WARNING: Not done.
+        """
+        # WARNING Not done.
+        value = stream
+        if _type == 0x0000: # PtypUnspecified
+            pass
+        elif _type == 0x0001: # PtypNull
+            if value != b'\x00\x00\x00\x00\x00\x00\x00\x00':
+                # DEBUG.
+                logger.warning('Property type is PtypNull, but is not equal to 0.')
+            value = None
+        elif _type == 0x0002: # PtypInteger16
+            value = constants.STI16.unpack(value)[0]
+        elif _type == 0x0003: # PtypInteger32
+            value = constants.STI32.unpack(value)[0]
+        elif _type == 0x0004: # PtypFloating32
+            value = constants.STF32.unpack(value)[0]
+        elif _type == 0x0005: # PtypFloating64
+            value = constants.STF64.unpack(value)[0]
+        elif _type == 0x0006: # PtypCurrency
+            value = (constants.STI64.unpack(value))[0] / 10000.0
+        elif _type == 0x0007: # PtypFloatingTime
+            value = constants.STF64.unpack(value)[0]
+            return constants.PYTPFLOATINGTIME_START + datetime.timedelta(days = value)
+        elif _type == 0x000A: # PtypErrorCode
+            value = constants.STI32.unpack(value)[0]
+            try:
+                value = ErrorCodeType(value)
+            except ValueError:
+                logger.warning(f'Error type found that was not from Additional Error Codes. Value was {value}. You should report this to the developers.')
+                # So here, the value should be from Additional Error Codes, but
+                # it wasn't. So we are just returning the int. However, we want
+                # to see if it is a normal error code.
+                try:
+                    logger.warning(f'REPORT TO DEVELOPERS: Error type of {ErrorCode(value)} was found.')
+                except ValueError:
+                    pass
+        elif _type == 0x000B:  # PtypBoolean
+            value = constants.ST3.unpack(value)[0] == 1
+        elif _type == 0x0014:  # PtypInteger64
+            value = constants.STI64.unpack(value)[0]
+        elif _type == 0x0040:  # PtypTime
+            rawTime = constants.ST3.unpack(value)[0]
+            try:
+                value = filetimeToDatetime(rawTime)
+            except ValueError as e:
+                logger.exception(e)
+                logger.error(self.rawData)
+        elif _type == 0x0048:  # PtypGuid
+            # TODO parsing for this
+            pass
+        return value
+
+    @property
+    def value(self) -> Any:
+        """
+        Property value.
+        """
+        return self.__value
+
+
+class VariableLengthProp(PropBase):
+    """
+    Class to contain the data for a single variable length property.
+    """
+
+    def __init__(self, data : bytes):
+        super().__init__(data)
+        self.__length, self.__reserved = constants.STVAR.unpack(data)
+        if self.type == 0x001E:
+            self.__realLength = self.__length - 1
+        elif self.type == 0x001F:
+            self.__realLength = self.__length - 2
+        elif self.type in constants.MULTIPLE_2_BYTES_HEX:
+            self.__realLength = self.__length // 2
+        elif self.type in constants.MULTIPLE_4_BYTES_HEX:
+            self.__realLength = self.__length // 4
+        elif self.type in constants.MULTIPLE_8_BYTES_HEX:
+            self.__realLength = self.__length // 8
+        elif self.type in constants.MULTIPLE_16_BYTES_HEX:
+            self.__realLength = self.__length // 16
+        elif self.type == 0x000D:
+            self.__realLength = None
+        else:
+            self.__realLength = self.__length
+
+    @property
+    def length(self) -> int:
+        """
+        The length field of the variable length property.
+        """
+        return self.__length
+
+    @property
+    def realLength(self) -> int:
+        """
+        The ACTUAL length of the stream that this property corresponds to.
+        """
+        return self.__realLength
+
+    @property
+    def reservedFlags(self) -> int:
+        """
+        The reserved flags field of the variable length property.
+        """
+        return self.__reserved
```

### Comparing `extract_msg-0.40.0/extract_msg/properties.py` & `extract_msg-0.41.0/extract_msg/properties.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,219 +1,229 @@
-import copy
-import datetime
-import logging
-import pprint
-
-from typing import Any, Dict, Optional, Union
-
-from . import constants
-from .enums import Intelligence, PropertiesType
-from .prop import createProp, PropBase
-from .utils import divide, properHex
-
-
-logger = logging.getLogger(__name__)
-logger.addHandler(logging.NullHandler())
-
-
-class Properties:
-    """
-    Parser for msg properties files.
-    """
-
-    def __init__(self, data : bytes, _type : Optional[PropertiesType] = None, skip : Optional[int] = None):
-        if not isinstance(data, bytes):
-            raise TypeError(':param data: MUST be bytes.')
-        self.__rawData = data
-        self.__pos = 0
-        self.__len = len(data)
-        self.__props = {}
-        self.__naid = None
-        self.__nrid = None
-        self.__ac = None
-        self.__rc = None
-        # Handle an empty properties stream.
-        if self.__len == 0:
-            self.__intel = Intelligence.ERROR
-            skip = 0
-        elif _type is not None:
-                _type = PropertiesType(_type)
-                self.__intel = Intelligence.SMART
-                if _type == PropertiesType.MESSAGE:
-                    skip = 32
-                    self.__nrid, self.__naid, self.__rc, self.__ac = constants.ST1.unpack(self.__rawData[:24])
-                elif _type == PropertiesType.MESSAGE_EMBED:
-                    skip = 24
-                    self.__nrid, self.__naid, self.__rc, self.__ac = constants.ST1.unpack(self.__rawData[:24])
-                else:
-                    skip = 8
-        else:
-            self.__intel = Intelligence.DUMB
-            if skip is None:
-                # This section of the skip handling is not very good. While it
-                # does work, it is likely to create extra properties that are
-                # created from the properties file's header data. While that
-                # won't actually mess anything up, it is far from ideal.
-                # Basically, this is the dumb skip length calculation.
-                # Preferably, we want the type to have been specified so all of
-                # the additional fields will have been filled out.
-                #
-                # If the skip would end up at 0, set it to 32.
-                skip = (self.__len % 16) or 32
-        streams = divide(self.__rawData[skip:], 16)
-        for st in streams:
-            if len(st) == 16:
-                prop = createProp(st)
-                self.__props[prop.name] = prop
-            else:
-                logger.warning(f'Found stream from divide that was not 16 bytes: {st}. Ignoring.')
-        self.__pl = len(self.__props)
-
-    def __contains__(self, key) -> bool:
-        self.__props.__contains__(key)
-
-    def __getitem__(self, key):
-        return self.__props.__getitem__(key)
-
-    def __iter__(self):
-        return self.__props.__iter__()
-
-    def __len__(self) -> int:
-        """
-        Returns the number of properties.
-        """
-        return self.__pl
-
-    def __repr__(self) -> str:
-        return self.__props.__repr__()
-
-    def get(self, name, default = None) -> Optional[Union[PropBase, Any]]:
-        """
-        Retrieve the property of :param name:. Returns the value of
-        :param default: if the property could not be found.
-        """
-        try:
-            return self.__props[name]
-        except KeyError:
-            # DEBUG
-            logger.debug('KeyError exception.')
-            logger.debug(properHex(self.__rawData))
-            logger.debug(self.__props)
-            return default
-
-    def has_key(self, key) -> bool:
-        """
-        Checks if :param key: is a key in the properties dictionary.
-        """
-        return key in self.__props
-
-    def items(self):
-        return self.__props.items()
-
-    def keys(self):
-        return self.__props.keys()
-
-    def pprintKeys(self) -> None:
-        """
-        Uses the pprint function on a sorted list of keys.
-        """
-        pprint.pprint(sorted(tuple(self.__props.keys())))
-
-    def values(self):
-        return self.__props.values()
-
-    items.__doc__ = dict.items.__doc__
-    keys.__doc__ = dict.keys.__doc__
-    values.__doc__ = dict.values.__doc__
-
-    @property
-    def attachmentCount(self) -> int:
-        """
-        The number of Attachment objects for the MSGFile object.
-
-        :raises TypeError: The Properties instance is not for an MSGFile object.
-        """
-        if self.__ac is None:
-            raise TypeError('Properties instance must be intelligent and of type MESSAGE to get attachment count.')
-        return self.__ac
-
-    @property
-    def date(self) -> Optional[datetime.datetime]:
-        """
-        Returns the send date contained in the Properties file.
-        """
-        try:
-            return self.__date
-        except AttributeError:
-            self.__date = None
-            if self.has_key('00390040'):
-                dateValue = self.get('00390040').value
-                # A date can by bytes if it fails to initialize, so we check it
-                # first.
-                if isinstance(dateValue, datetime.datetime):
-                    self.__date = dateValue.__format__('%a, %d %b %Y %H:%M:%S %z')
-            return self.__date
-
-    @property
-    def intelligence(self) -> Intelligence:
-        """
-        Returns the inteligence level of the Properties instance.
-        """
-        return self.__intel
-
-    @property
-    def nextAttachmentId(self) -> int:
-        """
-        The ID to use for naming the next Attachment object storage if one is
-        created inside the .msg file.
-
-        :raises TypeError: The Properties instance is not for an MSGFile object.
-        """
-        if self.__naid is None:
-            raise TypeError('Properties instance must be intelligent and of type MESSAGE to get next attachment id.')
-        return self.__naid
-
-    @property
-    def nextRecipientId(self) -> int:
-        """
-        The ID to use for naming the next Recipient object storage if one is
-        created inside the .msg file.
-
-        :raises TypeError: The Properties instance is not for an MSGFile object.
-        """
-        if self.__nrid is None:
-            raise TypeError('Properties instance must be intelligent and of type MESSAGE to get next recipient id.')
-        return self.__nrid
-
-    @property
-    def props(self) -> Dict:
-        """
-        Returns a copy of the internal properties dict.
-        """
-        return copy.deepcopy(self.__props)
-
-    @property
-    def _propDict(self) -> Dict:
-        """
-        A direct reference to the underlying property dictionary. Used in one
-        place in the code, and not recommended to be used if you are not a
-        developer. Use `Properties.props` instead for a safe reference.
-        """
-        return self.__props
-
-    @property
-    def rawData(self) -> bytes:
-        """
-        The raw bytes used to create this object.
-        """
-        return self.__rawData
-
-    @property
-    def recipientCount(self) -> int:
-        """
-        The number of Recipient objects for the MSGFile object.
-
-        :raises TypeError: The Properties instance is not for an MSGFile object.
-        """
-        if self.__rc is None:
-            raise TypeError('Properties instance must be intelligent and of type MESSAGE to get recipient count.')
-        return self.__rc
+__all__ = [
+    'Properties',
+]
+
+
+import copy
+import datetime
+import logging
+import pprint
+
+from typing import Any, Dict, Optional, Union
+from warnings import warn
+
+from . import constants
+from .enums import Intelligence, PropertiesType
+from .prop import createProp, PropBase
+from .utils import divide, properHex
+
+
+logger = logging.getLogger(__name__)
+logger.addHandler(logging.NullHandler())
+
+
+class Properties:
+    """
+    Parser for msg properties files.
+    """
+
+    def __init__(self, data : Optional[bytes], _type : Optional[PropertiesType] = None, skip : Optional[int] = None):
+        if not data:
+            # If data comes back false, make sure is is empty bytes.
+            data = b''
+        if not isinstance(data, bytes):
+            raise TypeError(':param data: MUST be bytes.')
+        self.__rawData = data
+        self.__pos = 0
+        self.__len = len(data)
+        self.__props = {}
+        self.__naid = None
+        self.__nrid = None
+        self.__ac = None
+        self.__rc = None
+        # Handle an empty properties stream.
+        if self.__len == 0:
+            self.__intel = Intelligence.ERROR
+            skip = 0
+        elif _type is not None:
+                _type = PropertiesType(_type)
+                self.__intel = Intelligence.SMART
+                if _type == PropertiesType.MESSAGE:
+                    skip = 32
+                    self.__nrid, self.__naid, self.__rc, self.__ac = constants.ST1.unpack(self.__rawData[:24])
+                elif _type == PropertiesType.MESSAGE_EMBED:
+                    skip = 24
+                    self.__nrid, self.__naid, self.__rc, self.__ac = constants.ST1.unpack(self.__rawData[:24])
+                else:
+                    skip = 8
+        else:
+            self.__intel = Intelligence.DUMB
+            if skip is None:
+                # This section of the skip handling is not very good. While it
+                # does work, it is likely to create extra properties that are
+                # created from the properties file's header data. While that
+                # won't actually mess anything up, it is far from ideal.
+                # Basically, this is the dumb skip length calculation.
+                # Preferably, we want the type to have been specified so all of
+                # the additional fields will have been filled out.
+                #
+                # If the skip would end up at 0, set it to 32.
+                skip = (self.__len % 16) or 32
+        streams = divide(self.__rawData[skip:], 16)
+        for st in streams:
+            if len(st) == 16:
+                prop = createProp(st)
+                self.__props[prop.name] = prop
+            else:
+                logger.warning(f'Found stream from divide that was not 16 bytes: {st}. Ignoring.')
+        self.__pl = len(self.__props)
+
+    def __contains__(self, key) -> bool:
+        return self.__props.__contains__(key)
+
+    def __getitem__(self, key):
+        return self.__props.__getitem__(key)
+
+    def __iter__(self):
+        return self.__props.__iter__()
+
+    def __len__(self) -> int:
+        """
+        Returns the number of properties.
+        """
+        return self.__pl
+
+    def __repr__(self) -> str:
+        return self.__props.__repr__()
+
+    def get(self, name, default = None) -> Optional[Union[PropBase, Any]]:
+        """
+        Retrieve the property of :param name:. Returns the value of
+        :param default: if the property could not be found.
+        """
+        try:
+            return self.__props[name]
+        except KeyError:
+            # DEBUG
+            logger.debug('KeyError exception.')
+            logger.debug(properHex(self.__rawData))
+            logger.debug(self.__props)
+            return default
+
+    def has_key(self, key) -> bool:
+        """
+        Checks if :param key: is a key in the properties dictionary.
+        """
+        warn('`Properties.has_key` is deprecated. Use the `in` keyword instead.', DeprecationWarning)
+        return key in self.__props
+
+    def items(self):
+        return self.__props.items()
+
+    def keys(self):
+        return self.__props.keys()
+
+    def pprintKeys(self) -> None:
+        """
+        Uses the pprint function on a sorted list of keys.
+        """
+        pprint.pprint(sorted(tuple(self.__props.keys())))
+
+    def values(self):
+        return self.__props.values()
+
+    items.__doc__ = dict.items.__doc__
+    keys.__doc__ = dict.keys.__doc__
+    values.__doc__ = dict.values.__doc__
+
+    @property
+    def attachmentCount(self) -> int:
+        """
+        The number of Attachment objects for the MSGFile object.
+
+        :raises TypeError: The Properties instance is not for an MSGFile object.
+        """
+        if self.__ac is None:
+            raise TypeError('Properties instance must be intelligent and of type MESSAGE to get attachment count.')
+        return self.__ac
+
+    @property
+    def date(self) -> Optional[datetime.datetime]:
+        """
+        Returns the send date contained in the Properties file.
+        """
+        try:
+            return self.__date
+        except AttributeError:
+            self.__date = None
+            if '00390040' in self:
+                dateValue = self.get('00390040').value
+                # A date can by bytes if it fails to initialize, so we check it
+                # first.
+                if isinstance(dateValue, datetime.datetime):
+                    self.__date = dateValue.__format__('%a, %d %b %Y %H:%M:%S %z')
+            return self.__date
+
+    @property
+    def intelligence(self) -> Intelligence:
+        """
+        Returns the inteligence level of the Properties instance.
+        """
+        return self.__intel
+
+    @property
+    def nextAttachmentId(self) -> int:
+        """
+        The ID to use for naming the next Attachment object storage if one is
+        created inside the .msg file.
+
+        :raises TypeError: The Properties instance is not for an MSGFile object.
+        """
+        if self.__naid is None:
+            raise TypeError('Properties instance must be intelligent and of type MESSAGE to get next attachment id.')
+        return self.__naid
+
+    @property
+    def nextRecipientId(self) -> int:
+        """
+        The ID to use for naming the next Recipient object storage if one is
+        created inside the .msg file.
+
+        :raises TypeError: The Properties instance is not for an MSGFile object.
+        """
+        if self.__nrid is None:
+            raise TypeError('Properties instance must be intelligent and of type MESSAGE to get next recipient id.')
+        return self.__nrid
+
+    @property
+    def props(self) -> Dict:
+        """
+        Returns a copy of the internal properties dict.
+        """
+        return copy.deepcopy(self.__props)
+
+    @property
+    def _propDict(self) -> Dict:
+        """
+        A direct reference to the underlying property dictionary. Used in one
+        place in the code, and not recommended to be used if you are not a
+        developer. Use `Properties.props` instead for a safe reference.
+        """
+        return self.__props
+
+    @property
+    def rawData(self) -> bytes:
+        """
+        The raw bytes used to create this object.
+        """
+        return self.__rawData
+
+    @property
+    def recipientCount(self) -> int:
+        """
+        The number of Recipient objects for the MSGFile object.
+
+        :raises TypeError: The Properties instance is not for an MSGFile object.
+        """
+        if self.__rc is None:
+            raise TypeError('Properties instance must be intelligent and of type MESSAGE to get recipient count.')
+        return self.__rc
```

### Comparing `extract_msg-0.40.0/extract_msg/recipient.py` & `extract_msg-0.41.0/extract_msg/recipient.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,309 +1,320 @@
-import logging
-
-from typing import Optional, Union
-
-from .enums import MeetingRecipientType, PropertiesType, RecipientType
-from .prop import FixedLengthProp
-from .properties import Properties
-from .structures.entry_id import PermanentEntryID
-from .utils import verifyPropertyId, verifyType
-
-
-logger = logging.getLogger(__name__)
-logger.addHandler(logging.NullHandler())
-
-
-class Recipient:
-    """
-    Contains the data of one of the recipients in an msg file.
-    """
-
-    def __init__(self, _dir, msg):
-        self.__msg = msg # Allows calls to original msg file.
-        self.__dir = _dir
-        self.__props = Properties(self._getStream('__properties_version1.0'), PropertiesType.RECIPIENT)
-        self.__email = self._getStringStream('__substg1.0_39FE')
-        if not self.__email:
-            self.__email = self._getStringStream('__substg1.0_3003')
-        self.__name = self._getStringStream('__substg1.0_3001')
-        self.__typeFlags = self.__props.get('0C150003').value or 0
-        from .calendar_base import CalendarBase
-        if isinstance(msg, CalendarBase):
-            self.__type = MeetingRecipientType(0xF & self.__typeFlags)
-        else:
-            self.__type = RecipientType(0xF & self.__typeFlags)
-        self.__formatted = f'{self.__name} <{self.__email}>'
-
-    def _ensureSet(self, variable, streamID, stringStream : bool = True, **kwargs):
-        """
-        Ensures that the variable exists, otherwise will set it using the
-        specified stream. After that, return said variable.
-
-        If the specified stream is not a string stream, make sure to set
-        :param string stream: to False.
-
-        :param overrideClass: Class/function to use to morph the data that was
-            read. The data will be the first argument to the class's __init__
-            function or the function itself, if that is what is provided. By
-            default, this will be completely ignored if the value was not found.
-        :param preserveNone: If true (default), causes the function to ignore
-            :param overrideClass: when the value could not be found (is None).
-            If this is changed to False, then the value will be used regardless.
-        """
-        try:
-            return getattr(self, variable)
-        except AttributeError:
-            if stringStream:
-                value = self._getStringStream(streamID)
-            else:
-                value = self._getStream(streamID)
-            # Check if we should be overriding the data type for this instance.
-            if kwargs:
-                overrideClass = kwargs.get('overrideClass')
-                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
-                    value = overrideClass(value)
-            setattr(self, variable, value)
-            return value
-
-    def _ensureSetProperty(self, variable : str, propertyName : str, **kwargs):
-        """
-        Ensures that the variable exists, otherwise will set it using the
-        property. After that, return said variable.
-
-        :param overrideClass: Class/function to use to morph the data that was
-            read. The data will be the first argument to the class's __init__
-            function or the function itself, if that is what is provided. By
-            default, this will be completely ignored if the value was not found.
-        :param preserveNone: If true (default), causes the function to ignore
-            :param overrideClass: when the value could not be found (is None).
-            If this is changed to False, then the value will be used regardless.
-        """
-        try:
-            return getattr(self, variable)
-        except AttributeError:
-            try:
-                value = self.props[propertyName].value
-            except (KeyError, AttributeError):
-                value = None
-            # Check if we should be overriding the data type for this instance.
-            if kwargs:
-                overrideClass = kwargs.get('overrideClass')
-                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
-                    value = overrideClass(value)
-            setattr(self, variable, value)
-            return value
-
-    def _ensureSetTyped(self, variable : str, _id, **kwargs):
-        """
-        Like the other ensure set functions, but designed for when something
-        could be multiple types (where only one will be present). This way you
-        have no need to set the type, it will be handled for you.
-
-        :param overrideClass: Class/function to use to morph the data that was
-            read. The data will be the first argument to the class's __init__
-            function or the function itself, if that is what is provided. By
-            default, this will be completely ignored if the value was not found.
-        :param preserveNone: If true (default), causes the function to ignore
-            :param overrideClass: when the value could not be found (is None).
-            If this is changed to False, then the value will be used regardless.
-        """
-        try:
-            return getattr(self, variable)
-        except AttributeError:
-            value = self._getTypedData(_id)
-            # Check if we should be overriding the data type for this instance.
-            if kwargs:
-                overrideClass = kwargs.get('overrideClass')
-                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
-                    value = overrideClass(value)
-            setattr(self, variable, value)
-            return value
-
-    def _getStream(self, filename) -> Optional[bytes]:
-        """
-        Gets a binary representation of the requested filename.
-
-        This should ALWAYS return a bytes object if it was found, otherwise
-        returns None.
-        """
-        return self.__msg._getStream([self.__dir, filename])
-
-    def _getStringStream(self, filename) -> Optional[str]:
-        """
-        Gets a string representation of the requested filename. Checks for both
-        Unicode and Non-Unicode representations and returns a value if possible.
-        If there are both Unicode and Non-Unicode versions, then :param prefer:
-        specifies which will be returned.
-        """
-        return self.__msg._getStringStream([self.__dir, filename])
-
-    def _getTypedData(self, _id, _type = None):
-        """
-        Gets the data for the specified id as the type that it is supposed to
-        be. :param id: MUST be a 4 digit hexadecimal string.
-
-        If you know for sure what type the data is before hand, you can specify
-        it as being one of the strings in the constant FIXED_LENGTH_PROPS_STRING
-        or VARIABLE_LENGTH_PROPS_STRING.
-        """
-        verifyPropertyId(id)
-        _id = _id.upper()
-        found, result = self._getTypedStream('__substg1.0_' + _id, _type)
-        if found:
-            return result
-        else:
-            found, result = self._getTypedProperty(_id, _type)
-            return result if found else None
-
-    def _getTypedProperty(self, propertyID : str, _type = None):
-        """
-        Gets the property with the specified id as the type that it is supposed
-        to be. :param id: MUST be a 4 digit hexadecimal string.
-
-        If you know for sure what type the property is before hand, you can
-        specify it as being one of the strings in the constant
-        FIXED_LENGTH_PROPS_STRING or VARIABLE_LENGTH_PROPS_STRING.
-        """
-        verifyPropertyId(propertyID)
-        verifyType(_type)
-        propertyID = propertyID.upper()
-        for x in (propertyID + _type,) if _type is not None else self.props:
-            if x.startswith(propertyID):
-                prop = self.props[x]
-                return True, (prop.value if isinstance(prop, FixedLengthProp) else prop)
-        return False, None
-
-    def _getTypedStream(self, filename, _type = None):
-        """
-        Gets the contents of the specified stream as the type that it is
-        supposed to be.
-
-        Rather than the full filename, you should only feed this function the
-        filename sans the type. So if the full name is "__substg1.0_001A001F",
-        the filename this function should receive should be "__substg1.0_001A".
-
-        If you know for sure what type the stream is before hand, you can
-        specify it as being one of the strings in the constant
-        FIXED_LENGTH_PROPS_STRING or VARIABLE_LENGTH_PROPS_STRING.
-
-        If you have not specified the type, the type this function returns in
-        many cases cannot be predicted. As such, when using this function it is
-        best for you to check the type that it returns. If the function returns
-        None, that means it could not find the stream specified.
-        """
-        self.__msg._getTypedStream(self, [self.__dir, filename], True, _type)
-
-    def exists(self, filename) -> bool:
-        """
-        Checks if stream exists inside the recipient folder.
-        """
-        return self.__msg.exists([self.__dir, filename])
-
-    def sExists(self, filename) -> bool:
-        """
-        Checks if the string stream exists inside the recipient folder.
-        """
-        return self.__msg.sExists([self.__dir, filename])
-
-    def existsTypedProperty(self, id, _type = None) -> bool:
-        """
-        Determines if the stream with the provided id exists. The return of this
-        function is 2 values, the first being a boolean for if anything was
-        found, and the second being how many were found.
-        """
-        return self.__msg.existsTypedProperty(id, self.__dir, _type, True, self.__props)
-
-    @property
-    def account(self) -> Optional[str]:
-        """
-        Returns the account of this recipient.
-        """
-        return self._ensureSet('_account', '__substg1.0_3A00')
-
-    @property
-    def email(self) -> Optional[str]:
-        """
-        Returns the recipient's email.
-        """
-        return self.__email
-
-    @property
-    def entryID(self) -> Optional[PermanentEntryID]:
-        """
-        Returns the recipient's Entry ID.
-        """
-        return self._ensureSet('_entryID', '__substg1.0_0FFF0102', False, overrideClass = PermanentEntryID)
-
-    @property
-    def formatted(self) -> str:
-        """
-        Returns the formatted recipient string.
-        """
-        return self.__formatted
-
-    @property
-    def instanceKey(self) -> Optional[bytes]:
-        """
-        Returns the instance key of this recipient.
-        """
-        return self._ensureSet('_instanceKey', '__substg1.0_0FF60102', False)
-
-    @property
-    def name(self) -> Optional[str]:
-        """
-        Returns the recipient's name.
-        """
-        return self.__name
-
-    @property
-    def props(self) -> Properties:
-        """
-        Returns the Properties instance of the recipient.
-        """
-        return self.__props
-
-    @property
-    def recordKey(self) -> Optional[bytes]:
-        """
-        Returns the instance key of this recipient.
-        """
-        return self._ensureSet('_recordKey', '__substg1.0_0FF90102', False)
-
-    @property
-    def searchKey(self) -> Optional[bytes]:
-        """
-        Returns the search key of this recipient.
-        """
-        return self._ensureSet('_searchKey', '__substg1.0_300B0102', False)
-
-    @property
-    def smtpAddress(self) -> Optional[str]:
-        """
-        Returns the SMTP address of this recipient.
-        """
-        return self._ensureSet('_smtpAddress', '__substg1.0_39FE')
-
-    @property
-    def transmittableDisplayName(self) -> Optional[str]:
-        """
-        Returns the transmittable display name of this recipient.
-        """
-        return self._ensureSet('_transmittableDisplayName', '__substg1.0_3A20')
-
-    @property
-    def type(self) -> Union[RecipientType, MeetingRecipientType]:
-        """
-        Returns the recipient type. Type is:
-            * Sender if `type & 0xf == 0`
-            * To if `type & 0xf == 1`
-            * Cc if `type & 0xf == 2`
-            * Bcc if `type & 0xf == 3`
-        """
-        return self.__type
-
-    @property
-    def typeFlags(self) -> int:
-        """
-        The raw recipient type value and all the flags it includes.
-        """
-        return self.__typeFlags
+__all__ = [
+    'Recipient',
+]
+
+
+import logging
+
+from typing import Optional, Union
+
+from .enums import ErrorBehavior, MeetingRecipientType, PropertiesType, RecipientType
+from .exceptions import StandardViolationError
+from .prop import FixedLengthProp
+from .properties import Properties
+from .structures.entry_id import PermanentEntryID
+from .utils import verifyPropertyId, verifyType
+
+
+logger = logging.getLogger(__name__)
+logger.addHandler(logging.NullHandler())
+
+
+class Recipient:
+    """
+    Contains the data of one of the recipients in an msg file.
+    """
+
+    def __init__(self, _dir, msg):
+        self.__msg = msg # Allows calls to original msg file.
+        self.__dir = _dir
+        if not self.exists('__properties_version1.0'):
+            if msg.errorBehavior & ErrorBehavior.STANDARDS_VIOLATION:
+                logger.error('Recipients MUST have a property stream.')
+            else:
+                raise StandardViolationError('Recipients MUST have a property stream.') from None
+        self.__props = Properties(self._getStream('__properties_version1.0'), PropertiesType.RECIPIENT)
+        self.__email = self._getStringStream('__substg1.0_39FE')
+        if not self.__email:
+            self.__email = self._getStringStream('__substg1.0_3003')
+        self.__name = self._getStringStream('__substg1.0_3001')
+        self.__typeFlags = self.__props.get('0C150003').value or 0
+        from .calendar_base import CalendarBase
+        if isinstance(msg, CalendarBase):
+            self.__type = MeetingRecipientType(0xF & self.__typeFlags)
+        else:
+            self.__type = RecipientType(0xF & self.__typeFlags)
+        self.__formatted = f'{self.__name} <{self.__email}>'
+
+    def _ensureSet(self, variable, streamID, stringStream : bool = True, **kwargs):
+        """
+        Ensures that the variable exists, otherwise will set it using the
+        specified stream. After that, return said variable.
+
+        If the specified stream is not a string stream, make sure to set
+        :param string stream: to False.
+
+        :param overrideClass: Class/function to use to morph the data that was
+            read. The data will be the first argument to the class's __init__
+            function or the function itself, if that is what is provided. By
+            default, this will be completely ignored if the value was not found.
+        :param preserveNone: If true (default), causes the function to ignore
+            :param overrideClass: when the value could not be found (is None).
+            If this is changed to False, then the value will be used regardless.
+        """
+        try:
+            return getattr(self, variable)
+        except AttributeError:
+            if stringStream:
+                value = self._getStringStream(streamID)
+            else:
+                value = self._getStream(streamID)
+            # Check if we should be overriding the data type for this instance.
+            if kwargs:
+                overrideClass = kwargs.get('overrideClass')
+                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
+                    value = overrideClass(value)
+            setattr(self, variable, value)
+            return value
+
+    def _ensureSetProperty(self, variable : str, propertyName : str, **kwargs):
+        """
+        Ensures that the variable exists, otherwise will set it using the
+        property. After that, return said variable.
+
+        :param overrideClass: Class/function to use to morph the data that was
+            read. The data will be the first argument to the class's __init__
+            function or the function itself, if that is what is provided. By
+            default, this will be completely ignored if the value was not found.
+        :param preserveNone: If true (default), causes the function to ignore
+            :param overrideClass: when the value could not be found (is None).
+            If this is changed to False, then the value will be used regardless.
+        """
+        try:
+            return getattr(self, variable)
+        except AttributeError:
+            try:
+                value = self.props[propertyName].value
+            except (KeyError, AttributeError):
+                value = None
+            # Check if we should be overriding the data type for this instance.
+            if kwargs:
+                overrideClass = kwargs.get('overrideClass')
+                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
+                    value = overrideClass(value)
+            setattr(self, variable, value)
+            return value
+
+    def _ensureSetTyped(self, variable : str, _id, **kwargs):
+        """
+        Like the other ensure set functions, but designed for when something
+        could be multiple types (where only one will be present). This way you
+        have no need to set the type, it will be handled for you.
+
+        :param overrideClass: Class/function to use to morph the data that was
+            read. The data will be the first argument to the class's __init__
+            function or the function itself, if that is what is provided. By
+            default, this will be completely ignored if the value was not found.
+        :param preserveNone: If true (default), causes the function to ignore
+            :param overrideClass: when the value could not be found (is None).
+            If this is changed to False, then the value will be used regardless.
+        """
+        try:
+            return getattr(self, variable)
+        except AttributeError:
+            value = self._getTypedData(_id)
+            # Check if we should be overriding the data type for this instance.
+            if kwargs:
+                overrideClass = kwargs.get('overrideClass')
+                if overrideClass is not None and (value is not None or not kwargs.get('preserveNone', True)):
+                    value = overrideClass(value)
+            setattr(self, variable, value)
+            return value
+
+    def _getStream(self, filename) -> Optional[bytes]:
+        """
+        Gets a binary representation of the requested filename.
+
+        This should ALWAYS return a bytes object if it was found, otherwise
+        returns None.
+        """
+        return self.__msg._getStream([self.__dir, filename])
+
+    def _getStringStream(self, filename) -> Optional[str]:
+        """
+        Gets a string representation of the requested filename. Checks for both
+        Unicode and Non-Unicode representations and returns a value if possible.
+        If there are both Unicode and Non-Unicode versions, then :param prefer:
+        specifies which will be returned.
+        """
+        return self.__msg._getStringStream([self.__dir, filename])
+
+    def _getTypedData(self, _id, _type = None):
+        """
+        Gets the data for the specified id as the type that it is supposed to
+        be. :param id: MUST be a 4 digit hexadecimal string.
+
+        If you know for sure what type the data is before hand, you can specify
+        it as being one of the strings in the constant FIXED_LENGTH_PROPS_STRING
+        or VARIABLE_LENGTH_PROPS_STRING.
+        """
+        verifyPropertyId(id)
+        _id = _id.upper()
+        found, result = self._getTypedStream('__substg1.0_' + _id, _type)
+        if found:
+            return result
+        else:
+            found, result = self._getTypedProperty(_id, _type)
+            return result if found else None
+
+    def _getTypedProperty(self, propertyID : str, _type = None):
+        """
+        Gets the property with the specified id as the type that it is supposed
+        to be. :param id: MUST be a 4 digit hexadecimal string.
+
+        If you know for sure what type the property is before hand, you can
+        specify it as being one of the strings in the constant
+        FIXED_LENGTH_PROPS_STRING or VARIABLE_LENGTH_PROPS_STRING.
+        """
+        verifyPropertyId(propertyID)
+        verifyType(_type)
+        propertyID = propertyID.upper()
+        for x in (propertyID + _type,) if _type is not None else self.props:
+            if x.startswith(propertyID):
+                prop = self.props[x]
+                return True, (prop.value if isinstance(prop, FixedLengthProp) else prop)
+        return False, None
+
+    def _getTypedStream(self, filename, _type = None):
+        """
+        Gets the contents of the specified stream as the type that it is
+        supposed to be.
+
+        Rather than the full filename, you should only feed this function the
+        filename sans the type. So if the full name is "__substg1.0_001A001F",
+        the filename this function should receive should be "__substg1.0_001A".
+
+        If you know for sure what type the stream is before hand, you can
+        specify it as being one of the strings in the constant
+        FIXED_LENGTH_PROPS_STRING or VARIABLE_LENGTH_PROPS_STRING.
+
+        If you have not specified the type, the type this function returns in
+        many cases cannot be predicted. As such, when using this function it is
+        best for you to check the type that it returns. If the function returns
+        None, that means it could not find the stream specified.
+        """
+        self.__msg._getTypedStream(self, [self.__dir, filename], True, _type)
+
+    def exists(self, filename) -> bool:
+        """
+        Checks if stream exists inside the recipient folder.
+        """
+        return self.__msg.exists([self.__dir, filename])
+
+    def sExists(self, filename) -> bool:
+        """
+        Checks if the string stream exists inside the recipient folder.
+        """
+        return self.__msg.sExists([self.__dir, filename])
+
+    def existsTypedProperty(self, id, _type = None) -> bool:
+        """
+        Determines if the stream with the provided id exists. The return of this
+        function is 2 values, the first being a boolean for if anything was
+        found, and the second being how many were found.
+        """
+        return self.__msg.existsTypedProperty(id, self.__dir, _type, True, self.__props)
+
+    @property
+    def account(self) -> Optional[str]:
+        """
+        Returns the account of this recipient.
+        """
+        return self._ensureSet('_account', '__substg1.0_3A00')
+
+    @property
+    def email(self) -> Optional[str]:
+        """
+        Returns the recipient's email.
+        """
+        return self.__email
+
+    @property
+    def entryID(self) -> Optional[PermanentEntryID]:
+        """
+        Returns the recipient's Entry ID.
+        """
+        return self._ensureSet('_entryID', '__substg1.0_0FFF0102', False, overrideClass = PermanentEntryID)
+
+    @property
+    def formatted(self) -> str:
+        """
+        Returns the formatted recipient string.
+        """
+        return self.__formatted
+
+    @property
+    def instanceKey(self) -> Optional[bytes]:
+        """
+        Returns the instance key of this recipient.
+        """
+        return self._ensureSet('_instanceKey', '__substg1.0_0FF60102', False)
+
+    @property
+    def name(self) -> Optional[str]:
+        """
+        Returns the recipient's name.
+        """
+        return self.__name
+
+    @property
+    def props(self) -> Properties:
+        """
+        Returns the Properties instance of the recipient.
+        """
+        return self.__props
+
+    @property
+    def recordKey(self) -> Optional[bytes]:
+        """
+        Returns the instance key of this recipient.
+        """
+        return self._ensureSet('_recordKey', '__substg1.0_0FF90102', False)
+
+    @property
+    def searchKey(self) -> Optional[bytes]:
+        """
+        Returns the search key of this recipient.
+        """
+        return self._ensureSet('_searchKey', '__substg1.0_300B0102', False)
+
+    @property
+    def smtpAddress(self) -> Optional[str]:
+        """
+        Returns the SMTP address of this recipient.
+        """
+        return self._ensureSet('_smtpAddress', '__substg1.0_39FE')
+
+    @property
+    def transmittableDisplayName(self) -> Optional[str]:
+        """
+        Returns the transmittable display name of this recipient.
+        """
+        return self._ensureSet('_transmittableDisplayName', '__substg1.0_3A20')
+
+    @property
+    def type(self) -> Union[RecipientType, MeetingRecipientType]:
+        """
+        Returns the recipient type. Type is:
+            * Sender if `type & 0xf == 0`
+            * To if `type & 0xf == 1`
+            * Cc if `type & 0xf == 2`
+            * Bcc if `type & 0xf == 3`
+        """
+        return self.__type
+
+    @property
+    def typeFlags(self) -> int:
+        """
+        The raw recipient type value and all the flags it includes.
+        """
+        return self.__typeFlags
```

### Comparing `extract_msg-0.40.0/extract_msg/structures/_helpers.py` & `extract_msg-0.41.0/extract_msg/structures/_helpers.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,337 +1,342 @@
-"""
-Module for helper classes to different data structures.
-"""
-
-import io
-import struct
-
-from typing import Any, Tuple, Union
-
-from .. import constants
-
-
-class BytesReader(io.BytesIO):
-    """
-    Extension of io.BytesIO that allows you to read specific data types from the
-    stream.
-    """
-
-    def __init__(self, *args, littleEndian = True, **kwargs):
-        super().__init__(*args, **kwargs)
-        self.__le = bool(littleEndian)
-        if self.__le:
-            self.__int8_t = constants.ST_LE_I8
-            self.__int16_t = constants.ST_LE_I16
-            self.__int32_t = constants.ST_LE_I32
-            self.__int64_t = constants.ST_LE_I64
-            self.__uint8_t = constants.ST_LE_UI8
-            self.__uint16_t = constants.ST_LE_UI16
-            self.__uint32_t = constants.ST_LE_UI32
-            self.__uint64_t = constants.ST_LE_UI64
-            self.__float_t = constants.ST_LE_F32
-            self.__double_t = constants.ST_LE_F64
-        else:
-            self.__int8_t = constants.ST_BE_I8
-            self.__int16_t = constants.ST_BE_I16
-            self.__int32_t = constants.ST_BE_I32
-            self.__int64_t = constants.ST_BE_I64
-            self.__uint8_t = constants.ST_BE_UI8
-            self.__uint16_t = constants.ST_BE_UI16
-            self.__uint32_t = constants.ST_BE_UI32
-            self.__uint64_t = constants.ST_BE_UI64
-            self.__float_t = constants.ST_BE_F32
-            self.__double_t = constants.ST_BE_F64
-
-    def _readDecodedString(self, encoding, width : int = 1) -> str:
-        """
-        Reads a null terminated string with the specified character width
-        decoded using the specified encoding. If it cannot be read or cannot be
-        decoded then the position of the read pointer will not be changed.
-        """
-        position = self.tell()
-        try:
-            return self.readByteString(width).decode(encoding)
-        except Exception:
-            while self.tell() != position:
-                self.seek(position)
-            raise
-
-    def assertNull(self, length : int, errorMsg : str = None) -> bytes:
-        """
-        Reads the number of bytes specified and ensures they are all null.
-
-        Ensures the reader returns back to the spot before attempting to read if
-        there are not enough bytes to read.
-
-        :param length: The amount of bytes to read.
-        :param errorMsg: Optional, the error message to use if the bytes are not
-            all null.
-
-        :returns: The bytes read, if you need them.
-
-        :raise IOError: Not enough bytes left to read.
-        :raises ValueError: Assertion failed.
-        """
-        # Quick return for reading 0 bytes.
-        if length == 0:
-            return b''
-
-        valueRead = self.tryReadBytes(length)
-        if valueRead:
-            if sum(valueRead) != 0:
-                errorMsg = errorMsg or 'Bytes read were not all null.'
-                raise ValueError(errorMsg)
-        else:
-            raise IOError('Not enough bytes left in buffer.')
-
-        return valueRead
-
-    def assertRead(self, value : bytes, errorMsg : str = None) -> bytes:
-        """
-        Reads the number of bytes and compares them to the value provided. If it
-        does not match, throws a value error.
-
-        Ensures the reader returns back to the spot before attempting to read if
-        there are not enough bytes to read.
-
-        :param value: Value to compare read bytes to.
-        :param errorMsg: Optional, an error message to emit on mismatch. Does
-            not apply to the buffer being too small. Allows for a format string
-            with the keyword values "expected" and "actual", representing the
-            value given to the function and the actual value read, respectively.
-
-        :returns: The bytes read, if you need them.
-
-        :raises TypeError: The value given was not bytes.
-        :raises ValueError: Assertion failed.
-        """
-        # Quick return for a value being empty.
-        if len(value) == 0:
-            return b''
-
-        if not isinstance(value, bytes):
-            raise TypeError(':param value: was not bytes.')
-
-        valueRead = self.tryReadBytes(len(value))
-        if valueRead:
-            if valueRead != value:
-                errorMsg = errorMsg or 'Value did not match (expected {expected}, got {actual}).'
-                raise ValueError(errorMsg.format(expected = value, actual = valueRead))
-        else:
-            raise IOError('Not enough bytes left in buffer.')
-
-        return valueRead
-
-    def readAnsiString(self) -> str:
-        """
-        Reads a null-terminated string in ANSI format.
-        """
-        return self._readDecodedString('ansi')
-
-    def readAsciiString(self) -> str:
-        """
-        Reads a null-terminated string in ASCII format.
-        """
-        return self._readDecodedString('ascii')
-
-    def readByte(self) -> int:
-        """
-        Reads a signed byte from the stream.
-        """
-        value = self.tryReadBytes(1)
-        if value:
-            return self.__int8_t.unpack(value)[0]
-        else:
-            raise IOError('Not enough bytes left in buffer.')
-
-    def readByteString(self, width : int = 1) -> bytes:
-        """
-        Reads a string of bytes until it finds the null character, returning
-        everything before that and consuming the null. Unlike other string
-        functions, this will not decode the data into a string.
-
-        :param width: tells how big a character is (in bytes), so this function
-        can be used for strings whose characters are multiple bytes.
-        """
-        if width < 1:
-            raise ValueError('Character width must be at least 1.')
-
-        position = self.tell()
-        string = b''
-        endFound = False;
-        null = b'\x00' * width
-
-        while True:
-            nextChar = self.read(width)
-            if nextChar == b'':
-                # We reached the end of the buffer without finding the null. We
-                # need to seek back to where we started and raise an exception.
-                while self.tell() != position:
-                    self.seek(position)
-                raise IOError('Could not find null character.')
-            elif nextChar == null:
-                # If we find the null character, return what we have read.
-                return string
-            else:
-                # Otherwise add the character to our string.
-                string += nextChar
-
-    def readClass(self, _class):
-        """
-        Takes anything with a __SIZE__ property and a call function that takes
-        a single bytes argument and returns the result of that function.
-
-        Generally, this is intended to take a fixed-size class and return an
-        instance of the class created with that amount of bytes. However, there
-        is little reason to truly limit it to only that.
-        """
-        value = self.tryReadBytes(_class.__SIZE__)
-        if value:
-            return _class(value)
-        else:
-            raise IOError('Not enough bytes left in buffer.')
-
-    def readDouble(self) -> float:
-        """
-        Reads a double from the stream.
-        """
-        value = self.tryReadBytes(8)
-        if value:
-            return self.__double_t.unpack(value)[0]
-        else:
-            raise IOError('Not enough bytes left in buffer.')
-
-    def readFloat(self) -> float:
-        """
-        Reads a float from the stream.
-        """
-        value = self.tryReadBytes(4)
-        if value:
-            return self.__float_t.unpack(value)[0]
-        else:
-            raise IOError('Not enough bytes left in buffer.')
-
-    def readInt(self) -> int:
-        """
-        Reads a signed int from the stream.
-        """
-        value = self.tryReadBytes(4)
-        if value:
-            return self.__int32_t.unpack(value)[0]
-        else:
-            raise IOError('Not enough bytes left in buffer.')
-
-    def readLong(self) -> int:
-        """
-        Reads a signed byte from the stream.
-        """
-        value = self.tryReadBytes(8)
-        if value:
-            return self.__int64_t.unpack(value)[0]
-        else:
-            raise IOError('Not enough bytes left in buffer.')
-
-    def readShort(self) -> int:
-        """
-        Reads a signed short from the stream.
-        """
-        value = self.tryReadBytes(2)
-        if value:
-            return self.__int16_t.unpack(value)[0]
-        else:
-            raise IOError('Not enough bytes left in buffer.')
-
-    def readStruct(self, _struct : Union[struct.Struct, Any]) -> Tuple:
-        """
-        Read enough bytes for a struct and unpack it, returning the tuple of
-        values.
-
-        :param _struct: A struct or struct-like object using duck-typing. Only
-            requires the object have an unpack method that takes a single
-            argument and a size property to tell how many bytes to read.
-
-        :raises IOError: If there are not enough bytes left to read.
-        """
-        value = self.tryReadBytes(_struct.size)
-        if value:
-            return _struct.unpack(value)
-        else:
-            raise IOError('Not enough bytes left in buffer.')
-
-    def readUnsignedByte(self) -> int:
-        """
-        Reads an unsigned byte from the stream.
-        """
-        value = self.tryReadBytes(1)
-        if value:
-            return self.__uint8_t.unpack(value)[0]
-        else:
-            raise IOError('Not enough bytes left in buffer.')
-
-    def readUnsignedInt(self) -> int:
-        """
-        Reads an unsigned int from the stream.
-        """
-        value = self.tryReadBytes(4)
-        if value:
-            return self.__uint32_t.unpack(value)[0]
-        else:
-            raise IOError('Not enough bytes left in buffer.')
-
-    def readUnsignedLong(self) -> int:
-        """
-        Reads an unsigned long from the stream.
-        """
-        value = self.tryReadBytes(8)
-        if value:
-            return self.__uint64_t.unpack(value)[0]
-        else:
-            raise IOError('Not enough bytes left in buffer.')
-
-    def readUnsignedShort(self) -> int:
-        """
-        Reads an unsigned short from the stream.
-        """
-        value = self.tryReadBytes(2)
-        if value:
-            return self.__uint16_t.unpack(value)[0]
-        else:
-            raise IOError('Not enough bytes left in buffer.')
-
-    def readUtf8String(self) -> str:
-        """
-        Reads a null-terminated string in UTF-8 format.
-        """
-        return self._readDecodedString('utf-8')
-
-    def readUtf16String(self) -> str:
-        """
-        Reads a null terminated string in UTF-16 format using the endienness of
-        the reader to determine which one to use.
-        """
-        return self._readDecodedString('utf-16-le' if self.__le else 'utf-16-be', 2)
-
-    def readUtf32String(self) -> str:
-        """
-        Reads a null terminated string in UTF-32 format using the endienness of
-        the reader to determine which one to use.
-        """
-        return self._readDecodedString('utf-32-le' if self.__le else 'utf-32-be', 4)
-
-    def tryReadBytes(self, size : int) -> bytes:
-        """
-        Tries to read the specified number of bytes, returning b'' if not
-        possible. Will only change the position of the read pointer if reading
-        was possible.
-        """
-        if size < 1:
-            raise ValueError(':param size: must be at least 1.')
-        position = self.tell()
-        value = self.read(size)
-        if len(value) == size:
-            return value
-
-        # Ensure that we seek back to where we started if we could not read.
-        while self.tell() != position:
-            self.seek(position)
-        return b''
+"""
+Module for helper classes to different data structures.
+"""
+
+__all__ = [
+    'BytesReader',
+]
+
+
+import io
+import struct
+
+from typing import Any, Tuple, Union
+
+from .. import constants
+
+
+class BytesReader(io.BytesIO):
+    """
+    Extension of io.BytesIO that allows you to read specific data types from the
+    stream.
+    """
+
+    def __init__(self, *args, littleEndian = True, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.__le = bool(littleEndian)
+        if self.__le:
+            self.__int8_t = constants.ST_LE_I8
+            self.__int16_t = constants.ST_LE_I16
+            self.__int32_t = constants.ST_LE_I32
+            self.__int64_t = constants.ST_LE_I64
+            self.__uint8_t = constants.ST_LE_UI8
+            self.__uint16_t = constants.ST_LE_UI16
+            self.__uint32_t = constants.ST_LE_UI32
+            self.__uint64_t = constants.ST_LE_UI64
+            self.__float_t = constants.ST_LE_F32
+            self.__double_t = constants.ST_LE_F64
+        else:
+            self.__int8_t = constants.ST_BE_I8
+            self.__int16_t = constants.ST_BE_I16
+            self.__int32_t = constants.ST_BE_I32
+            self.__int64_t = constants.ST_BE_I64
+            self.__uint8_t = constants.ST_BE_UI8
+            self.__uint16_t = constants.ST_BE_UI16
+            self.__uint32_t = constants.ST_BE_UI32
+            self.__uint64_t = constants.ST_BE_UI64
+            self.__float_t = constants.ST_BE_F32
+            self.__double_t = constants.ST_BE_F64
+
+    def _readDecodedString(self, encoding, width : int = 1) -> str:
+        """
+        Reads a null terminated string with the specified character width
+        decoded using the specified encoding. If it cannot be read or cannot be
+        decoded then the position of the read pointer will not be changed.
+        """
+        position = self.tell()
+        try:
+            return self.readByteString(width).decode(encoding)
+        except Exception:
+            while self.tell() != position:
+                self.seek(position)
+            raise
+
+    def assertNull(self, length : int, errorMsg : str = None) -> bytes:
+        """
+        Reads the number of bytes specified and ensures they are all null.
+
+        Ensures the reader returns back to the spot before attempting to read if
+        there are not enough bytes to read.
+
+        :param length: The amount of bytes to read.
+        :param errorMsg: Optional, the error message to use if the bytes are not
+            all null.
+
+        :returns: The bytes read, if you need them.
+
+        :raise IOError: Not enough bytes left to read.
+        :raises ValueError: Assertion failed.
+        """
+        # Quick return for reading 0 bytes.
+        if length == 0:
+            return b''
+
+        valueRead = self.tryReadBytes(length)
+        if valueRead:
+            if sum(valueRead) != 0:
+                errorMsg = errorMsg or 'Bytes read were not all null.'
+                raise ValueError(errorMsg)
+        else:
+            raise IOError('Not enough bytes left in buffer.')
+
+        return valueRead
+
+    def assertRead(self, value : bytes, errorMsg : str = None) -> bytes:
+        """
+        Reads the number of bytes and compares them to the value provided. If it
+        does not match, throws a value error.
+
+        Ensures the reader returns back to the spot before attempting to read if
+        there are not enough bytes to read.
+
+        :param value: Value to compare read bytes to.
+        :param errorMsg: Optional, an error message to emit on mismatch. Does
+            not apply to the buffer being too small. Allows for a format string
+            with the keyword values "expected" and "actual", representing the
+            value given to the function and the actual value read, respectively.
+
+        :returns: The bytes read, if you need them.
+
+        :raises TypeError: The value given was not bytes.
+        :raises ValueError: Assertion failed.
+        """
+        # Quick return for a value being empty.
+        if len(value) == 0:
+            return b''
+
+        if not isinstance(value, bytes):
+            raise TypeError(':param value: was not bytes.')
+
+        valueRead = self.tryReadBytes(len(value))
+        if valueRead:
+            if valueRead != value:
+                errorMsg = errorMsg or 'Value did not match (expected {expected}, got {actual}).'
+                raise ValueError(errorMsg.format(expected = value, actual = valueRead))
+        else:
+            raise IOError('Not enough bytes left in buffer.')
+
+        return valueRead
+
+    def readAnsiString(self) -> str:
+        """
+        Reads a null-terminated string in ANSI format.
+        """
+        return self._readDecodedString('ansi')
+
+    def readAsciiString(self) -> str:
+        """
+        Reads a null-terminated string in ASCII format.
+        """
+        return self._readDecodedString('ascii')
+
+    def readByte(self) -> int:
+        """
+        Reads a signed byte from the stream.
+        """
+        value = self.tryReadBytes(1)
+        if value:
+            return self.__int8_t.unpack(value)[0]
+        else:
+            raise IOError('Not enough bytes left in buffer.')
+
+    def readByteString(self, width : int = 1) -> bytes:
+        """
+        Reads a string of bytes until it finds the null character, returning
+        everything before that and consuming the null. Unlike other string
+        functions, this will not decode the data into a string.
+
+        :param width: tells how big a character is (in bytes), so this function
+        can be used for strings whose characters are multiple bytes.
+        """
+        if width < 1:
+            raise ValueError('Character width must be at least 1.')
+
+        position = self.tell()
+        string = b''
+        endFound = False;
+        null = b'\x00' * width
+
+        while True:
+            nextChar = self.read(width)
+            if nextChar == b'':
+                # We reached the end of the buffer without finding the null. We
+                # need to seek back to where we started and raise an exception.
+                while self.tell() != position:
+                    self.seek(position)
+                raise IOError('Could not find null character.')
+            elif nextChar == null:
+                # If we find the null character, return what we have read.
+                return string
+            else:
+                # Otherwise add the character to our string.
+                string += nextChar
+
+    def readClass(self, _class):
+        """
+        Takes anything with a __SIZE__ property and a call function that takes
+        a single bytes argument and returns the result of that function.
+
+        Generally, this is intended to take a fixed-size class and return an
+        instance of the class created with that amount of bytes. However, there
+        is little reason to truly limit it to only that.
+        """
+        value = self.tryReadBytes(_class.__SIZE__)
+        if value:
+            return _class(value)
+        else:
+            raise IOError('Not enough bytes left in buffer.')
+
+    def readDouble(self) -> float:
+        """
+        Reads a double from the stream.
+        """
+        value = self.tryReadBytes(8)
+        if value:
+            return self.__double_t.unpack(value)[0]
+        else:
+            raise IOError('Not enough bytes left in buffer.')
+
+    def readFloat(self) -> float:
+        """
+        Reads a float from the stream.
+        """
+        value = self.tryReadBytes(4)
+        if value:
+            return self.__float_t.unpack(value)[0]
+        else:
+            raise IOError('Not enough bytes left in buffer.')
+
+    def readInt(self) -> int:
+        """
+        Reads a signed int from the stream.
+        """
+        value = self.tryReadBytes(4)
+        if value:
+            return self.__int32_t.unpack(value)[0]
+        else:
+            raise IOError('Not enough bytes left in buffer.')
+
+    def readLong(self) -> int:
+        """
+        Reads a signed byte from the stream.
+        """
+        value = self.tryReadBytes(8)
+        if value:
+            return self.__int64_t.unpack(value)[0]
+        else:
+            raise IOError('Not enough bytes left in buffer.')
+
+    def readShort(self) -> int:
+        """
+        Reads a signed short from the stream.
+        """
+        value = self.tryReadBytes(2)
+        if value:
+            return self.__int16_t.unpack(value)[0]
+        else:
+            raise IOError('Not enough bytes left in buffer.')
+
+    def readStruct(self, _struct : Union[struct.Struct, Any]) -> Tuple:
+        """
+        Read enough bytes for a struct and unpack it, returning the tuple of
+        values.
+
+        :param _struct: A struct or struct-like object using duck-typing. Only
+            requires the object have an unpack method that takes a single
+            argument and a size property to tell how many bytes to read.
+
+        :raises IOError: If there are not enough bytes left to read.
+        """
+        value = self.tryReadBytes(_struct.size)
+        if value:
+            return _struct.unpack(value)
+        else:
+            raise IOError('Not enough bytes left in buffer.')
+
+    def readUnsignedByte(self) -> int:
+        """
+        Reads an unsigned byte from the stream.
+        """
+        value = self.tryReadBytes(1)
+        if value:
+            return self.__uint8_t.unpack(value)[0]
+        else:
+            raise IOError('Not enough bytes left in buffer.')
+
+    def readUnsignedInt(self) -> int:
+        """
+        Reads an unsigned int from the stream.
+        """
+        value = self.tryReadBytes(4)
+        if value:
+            return self.__uint32_t.unpack(value)[0]
+        else:
+            raise IOError('Not enough bytes left in buffer.')
+
+    def readUnsignedLong(self) -> int:
+        """
+        Reads an unsigned long from the stream.
+        """
+        value = self.tryReadBytes(8)
+        if value:
+            return self.__uint64_t.unpack(value)[0]
+        else:
+            raise IOError('Not enough bytes left in buffer.')
+
+    def readUnsignedShort(self) -> int:
+        """
+        Reads an unsigned short from the stream.
+        """
+        value = self.tryReadBytes(2)
+        if value:
+            return self.__uint16_t.unpack(value)[0]
+        else:
+            raise IOError('Not enough bytes left in buffer.')
+
+    def readUtf8String(self) -> str:
+        """
+        Reads a null-terminated string in UTF-8 format.
+        """
+        return self._readDecodedString('utf-8')
+
+    def readUtf16String(self) -> str:
+        """
+        Reads a null terminated string in UTF-16 format using the endienness of
+        the reader to determine which one to use.
+        """
+        return self._readDecodedString('utf-16-le' if self.__le else 'utf-16-be', 2)
+
+    def readUtf32String(self) -> str:
+        """
+        Reads a null terminated string in UTF-32 format using the endienness of
+        the reader to determine which one to use.
+        """
+        return self._readDecodedString('utf-32-le' if self.__le else 'utf-32-be', 4)
+
+    def tryReadBytes(self, size : int) -> bytes:
+        """
+        Tries to read the specified number of bytes, returning b'' if not
+        possible. Will only change the position of the read pointer if reading
+        was possible.
+        """
+        if size < 1:
+            raise ValueError(':param size: must be at least 1.')
+        position = self.tell()
+        value = self.read(size)
+        if len(value) == size:
+            return value
+
+        # Ensure that we seek back to where we started if we could not read.
+        while self.tell() != position:
+            self.seek(position)
+        return b''
```

### Comparing `extract_msg-0.40.0/extract_msg/structures/entry_id.py` & `extract_msg-0.41.0/extract_msg/structures/entry_id.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,574 +1,589 @@
-import logging
-from typing import Union
-
-from ._helpers import BytesReader
-from .. import constants
-from ..enums import AddressBookType, ContactAddressIndex, DisplayType, EntryIDType, MacintoshEncoding, MessageFormat, MessageType, OORBodyFormat
-from ..utils import bitwiseAdjustedAnd, bytesToGuid
-
-
-logger = logging.getLogger(__name__)
-logger.addHandler(logging.NullHandler())
-
-
-# First we define the main EntryID structure that is the base for the others.
-class EntryID:
-    """
-    Base class for all EntryID structures. Use :classmethod autoCreate: to
-    automatically create the correct EntryID structure type from the specified
-    data.
-    """
-
-    @classmethod
-    def autoCreate(cls, data) -> 'EntryID':
-        """
-        Automatically determines the type of EntryID and returns an instance of
-        the correct subclass. If the subclass cannot be determined, will return
-        a plain EntryID instance.
-        """
-        if len(data) < 20:
-            raise ValueError('Cannot create an EntryID with less than 20 bytes.')
-        providerUID = data[4:20]
-        try:
-            providerUID = EntryIDType(providerUID)
-        except ValueError:
-            raise ValueError(f'Unrecognized UID "{"".join(f"{x:02X}" for x in providerUID)}". You should probably report this to the developers.') from None
-
-        # Now check the Provider UID against the known ones.
-        if providerUID == EntryIDType.ADDRESS_BOOK_RECIPIENT:
-            return AddressBookEntryID(data)
-        if providerUID == EntryIDType.CA_OR_PDL_RECIPIENT:
-            # Verify that the type signature is correct.
-            if data[24:28] not in (b'\x04\x00\x00\x00', b'\x05\x00\x00\x00'):
-                raise ValueError(f'Found Entry ID matching ContactAddress or PersonalDistributionList but the type was invalid ({data[24:28]}).')
-            if data[24] == 4:
-                return ContactAddressEntryID(data)
-            else:
-                return PersonalDistributionListEntryID(data)
-        if providerUID == EntryIDType.NNTP_NEWSGROUP_FOLDER:
-            # This is, of course, another one with a shared unique identifier.
-            # Technically it's the UID of the provider, but why do multiple
-            # structures use the same provider?
-            if data[20] == 0xC:
-                return NNTPNewsgroupFolderEntryID(data)
-            else:
-                return StoreObjectEntryID(data)
-        if providerUID == EntryIDType.ONE_OFF_RECIPIENT:
-            return OneOffRecipient(data)
-        if providerUID == EntryIDType.PUBLIC_MESSAGE_STORE:
-            if len(data) == 46:
-                return FolderEntryID(data)
-            else:
-                return MessageEntryID(data)
-        if providerUID == EntryIDType.WRAPPED:
-            return WrappedEntryID(data)
-
-        logger.warn(f'UID for EntryID found in database, but no class was specified for it: {providerUID}')
-        # If all else fails and we do recognize it, just return a plain EntryID.
-        return cls(data)
-
-    def __init__(self, data : bytes):
-        self.__flags = data[:4]
-        self.__providerUID = data[4:20]
-        self.__rawData = data
-
-    @property
-    def flags(self) -> bytes:
-        """
-        The flags for this Entry ID.
-        """
-        return self.__flags
-
-    @property
-    def entryIDType(self) -> Union[EntryIDType, bytes]:
-        """
-        Returns an instance of EntryIDType corresponding to the provider UID of
-        this EntryID. If none is found, returns the bytes.
-        """
-        try:
-            return EntryIDType(self.__providerUID)
-        except ValueError:
-            return self.__providerUID
-
-    @property
-    def longTerm(self) -> bool:
-        """
-        Whether the EntryID is long term or not.
-        """
-        return self__flags == b'\x00\x00\x00\x00'
-
-    @property
-    def providerUID(self) -> bytes:
-        """
-        The 16 byte UID that identifies the type of Entry ID.
-        """
-        return self.__providerUID
-
-    @property
-    def rawData(self) -> bytes:
-        """
-        The raw bytes used in this Entry ID.
-        """
-        return self.__rawData
-
-
-
-# Now for the specific types.
-class AddressBookEntryID(EntryID):
-    """
-    An Address Book EntryID structure, as specified in [MS-OXCDATA].
-    """
-
-    def __init__(self, data : bytes):
-        super().__init__(data)
-        reader = BytesReader(data[20:])
-        # Version *MUST* be 1.
-        self.__version = reader.readUnsignedInt()
-        if self.__version != 1:
-            raise ValueError(f'Version must be 1 on address book entry IDs (got {self.__version}).')
-
-        self.__type = AddressBookType(reader.readUnsignedInt())
-        self.__X500DN = reader.readByteString()
-
-    @property
-    def type(self) -> AddressBookType:
-        """
-        The type of the object.
-        """
-        return self.__type
-
-    @property
-    def version(self) -> int:
-        """
-        The version. MUST be 1.
-        """
-        return self.__version
-
-    @property
-    def X5000DN(self) -> bytes:
-        """
-        The X500 DN of the Address Book object.
-        """
-        return self.__X500DN
-
-
-
-class ContactAddressEntryID(EntryID):
-    """
-    A Contact Address EntryID structure, as defined in [MS-OXCDATA]. Specifies a
-    set of data representing recipients whose information is stored in a Contact
-    object.
-    """
-
-    def __init__(self, data : bytes):
-        super().__init__(data)
-        reader = BytesReader(data[20:])
-        if reader.readUnsignedInt() != 3:
-            raise ValueError(f'Version must be 3 (got {self.__version}).')
-        if reader.readUnsignedInt() != 5:
-            raise ValueError(f'Type must be 4 (got {self.__version}).')
-        self.__index = ContactAddressIndex(reader.readUnsignedInt())
-        self.__entryIdCount = reader.readUnsignedInt()
-        self.__entryID = MessageEntryID(reader.read(self.__entryIdCount))
-
-    @property
-    def entryID(self) -> 'MessageEntryID':
-        """
-        The EntryID contained in this object.
-        """
-        return self.__entryID
-
-    @property
-    def entryIDCount(self) -> int:
-        """
-        The size, in bytes, of the EntryID contained in this object.
-        """
-        return self.__entryIdCount
-
-    @property
-    def index(self) -> ContactAddressIndex:
-        """
-        The electronic address in the contact information to use.
-        """
-        return self.__index
-
-
-
-class FolderEntryID(EntryID):
-    """
-    A Folder EntryID structure, as defined in [MS-OXCDATA].
-    """
-
-    __SIZE__ : int = 46
-
-    def __init__(self, data : bytes):
-        super().__init__(data)
-        reader = BytesReader(data[20:])
-        self.__folderType = MessageType(reader.readUnsignedShort())
-        self.__databaseGuid = bytesToGuid(reader.read(16))
-        # This entry is 6 bytes, so we pull some shenanigans to unpack it.
-        self.__globalCounter = constants.ST_LE_UI64.unpack(reader.read(6) + b'\x00\x00')
-        reader.assertNull(2, 'Pad bytes were not 0.')
-
-    @property
-    def databaseGuid(self) -> str:
-        """
-        A GUID associated with the Store Object and corresponding to the
-        ReplicaID field of the FID structure.
-        """
-        return self.__databaseGuid
-
-    @property
-    def folderType(self) -> MessageType:
-        """
-        The type of folder.
-        """
-        return self.__folderType
-
-    @property
-    def globalCounter(self) -> int:
-        """
-        An unsigned integer identifying the folder.
-        """
-        return self.__globalCounter
-
-
-
-class MessageEntryID(EntryID):
-    """
-    A Message EntryID structure, as defined in [MS-OXCDATA].
-    """
-
-    __SIZE__ : int = 70
-
-    def __init__(self, data : bytes):
-        super().__init__(data)
-        reader = BytesReader(data[20:])
-        self.__messageType = MessageType(reader.readUnsignedShort())
-        self.__folderDatabaseGuid = bytesToGuid(reader.read(16))
-        # This entry is 6 bytes, so we pull some shenanigans to unpack it.
-        self.__folderGlobalCounter = constants.ST_LE_UI64.unpack(reader.read(6) + b'\x00\x00')
-        reader.assertNull(2, 'Pad bytes were not 0.')
-        self.__messageDatabaseGuid = bytesToGuid(reader.read(16))
-        # This entry is 6 bytes, so we pull some shenanigans to unpack it.
-        self.__messageGlobalCounter = constants.ST_LE_UI64.unpack(reader.read(6) + b'\x00\x00')
-        reader.assertNull(2, 'Pad bytes were not 0.')
-        # Not sure why Microsoft decided to say "yes, let's do 2 6-byte integers
-        # followed by 2 pad bits each" instead of just 2 8-byte integers with a
-        # maximum value, but here we are.
-
-    @property
-    def folderDatabaseGuid(self) -> str:
-        """
-        A GUID associated with the Store object of the folder in which the
-        message resides and corresponding to the ReplicaId field in the folder
-        ID structure.
-        """
-        return self.__folderDatabaseGuid
-
-    @property
-    def folderGlobalCounter(self) -> int:
-        """
-        An unsigned integer identifying the folder in which the message resides.
-        """
-        return self.__folderGlobalCounter
-
-    @property
-    def messageDatabaseGuid(self) -> str:
-        """
-        A GUID associated with the Store object of the message and corresponding
-        to the ReplicaId field of the Message ID structure.
-        """
-        return self.__messageDatabaseGuid
-
-    @property
-    def messageGlobalCounter(self) -> int:
-        """
-        An unsigned integer identifying the message.
-        """
-        return self.__messageGlobalCounter
-
-    @property
-    def messageType(self) -> MessageType:
-        """
-        The Store object type.
-        """
-        return self.__messageType
-
-
-
-class NNTPNewsgroupFolderEntryID(EntryID):
-    """
-    A NNTP Newsgroup Folder EntryID structure, as defined in [MS-OXCDATA].
-    """
-
-    def __init__(self, data : bytes):
-        super().__init__(data)
-        reader = BytesReader(data[20:])
-        self.__folderType = reader.readUnsignedShort()
-        if self.__folderType != 0x000C:
-            raise ValueError(f'Folder type was not 0x000C (got {self.__folderType})')
-        self.__newsgroupName = reader.readAnsiString()
-
-    @property
-    def folderType(self) -> int:
-        """
-        The type of folder. MUST be 0x000C.
-        """
-        return self.__folderType
-
-    @property
-    def newsgroupName(self) -> str:
-        """
-        The name of the newsgroup.
-        """
-        return self.__newsgroupName
-
-
-
-class OneOffRecipient(EntryID):
-    """
-    A One-Off EntryID structure, as specified in [MS-OXCDATA].
-    """
-
-    def __init__(self, data : bytes):
-        super().__init__(data)
-        # Create a reader to easily
-        reader = BytesReader(data[20:])
-        self.__version = reader.readUnsignedShort()
-        # It's not really flags, but I can't come up with a descriptive name for
-        # this collection of data, so `flagsThing` it is.
-        flagsThing = reader.readUnsignedShort()
-
-        # Just a little forewarning, I am *well* aware that these masks for each
-        # flag do not match the specification as you might expect. That is
-        # because, unlike with other parts of the documentation, these bytes
-        # are, for some reason, *not read together*. This means they are not
-        # meant to be swapped for little endian, and as such I had to flip the
-        # masks to compensate. Again, this is *despite other portions of the
-        # documentation using an identical format and being read in little
-        # endian. Took me way too long to figure out why this was not working
-        # despite following the documentation to the letter. If I had to guess,
-        # the reason this one is not flipped and the others are is because this
-        # is not grouped together.
-
-        self.__macintoshEncoding = MacintoshEncoding(bitwiseAdjustedAnd(flagsThing, 0xC))
-        self.__format = OORBodyFormat(bitwiseAdjustedAnd(flagsThing, 0x1E))
-        # Flag to indicate how messages are to be sent. 0 means TNEF, 1 means
-        # MIME.
-        self.__messageFormat = MessageFormat(bitwiseAdjustedAnd(flagsThing, 0x1))
-        # Whether the strings are UTF-16 or not.
-        self.__stringFormatUnicode = bitwiseAdjustedAnd(flagsThing, 0x8000) == 1
-        self.__canLookup = bitwiseAdjustedAnd(flagsThing, 0x1000) == 0
-        if self.__stringFormatUnicode:
-            self.__displayName = reader.readUtf16String()
-            self.__addressType = reader.readUtf16String()
-            self.__emailAddress = reader.readUtf16String()
-        else:
-            # Don't actually know how to properly handle this kind of encoding,
-            # since the documentation doesn't define exactly what encoding to
-            # use for this of even how to find out, so for now we just don't
-            # decode it at all and just leave it as bytes.
-            self.__displayName = reader.readByteString()
-            self.__addressType = reader.readByteString()
-            self.__emailAddress = reader.readByteString()
-
-    @property
-    def addressType(self) -> Union[str, bytes]:
-        """
-        The address type for this Recipient.
-        """
-        return self.__addressType
-
-    @property
-    def areStringUnicode(self) -> bool:
-        """
-        Whether or not the strings are in UTF-16 format.
-        """
-        return self.__stringFormatUnicode
-
-    @property
-    def canLookup(self) -> bool:
-        """
-        Whether the server can lookup the user's email in the address book.
-        """
-        return self.__canLookup
-
-    @property
-    def displayName(self) -> Union[str, bytes]:
-        """
-        The display name for this Recipient.
-        """
-        return self.__displayName
-
-    @property
-    def emailAddress(self) -> Union[str, bytes]:
-        """
-        The email address for this Recipient.
-        """
-        return self.__emailAddress
-
-    @property
-    def format(self) -> OORBodyFormat:
-        """
-        The message body format desired for this recipient.
-        """
-        return self.__format
-
-    @property
-    def macintoshEncoding(self) -> MacintoshEncoding:
-        """
-        The encoding used for Macintosh-specific data attachments.
-        """
-        return self.__macintoshEncoding
-
-    @property
-    def messageFormat(self) -> MessageFormat:
-        """
-        The message format to use for messages sent to this recipient.
-        """
-        return self.__messageFormat
-
-
-
-class PermanentEntryID(EntryID):
-    """
-    A Permanent EntryID structure, as defined in [MS-OXNSPI].
-    """
-
-    def __init__(self, data : bytes):
-        super().__init__(data)
-        unpacked = constants.STPEID.unpack(data[:28])
-        if unpacked[0] != 0:
-            raise TypeError(f'Not a PermanentEntryID (expected 0, got {unpacked[0]}).')
-        self.__displayTypeString = DisplayType(unpacked[2])
-        self.__distinguishedName = data[28:-1].decode('ascii') # Cut off the null character at the end and decode the data as ascii
-
-    @property
-    def displayTypeString(self) -> DisplayType:
-        """
-        Returns the display type string value.
-        """
-        return self.__displayTypeString
-
-    @property
-    def distinguishedName(self) -> str:
-        """
-        Returns the distinguished name.
-        """
-        return self.__distinguishedName
-
-
-
-class PersonalDistributionListEntryID(EntryID):
-    """
-    A Personal Distribution List EntryID structure, as defined in [MS-OXCDATA].
-    """
-
-    def __init__(self, data : bytes):
-        super().__init__(data)
-        reader = BytesReader(data[20:])
-        if reader.readUnsignedInt() != 3:
-            raise ValueError(f'Version must be 3 (got {self.__version}).')
-        if reader.readUnsignedInt() != 5:
-            raise ValueError(f'Type must be 5 (got {self.__version}).')
-        if reader.readUnsignedInt() != 0xFF:
-            raise ValueError(f'Index must be 255 (got {self.__version}).')
-        self.__entryIdCount = reader.readUnsignedInt()
-        self.__entryID = MessageEntryID(reader.read(self.__entryIdCount))
-
-    @property
-    def entryID(self) -> MessageEntryID:
-        """
-        The EntryID contained in this object.
-        """
-        return self.__entryID
-
-    @property
-    def entryIDCount(self) -> int:
-        """
-        The size, in bytes, of the EntryID contained in this object.
-        """
-        return self.__entryIdCount
-
-
-class StoreObjectEntryID(EntryID):
-    """
-    A Store Object EntryID structure, as defined in [MS-OXCDATA].
-    """
-
-    def __init__(self, data : bytes):
-        super().__init__(data)
-        reader = BytesReader(data[20:])
-
-        self.__version = reader.readUnsignedByte()
-        if self.__version != 0:
-            raise ValueError(f'Version was not set to 0 (got {self.__version}).')
-
-        self.__flag = reader.readUnsignedByte()
-        if self.__flag != 0:
-            raise ValueError(f'Flag was not set to 0 (got {self.__flag}).')
-
-        self.__dllFileName = reader.read(14)
-
-        self.__wrappedFlags = reader.readUnsignedInt()
-        if self.__wrappedFlags != 0:
-            raise ValueError(f'Wrapped flags was not set to 0 (got {self.__wrappedFlags}).')
-
-    @property
-    def dllFileName(self) -> bytes:
-        """
-        Must be set to b'emsmdb.dll\\x00\\x00\\x00\\x00'.
-        """
-        return self.__dllFileName
-
-    @property
-    def flag(self) -> int:
-        return self.__flag
-
-    @property
-    def version(self) -> int:
-        return self.__version
-
-
-class WrappedEntryID(EntryID):
-    """
-    A WrappedEntryId structure, as specified in [MS-OXOCNTC].
-    """
-
-    def __init__(self, data : bytes):
-        super().__init__(data)
-        # Grab the type byte and parse it.
-        self.__type = data[20]
-        bits = self.__type & 0xF
-        if bits == 0:
-            self.__embeddedEntryID = OneOffRecipient(data[21:])
-        elif bits == 3 or bits == 4:
-            self.__embeddedEntryID = MessageEntryID(data[21:])
-        elif bits == 5 or bits == 6:
-            self.__embeddedEntryID = AddressBookEntryID(data[21:])
-        else:
-            raise ValueError(f'Found wrapped entry id with invalid type (type bits were {bits}).')
-
-        self.__embeddedIsOneOff = self.__type & 0x80 == 0
-
-    @property
-    def embeddedEntryID(self) -> EntryID:
-        """
-        The embedded EntryID of this object.
-        """
-        return self.__embeddedEntryID
-
-    @property
-    def embeddedIsOneOff(self) -> bool:
-        """
-        Whether the embedded EntryID is a One-Off EntryID.
-        """
-        return self.__embeddedIsOneOff
-
-    @property
-    def type(self) -> int:
-        """
-        The type bits of this object.
-        """
-        return self.__type
+__all__ = [
+    'AddressBookEntryID',
+    'ContactAddressEntryID',
+    'EntryID',
+    'FolderEntryID',
+    'MessageEntryID',
+    'NNTPNewsgroupFolderEntryID',
+    'OneOffRecipient',
+    'PermanentEntryID',
+    'PersonalDistributionListEntryID',
+    'StoreObjectEntryID',
+    'WrappedEntryID',
+]
+
+
+import logging
+from typing import Union
+
+from ._helpers import BytesReader
+from .. import constants
+from ..enums import AddressBookType, ContactAddressIndex, DisplayType, EntryIDType, MacintoshEncoding, MessageFormat, MessageType, OORBodyFormat
+from ..utils import bitwiseAdjustedAnd, bytesToGuid
+
+
+logger = logging.getLogger(__name__)
+logger.addHandler(logging.NullHandler())
+
+
+# First we define the main EntryID structure that is the base for the others.
+class EntryID:
+    """
+    Base class for all EntryID structures. Use :classmethod autoCreate: to
+    automatically create the correct EntryID structure type from the specified
+    data.
+    """
+
+    @classmethod
+    def autoCreate(cls, data) -> 'EntryID':
+        """
+        Automatically determines the type of EntryID and returns an instance of
+        the correct subclass. If the subclass cannot be determined, will return
+        a plain EntryID instance.
+        """
+        if len(data) < 20:
+            raise ValueError('Cannot create an EntryID with less than 20 bytes.')
+        providerUID = data[4:20]
+        try:
+            providerUID = EntryIDType(providerUID)
+        except ValueError:
+            raise ValueError(f'Unrecognized UID "{"".join(f"{x:02X}" for x in providerUID)}". You should probably report this to the developers.') from None
+
+        # Now check the Provider UID against the known ones.
+        if providerUID == EntryIDType.ADDRESS_BOOK_RECIPIENT:
+            return AddressBookEntryID(data)
+        if providerUID == EntryIDType.CA_OR_PDL_RECIPIENT:
+            # Verify that the type signature is correct.
+            if data[24:28] not in (b'\x04\x00\x00\x00', b'\x05\x00\x00\x00'):
+                raise ValueError(f'Found Entry ID matching ContactAddress or PersonalDistributionList but the type was invalid ({data[24:28]}).')
+            if data[24] == 4:
+                return ContactAddressEntryID(data)
+            else:
+                return PersonalDistributionListEntryID(data)
+        if providerUID == EntryIDType.NNTP_NEWSGROUP_FOLDER:
+            # This is, of course, another one with a shared unique identifier.
+            # Technically it's the UID of the provider, but why do multiple
+            # structures use the same provider?
+            if data[20] == 0xC:
+                return NNTPNewsgroupFolderEntryID(data)
+            else:
+                return StoreObjectEntryID(data)
+        if providerUID == EntryIDType.ONE_OFF_RECIPIENT:
+            return OneOffRecipient(data)
+        if providerUID == EntryIDType.PUBLIC_MESSAGE_STORE:
+            if len(data) == 46:
+                return FolderEntryID(data)
+            else:
+                return MessageEntryID(data)
+        if providerUID == EntryIDType.WRAPPED:
+            return WrappedEntryID(data)
+
+        logger.warn(f'UID for EntryID found in database, but no class was specified for it: {providerUID}')
+        # If all else fails and we do recognize it, just return a plain EntryID.
+        return cls(data)
+
+    def __init__(self, data : bytes):
+        self.__flags = data[:4]
+        self.__providerUID = data[4:20]
+        self.__rawData = data
+
+    @property
+    def flags(self) -> bytes:
+        """
+        The flags for this Entry ID.
+        """
+        return self.__flags
+
+    @property
+    def entryIDType(self) -> Union[EntryIDType, bytes]:
+        """
+        Returns an instance of EntryIDType corresponding to the provider UID of
+        this EntryID. If none is found, returns the bytes.
+        """
+        try:
+            return EntryIDType(self.__providerUID)
+        except ValueError:
+            return self.__providerUID
+
+    @property
+    def longTerm(self) -> bool:
+        """
+        Whether the EntryID is long term or not.
+        """
+        return self.__flags == b'\x00\x00\x00\x00'
+
+    @property
+    def providerUID(self) -> bytes:
+        """
+        The 16 byte UID that identifies the type of Entry ID.
+        """
+        return self.__providerUID
+
+    @property
+    def rawData(self) -> bytes:
+        """
+        The raw bytes used in this Entry ID.
+        """
+        return self.__rawData
+
+
+
+# Now for the specific types.
+class AddressBookEntryID(EntryID):
+    """
+    An Address Book EntryID structure, as specified in [MS-OXCDATA].
+    """
+
+    def __init__(self, data : bytes):
+        super().__init__(data)
+        reader = BytesReader(data[20:])
+        # Version *MUST* be 1.
+        self.__version = reader.readUnsignedInt()
+        if self.__version != 1:
+            raise ValueError(f'Version must be 1 on address book entry IDs (got {self.__version}).')
+
+        self.__type = AddressBookType(reader.readUnsignedInt())
+        self.__X500DN = reader.readByteString()
+
+    @property
+    def type(self) -> AddressBookType:
+        """
+        The type of the object.
+        """
+        return self.__type
+
+    @property
+    def version(self) -> int:
+        """
+        The version. MUST be 1.
+        """
+        return self.__version
+
+    @property
+    def X5000DN(self) -> bytes:
+        """
+        The X500 DN of the Address Book object.
+        """
+        return self.__X500DN
+
+
+
+class ContactAddressEntryID(EntryID):
+    """
+    A Contact Address EntryID structure, as defined in [MS-OXCDATA]. Specifies a
+    set of data representing recipients whose information is stored in a Contact
+    object.
+    """
+
+    def __init__(self, data : bytes):
+        super().__init__(data)
+        reader = BytesReader(data[20:])
+        if reader.readUnsignedInt() != 3:
+            raise ValueError(f'Version must be 3 (got {self.__version}).')
+        if reader.readUnsignedInt() != 5:
+            raise ValueError(f'Type must be 4 (got {self.__version}).')
+        self.__index = ContactAddressIndex(reader.readUnsignedInt())
+        self.__entryIdCount = reader.readUnsignedInt()
+        self.__entryID = MessageEntryID(reader.read(self.__entryIdCount))
+
+    @property
+    def entryID(self) -> 'MessageEntryID':
+        """
+        The EntryID contained in this object.
+        """
+        return self.__entryID
+
+    @property
+    def entryIDCount(self) -> int:
+        """
+        The size, in bytes, of the EntryID contained in this object.
+        """
+        return self.__entryIdCount
+
+    @property
+    def index(self) -> ContactAddressIndex:
+        """
+        The electronic address in the contact information to use.
+        """
+        return self.__index
+
+
+
+class FolderEntryID(EntryID):
+    """
+    A Folder EntryID structure, as defined in [MS-OXCDATA].
+    """
+
+    __SIZE__ : int = 46
+
+    def __init__(self, data : bytes):
+        super().__init__(data)
+        reader = BytesReader(data[20:])
+        self.__folderType = MessageType(reader.readUnsignedShort())
+        self.__databaseGuid = bytesToGuid(reader.read(16))
+        # This entry is 6 bytes, so we pull some shenanigans to unpack it.
+        self.__globalCounter = constants.ST_LE_UI64.unpack(reader.read(6) + b'\x00\x00')
+        reader.assertNull(2, 'Pad bytes were not 0.')
+
+    @property
+    def databaseGuid(self) -> str:
+        """
+        A GUID associated with the Store Object and corresponding to the
+        ReplicaID field of the FID structure.
+        """
+        return self.__databaseGuid
+
+    @property
+    def folderType(self) -> MessageType:
+        """
+        The type of folder.
+        """
+        return self.__folderType
+
+    @property
+    def globalCounter(self) -> int:
+        """
+        An unsigned integer identifying the folder.
+        """
+        return self.__globalCounter
+
+
+
+class MessageEntryID(EntryID):
+    """
+    A Message EntryID structure, as defined in [MS-OXCDATA].
+    """
+
+    __SIZE__ : int = 70
+
+    def __init__(self, data : bytes):
+        super().__init__(data)
+        reader = BytesReader(data[20:])
+        self.__messageType = MessageType(reader.readUnsignedShort())
+        self.__folderDatabaseGuid = bytesToGuid(reader.read(16))
+        # This entry is 6 bytes, so we pull some shenanigans to unpack it.
+        self.__folderGlobalCounter = constants.ST_LE_UI64.unpack(reader.read(6) + b'\x00\x00')
+        reader.assertNull(2, 'Pad bytes were not 0.')
+        self.__messageDatabaseGuid = bytesToGuid(reader.read(16))
+        # This entry is 6 bytes, so we pull some shenanigans to unpack it.
+        self.__messageGlobalCounter = constants.ST_LE_UI64.unpack(reader.read(6) + b'\x00\x00')
+        reader.assertNull(2, 'Pad bytes were not 0.')
+        # Not sure why Microsoft decided to say "yes, let's do 2 6-byte integers
+        # followed by 2 pad bits each" instead of just 2 8-byte integers with a
+        # maximum value, but here we are.
+
+    @property
+    def folderDatabaseGuid(self) -> str:
+        """
+        A GUID associated with the Store object of the folder in which the
+        message resides and corresponding to the ReplicaId field in the folder
+        ID structure.
+        """
+        return self.__folderDatabaseGuid
+
+    @property
+    def folderGlobalCounter(self) -> int:
+        """
+        An unsigned integer identifying the folder in which the message resides.
+        """
+        return self.__folderGlobalCounter
+
+    @property
+    def messageDatabaseGuid(self) -> str:
+        """
+        A GUID associated with the Store object of the message and corresponding
+        to the ReplicaId field of the Message ID structure.
+        """
+        return self.__messageDatabaseGuid
+
+    @property
+    def messageGlobalCounter(self) -> int:
+        """
+        An unsigned integer identifying the message.
+        """
+        return self.__messageGlobalCounter
+
+    @property
+    def messageType(self) -> MessageType:
+        """
+        The Store object type.
+        """
+        return self.__messageType
+
+
+
+class NNTPNewsgroupFolderEntryID(EntryID):
+    """
+    A NNTP Newsgroup Folder EntryID structure, as defined in [MS-OXCDATA].
+    """
+
+    def __init__(self, data : bytes):
+        super().__init__(data)
+        reader = BytesReader(data[20:])
+        self.__folderType = reader.readUnsignedShort()
+        if self.__folderType != 0x000C:
+            raise ValueError(f'Folder type was not 0x000C (got {self.__folderType})')
+        self.__newsgroupName = reader.readAnsiString()
+
+    @property
+    def folderType(self) -> int:
+        """
+        The type of folder. MUST be 0x000C.
+        """
+        return self.__folderType
+
+    @property
+    def newsgroupName(self) -> str:
+        """
+        The name of the newsgroup.
+        """
+        return self.__newsgroupName
+
+
+
+class OneOffRecipient(EntryID):
+    """
+    A One-Off EntryID structure, as specified in [MS-OXCDATA].
+    """
+
+    def __init__(self, data : bytes):
+        super().__init__(data)
+        # Create a reader to easily
+        reader = BytesReader(data[20:])
+        self.__version = reader.readUnsignedShort()
+        # It's not really flags, but I can't come up with a descriptive name for
+        # this collection of data, so `flagsThing` it is.
+        flagsThing = reader.readUnsignedShort()
+
+        # Just a little forewarning, I am *well* aware that these masks for each
+        # flag do not match the specification as you might expect. That is
+        # because, unlike with other parts of the documentation, these bytes
+        # are, for some reason, *not read together*. This means they are not
+        # meant to be swapped for little endian, and as such I had to flip the
+        # masks to compensate. Again, this is *despite other portions of the
+        # documentation using an identical format and being read in little
+        # endian. Took me way too long to figure out why this was not working
+        # despite following the documentation to the letter. If I had to guess,
+        # the reason this one is not flipped and the others are is because this
+        # is not grouped together.
+
+        self.__macintoshEncoding = MacintoshEncoding(bitwiseAdjustedAnd(flagsThing, 0xC))
+        self.__format = OORBodyFormat(bitwiseAdjustedAnd(flagsThing, 0x1E))
+        # Flag to indicate how messages are to be sent. 0 means TNEF, 1 means
+        # MIME.
+        self.__messageFormat = MessageFormat(bitwiseAdjustedAnd(flagsThing, 0x1))
+        # Whether the strings are UTF-16 or not.
+        self.__stringFormatUnicode = bitwiseAdjustedAnd(flagsThing, 0x8000) == 1
+        self.__canLookup = bitwiseAdjustedAnd(flagsThing, 0x1000) == 0
+        if self.__stringFormatUnicode:
+            self.__displayName = reader.readUtf16String()
+            self.__addressType = reader.readUtf16String()
+            self.__emailAddress = reader.readUtf16String()
+        else:
+            # Don't actually know how to properly handle this kind of encoding,
+            # since the documentation doesn't define exactly what encoding to
+            # use for this of even how to find out, so for now we just don't
+            # decode it at all and just leave it as bytes.
+            self.__displayName = reader.readByteString()
+            self.__addressType = reader.readByteString()
+            self.__emailAddress = reader.readByteString()
+
+    @property
+    def addressType(self) -> Union[str, bytes]:
+        """
+        The address type for this Recipient.
+        """
+        return self.__addressType
+
+    @property
+    def areStringUnicode(self) -> bool:
+        """
+        Whether or not the strings are in UTF-16 format.
+        """
+        return self.__stringFormatUnicode
+
+    @property
+    def canLookup(self) -> bool:
+        """
+        Whether the server can lookup the user's email in the address book.
+        """
+        return self.__canLookup
+
+    @property
+    def displayName(self) -> Union[str, bytes]:
+        """
+        The display name for this Recipient.
+        """
+        return self.__displayName
+
+    @property
+    def emailAddress(self) -> Union[str, bytes]:
+        """
+        The email address for this Recipient.
+        """
+        return self.__emailAddress
+
+    @property
+    def format(self) -> OORBodyFormat:
+        """
+        The message body format desired for this recipient.
+        """
+        return self.__format
+
+    @property
+    def macintoshEncoding(self) -> MacintoshEncoding:
+        """
+        The encoding used for Macintosh-specific data attachments.
+        """
+        return self.__macintoshEncoding
+
+    @property
+    def messageFormat(self) -> MessageFormat:
+        """
+        The message format to use for messages sent to this recipient.
+        """
+        return self.__messageFormat
+
+
+
+class PermanentEntryID(EntryID):
+    """
+    A Permanent EntryID structure, as defined in [MS-OXNSPI].
+    """
+
+    def __init__(self, data : bytes):
+        super().__init__(data)
+        unpacked = constants.STPEID.unpack(data[:28])
+        if unpacked[0] != 0:
+            raise TypeError(f'Not a PermanentEntryID (expected 0, got {unpacked[0]}).')
+        self.__displayTypeString = DisplayType(unpacked[2])
+        self.__distinguishedName = data[28:-1].decode('ascii') # Cut off the null character at the end and decode the data as ascii
+
+    @property
+    def displayTypeString(self) -> DisplayType:
+        """
+        Returns the display type string value.
+        """
+        return self.__displayTypeString
+
+    @property
+    def distinguishedName(self) -> str:
+        """
+        Returns the distinguished name.
+        """
+        return self.__distinguishedName
+
+
+
+class PersonalDistributionListEntryID(EntryID):
+    """
+    A Personal Distribution List EntryID structure, as defined in [MS-OXCDATA].
+    """
+
+    def __init__(self, data : bytes):
+        super().__init__(data)
+        reader = BytesReader(data[20:])
+        if reader.readUnsignedInt() != 3:
+            raise ValueError(f'Version must be 3 (got {self.__version}).')
+        if reader.readUnsignedInt() != 5:
+            raise ValueError(f'Type must be 5 (got {self.__version}).')
+        if reader.readUnsignedInt() != 0xFF:
+            raise ValueError(f'Index must be 255 (got {self.__version}).')
+        self.__entryIdCount = reader.readUnsignedInt()
+        self.__entryID = MessageEntryID(reader.read(self.__entryIdCount))
+
+    @property
+    def entryID(self) -> MessageEntryID:
+        """
+        The EntryID contained in this object.
+        """
+        return self.__entryID
+
+    @property
+    def entryIDCount(self) -> int:
+        """
+        The size, in bytes, of the EntryID contained in this object.
+        """
+        return self.__entryIdCount
+
+
+class StoreObjectEntryID(EntryID):
+    """
+    A Store Object EntryID structure, as defined in [MS-OXCDATA].
+    """
+
+    def __init__(self, data : bytes):
+        super().__init__(data)
+        reader = BytesReader(data[20:])
+
+        self.__version = reader.readUnsignedByte()
+        if self.__version != 0:
+            raise ValueError(f'Version was not set to 0 (got {self.__version}).')
+
+        self.__flag = reader.readUnsignedByte()
+        if self.__flag != 0:
+            raise ValueError(f'Flag was not set to 0 (got {self.__flag}).')
+
+        self.__dllFileName = reader.read(14)
+
+        self.__wrappedFlags = reader.readUnsignedInt()
+        if self.__wrappedFlags != 0:
+            raise ValueError(f'Wrapped flags was not set to 0 (got {self.__wrappedFlags}).')
+
+    @property
+    def dllFileName(self) -> bytes:
+        """
+        Must be set to b'emsmdb.dll\\x00\\x00\\x00\\x00'.
+        """
+        return self.__dllFileName
+
+    @property
+    def flag(self) -> int:
+        return self.__flag
+
+    @property
+    def version(self) -> int:
+        return self.__version
+
+
+class WrappedEntryID(EntryID):
+    """
+    A WrappedEntryId structure, as specified in [MS-OXOCNTC].
+    """
+
+    def __init__(self, data : bytes):
+        super().__init__(data)
+        # Grab the type byte and parse it.
+        self.__type = data[20]
+        bits = self.__type & 0xF
+        if bits == 0:
+            self.__embeddedEntryID = OneOffRecipient(data[21:])
+        elif bits == 3 or bits == 4:
+            self.__embeddedEntryID = MessageEntryID(data[21:])
+        elif bits == 5 or bits == 6:
+            self.__embeddedEntryID = AddressBookEntryID(data[21:])
+        else:
+            raise ValueError(f'Found wrapped entry id with invalid type (type bits were {bits}).')
+
+        self.__embeddedIsOneOff = self.__type & 0x80 == 0
+
+    @property
+    def embeddedEntryID(self) -> EntryID:
+        """
+        The embedded EntryID of this object.
+        """
+        return self.__embeddedEntryID
+
+    @property
+    def embeddedIsOneOff(self) -> bool:
+        """
+        Whether the embedded EntryID is a One-Off EntryID.
+        """
+        return self.__embeddedIsOneOff
+
+    @property
+    def type(self) -> int:
+        """
+        The type bits of this object.
+        """
+        return self.__type
```

### Comparing `extract_msg-0.40.0/extract_msg/structures/recurrence_pattern.py` & `extract_msg-0.41.0/extract_msg/structures/recurrence_pattern.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,191 +1,197 @@
-from typing import Any, Tuple
-
-from .. import constants
-from ..enums import RecurCalendarType, RecurDOW, RecurEndType, RecurFrequency, RecurMonthNthWeek, RecurPatternType, RecurPatternTypeSpecificWeekday
-from ._helpers import BytesReader
-
-
-class RecurrencePattern:
-    """
-    A RecurrencePattern structure, as specified in [MS-OXOCAL].
-    """
-
-    def __init__(self, data : bytes):
-        self.__rawData = data
-        reader = BytesReader(data)
-        self.__readerVersion = reader.readUnsignedShort()
-        self.__writerVersion = reader.readUnsignedShort()
-        if not (self.__readerVersion == self.__writerVersion == 0x3004):
-            raise ValueError('Reader version or writer version was not set to 0x3004.')
-
-        self.__recurFrequency = RecurFrequency(reader.readUnsignedShort())
-        self.__patternType = RecurPatternType(reader.readUnsignedShort())
-        self.__calendarType = RecurCalendarType(reader.readUnsignedShort())
-        self.__firstDateTime = reader.readUnsignedInt()
-        self.__period = reader.readUnsignedInt()
-        self.__slidingFlag = reader.readUnsignedInt()
-        # This is just here to help shorten lines.
-        RPTSW = RecurPatternTypeSpecificWeekday
-        # This field changes depending on the recurrence type.
-        if self.__patternType == RecurPatternType.DAY:
-            self.__patternTypeSpecific = None
-        elif self.__patternType == RecurPatternType.WEEK:
-            self.__paternTypeSpecific = RPTSW.fromBits(reader.readUnsignedInt())
-        elif self.__patternType in (RecurPatternType.MONTH_NTH, RecurPatternType.HJ_MONTH_NTH):
-            self.__patternTypeSpecific = reader.readUnsignedInt()
-        else:
-            self.__patternTypeSpecific = (RPTSW.fromBits(reader.readUnsignedInt()),
-                                          RecurMonthNthWeek(reader.readUnsignedInt()))
-
-        self.__endType = RecurEndType.fromInt(reader.readUnsignedInt())
-        self.__occurrenceCount = reader.readUnsignedInt()
-        self.__firstDOW = RecurDOW(reader.readUnsignedInt())
-        deletedInstanceCount = reader.readUnsignedInt()
-        self.__deletedInstanceDates = tuple(reader.readUnsignedInt() for x in range(deletedInstanceCount))
-        modifiedInstanceCount = reader.readUnsignedInt()
-        self.__modifiedInstanceDates = tuple(reader.readUnsignedInt() for x in range(deletedInstanceCount))
-        self.__startDate = reader.readUnsignedInt()
-        self.__endDate = reader.readUnsignedInt()
-
-    @property
-    def calendarType(self) -> RecurCalendarType:
-        """
-        The type of calendar that is used.
-        """
-        return self.__calendarType
-
-    @property
-    def deletedInstanceDates() -> Tuple[int]:
-        """
-        A tuple of the dates (stored as number of minutes between midnight,
-        January 1, 1601, and midnight on the specified day in the timezone
-        specified in the calendar object), ordered from earliest to latest, of
-        either a deleted instance or a modified instance for this recurrence.
-        """
-        return self.__deletedInstanceDates
-
-    @property
-    def endDate(self) -> int:
-        """
-        An integer that specifies the ending date for the recurrence. The value
-        is the number of minutes between midnight, January 1, 1601, and midnight
-        of the date of the last occurrence. When the value of the endType field
-        is END_AFTER_N_OCCURRENCES, this value is calculated based on the number
-        of occurrences. If the recurrence does not have an end date, the value
-        of the endDate field MUST be set to 0x5AE980DF.
-        """
-        return self.__endDate
-
-    @property
-    def endType(self) -> RecurEndType:
-        """
-        The ending type for the recurrence.
-        """
-        return self.__endType
-
-    @property
-    def firstDateTime(self) -> int:
-        """
-        The first ever dat, week, or month of a recurring series, dating back to
-        a reference date, which is January 1, 1601, for a Gregorian calendar.
-        """
-        return self.__firstDateTime
-
-    @property
-    def firstDayOfWeek(self) -> RecurDOW:
-        """
-        The day on which the calendar week begins.
-        """
-        return self.__firstDOW
-
-    @property
-    def modifiedInstanceDates() -> Tuple[int]:
-        """
-        A tuple of the dates (stored as number of minutes between midnight,
-        January 1, 1601, and midnight on the specified day in the timezone
-        specified in the calendar object), ordered from earliest to latest, of
-        a modified instance.
-        """
-        return self.__deletedInstanceDates
-
-    @property
-    def occurrenceCount(self) -> int:
-        """
-        Number of occurrences for a recurrence that ends after N occurrences.
-        """
-        return self.__occurrenceCount
-
-    @property
-    def patternType(self) -> RecurPatternType:
-        """
-        The type of recurrence pattern.
-        """
-        return self.__patternType
-
-    @property
-    def patternTypeSpecific(self) -> Any:
-        """
-        The specifics for the pattern type. Return is different depending on
-        what type of pattern is being used.
-
-        RecurPatternType.DAY: No value is returned.
-        RecurPatternType.WEEK: A set of RecurPatternTypeSpecificWeekday bits.
-        RecurPatternType.MONTH: The day of the month on which the recurrence
-            falls.
-        RecurPatternType.MONTH_NTH: A tuple containing information from
-            [MS-OXOCAL] PatternTypeSpecific MonthNth.
-        RecurPatternType.MONTH_END: The day of the month on which the recurrence
-            falls.
-        RecurPatternType.HJ_MONTH: The day of the month on which the recurrence
-            falls.
-        RecurPatternType.HJ_MONTH_NTH: A tuple containing information from
-            [MS-OXOCAL] PatternTypeSpecific MonthNth.
-        RecurPatternType.HJ_MONTH_END: The day of the month on which the
-            recurrence falls.
-        """
-
-    @property
-    def period(self) -> int:
-        """
-        An integer that specifies the interval at which the meeting pattern
-        specified in PatternTypeSpecific field repeats. The Period value MUST be
-        between 1 and the maximum recurrence interval, which is 999 days for
-        daily recurrences, 99 weeks for weekly recurrences, and 99 months for
-        monthly recurrences.
-        """
-        return self.__period
-
-    @property
-    def rawData(self) -> bytes:
-        """
-        The raw bytes used to create this object.
-        """
-        return self.__rawData
-
-    @property
-    def readerVersion(self) -> int:
-        return self.__readerVersion
-
-    @property
-    def recurFrequency(self) -> RecurFrequency:
-        """
-        The frequency of the recurring series.
-        """
-        return self.__recurFrequency
-
-    @property
-    def slidingFlag(self) -> int:
-        return self.__slidingFlag
-
-    @property
-    def startDate(self) -> int:
-        """
-        An integer that specifies the date of the first occurrence. The value is
-        the number of minutes between midnight, January 1, 1601, and midnight of
-        the date of the first occurrence.
-        """
-        return self.__startDate
-
-    @property
-    def writerVersion(self) -> int:
-        return self.__writerVersion
+__all__ = [
+    'RecurrencePattern',
+]
+
+
+from typing import Any, Tuple
+
+from .. import constants
+from ..enums import RecurCalendarType, RecurDOW, RecurEndType, RecurFrequency, RecurMonthNthWeek, RecurPatternType, RecurPatternTypeSpecificWeekday
+from ._helpers import BytesReader
+
+
+class RecurrencePattern:
+    """
+    A RecurrencePattern structure, as specified in [MS-OXOCAL].
+    """
+
+    def __init__(self, data : bytes):
+        self.__rawData = data
+        reader = BytesReader(data)
+        self.__readerVersion = reader.readUnsignedShort()
+        self.__writerVersion = reader.readUnsignedShort()
+        if not (self.__readerVersion == self.__writerVersion == 0x3004):
+            raise ValueError('Reader version or writer version was not set to 0x3004.')
+
+        self.__recurFrequency = RecurFrequency(reader.readUnsignedShort())
+        self.__patternType = RecurPatternType(reader.readUnsignedShort())
+        self.__calendarType = RecurCalendarType(reader.readUnsignedShort())
+        self.__firstDateTime = reader.readUnsignedInt()
+        self.__period = reader.readUnsignedInt()
+        self.__slidingFlag = reader.readUnsignedInt()
+        # This is just here to help shorten lines.
+        RPTSW = RecurPatternTypeSpecificWeekday
+        # This field changes depending on the recurrence type.
+        if self.__patternType == RecurPatternType.DAY:
+            self.__patternTypeSpecific = None
+        elif self.__patternType == RecurPatternType.WEEK:
+            self.__patternTypeSpecific = RPTSW.fromBits(reader.readUnsignedInt())
+        elif self.__patternType in (RecurPatternType.MONTH_NTH, RecurPatternType.HJ_MONTH_NTH):
+            self.__patternTypeSpecific = reader.readUnsignedInt()
+        else:
+            self.__patternTypeSpecific = (RPTSW.fromBits(reader.readUnsignedInt()),
+                                          RecurMonthNthWeek(reader.readUnsignedInt()))
+
+        self.__endType = RecurEndType.fromInt(reader.readUnsignedInt())
+        self.__occurrenceCount = reader.readUnsignedInt()
+        self.__firstDOW = RecurDOW(reader.readUnsignedInt())
+        deletedInstanceCount = reader.readUnsignedInt()
+        self.__deletedInstanceDates = tuple(reader.readUnsignedInt() for x in range(deletedInstanceCount))
+        modifiedInstanceCount = reader.readUnsignedInt()
+        self.__modifiedInstanceDates = tuple(reader.readUnsignedInt() for x in range(modifiedInstanceCount))
+        self.__startDate = reader.readUnsignedInt()
+        self.__endDate = reader.readUnsignedInt()
+
+    @property
+    def calendarType(self) -> RecurCalendarType:
+        """
+        The type of calendar that is used.
+        """
+        return self.__calendarType
+
+    @property
+    def deletedInstanceDates(self) -> Tuple[int]:
+        """
+        A tuple of the dates (stored as number of minutes between midnight,
+        January 1, 1601, and midnight on the specified day in the timezone
+        specified in the calendar object), ordered from earliest to latest, of
+        either a deleted instance or a modified instance for this recurrence.
+        """
+        return self.__deletedInstanceDates
+
+    @property
+    def endDate(self) -> int:
+        """
+        An integer that specifies the ending date for the recurrence. The value
+        is the number of minutes between midnight, January 1, 1601, and midnight
+        of the date of the last occurrence. When the value of the endType field
+        is END_AFTER_N_OCCURRENCES, this value is calculated based on the number
+        of occurrences. If the recurrence does not have an end date, the value
+        of the endDate field MUST be set to 0x5AE980DF.
+        """
+        return self.__endDate
+
+    @property
+    def endType(self) -> RecurEndType:
+        """
+        The ending type for the recurrence.
+        """
+        return self.__endType
+
+    @property
+    def firstDateTime(self) -> int:
+        """
+        The first ever dat, week, or month of a recurring series, dating back to
+        a reference date, which is January 1, 1601, for a Gregorian calendar.
+        """
+        return self.__firstDateTime
+
+    @property
+    def firstDayOfWeek(self) -> RecurDOW:
+        """
+        The day on which the calendar week begins.
+        """
+        return self.__firstDOW
+
+    @property
+    def modifiedInstanceDates(self) -> Tuple[int]:
+        """
+        A tuple of the dates (stored as number of minutes between midnight,
+        January 1, 1601, and midnight on the specified day in the timezone
+        specified in the calendar object), ordered from earliest to latest, of
+        a modified instance.
+        """
+        return self.__modifiedInstanceDates
+
+    @property
+    def occurrenceCount(self) -> int:
+        """
+        Number of occurrences for a recurrence that ends after N occurrences.
+        """
+        return self.__occurrenceCount
+
+    @property
+    def patternType(self) -> RecurPatternType:
+        """
+        The type of recurrence pattern.
+        """
+        return self.__patternType
+
+    @property
+    def patternTypeSpecific(self) -> Any:
+        """
+        The specifics for the pattern type. Return is different depending on
+        what type of pattern is being used.
+
+        RecurPatternType.DAY: No value is returned.
+        RecurPatternType.WEEK: A set of RecurPatternTypeSpecificWeekday bits.
+        RecurPatternType.MONTH: The day of the month on which the recurrence
+            falls.
+        RecurPatternType.MONTH_NTH: A tuple containing information from
+            [MS-OXOCAL] PatternTypeSpecific MonthNth.
+        RecurPatternType.MONTH_END: The day of the month on which the recurrence
+            falls.
+        RecurPatternType.HJ_MONTH: The day of the month on which the recurrence
+            falls.
+        RecurPatternType.HJ_MONTH_NTH: A tuple containing information from
+            [MS-OXOCAL] PatternTypeSpecific MonthNth.
+        RecurPatternType.HJ_MONTH_END: The day of the month on which the
+            recurrence falls.
+        """
+        return self.__patternTypeSpecific
+
+    @property
+    def period(self) -> int:
+        """
+        An integer that specifies the interval at which the meeting pattern
+        specified in PatternTypeSpecific field repeats. The Period value MUST be
+        between 1 and the maximum recurrence interval, which is 999 days for
+        daily recurrences, 99 weeks for weekly recurrences, and 99 months for
+        monthly recurrences.
+        """
+        return self.__period
+
+    @property
+    def rawData(self) -> bytes:
+        """
+        The raw bytes used to create this object.
+        """
+        return self.__rawData
+
+    @property
+    def readerVersion(self) -> int:
+        return self.__readerVersion
+
+    @property
+    def recurFrequency(self) -> RecurFrequency:
+        """
+        The frequency of the recurring series.
+        """
+        return self.__recurFrequency
+
+    @property
+    def slidingFlag(self) -> int:
+        return self.__slidingFlag
+
+    @property
+    def startDate(self) -> int:
+        """
+        An integer that specifies the date of the first occurrence. The value is
+        the number of minutes between midnight, January 1, 1601, and midnight of
+        the date of the first occurrence.
+        """
+        return self.__startDate
+
+    @property
+    def writerVersion(self) -> int:
+        return self.__writerVersion
```

### Comparing `extract_msg-0.40.0/extract_msg/structures/report_tag.py` & `extract_msg-0.41.0/extract_msg/structures/report_tag.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,117 +1,122 @@
-from typing import Optional
-
-from ._helpers import BytesReader
-from .entry_id import EntryID, FolderEntryID, MessageEntryID, StoreObjectEntryID
-
-
-class ReportTag:
-    """
-    A Report Tag structure, as defined in [MS-OXOMSG].
-    """
-
-    def __init__(self, data : bytes):
-        self.__rawData = data
-        reader = BytesReader(data)
-
-        self.__cookie = reader.assertRead(b'PCDFEB09\x00')
-
-        self.__version = reader.readUnsignedInt()
-        entrySize = reader.readInt()
-        if entrySize:
-            self.__storeEntryID = StoreObjectEntryID(reader.read(entrySize))
-        else:
-            self.__storeEntryID = None
-
-        entrySize = reader.readInt()
-        if entrySize:
-            self.__folderEntryID = FolderEntryID(reader.read(entrySize))
-        else:
-            self.__folderEntryID = None
-
-        entrySize = reader.readInt()
-        if entrySize:
-            self.__messageEntryID = MessageEntryID(reader.read(entrySize))
-        else:
-            self.__messageEntryID = None
-
-        entrySize = reader.readInt()
-        if entrySize:
-            self.__searchFolderEntryID = FolderEntryID(reader.read(entrySize))
-        else:
-            self.__searchFolderEntryID = None
-
-        entrySize = reader.readInt()
-        if entrySize:
-            self.__messageSearchKey = reader.read(entrySize)
-        else:
-            self.__messageSearchKey = None
-
-        entrySize = reader.readInt()
-        if entrySize:
-            self.__ansiText = reader.read(entrySize)
-        else:
-            self.__ansiText = None
-
-    @property
-    def ansiText(self) -> Optional[bytes]:
-        """
-        The subject of the original message. Set to None if not present.
-        """
-        return self.__ansiText
-
-    @property
-    def cookie(self) -> bytes:
-        """
-        String used for validation. Set to b'PCDFEB09\x00'.
-        """
-        return self.__cookie
-
-    @property
-    def folderEntryID(self) -> Optional[EntryID]:
-        """
-        The EntryID of the folder than contains the original message.
-        """
-        return self.__folderEntryID
-
-    @property
-    def messageEntryID(self) -> Optional[EntryID]:
-        """
-        The EntryID of the original message.
-        """
-        return self.__messageEntryID
-
-    @property
-    def messageSearchKey(self) -> Optional[bytes]:
-        """
-        The search key of the original message.
-        """
-        return self.__messageSearchKey
-
-    @property
-    def rawData(self) -> bytes:
-        """
-        The raw bytes used to create this object.
-        """
-        return self.__rawData
-
-    @property
-    def searchFolderEntryID(self) -> Optional[EntryID]:
-        """
-        The EntryID of an alternate folder that contains the original message.
-        """
-        return self.__searchFolderEntryID
-
-    @property
-    def storeEntryID(self) -> Optional[EntryID]:
-        """
-        The EntryID of the mailbox that contains the original message.
-        """
-        return self.__storeEntryID
-
-    @property
-    def version(self) -> int:
-        """
-        The version used. If SearchFolderEntryID is present, this MUST be
-        0x00020001, otherwise it MUST be 0x00010001.
-        """
-        return self.__version
+__all__ = [
+    'ReportTag',
+]
+
+
+from typing import Optional
+
+from ._helpers import BytesReader
+from .entry_id import EntryID, FolderEntryID, MessageEntryID, StoreObjectEntryID
+
+
+class ReportTag:
+    """
+    A Report Tag structure, as defined in [MS-OXOMSG].
+    """
+
+    def __init__(self, data : bytes):
+        self.__rawData = data
+        reader = BytesReader(data)
+
+        self.__cookie = reader.assertRead(b'PCDFEB09\x00')
+
+        self.__version = reader.readUnsignedInt()
+        entrySize = reader.readInt()
+        if entrySize:
+            self.__storeEntryID = StoreObjectEntryID(reader.read(entrySize))
+        else:
+            self.__storeEntryID = None
+
+        entrySize = reader.readInt()
+        if entrySize:
+            self.__folderEntryID = FolderEntryID(reader.read(entrySize))
+        else:
+            self.__folderEntryID = None
+
+        entrySize = reader.readInt()
+        if entrySize:
+            self.__messageEntryID = MessageEntryID(reader.read(entrySize))
+        else:
+            self.__messageEntryID = None
+
+        entrySize = reader.readInt()
+        if entrySize:
+            self.__searchFolderEntryID = FolderEntryID(reader.read(entrySize))
+        else:
+            self.__searchFolderEntryID = None
+
+        entrySize = reader.readInt()
+        if entrySize:
+            self.__messageSearchKey = reader.read(entrySize)
+        else:
+            self.__messageSearchKey = None
+
+        entrySize = reader.readInt()
+        if entrySize:
+            self.__ansiText = reader.read(entrySize)
+        else:
+            self.__ansiText = None
+
+    @property
+    def ansiText(self) -> Optional[bytes]:
+        """
+        The subject of the original message. Set to None if not present.
+        """
+        return self.__ansiText
+
+    @property
+    def cookie(self) -> bytes:
+        """
+        String used for validation. Set to b'PCDFEB09\x00'.
+        """
+        return self.__cookie
+
+    @property
+    def folderEntryID(self) -> Optional[EntryID]:
+        """
+        The EntryID of the folder than contains the original message.
+        """
+        return self.__folderEntryID
+
+    @property
+    def messageEntryID(self) -> Optional[EntryID]:
+        """
+        The EntryID of the original message.
+        """
+        return self.__messageEntryID
+
+    @property
+    def messageSearchKey(self) -> Optional[bytes]:
+        """
+        The search key of the original message.
+        """
+        return self.__messageSearchKey
+
+    @property
+    def rawData(self) -> bytes:
+        """
+        The raw bytes used to create this object.
+        """
+        return self.__rawData
+
+    @property
+    def searchFolderEntryID(self) -> Optional[EntryID]:
+        """
+        The EntryID of an alternate folder that contains the original message.
+        """
+        return self.__searchFolderEntryID
+
+    @property
+    def storeEntryID(self) -> Optional[EntryID]:
+        """
+        The EntryID of the mailbox that contains the original message.
+        """
+        return self.__storeEntryID
+
+    @property
+    def version(self) -> int:
+        """
+        The version used. If SearchFolderEntryID is present, this MUST be
+        0x00020001, otherwise it MUST be 0x00010001.
+        """
+        return self.__version
```

### Comparing `extract_msg-0.40.0/extract_msg/structures/time_zone_definition.py` & `extract_msg-0.41.0/extract_msg/structures/time_zone_definition.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,59 +1,63 @@
-from typing import Tuple
-
-from .. import constants
-from ._helpers import BytesReader
-from .tz_rule import TZRule
-
-
-class TimeZoneDefinition:
-    """
-    Structure for PidLidAppointmentTimeZoneDefinitionRecur from [MS-OXOCAL].
-    """
-
-    def __init__(self, data : bytes):
-        self.__rawData = data
-        reader = BytesReader(data)
-        self.__majorVersion = reader.readUnsignedByte()
-        self.__minorVersion = reader.readUnsignedByte()
-        cbHeader = reader.readUnsignedShort()
-        reader.assertRead(b'\x02\x00')
-        cchKeyName = reader.readUnsignedShort()
-        self.__keyName = reader.read(2 * cchKeyName).decode('utf-16-le')
-        cRules = reader.readUnsignedShort()
-        self.__rules = tuple(reader.readClass(TZRule) for x in range(cRules))
-
-    @property
-    def keyName(self) -> str:
-        """
-        The name of the associated time zone. Not localized but instead set to
-        the unique name of the desired time zone.
-        """
-        return self.__keyName
-
-    @property
-    def majorVersion(self) -> int:
-        """
-        The major version.
-        """
-        return self.__majorVersion
-
-    @property
-    def minorVersion(self) -> int:
-        """
-        The minor version.
-        """
-        return self.__minorVersion
-
-    @property
-    def rawData(self) -> bytes:
-        """
-        The raw bytes used to create this object.
-        """
-        return self.__rawData
-
-    @property
-    def rules(self) -> Tuple[TZRule]:
-        """
-        A tuple of TZRule structures that specifies a time zone.
-        """
-        return self.__rules
+__all__ = [
+    'TimeZoneDefinition',
+]
+
+
+from typing import Tuple
+
+from ._helpers import BytesReader
+from .tz_rule import TZRule
+
+
+class TimeZoneDefinition:
+    """
+    Structure for PidLidAppointmentTimeZoneDefinitionRecur from [MS-OXOCAL].
+    """
+
+    def __init__(self, data : bytes):
+        self.__rawData = data
+        reader = BytesReader(data)
+        self.__majorVersion = reader.readUnsignedByte()
+        self.__minorVersion = reader.readUnsignedByte()
+        cbHeader = reader.readUnsignedShort()
+        reader.assertRead(b'\x02\x00')
+        cchKeyName = reader.readUnsignedShort()
+        self.__keyName = reader.read(2 * cchKeyName).decode('utf-16-le')
+        cRules = reader.readUnsignedShort()
+        self.__rules = tuple(reader.readClass(TZRule) for x in range(cRules))
+
+    @property
+    def keyName(self) -> str:
+        """
+        The name of the associated time zone. Not localized but instead set to
+        the unique name of the desired time zone.
+        """
+        return self.__keyName
+
+    @property
+    def majorVersion(self) -> int:
+        """
+        The major version.
+        """
+        return self.__majorVersion
+
+    @property
+    def minorVersion(self) -> int:
+        """
+        The minor version.
+        """
+        return self.__minorVersion
+
+    @property
+    def rawData(self) -> bytes:
+        """
+        The raw bytes used to create this object.
+        """
+        return self.__rawData
+
+    @property
+    def rules(self) -> Tuple[TZRule]:
+        """
+        A tuple of TZRule structures that specifies a time zone.
+        """
+        return self.__rules
```

### Comparing `extract_msg-0.40.0/extract_msg/structures/tz_rule.py` & `extract_msg-0.41.0/extract_msg/structures/tz_rule.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,113 +1,118 @@
-from typing import Set
-
-from .. import constants
-from ..enums import TZFlag
-from ._helpers import BytesReader
-from .system_time import SystemTime
-
-
-class TZRule:
-    """
-    A TZRule structure, as defined in [MS-OXOCAL].
-    """
-
-    __SIZE__ : int = 66
-
-    def __init__(self, data : bytes):
-        self.__rawData = data
-        reader = BytesReader(data)
-        self.__majorVersion = reader.readByte()
-        self.__minorVersion = reader.readByte()
-        reader.assertRead(b'\x3E\x00')
-        self.__flags = TZFlag.fromBits(reader.readUnsignedShort())
-        self.__year = reader.readShort()
-        # We *should* be doing this, but Outlook is violating the standard so...
-        #reader.assertNull(14)
-        self.__bias = reader.readInt()
-        self.__standardBias = reader.readInt()
-        self.__daylightBias = reader.readInt()
-        self.__standardDate = SystemTime(reader.read(16))
-        self.__daylightDate = SystemTime(reader.read(16))
-
-    @property
-    def bias(self) -> int:
-        """
-        The time zone's offset in minutes from UTC.
-        """
-        return self.__bias
-
-    @property
-    def daylightBias(self) -> int:
-        """
-        The offset in minutes from the value of the bias field during daylight
-        saving time.
-        """
-        return self.__daylightBias
-
-    @property
-    def daylightDate(self) -> SystemTime:
-        """
-        The date and local time that indicate when to begin using the value
-        specified in the daylightBias field. Uses the same format as
-        standardDate.
-        """
-        return self.__daylightDate
-
-    @property
-    def flags(self) -> Set[TZFlag]:
-        """
-        The flags for this rule.
-        """
-        return self.__flags
-
-    @property
-    def majorVersion(self) -> int:
-        """
-        The major version.
-        """
-        return self.__majorVersion
-
-    @property
-    def minorVersion(self) -> int:
-        """
-        The minor version.
-        """
-        return self.__minorVersion
-
-    @property
-    def rawData(self) -> bytes:
-        """
-        The raw bytes used to create this object.
-        """
-        return self.__rawData
-
-    @property
-    def standardBias(self) -> int:
-        """
-        The offset in minutes from the value of the bias field during standard
-        time.
-        """
-        return self.__standardBias
-
-    @property
-    def standardDate(self) -> SystemTime:
-        """
-        The date and local time that indicate when to begin using the value
-        specified in the standardBias field. If the time zone does not support
-        daylight's savings time, the month member must be 0. If the year is not
-        0, then it is an absolute date than only occurs once, otherwise it is a
-        relative date that occurs yearly.
-
-        See [MS-OXOCAL] for details.
-        """
-        return self.__standardDate
-
-    @property
-    def year(self) -> int:
-        """
-        The year this rule is scheduled to take place. A rule will remain in
-        effect from January 1 of it's year until January 1 of the next rule's
-        year field. If no rules exist for subsequent years, this rule will
-        remain in effect indefinately.
-        """
-        return self.__year
+__all__ = [
+    'TZRule',
+]
+
+
+from typing import Set
+
+from .. import constants
+from ..enums import TZFlag
+from ._helpers import BytesReader
+from .system_time import SystemTime
+
+
+class TZRule:
+    """
+    A TZRule structure, as defined in [MS-OXOCAL].
+    """
+
+    __SIZE__ : int = 66
+
+    def __init__(self, data : bytes):
+        self.__rawData = data
+        reader = BytesReader(data)
+        self.__majorVersion = reader.readByte()
+        self.__minorVersion = reader.readByte()
+        reader.assertRead(b'\x3E\x00')
+        self.__flags = TZFlag.fromBits(reader.readUnsignedShort())
+        self.__year = reader.readShort()
+        # We *should* be doing this, but Outlook is violating the standard so...
+        #reader.assertNull(14)
+        self.__bias = reader.readInt()
+        self.__standardBias = reader.readInt()
+        self.__daylightBias = reader.readInt()
+        self.__standardDate = SystemTime(reader.read(16))
+        self.__daylightDate = SystemTime(reader.read(16))
+
+    @property
+    def bias(self) -> int:
+        """
+        The time zone's offset in minutes from UTC.
+        """
+        return self.__bias
+
+    @property
+    def daylightBias(self) -> int:
+        """
+        The offset in minutes from the value of the bias field during daylight
+        saving time.
+        """
+        return self.__daylightBias
+
+    @property
+    def daylightDate(self) -> SystemTime:
+        """
+        The date and local time that indicate when to begin using the value
+        specified in the daylightBias field. Uses the same format as
+        standardDate.
+        """
+        return self.__daylightDate
+
+    @property
+    def flags(self) -> Set[TZFlag]:
+        """
+        The flags for this rule.
+        """
+        return self.__flags
+
+    @property
+    def majorVersion(self) -> int:
+        """
+        The major version.
+        """
+        return self.__majorVersion
+
+    @property
+    def minorVersion(self) -> int:
+        """
+        The minor version.
+        """
+        return self.__minorVersion
+
+    @property
+    def rawData(self) -> bytes:
+        """
+        The raw bytes used to create this object.
+        """
+        return self.__rawData
+
+    @property
+    def standardBias(self) -> int:
+        """
+        The offset in minutes from the value of the bias field during standard
+        time.
+        """
+        return self.__standardBias
+
+    @property
+    def standardDate(self) -> SystemTime:
+        """
+        The date and local time that indicate when to begin using the value
+        specified in the standardBias field. If the time zone does not support
+        daylight's savings time, the month member must be 0. If the year is not
+        0, then it is an absolute date than only occurs once, otherwise it is a
+        relative date that occurs yearly.
+
+        See [MS-OXOCAL] for details.
+        """
+        return self.__standardDate
+
+    @property
+    def year(self) -> int:
+        """
+        The year this rule is scheduled to take place. A rule will remain in
+        effect from January 1 of it's year until January 1 of the next rule's
+        year field. If no rules exist for subsequent years, this rule will
+        remain in effect indefinately.
+        """
+        return self.__year
```

### Comparing `extract_msg-0.40.0/extract_msg/task.py` & `extract_msg-0.41.0/extract_msg/task.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,347 +1,355 @@
-import datetime
-import logging
-
-from typing import Optional, Set
-
-from . import constants
-from .enums import TaskAcceptance, TaskHistory, TaskMode, TaskMultipleRecipients, TaskOwnership, TaskState, TaskStatus
-from .message_base import MessageBase
-from .structures.recurrence_pattern import RecurrencePattern
-from .utils import unsignedToSignedInt
-
-
-logger = logging.getLogger(__name__)
-logger.addHandler(logging.NullHandler())
-
-
-class Task(MessageBase):
-    """
-    Class used for parsing task files.
-    """
-
-    @property
-    def headerFormatProperties(self) -> constants.HEADER_FORMAT_TYPE:
-        """
-        Returns a dictionary of properties, in order, to be formatted into the
-        header. Keys are the names to use in the header while the values are one
-        of the following:
-        None: Signifies no data was found for the property and it should be
-            omitted from the header.
-        str: A string to be formatted into the header using the string encoding.
-        Tuple[Union[str, None], bool]: A string should be formatted into the
-            header. If the bool is True, then place an empty string if the value
-            is None, otherwise follow the same behavior as regular None.
-
-        Additional note: If the value is an empty string, it will be dropped as
-        well by default.
-
-        Additionally you can group members of a header together by placing them
-        in an embedded dictionary. Groups will be spaced out using a second
-        instance of the join string. If any member of a group is being printed,
-        it will be spaced apart from the next group/item.
-
-        If you class should not do *any* header injection, return None from this
-        property.
-        """
-        status = {
-            TaskStatus.NOT_STARTED: 'Not Started',
-            TaskStatus.IN_PROGRESS: 'In Progress',
-            TaskStatus.COMPLETE: 'Completed',
-            TaskStatus.WAITING_ON_OTHER: 'Waiting on someone else',
-            TaskStatus.DEFERRED: 'Deferred',
-            None: None,
-        }[self.taskStatus]
-
-        return {
-            '-basic info-': {
-                'Subject': self.subject,
-            },
-            '-status-': {
-                'Status': status,
-                'Percent Complete': f'{self.percentComplete*100:.0f}%',
-                'Date Completed': self.taskDateCompleted.__format__('%w, %B %d, %Y') if self.taskDateCompleted else None,
-            },
-            '-work-': {
-                'Total Work': f'{self.taskEstimatedEffort or 0} minutes',
-                'Actual Work': f'{self.taskActualEffort or 0} minutes',
-            },
-            '-owner-': {
-                'Owner': self.taskOwner,
-            },
-            '-importance-': {
-                'Importance': self.importanceString,
-            },
-        }
-
-    @property
-    def percentComplete(self) -> Optional[float]:
-        """
-        Indicates whether a time-flagged Message object is complete. Returns a
-        percentage in decimal form. 1.0 indicates it is complete.
-        """
-        return self._ensureSetNamed('_percentComplete', '8102', constants.PSETID_TASK)
-
-    @property
-    def taskAcceptanceState(self) -> Optional[TaskAcceptance]:
-        """
-        Indicates the acceptance state of the task.
-        """
-        return self._ensureSetNamed('_taskAcceptanceState', '812A', constants.PSETID_TASK, overrideClass = TaskAcceptance)
-
-    @property
-    def taskAccepted(self) -> bool:
-        """
-        Indicates whether a task assignee has replied to a tesk request for this
-        task object. Does not indicate if it was accepted or rejected.
-        """
-        return self._ensureSetNamed('_taskAccepted', '8108', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
-
-    @property
-    def taskActualEffort(self) -> Optional[int]:
-        """
-        Indicates the number of minutes that the user actually spent working on
-        a task.
-        """
-        return self._ensureSetNamed('_taskActualEffort', '8110', constants.PSETID_TASK)
-
-    @property
-    def taskAssigner(self) -> Optional[str]:
-        """
-        Specifies the name of the user that last assigned the task.
-        """
-        return self._ensureSetNamed('_taskAssigner', '8121', constants.PSETID_TASK)
-
-    @property
-    def taskAssigners(self) -> Optional[bytes]:
-        """
-        A stack of entries, each representing a task assigner. The most recent
-        task assigner (that is, the top) appears at the bottom.
-
-        The documentation on this is weird, so I don't know how to parse it.
-        """
-        return self._ensureSetNamed('_taskAssigners', '8117', constants.PSETID_TASK)
-
-    @property
-    def taskComplete(self) -> bool:
-        """
-        Indicates if the task is complete.
-        """
-        return self._ensureSetNamed('_taskComplete', '811C', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
-
-    @property
-    def taskCustomFlags(self) -> Optional[int]:
-        """
-        Custom flags set on the task.
-        """
-        return self._ensureSetNamed('_taskCustomFlags', '8139', constants.PSETID_TASK)
-
-    @property
-    def taskDateCompleted(self) -> Optional[datetime.datetime]:
-        """
-        The date when the user completed work on the task.
-        """
-        return self._ensureSetNamed('_taskDateCompleted', '810F', constants.PSETID_TASK)
-
-    @property
-    def taskDeadOccurrence(self) -> bool:
-        """
-        Indicates whether a new recurring task remains to be generated. Set to
-        False on a new Task object and True when the client generates the last
-        recurring task.
-        """
-        return self._ensureSetNamed('_taskDeadOccurrence', '8109', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
-
-    @property
-    def taskDueDate(self) -> Optional[datetime.datetime]:
-        """
-        Specifies the date by which the user expects work on the task to be
-        complete.
-        """
-        return self._ensureSetNamed('_taskDueDate', '8105', constants.PSETID_TASK)
-
-    @property
-    def taskEstimatedEffort(self) -> Optional[int]:
-        """
-        Indicates the number of minutes that the user expects to work on a task.
-        """
-        return self._ensureSetNamed('_taskEstimatedEffort', '8111', constants.PSETID_TASK)
-
-    @property
-    def taskFCreator(self) -> bool:
-        """
-        Indicates that the task object was originally created by the action of
-        the current user or user agent instead of by the processing of a task
-        request.
-        """
-        return self._ensureSetNamed('_taskFCreator', '811E', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
-
-    @property
-    def taskFFixOffline(self) -> bool:
-        """
-        Indicates whether the value of the taskOwner property is correct.
-        """
-        return self._ensureSetNamed('taskFFixOffline', '812C', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
-
-    @property
-    def taskFRecurring(self) -> bool:
-        """
-        Indicates whether the task includes a recurrence pattern.
-        """
-        return self._ensureSetNamed('_taskFRecurring', '8126', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
-
-    @property
-    def taskGlobalID(self) -> Optional[bytes]:
-        """
-        Specifies a unique GUID for this task, used to locate an existing task
-        upon receipt of a task response or task update.
-        """
-        return self._ensureSetNamed('_taskGlobalID', '8519', constants.PSETID_COMMON)
-
-    @property
-    def taskHistory(self) -> Optional[TaskHistory]:
-        """
-        Indicates the type of change that was last made to the Task object.
-        """
-        return self._ensureSetNamed('_taskHistory', '811A', constants.PSETID_TASK, overrideClass = TaskHistory)
-
-    @property
-    def taskLastDelegate(self) -> Optional[str]:
-        """
-        Contains the name of the user who most recently assigned the task, or
-        the user to whom it was most recently assigned.
-        """
-        return self._ensureSetNamed('_taskLastDelegate', '8125', constants.PSETID_TASK)
-
-    @property
-    def taskLastUpdate(self) -> Optional[datetime.datetime]:
-        """
-        The date and time of the most recent change made to the task object.
-        """
-        return self._ensureSetNamed('_taskLastUpdate', '8115', constants.PSETID_TASK)
-
-    @property
-    def taskLastUser(self) -> Optional[str]:
-        """
-        Contains the name of the most recent user to have been the owner of the
-        task.
-        """
-        return self._ensureSetNamed('_taskLastUser', '8122', constants.PSETID_TASK)
-
-    @property
-    def taskMode(self) -> Optional[TaskMode]:
-        """
-        Used in a task communication. Should be 0 (UNASSIGNED) on task objects.
-        """
-        return self._ensureSetNamed('_taskMode', '8518', constants.PSETID_COMMON, overrideClass = TaskMode)
-
-    @property
-    def taskMultipleRecipients(self) -> Optional[Set[TaskMultipleRecipients]]:
-        """
-        Returns a set of flags that specify optimization hints about the
-        recipients of a Task object.
-        """
-        return self._ensureSetNamed('_taskMultipleRecipients', '8120', constants.PSETID_TASK, overrideClass = TaskMultipleRecipients.fromBits)
-
-    @property
-    def taskNoCompute(self) -> Optional[bool]:
-        """
-        This value is not used and has no impact on a Task, but is provided for
-        completeness.
-        """
-        return self._ensureSetNamed('_taskNoCompute', '8124', constants.PSETID_TASK)
-
-    @property
-    def taskOrdinal(self) -> Optional[int]:
-        """
-        Specifies a number that aids custom sorting of Task objects.
-        """
-        return self._ensureSetNamed('_taskOrdinal', '8123', constants.PSETID_TASK, overrideClass = unsignedToSignedInt)
-
-    @property
-    def taskOwner(self) -> Optional[str]:
-        """
-        Contains the name of the owner of the task.
-        """
-        return self._ensureSetNamed('_taskOwner', '811F', constants.PSETID_TASK)
-
-    @property
-    def taskOwnership(self) -> Optional[TaskOwnership]:
-        """
-        Contains the name of the owner of the task.
-        """
-        return self._ensureSetNamed('_taskOwnership', '8129', constants.PSETID_TASK, overrideClass = TaskOwnership)
-
-    @property
-    def taskRecurrence(self) -> Optional[RecurrencePattern]:
-        """
-        Contains a RecurrencePattern structure that provides information about
-        recurring tasks.
-        """
-        return self._ensureSetNamed('_taskRecurrence', '8116', constants.PSETID_TASK, overrideClass = RecurrencePattern)
-
-    @property
-    def taskResetReminder(self) -> bool:
-        """
-        Indicates whether future recurring tasks need reminders.
-        """
-        return self._ensureSetNamed('_taskResetReminder', '8107', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
-
-    @property
-    def taskRole(self) -> Optional[str]:
-        """
-        This value is not used and has no impact on a Task, but is provided for
-        completeness.
-        """
-        return self._ensureSetNamed('_taskRole', '8127', constants.PSETID_TASK)
-
-    @property
-    def taskStartDate(self) -> Optional[datetime.datetime]:
-        """
-        Specifies the date on which the user expects work on the task to begin.
-        """
-        return self._ensureSetNamed('_taskStartDate', '8104', constants.PSETID_TASK)
-
-    @property
-    def taskState(self) -> Optional[TaskState]:
-        """
-        Indicates the current assignment state of the Task object.
-        """
-        return self._ensureSetNamed('_taskState', '8113', constants.PSETID_TASK, overrideClass = TaskState)
-
-    @property
-    def taskStatus(self) -> Optional[TaskStatus]:
-        """
-        The completion status of a task.
-        """
-        return self._ensureSetNamed('_taskStatus', '8101', constants.PSETID_TASK, overrideClass = TaskStatus)
-
-    @property
-    def taskStatusOnComplete(self) -> bool:
-        """
-        Indicates whether the task assignee has been requested to send an email
-        message upon completion of the assigned task.
-        """
-        return self._ensureSetNamed('_taskStatusOnComplete', '8119', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
-
-    @property
-    def taskUpdates(self) -> bool:
-        """
-        Indicates whether the task assignee has been requested to send a task
-        update when the assigned Task object changes.
-        """
-        return self._ensureSetNamed('_taskUpdates', '811B', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
-
-    @property
-    def taskVersion(self) -> Optional[int]:
-        """
-        Indicates which copy is the latest update of a Task object.
-        """
-        return self._ensureSetNamed('_taskVersion', '8112', constants.PSETID_TASK)
-
-    @property
-    def teamTask(self) -> Optional[bool]:
-        """
-        This value is not used and has no impact on a Task, but is provided for
-        completeness.
-        """
-        return self._ensureSetNamed('_teamTask', '8103', constants.PSETID_TASK)
+__all__ = [
+    'Task',
+]
+
+
+import datetime
+import logging
+
+from typing import Optional, Set
+
+from . import constants
+from .enums import (
+        TaskAcceptance, TaskHistory, TaskMode, TaskMultipleRecipients,
+        TaskOwnership, TaskState, TaskStatus
+    )
+from .message_base import MessageBase
+from .structures.recurrence_pattern import RecurrencePattern
+from .utils import unsignedToSignedInt
+
+
+logger = logging.getLogger(__name__)
+logger.addHandler(logging.NullHandler())
+
+
+class Task(MessageBase):
+    """
+    Class used for parsing task files.
+    """
+
+    @property
+    def headerFormatProperties(self) -> constants.HEADER_FORMAT_TYPE:
+        """
+        Returns a dictionary of properties, in order, to be formatted into the
+        header. Keys are the names to use in the header while the values are one
+        of the following:
+        None: Signifies no data was found for the property and it should be
+            omitted from the header.
+        str: A string to be formatted into the header using the string encoding.
+        Tuple[Union[str, None], bool]: A string should be formatted into the
+            header. If the bool is True, then place an empty string if the value
+            is None, otherwise follow the same behavior as regular None.
+
+        Additional note: If the value is an empty string, it will be dropped as
+        well by default.
+
+        Additionally you can group members of a header together by placing them
+        in an embedded dictionary. Groups will be spaced out using a second
+        instance of the join string. If any member of a group is being printed,
+        it will be spaced apart from the next group/item.
+
+        If you class should not do *any* header injection, return None from this
+        property.
+        """
+        status = {
+            TaskStatus.NOT_STARTED: 'Not Started',
+            TaskStatus.IN_PROGRESS: 'In Progress',
+            TaskStatus.COMPLETE: 'Completed',
+            TaskStatus.WAITING_ON_OTHER: 'Waiting on someone else',
+            TaskStatus.DEFERRED: 'Deferred',
+            None: None,
+        }[self.taskStatus]
+
+        return {
+            '-basic info-': {
+                'Subject': self.subject,
+            },
+            '-status-': {
+                'Status': status,
+                'Percent Complete': f'{self.percentComplete*100:.0f}%',
+                'Date Completed': self.taskDateCompleted.__format__('%w, %B %d, %Y') if self.taskDateCompleted else None,
+            },
+            '-work-': {
+                'Total Work': f'{self.taskEstimatedEffort or 0} minutes',
+                'Actual Work': f'{self.taskActualEffort or 0} minutes',
+            },
+            '-owner-': {
+                'Owner': self.taskOwner,
+            },
+            '-importance-': {
+                'Importance': self.importanceString,
+            },
+        }
+
+    @property
+    def percentComplete(self) -> Optional[float]:
+        """
+        Indicates whether a time-flagged Message object is complete. Returns a
+        percentage in decimal form. 1.0 indicates it is complete.
+        """
+        return self._ensureSetNamed('_percentComplete', '8102', constants.PSETID_TASK)
+
+    @property
+    def taskAcceptanceState(self) -> Optional[TaskAcceptance]:
+        """
+        Indicates the acceptance state of the task.
+        """
+        return self._ensureSetNamed('_taskAcceptanceState', '812A', constants.PSETID_TASK, overrideClass = TaskAcceptance)
+
+    @property
+    def taskAccepted(self) -> bool:
+        """
+        Indicates whether a task assignee has replied to a tesk request for this
+        task object. Does not indicate if it was accepted or rejected.
+        """
+        return self._ensureSetNamed('_taskAccepted', '8108', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
+
+    @property
+    def taskActualEffort(self) -> Optional[int]:
+        """
+        Indicates the number of minutes that the user actually spent working on
+        a task.
+        """
+        return self._ensureSetNamed('_taskActualEffort', '8110', constants.PSETID_TASK)
+
+    @property
+    def taskAssigner(self) -> Optional[str]:
+        """
+        Specifies the name of the user that last assigned the task.
+        """
+        return self._ensureSetNamed('_taskAssigner', '8121', constants.PSETID_TASK)
+
+    @property
+    def taskAssigners(self) -> Optional[bytes]:
+        """
+        A stack of entries, each representing a task assigner. The most recent
+        task assigner (that is, the top) appears at the bottom.
+
+        The documentation on this is weird, so I don't know how to parse it.
+        """
+        return self._ensureSetNamed('_taskAssigners', '8117', constants.PSETID_TASK)
+
+    @property
+    def taskComplete(self) -> bool:
+        """
+        Indicates if the task is complete.
+        """
+        return self._ensureSetNamed('_taskComplete', '811C', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
+
+    @property
+    def taskCustomFlags(self) -> Optional[int]:
+        """
+        Custom flags set on the task.
+        """
+        return self._ensureSetNamed('_taskCustomFlags', '8139', constants.PSETID_TASK)
+
+    @property
+    def taskDateCompleted(self) -> Optional[datetime.datetime]:
+        """
+        The date when the user completed work on the task.
+        """
+        return self._ensureSetNamed('_taskDateCompleted', '810F', constants.PSETID_TASK)
+
+    @property
+    def taskDeadOccurrence(self) -> bool:
+        """
+        Indicates whether a new recurring task remains to be generated. Set to
+        False on a new Task object and True when the client generates the last
+        recurring task.
+        """
+        return self._ensureSetNamed('_taskDeadOccurrence', '8109', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
+
+    @property
+    def taskDueDate(self) -> Optional[datetime.datetime]:
+        """
+        Specifies the date by which the user expects work on the task to be
+        complete.
+        """
+        return self._ensureSetNamed('_taskDueDate', '8105', constants.PSETID_TASK)
+
+    @property
+    def taskEstimatedEffort(self) -> Optional[int]:
+        """
+        Indicates the number of minutes that the user expects to work on a task.
+        """
+        return self._ensureSetNamed('_taskEstimatedEffort', '8111', constants.PSETID_TASK)
+
+    @property
+    def taskFCreator(self) -> bool:
+        """
+        Indicates that the task object was originally created by the action of
+        the current user or user agent instead of by the processing of a task
+        request.
+        """
+        return self._ensureSetNamed('_taskFCreator', '811E', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
+
+    @property
+    def taskFFixOffline(self) -> bool:
+        """
+        Indicates whether the value of the taskOwner property is correct.
+        """
+        return self._ensureSetNamed('taskFFixOffline', '812C', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
+
+    @property
+    def taskFRecurring(self) -> bool:
+        """
+        Indicates whether the task includes a recurrence pattern.
+        """
+        return self._ensureSetNamed('_taskFRecurring', '8126', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
+
+    @property
+    def taskGlobalID(self) -> Optional[bytes]:
+        """
+        Specifies a unique GUID for this task, used to locate an existing task
+        upon receipt of a task response or task update.
+        """
+        return self._ensureSetNamed('_taskGlobalID', '8519', constants.PSETID_COMMON)
+
+    @property
+    def taskHistory(self) -> Optional[TaskHistory]:
+        """
+        Indicates the type of change that was last made to the Task object.
+        """
+        return self._ensureSetNamed('_taskHistory', '811A', constants.PSETID_TASK, overrideClass = TaskHistory)
+
+    @property
+    def taskLastDelegate(self) -> Optional[str]:
+        """
+        Contains the name of the user who most recently assigned the task, or
+        the user to whom it was most recently assigned.
+        """
+        return self._ensureSetNamed('_taskLastDelegate', '8125', constants.PSETID_TASK)
+
+    @property
+    def taskLastUpdate(self) -> Optional[datetime.datetime]:
+        """
+        The date and time of the most recent change made to the task object.
+        """
+        return self._ensureSetNamed('_taskLastUpdate', '8115', constants.PSETID_TASK)
+
+    @property
+    def taskLastUser(self) -> Optional[str]:
+        """
+        Contains the name of the most recent user to have been the owner of the
+        task.
+        """
+        return self._ensureSetNamed('_taskLastUser', '8122', constants.PSETID_TASK)
+
+    @property
+    def taskMode(self) -> Optional[TaskMode]:
+        """
+        Used in a task communication. Should be 0 (UNASSIGNED) on task objects.
+        """
+        return self._ensureSetNamed('_taskMode', '8518', constants.PSETID_COMMON, overrideClass = TaskMode)
+
+    @property
+    def taskMultipleRecipients(self) -> Optional[Set[TaskMultipleRecipients]]:
+        """
+        Returns a set of flags that specify optimization hints about the
+        recipients of a Task object.
+        """
+        return self._ensureSetNamed('_taskMultipleRecipients', '8120', constants.PSETID_TASK, overrideClass = TaskMultipleRecipients.fromBits)
+
+    @property
+    def taskNoCompute(self) -> Optional[bool]:
+        """
+        This value is not used and has no impact on a Task, but is provided for
+        completeness.
+        """
+        return self._ensureSetNamed('_taskNoCompute', '8124', constants.PSETID_TASK)
+
+    @property
+    def taskOrdinal(self) -> Optional[int]:
+        """
+        Specifies a number that aids custom sorting of Task objects.
+        """
+        return self._ensureSetNamed('_taskOrdinal', '8123', constants.PSETID_TASK, overrideClass = unsignedToSignedInt)
+
+    @property
+    def taskOwner(self) -> Optional[str]:
+        """
+        Contains the name of the owner of the task.
+        """
+        return self._ensureSetNamed('_taskOwner', '811F', constants.PSETID_TASK)
+
+    @property
+    def taskOwnership(self) -> Optional[TaskOwnership]:
+        """
+        Contains the name of the owner of the task.
+        """
+        return self._ensureSetNamed('_taskOwnership', '8129', constants.PSETID_TASK, overrideClass = TaskOwnership)
+
+    @property
+    def taskRecurrence(self) -> Optional[RecurrencePattern]:
+        """
+        Contains a RecurrencePattern structure that provides information about
+        recurring tasks.
+        """
+        return self._ensureSetNamed('_taskRecurrence', '8116', constants.PSETID_TASK, overrideClass = RecurrencePattern)
+
+    @property
+    def taskResetReminder(self) -> bool:
+        """
+        Indicates whether future recurring tasks need reminders.
+        """
+        return self._ensureSetNamed('_taskResetReminder', '8107', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
+
+    @property
+    def taskRole(self) -> Optional[str]:
+        """
+        This value is not used and has no impact on a Task, but is provided for
+        completeness.
+        """
+        return self._ensureSetNamed('_taskRole', '8127', constants.PSETID_TASK)
+
+    @property
+    def taskStartDate(self) -> Optional[datetime.datetime]:
+        """
+        Specifies the date on which the user expects work on the task to begin.
+        """
+        return self._ensureSetNamed('_taskStartDate', '8104', constants.PSETID_TASK)
+
+    @property
+    def taskState(self) -> Optional[TaskState]:
+        """
+        Indicates the current assignment state of the Task object.
+        """
+        return self._ensureSetNamed('_taskState', '8113', constants.PSETID_TASK, overrideClass = TaskState)
+
+    @property
+    def taskStatus(self) -> Optional[TaskStatus]:
+        """
+        The completion status of a task.
+        """
+        return self._ensureSetNamed('_taskStatus', '8101', constants.PSETID_TASK, overrideClass = TaskStatus)
+
+    @property
+    def taskStatusOnComplete(self) -> bool:
+        """
+        Indicates whether the task assignee has been requested to send an email
+        message upon completion of the assigned task.
+        """
+        return self._ensureSetNamed('_taskStatusOnComplete', '8119', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
+
+    @property
+    def taskUpdates(self) -> bool:
+        """
+        Indicates whether the task assignee has been requested to send a task
+        update when the assigned Task object changes.
+        """
+        return self._ensureSetNamed('_taskUpdates', '811B', constants.PSETID_TASK, overrideClass = bool, preserveNone = False)
+
+    @property
+    def taskVersion(self) -> Optional[int]:
+        """
+        Indicates which copy is the latest update of a Task object.
+        """
+        return self._ensureSetNamed('_taskVersion', '8112', constants.PSETID_TASK)
+
+    @property
+    def teamTask(self) -> Optional[bool]:
+        """
+        This value is not used and has no impact on a Task, but is provided for
+        completeness.
+        """
+        return self._ensureSetNamed('_teamTask', '8103', constants.PSETID_TASK)
```

### Comparing `extract_msg-0.40.0/extract_msg/utils.py` & `extract_msg-0.41.0/extract_msg/utils.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,1324 +1,1345 @@
-"""
-Utility functions of extract_msg.
-"""
-
-import argparse
-import codecs
-import collections
-import copy
-import datetime
-import email.message
-import email.policy
-import glob
-import json
-import logging
-import logging.config
-import os
-import pathlib
-import shutil
-import struct
-# Not actually sure if this needs to be here for the logging, so just in case.
-import sys
-import zipfile
-
-import bs4
-import olefile
-import tzlocal
-
-from html import escape as htmlEscape
-from typing import Any, Dict, List, Optional, Tuple, Union
-
-from . import constants
-from .enums import AttachmentType
-from .exceptions import BadHtmlError, ConversionError, IncompatibleOptionsError, InvalidFileFormatError, InvaildPropertyIdError, TZError, UnknownCodepageError, UnknownTypeError, UnrecognizedMSGTypeError, UnsupportedMSGTypeError
-
-
-logger = logging.getLogger(__name__)
-logger.addHandler(logging.NullHandler())
-logging.addLevelName(5, 'DEVELOPER')
-
-
-def addNumToDir(dirName : pathlib.Path) -> Optional[pathlib.Path]:
-    """
-    Attempt to create the directory with a '(n)' appended.
-    """
-    for i in range(2, 100):
-        try:
-            newDirName = dirName.with_name(dirName.name + f' ({i})')
-            os.makedirs(newDirName)
-            return newDirName
-        except Exception as e:
-            pass
-    return None
-
-
-def addNumToZipDir(dirName : pathlib.Path, _zip) -> Optional[pathlib.Path]:
-    """
-    Attempt to create the directory with a '(n)' appended.
-    """
-    for i in range(2, 100):
-        newDirName = dirName.with_name(dirName.name + f' ({i})')
-        pathCompare = str(newDirName).rstrip('/') + '/'
-        if not any(x.startswith(pathCompare) for x in _zip.namelist()):
-            return newDirName
-    return None
-
-
-def bitwiseAdjust(inp : int, mask : int) -> int:
-    """
-    Uses a given mask to adjust the location of bits after an operation like
-    bitwise AND. This is useful for things like flags where you are trying to
-    get a small portion of a larger number. Say for example, you had the number
-    0xED (0b11101101) and you needed the adjusted result of the AND operation
-    with 0x70 (0b01110000). The result of the AND operation (0b01100000) and the
-    mask used to get it (0x70) are given to this function and the adjustment
-    will be done automatically.
-
-    :param mask: MUST be greater than 0.
-
-    :raises ValueError: if the mask is not greater than 0.
-    """
-    if mask < 1:
-        raise ValueError('Mask MUST be greater than 0')
-    return inp >> bin(mask)[::-1].index('1')
-
-
-def bitwiseAdjustedAnd(inp : int, mask : int) -> int:
-    """
-    Preforms the bitwise AND operation between :param inp: and :param mask: and
-    adjusts the results based on the rules of the bitwiseAdjust function.
-
-    :raises ValueError: if the mask is not greater than 0.
-    """
-    if mask < 1:
-        raise ValueError('Mask MUST be greater than 0')
-    return (inp & mask) >> bin(mask)[::-1].index('1')
-
-
-def bytesToGuid(bytesInput : bytes) -> str:
-    """
-    Converts a bytes instance to a GUID.
-    """
-    guidVals = constants.ST_GUID.unpack(bytesInput)
-    return f'{{{guidVals[0]:08X}-{guidVals[1]:04X}-{guidVals[2]:04X}-{guidVals[3][:2].hex().upper()}-{guidVals[3][2:].hex().upper()}}}'
-
-
-def ceilDiv(n : int, d : int) -> int:
-    """
-    Returns the int from the ceil division of n / d.
-    ONLY use ints as inputs to this function.
-
-    For ints, this is faster and more accurate for numbers
-    outside the precision range of float.
-    """
-    return -(n // -d)
-
-
-def cloneOleFile(sourcePath, outputPath) -> None:
-    """
-    Uses the OleWriter class to clone the specified OLE file into a new
-    location. Mainly designed for testing.
-    """
-    from .ole_writer import OleWriter
-
-    with olefile.OleFileIO(sourcePath) as f:
-        writer = OleWriter()
-        writer.fromOleFile(f)
-
-    writer.write(outputPath)
-
-
-def createZipOpen(func):
-    """
-    Creates a wrapper for the open function of a ZipFile that will automatically
-    set the current date as the modified time to the current time.
-    """
-    def _open(name, mode, *args, **kwargs):
-        if mode == 'w':
-            name = zipfile.ZipInfo(name, datetime.datetime.now().timetuple())
-
-        return func(name, mode, *args, **kwargs)
-
-    return _open
-
-
-def dictGetCasedKey(_dict : Dict, key : Any) -> Any:
-    """
-    Retrieves the key from the dictionary with the proper casing using a
-    caseless key.
-    """
-    try:
-        return next((x for x in _dict.keys() if x.lower() == key.lower()))
-    except StopIteration:
-        # If we couldn't find the key, raise a KeyError.
-        raise KeyError(key)
-
-
-def divide(string, length : int) -> List:
-    """
-    Divides a string into multiple substrings of equal length. If there is not
-    enough for the last substring to be equal, it will simply use the rest of
-    the string. Can also be used for things like lists and tuples.
-
-    :param string: string to be divided.
-    :param length: length of each division.
-    :returns: list containing the divided strings.
-
-    Example:
-    >>>> a = divide('Hello World!', 2)
-    >>>> print(a)
-    ['He', 'll', 'o ', 'Wo', 'rl', 'd!']
-    >>>> a = divide('Hello World!', 5)
-    >>>> print(a)
-    ['Hello', ' Worl', 'd!']
-    """
-    return [string[length * x:length * (x + 1)] for x in range(int(ceilDiv(len(string), length)))]
-
-
-def filetimeToDatetime(rawTime : int) -> datetime.datetime:
-    """
-    Converts a filetime into a datetime.
-
-    Some values have specialized meanings, listed below:
-        915151392000000000: December 31, 4500, representing a null time. Returns
-            extract_msg.constants.NULL_DATE.
-        915046235400000000: 23:59 on August 31, 4500, representing a null time.
-            Returns extract_msg.constants.NULL_DATE.
-    """
-    try:
-        if rawTime < 116444736000000000:
-            # We can't properly parse this with our current setup, so
-            # we will rely on olefile to handle this one.
-            return olefile.olefile.filetime2datetime(rawTime)
-        elif rawTime == 915151392000000000:
-            # So this is actually a different null date, specifically
-            # supposed to be December 31, 4500, but it's weird that the
-            # same spec has 2 different ones, so we just return the same
-            # one for both.
-            return constants.NULL_DATE
-        elif rawTime == 915046235400000000:
-            return constants.NULL_DATE
-        else:
-            return fromTimeStamp(filetimeToUtc(rawTime))
-    except TZError:
-        # For TZError we just raise it again. It is a fatal error.
-        raise
-    except Exception as e:
-        raise ValueError(f'Timestamp value of {filetimeToUtc(rawTime)} caused an exception. This was probably caused by the time stamp being too far in the future.')
-
-
-def findWk(path = None):
-    """
-    Attempt to find the path of the wkhtmltopdf executable. If :param path: is
-    provided, verifies that it is executable and returns the path if it is.
-
-    :raises ExecutableNotFound: A valid executable could not be found.
-    """
-    if path:
-        if os.path.isfile(path):
-            # Check if executable.
-            if os.access(path, os.X_OK):
-                return path
-            else:
-                raise ExecutableNotFound('Path provided was not a valid executable (execution bit not set).')
-        else:
-            raise ExecutableNotFound('Path provided was not a valid executable (not a file).')
-
-    candidate = shutil.which('wkhtmltopdf')
-    if candidate:
-        return candidate
-
-    raise ExecutableNotFound('Could not find wkhtmltopdf.')
-
-
-def fromTimeStamp(stamp : int) -> datetime.datetime:
-    """
-    Returns a datetime from the UTC timestamp given the current timezone.
-    """
-    try:
-        tz = tzlocal.get_localzone()
-    except Exception as e:
-        # I know "generalized exception catching is bad" but if *any* exception
-        # happens here that is a subclass of Exception then something has gone
-        # wrong with tzlocal.
-        raise TZError(f'Error occured using tzlocal. If you are seeing this, this is likely a problem with your installation ot tzlocal or tzdata.')
-    return datetime.datetime.fromtimestamp(stamp, tz)
-
-
-def getCommandArgs(args) -> argparse.Namespace:
-    """
-    Parse command-line arguments.
-
-    :raises IncompatibleOptionsError: Some options were provided that are
-        incompatible.
-    :raises ValueError: Something about the options was invalid. This could mean
-        an option was specified that requires another option or it could mean
-        that an option was looking for data that was not found.
-    """
-    parser = argparse.ArgumentParser(description = constants.MAINDOC, prog = 'extract_msg')
-    outFormat = parser.add_mutually_exclusive_group()
-    inputFormat = parser.add_mutually_exclusive_group()
-    # --use-content-id, --cid
-    parser.add_argument('--use-content-id', '--cid', dest='cid', action='store_true',
-                        help='Save attachments by their Content ID, if they have one. Useful when working with the HTML body.')
-    # --dev
-    parser.add_argument('--dev', dest='dev', action='store_true',
-                        help='Changes to use developer mode. Automatically enables the --verbose flag. Takes precedence over the --validate flag.')
-    # --validate
-    parser.add_argument('--validate', dest='validate', action='store_true',
-                        help='Turns on file validation mode. Turns off regular file output.')
-    # --json
-    outFormat.add_argument('--json', dest='json', action='store_true',
-                        help='Changes to write output files as json.')
-    # --file-logging
-    parser.add_argument('--file-logging', dest='fileLogging', action='store_true',
-                        help='Enables file logging. Implies --verbose level 1.')
-    # --verbose
-    parser.add_argument('-v', '--verbose', dest='verbose', action='count', default=0,
-                        help='Turns on console logging. Specify more than once for higher verbosity.')
-    # --log PATH
-    parser.add_argument('--log', dest='log',
-                        help='Set the path to write the file log to.')
-    # --config PATH
-    parser.add_argument('--config', dest='configPath',
-                        help='Set the path to load the logging config from.')
-    # --out PATH
-    parser.add_argument('--out', dest='outPath',
-                        help='Set the folder to use for the program output. (Default: Current directory)')
-    # --use-filename
-    parser.add_argument('--use-filename', dest='useFilename', action='store_true',
-                        help='Sets whether the name of each output is based on the msg filename.')
-    # --dump-stdout
-    parser.add_argument('--dump-stdout', dest='dumpStdout', action='store_true',
-                        help='Tells the program to dump the message body (plain text) to stdout. Overrides saving arguments.')
-    # --html
-    outFormat.add_argument('--html', dest='html', action='store_true',
-                        help='Sets whether the output should be HTML. If this is not possible, will error.')
-    # --pdf
-    outFormat.add_argument('--pdf', dest='pdf', action='store_true',
-                           help='Saves the body as a PDF. If this is not possible, will error.')
-    # --wk-path PATH
-    parser.add_argument('--wk-path', dest='wkPath',
-                        help='Overrides the path for finding wkhtmltopdf.')
-    # --wk-options OPTIONS
-    parser.add_argument('--wk-options', dest='wkOptions', nargs='*',
-                        help='Sets additional options to be used in wkhtmltopdf. Should be a series of options and values, replacing the - or -- in the beginning with + or ++, respectively. For example: --wk-options "+O Landscape"')
-    # --prepared-html
-    parser.add_argument('--prepared-html', dest='preparedHtml', action='store_true',
-                        help='When used in conjunction with --html, sets whether the HTML output should be prepared for embedded attachments.')
-    # --charset
-    parser.add_argument('--charset', dest='charset', default='utf-8',
-                        help='Character set to use for the prepared HTML in the added tag. (Default: utf-8)')
-    # --raw
-    outFormat.add_argument('--raw', dest='raw', action='store_true',
-                           help='Sets whether the output should be raw. If this is not possible, will error.')
-    # --rtf
-    outFormat.add_argument('--rtf', dest='rtf', action='store_true',
-                           help='Sets whether the output should be RTF. If this is not possible, will error.')
-    # --allow-fallback
-    parser.add_argument('--allow-fallback', dest='allowFallback', action='store_true',
-                        help='Tells the program to fallback to a different save type if the selected one is not possible.')
-    # --skip-body-not-found
-    parser.add_argument('--skip-body-not-found', dest='skipBodyNotFound', action='store_true',
-                        help='Skips saving the body if the body cannot be found, rather than throwing an error.')
-    # --zip
-    parser.add_argument('--zip', dest='zip',
-                        help='Path to use for saving to a zip file.')
-    # --save-header
-    parser.add_argument('--save-header', dest='saveHeader', action='store_true',
-                        help='Store the header in a separate file.')
-    # --attachments-only
-    outFormat.add_argument('--attachments-only', dest='attachmentsOnly', action='store_true',
-                           help='Specify to only save attachments from an msg file.')
-    # --skip-hidden
-    parser.add_argument('--skip-hidden', dest='skipHidden', action='store_true',
-                        help='Skips any attachment marked as hidden (usually ones embedded in the body).')
-    # --no-folders
-    parser.add_argument('--no-folders', dest='noFolders', action='store_true',
-                        help='Stores everything in the location specified by --out. Requires --attachments-only and is incompatible with --out-name.')
-    # --skip-embedded
-    parser.add_argument('--skip-embedded', dest='skipEmbedded', action='store_true',
-                        help='Skips all embedded MSG files when saving attachments.')
-    # --extract-embedded
-    parser.add_argument('--extract-embedded', dest='extractEmbedded', action='store_true',
-                        help='Extracts the embedded MSG files as MSG files instead of running their save functions.')
-    # --skip-not-implemented
-    parser.add_argument('--skip-not-implemented', '--skip-ni', dest='skipNotImplemented', action='store_true',
-                        help='Skips any attachments that are not implemented, allowing saving of the rest of the message.')
-    # --out-name NAME
-    inputFormat.add_argument('--out-name', dest='outName',
-                        help='Name to be used with saving the file output. Cannot be used if you are saving more than one file.')
-    # --glob
-    inputFormat.add_argument('--glob', '--wildcard', dest='glob', action='store_true',
-                        help='Interpret all paths as having wildcards. Incompatible with --out-name.')
-    # --ignore-rtfde
-    parser.add_argument('--ignore-rtfde', dest='ignoreRtfDeErrors', action='store_true',
-                        help='Ignores all errors thrown from RTFDE when trying to save. Useful for allowing fallback to continue when an exception happens.')
-    # --progress
-    parser.add_argument('--progress', dest='progress', action='store_true',
-                        help='Shows what file the program is currently working on during it\'s progress.')
-    # [msg files]
-    parser.add_argument('msgs', metavar='msg', nargs='+',
-                        help='An MSG file to be parsed.')
-
-    options = parser.parse_args(args)
-
-    if options.outName and options.noFolders:
-        raise IncompatibleOptionsError('--out-name is not compatible with --no-folders.')
-
-    if options.dev or options.fileLogging:
-        options.verbose = options.verbose or 1
-
-    # Handle the wkOptions if they exist.
-    if options.wkOptions:
-        wkOptions = []
-        for option in options.wkOptions:
-            if option.startswith('++'):
-                option = '--' + option[2:]
-            elif option.startswith('+'):
-                option = '-' + option[1:]
-
-            # Now that we have corrected to the correct start, split the argument if
-            # necessary.
-            split = option.split(' ')
-            if len(split) == 1:
-                # No spaces means we just pass that directly.
-                wkOptions.append(option)
-            else:
-                wkOptions.append(split[0])
-                wkOptions.append(' '.join(split[1:]))
-
-        options.wkOptions = wkOptions
-
-    # If dump_stdout is True, we need to unset all arguments used in files.
-    # Technically we actually only *need* to unset `out_path`, but that may
-    # change in the future, so let's be thorough.
-    if options.dumpStdout:
-        options.outPath = None
-        options.json = False
-        options.rtf = False
-        options.html = False
-        options.useFilename = False
-        options.cid = False
-
-    if options.glob:
-        if options.outName:
-            raise IncompatibleOptionsError('--out-name is not supported when using wildcards.')
-        fileLists = []
-        for path in options.msgs:
-            fileLists += glob.glob(path)
-
-        if len(fileLists) == 0:
-            raise ValueError('Could not find any msg files using the specified wildcards.')
-        options.msgs = fileLists
-
-    # Make it so outName can only be used on single files.
-    if options.outName and len(options.msgs) > 1:
-        raise IncompatibleOptionsError('--out-name is not supported when saving multiple MSG files.')
-
-    # Handle the verbosity level.
-    if options.verbose == 0:
-        options.logLevel = logging.ERROR
-    elif options.verbose == 1:
-        options.logLevel = logging.WARNING
-    elif options.verbose == 2:
-        options.logLevel = logging.INFO
-    else:
-        options.logLevel = 5
-
-    # If --no-folders is turned on but --attachments-only is not, error.
-    if options.noFolders and not options.attachmentsOnly:
-        raise ValueError('--no-folders requires the --attachments-only option.')
-
-    return options
-
-
-def getEncodingName(codepage : int) -> str:
-    """
-    Returns the name of the encoding with the specified codepage.
-
-    :raises UnknownCodepageError: if the codepage is unrecognized.
-    :raises UnsupportedEncodingError: if the codepage is not supported.
-    """
-    if codepage not in constants.CODE_PAGES:
-        raise UnknownCodepageError(str(codepage))
-    try:
-        codecs.lookup(constants.CODE_PAGES[codepage])
-        return constants.CODE_PAGES[codepage]
-    except LookupError:
-        raise UnsupportedEncodingError(f'The codepage {codepage} ({constants.CODE_PAGES[codepage]}) is not currently supported by your version of Python.')
-
-
-def getFullClassName(inp) -> str:
-    return inp.__class__.__module__ + '.' + inp.__class__.__name__
-
-
-def hasLen(obj) -> bool:
-    """
-    Checks if :param obj: has a __len__ attribute.
-    """
-    return hasattr(obj, '__len__')
-
-
-def htmlSanitize(inp : str) -> str:
-    """
-    Santizes the input for injection into an HTML string. Converts characters
-    into forms that will not be misinterpreted, if necessary.
-    """
-    # First step, do a basic escape of the HTML.
-    inp = htmlEscape(inp)
-
-    # Change newlines to <br/> to they won't be ignored.
-    inp = inp.replace('\r\n', '\n').replace('\n', '<br/>')
-
-    # Escape long sections of spaces to ensure they won't be ignored.
-    inp = constants.RE_HTML_SAN_SPACE.sub((lambda spaces : '&nbsp;' * len(spaces.group(0))),inp)
-
-    return inp
-
-
-def inputToBytes(stringInputVar, encoding) -> bytes:
-    """
-    Converts the input into bytes.
-
-    :raises ConversionError: if the input cannot be converted.
-    """
-    if isinstance(stringInputVar, bytes):
-        return stringInputVar
-    elif isinstance(stringInputVar, str):
-        return stringInputVar.encode(encoding)
-    elif stringInputVar is None:
-        return b''
-    else:
-        raise ConversionError('Cannot convert to bytes.')
-
-
-def inputToMsgPath(inp) -> List:
-    """
-    Converts the input into an msg path.
-
-    :raises ValueError: The path contains an illegal character.
-    """
-    if isinstance(inp, (list, tuple)):
-        inp = '/'.join(inp)
-
-    inp = inputToString(inp, 'utf-8')
-
-    # Validate the path is okay. Normally we would check for '/' and '\', but
-    # we are expecting a string or similar which will use those as path
-    # separators, so we will ignore that for now.
-    if ':' in inp or '!' in inp:
-        raise ValueError('Illegal character ("!" or ":") found in MSG path.')
-
-    ret = [x for x in inp.replace('\\', '/').split('/') if x]
-
-    # One last thing to check: all path segments can be, at most, 31 characters
-    # (32 if you include the null character), so we should verify that.
-    if any(len(x) > 31 for x in ret):
-        raise ValueError('Path segments must not be greater than 31 characters.')
-    return ret
-
-
-def inputToString(bytesInputVar, encoding) -> str:
-    """
-    Converts the input into a string.
-
-    :raises ConversionError: if the input cannot be converted.
-    """
-    if isinstance(bytesInputVar, str):
-        return bytesInputVar
-    elif isinstance(bytesInputVar, bytes):
-        return bytesInputVar.decode(encoding)
-    elif bytesInputVar is None:
-        return ''
-    else:
-        raise ConversionError('Cannot convert to str type.')
-
-
-def isEncapsulatedRtf(inp : bytes) -> bool:
-    """
-    Currently the detection is made to be *extremly* basic, but this will work
-    for now. In the future this will be fixed so that literal text in the body
-    of a message won't cause false detection.
-    """
-    return b'\\fromhtml' in inp
-
-
-def isEmptyString(inp : str) -> bool:
-    """
-    Returns true if the input is None or is an Empty string.
-    """
-    return (inp == '' or inp is None)
-
-
-def knownMsgClass(classType : str) -> bool:
-    """
-    Checks if the specified class type is recognized by the module. Usually used
-    for checking if a type is simply unsupported rather than unknown.
-    """
-    classType = classType.lower()
-    if classType == 'ipm':
-        return True
-
-    for item in constants.KNOWN_CLASS_TYPES:
-        if classType.startswith(item):
-            return True
-
-    return False
-
-
-def filetimeToUtc(inp : int) -> float:
-    """
-    Converts a FILETIME into a unix timestamp.
-    """
-    return (inp - 116444736000000000) / 10000000.0
-
-
-def msgPathToString(inp) -> str:
-    """
-    Converts an MSG path (one of the internal paths inside an MSG file) into a
-    string.
-    """
-    if inp is None:
-        return None
-    if isinstance(inp, (list, tuple)):
-        inp = '/'.join(inp)
-    inp.replace('\\', '/')
-    return inp
-
-
-def openMsg(path, **kwargs) -> 'MSGFile':
-    """
-    Function to automatically open an MSG file and detect what type it is.
-
-    :param path: Path to the msg file in the system or is the raw msg file.
-    :param prefix: Used for extracting embeded msg files inside the main one.
-        Do not set manually unless you know what you are doing.
-    :param parentMsg: Used for syncronizing named properties instances. Do not
-        set this unless you know what you are doing.
-    :param attachmentClass: Optional, the class the Message object will use for
-        attachments. You probably should not change this value unless you know
-        what you are doing.
-    :param signedAttachmentClass: Optional, the class the object will use for
-        signed attachments.
-    :param filename: Optional, the filename to be used by default when saving.
-    :param delayAttachments: Optional, delays the initialization of attachments
-        until the user attempts to retrieve them. Allows MSG files with bad
-        attachments to be initialized so the other data can be retrieved.
-    :param overrideEncoding: Optional, overrides the specified encoding of the
-        MSG file.
-    :param attachmentErrorBehavior: Optional, the behaviour to use in the event
-        of an error when parsing the attachments.
-    :param recipientSeparator: Optional, Separator string to use between
-        recipients.
-    :param ignoreRtfDeErrors: Optional, specifies that any errors that occur
-        from the usage of RTFDE should be ignored (default: False).
-
-    If :param strict: is set to `True`, this function will raise an exception
-    when it cannot identify what MSGFile derivitive to use. Otherwise, it will
-    log the error and return a basic MSGFile instance.
-
-    :raises UnsupportedMSGTypeError: if the type is recognized but not suppoted.
-    :raises UnrecognizedMSGTypeError: if the type is not recognized.
-    """
-    from .appointment import AppointmentMeeting
-    from .contact import Contact
-    from .meeting_cancellation import MeetingCancellation
-    from .meeting_exception import MeetingException
-    from .meeting_forward import MeetingForwardNotification
-    from .meeting_request import MeetingRequest
-    from .meeting_response import MeetingResponse
-    from .message import Message
-    from .msg import MSGFile
-    from .message_signed import MessageSigned
-    from .post import Post
-    from .task import Task
-    from .task_request import TaskRequest
-
-    # When the initial MSG file is opened, it should *always* delay attachments
-    # so it can get the main class type. We only need to load them after that
-    # if we are directly returning the MSGFile instance *and* delayAttachments
-    # is False.
-    #
-    # So first let's store the original value.
-    delayAttachments = kwargs.get('delayAttachments', False)
-    kwargs['delayAttachments'] = True
-
-    msg = MSGFile(path, **kwargs)
-
-    # Restore the option in the kwargs so we don't have to worry about it.
-    kwargs['delayAttachments'] = delayAttachments
-
-    # After rechecking the docs, all comparisons should be case-insensitive, not
-    # case-sensitive. My reading ability is great.
-    #
-    # Also after consideration, I realized we need to be very careful here, as
-    # other file types (like doc, ppt, etc.) might open but not return a class
-    # type. If the stream is not found, classType returns None, which has no
-    # lower function. So let's make sure we got a good return first.
-    if not msg.classType:
-        if kwargs.get('strict', True):
-            raise InvalidFileFormatError('File was confirmed to be an olefile, but was not an MSG file.')
-        else:
-            # If strict mode is off, we'll just return an MSGFile anyways.
-            logging.critical('Received file that was an olefile but was not an MSG file. Returning MSGFile anyways because strict mode is off.')
-            return msg
-    classType = msg.classType.lower()
-    # Put the message class first as it is most common.
-    if classType.startswith('ipm.note') or classType.startswith('report'):
-        msg.close()
-        if classType.endswith('smime.multipartsigned') or classType.endswith('smime'):
-            return MessageSigned(path, **kwargs)
-        else:
-            return Message(path, **kwargs)
-    elif classType.startswith('ipm.appointment'):
-        msg.close()
-        return AppointmentMeeting(path, **kwargs)
-    elif classType.startswith('ipm.contact') or classType.startswith('ipm.distlist'):
-        msg.close()
-        return Contact(path, **kwargs)
-    elif classType.startswith('ipm.post'):
-        msg.close()
-        return Post(path, **kwargs)
-    elif classType.startswith('ipm.schedule.meeting.request'):
-        msg.close()
-        return MeetingRequest(path, **kwargs)
-    elif classType.startswith('ipm.schedule.meeting.canceled'):
-        msg.close()
-        return MeetingCancellation(path, **kwargs)
-    elif classType.startswith('ipm.schedule.meeting.notification.forward'):
-        msg.close()
-        return MeetingForwardNotification(path, **kwargs)
-    elif classType.startswith('ipm.schedule.meeting.resp'):
-        msg.close()
-        return MeetingResponse(path, **kwargs)
-    elif classType.startswith('ipm.taskrequest'):
-        msg.close()
-        return TaskRequest(path, **kwargs)
-    elif classType.startswith('ipm.task'):
-        msg.close()
-        return Task(path, **kwargs)
-    elif classType.startswith('ipm.ole.class.{00061055-0000-0000-c000-000000000046}'):
-        # Exception objects have a weird class type.
-        msg.close()
-        return MeetingException(path, **kwargs)
-    elif classType == 'ipm':
-        # Unspecified format. It should be equal to this and not just start with
-        # it.
-        if not delayAttachments:
-            msg.attachments
-        return msg
-    elif kwargs.get('strict', True):
-        # Because we are closing it, we need to store it in a variable first.
-        ct = msg.classType
-        msg.close()
-        if knownMsgClass(classType):
-            raise UnsupportedMSGTypeError(f'MSG type "{ct}" currently is not supported by the module. If you would like support, please make a feature request.')
-        raise UnrecognizedMSGTypeError(f'Could not recognize msg class type "{ct}".')
-    else:
-        logger.error(f'Could not recognize msg class type "{msg.classType}". This most likely means it hasn\'t been implemented yet, and you should ask the developers to add support for it.')
-        if not delayAttachments:
-            msg.attachments
-        return msg
-
-
-def openMsgBulk(path, **kwargs) -> Union[List['MSGFile'], Tuple[Exception, Union[str, bytes]]]:
-    """
-    Takes the same arguments as openMsg, but opens a collection of msg files
-    based on a wild card. Returns a list if successful, otherwise returns a
-    tuple.
-
-    :param ignoreFailures: If this is True, will return a list of all successful
-        files, ignoring any failures. Otherwise, will close all that
-        successfully opened, and return a tuple of the exception and the path of
-        the file that failed.
-    """
-    files = []
-    for x in glob.glob(str(path)):
-        try:
-            files.append(openMsg(x, **kwargs))
-        except Exception as e:
-            if not kwargs.get('ignoreFailures', False):
-                for msg in files:
-                    msg.close()
-                return (e, x)
-
-    return files
-
-
-def parseType(_type : int, stream, encoding, extras):
-    """
-    Converts the data in :param stream: to a much more accurate type, specified
-    by :param _type:.
-    :param _type: the data's type.
-    :param stream: is the data to be converted.
-    :param encoding: is the encoding to be used for regular strings.
-    :param extras: is used in the case of types like PtypMultipleString.
-    For that example, extras should be a list of the bytes from rest of the
-    streams.
-
-    :raises NotImplementedError: for types with no current support. Most of
-        these types have no documentation of existing in an MSG file.
-    """
-    # WARNING Not done. Do not try to implement anywhere where it is not already implemented.
-    value = stream
-    lengthExtras = len(extras)
-    if _type == 0x0000:  # PtypUnspecified
-        pass
-    elif _type == 0x0001:  # PtypNull
-        if value != b'\x00\x00\x00\x00\x00\x00\x00\x00':
-            # DEBUG
-            logger.warning('Property type is PtypNull, but is not equal to 0.')
-        return None
-    elif _type == 0x0002:  # PtypInteger16
-        return constants.STI16.unpack(value)[0]
-    elif _type == 0x0003:  # PtypInteger32
-        return constants.STI32.unpack(value)[0]
-    elif _type == 0x0004:  # PtypFloating32
-        return constants.STF32.unpack(value)[0]
-    elif _type == 0x0005:  # PtypFloating64
-        return constants.STF64.unpack(value)[0]
-    elif _type == 0x0006:  # PtypCurrency
-        return (constants.STI64.unpack(value)[0]) / 10000.0
-    elif _type == 0x0007:  # PtypFloatingTime
-        value = constants.STF64.unpack(value)[0]
-        return constants.PYTPFLOATINGTIME_START + datetime.timedelta(days = value)
-    elif _type == 0x000A:  # PtypErrorCode
-        from .enums import ErrorCode, ErrorCodeType
-        value = constants.STUI32.unpack(value)[0]
-        try:
-            value = ErrorCodeType(value)
-        except ValueError:
-            logger.warning(f'Error type found that was not from Additional Error Codes. Value was {value}. You should report this to the developers.')
-            # So here, the value should be from Additional Error Codes, but it
-            # wasn't. So we are just returning the int. However, we want to see
-            # if it is a normal error type.
-            try:
-                logger.warning(f'REPORT TO DEVELOPERS: Error type of {ErrorType(value)} was found.')
-            except ValueError:
-                pass
-        return value
-    elif _type == 0x000B:  # PtypBoolean
-        return constants.ST3.unpack(value)[0] == 1
-    elif _type == 0x000D:  # PtypObject/PtypEmbeddedTable
-        # TODO parsing for this.
-        # Wait, that's the extension for an attachment folder, so parsing this
-        # might not be as easy as we would hope. The function may be released
-        # without support for this.
-        raise NotImplementedError('Current version of extract-msg does not support the parsing of PtypObject/PtypEmbeddedTable in this function.')
-    elif _type == 0x0014:  # PtypInteger64
-        return constants.STI64.unpack(value)[0]
-    elif _type == 0x001E:  # PtypString8
-        return value.decode(encoding)
-    elif _type == 0x001F:  # PtypString
-        return value.decode('utf-16-le')
-    elif _type == 0x0040:  # PtypTime
-        rawTime = constants.ST3.unpack(value)[0]
-        return filetimeToDatetime(rawTime)
-    elif _type == 0x0048:  # PtypGuid
-        return bytesToGuid(value)
-    elif _type == 0x00FB:  # PtypServerId
-        count = constants.STUI16.unpack(value[:2])
-        # If the first byte is a 1 then it uses the ServerID structure.
-        if value[3] == 1:
-            from .structures.misc_id import ServerID
-            return ServerID(value)
-        else:
-            return (count, value[2:count + 2])
-    elif _type == 0x00FD:  # PtypRestriction
-        # TODO parsing for this.
-        raise NotImplementedError('Parsing for type 0x00FD (PtypRestriction) has not yet been implmented. If you need this type, please create a new issue labeled "NotImplementedError: parseType 0x00FD PtypRestriction".')
-    elif _type == 0x00FE:  # PtypRuleAction
-        # TODO parsing for this.
-        raise NotImplementedError('Parsing for type 0x00FE (PtypRuleAction) has not yet been implmented. If you need this type, please create a new issue labeled "NotImplementedError: parseType 0x00FE PtypRuleAction".')
-    elif _type == 0x0102:  # PtypBinary
-        return value
-    elif _type & 0x1000 == 0x1000:  # PtypMultiple
-        # TODO parsing for `multiple` types.
-        if _type in (0x101F, 0x101E): # PtypMultipleString/PtypMultipleString8
-            ret = [x.decode(encoding) for x in extras]
-            lengths = struct.unpack(f'<{len(ret)}i', stream)
-            lengthLengths = len(lengths)
-            if lengthLengths > lengthExtras:
-                logger.warning(f'Error while parsing multiple type. Expected {lengthLengths} stream{"s" if lengthLengths != 1 else ""}, got {lengthExtras}. Ignoring.')
-            for x, y in enumerate(extras):
-                if lengths[x] != len(y):
-                    logger.warning(f'Error while parsing multiple type. Expected length {lengths[x]}, got {len(y)}. Ignoring.')
-            return ret
-        elif _type == 0x1102: # PtypMultipleBinary
-            ret = copy.deepcopy(extras)
-            lengths = tuple(constants.STUI32.unpack(stream[pos*8:(pos+1)*8])[0] for pos in range(len(stream) // 8))
-            lengthLengths = len(lengths)
-            if lengthLengths > lengthExtras:
-                logger.warning(f'Error while parsing multiple type. Expected {lengthLengths} stream{"s" if lengthLengths != 1 else ""}, got {lengthExtras}. Ignoring.')
-            for x, y in enumerate(extras):
-                if lengths[x] != len(y):
-                    logger.warning(f'Error while parsing multiple type. Expected length {lengths[x]}, got {len(y)}. Ignoring.')
-            return ret
-        elif _type in (0x1002, 0x1003, 0x1004, 0x1005, 0x1007, 0x1014, 0x1040, 0x1048):
-            if stream != len(extras):
-                logger.warning(f'Error while parsing multiple type. Expected {stream} entr{"y" if stream == 1 else "ies"}, got {len(extras)}. Ignoring.')
-            if _type == 0x1002: # PtypMultipleInteger16
-                return tuple(constants.STMI16.unpack(x)[0] for x in extras)
-            if _type == 0x1003: # PtypMultipleInteger32
-                return tuple(constants.STMI32.unpack(x)[0] for x in extras)
-            if _type == 0x1004: # PtypMultipleFloating32
-                return tuple(constants.STMF32.unpack(x)[0] for x in extras)
-            if _type == 0x1005: # PtypMultipleFloating64
-                return tuple(constants.STMF64.unpack(x)[0] for x in extras)
-            if _type == 0x1007: # PtypMultipleFloatingTime
-                values = tuple(constants.STMF64.unpack(x)[0] for x in extras)
-                return tuple(constants.PYTPFLOATINGTIME_START + datetime.timedelta(days = amount) for amount in values)
-            if _type == 0x1014: # PtypMultipleInteger64
-                return tuple(constants.STMI64.unpack(x)[0] for x in extras)
-            if _type == 0x1040: # PtypMultipleTime
-                return tuple(filetimeToUtc(constants.ST3.unpack(x)[0]) for x in extras)
-            if _type == 0x1048: # PtypMultipleGuid
-                return tuple(bytesToGuid(x) for x in extras)
-        else:
-            raise NotImplementedError(f'Parsing for type {_type} has not yet been implmented. If you need this type, please create a new issue labeled "NotImplementedError: parseType {_type}".')
-    return value
-
-
-def prepareFilename(filename) -> str:
-    """
-    Adjusts :param filename: so that it can succesfully be used as an actual
-    file name.
-    """
-    # I would use re here, but it tested to be slightly slower than this.
-    return ''.join(i for i in filename if i not in r'\/:*?"<>|' + '\x00').strip()
-
-
-def properHex(inp, length : int = 0) -> str:
-    """
-    Takes in various input types and converts them into a hex string whose
-    length will always be even.
-    """
-    a = ''
-    if isinstance(inp, str):
-        a = ''.join([hex(ord(inp[x]))[2:].rjust(2, '0') for x in range(len(inp))])
-    elif isinstance(inp, bytes):
-        a = inp.hex()
-    elif isinstance(inp, int):
-        a = hex(inp)[2:]
-    if len(a) % 2 != 0:
-        a = '0' + a
-    return a.rjust(length, '0').upper()
-
-
-def roundUp(inp : int, mult : int) -> int:
-    """
-    Rounds :param inp: up to the nearest multiple of :param mult:.
-    """
-    return inp + (mult - inp) % mult
-
-
-def rtfSanitizeHtml(inp : str) -> str:
-    """
-    Sanitizes input to an RTF stream that has encapsulated HTML.
-    """
-    if not inp:
-        return ''
-    output = ''
-    for char in inp:
-        # Check if it is in the right range to be printed directly.
-        if 32 <= ord(char) < 128:
-            # Quick check for handling the HTML escapes. Will eventually
-            # upgrade this code to actually handle all the HTML escapes
-            # but this will do for now.
-            if char == '<':
-                output += r'{\*\htmltag84 &lt;}\htmlrtf <\htmlrtf0 '
-            elif char == '>':
-                output += r'{\*\htmltag84 &gt;}\htmlrtf >\htmlrtf0'
-            else:
-                if char in ('\\', '{', '}'):
-                    output += '\\'
-                output += char
-        elif ord(char) < 32 or 128 <= ord(char) <= 255:
-            # Otherwise, see if it is just a small escape.
-            output += "\\'" + properHex(char, 2)
-        else:
-            # Handle Unicode characters.
-            enc = char.encode('utf-16-le')
-            output += ''.join(f'\\u{x}?' for x in struct.unpack(f'<{len(enc) // 2}h', enc))
-
-    return output
-
-
-def rtfSanitizePlain(inp : str) -> str:
-    """
-    Sanitizes input to a plain RTF stream.
-    """
-    if not inp:
-        return ''
-    output = ''
-    for char in inp:
-        # Check if it is in the right range to be printed directly.
-        if 32 <= ord(char) < 128:
-            if char in ('\\', '{', '}'):
-                output += '\\'
-            output += char
-        elif ord(char) < 32 or 128 <= ord(char) <= 255:
-            # Otherwise, see if it is just a small escape.
-            output += "\\'" + properHex(char, 2)
-        else:
-            # Handle Unicode characters.
-            # Handle Unicode characters.
-            enc = char.encode('utf-16-le')
-            output += ''.join(f'\\u{x}?' for x in struct.unpack(f'<{len(enc) // 2}h', enc))
-
-    return output
-
-
-def setupLogging(defaultPath = None, defaultLevel = logging.WARN, logfile = None, enableFileLogging : bool = False,
-                  env_key = 'EXTRACT_MSG_LOG_CFG') -> bool:
-    """
-    Setup logging configuration
-
-    Args:
-    :param defaultPath: Default path to use for the logging configuration file.
-    :param defaultLevel: Default logging level.
-    :param env_key: Environment variable name to search for, for setting logfile
-        path.
-    :param enableFileLogging: Whether to use a file to log or not.
-
-    Returns:
-        bool: True if the configuration file was found and applied, False otherwise
-    """
-    shippedConfig = pathlib.Path(__file__).parent / 'logging-config'
-    if os.name == 'nt':
-        null = 'NUL'
-        shippedConfig /= 'logging-nt.json'
-    elif os.name == 'posix':
-        null = '/dev/null'
-        shippedConfig /= 'logging-posix.json'
-    # Find logging.json if not provided
-    defaultPath = pathlib.Path(defaultPath) if defaultPath else shippedConfig
-
-    paths = [
-        defaultPath,
-        pathlib.Path('logging.json'),
-        pathlib.Path('../logging.json'),
-        pathlib.Path('../../logging.json'),
-        shippedConfig,
-    ]
-
-    path = None
-
-    for configPath in paths:
-        if configPath.exists():
-            path = configPath
-            break
-
-    value = os.getenv(env_key, None)
-    if value and os.path.exists(value) and os.path.isfile(value):
-        path = pathlib.Path(value)
-
-    if not path:
-        print('Unable to find logging.json configuration file')
-        print('Make sure a valid logging configuration file is referenced in the defaultPath'
-              ' argument, is inside the extract_msg install location, or is available at one '
-              'of the following file-paths:')
-        print(str(paths[1:]))
-        logging.basicConfig(level = defaultLevel)
-        logging.warning('The extract_msg logging configuration was not found - using a basic configuration.'
-                        f'Please check the extract_msg installation directory for "logging-{os.name}.json".')
-        return False
-
-    with open(path, 'rt') as f:
-        config = json.load(f)
-
-    for x in config['handlers']:
-        if 'filename' in config['handlers'][x]:
-            if enableFileLogging:
-                config['handlers'][x]['filename'] = tmp = os.path.expanduser(
-                    os.path.expandvars(logfile if logfile else config['handlers'][x]['filename']))
-                tmp = pathlib.Path(tmp).parent
-                if not tmp.exists:
-                    os.makedirs(tmp)
-            else:
-                config['handlers'][x]['filename'] = null
-
-    try:
-        logging.config.dictConfig(config)
-    except ValueError as e:
-        print('Failed to configure the logger. Did your installation get messed up?')
-        print(e)
-
-    logging.getLogger().setLevel(defaultLevel)
-    return True
-
-
-def tryGetMimetype(att, mimetype : Union[str, None]) -> Union[str, None]:
-    """
-    Uses an optional dependency to try and get the mimetype of an attachment. If
-    the mimetype has already been found, the optional dependency does not exist,
-    or an error occurs in the optional dependency, then the provided mimetype is
-    returned.
-
-    :param att: The attachment to use for getting the mimetype.
-    :param mimetype: The mimetype acquired directly from an attachment stream.
-        If this value evaluates to False, the function will try to determine it.
-    """
-    if mimetype:
-        return mimetype
-
-    # We only try anything if it is a plain attachment or signed attachment.
-    # Web attachments and embedded MSG files are completely ignored.
-    if att.type in (AttachmentType.DATA, AttachmentType.SIGNED):
-        # Try to import our dependency module to use it.
-        try:
-            import magic
-
-            return magic.from_buffer(att.data, mime = True)
-        except ImportError:
-            logger.info('Mimetype not found on attachment, and `mime` dependency not installed. Won\'t try to generate.')
-
-        except Exception:
-            logger.exception('Error occured while using python-magic. This error will be ignored.')
-
-    return mimetype
-
-
-def unsignedToSignedInt(uInt : int) -> int:
-    """
-    Convert the bits of an unsigned int (32-bit) to an int.
-
-    :raises ValueError: The number was not valid.
-    """
-    if uInt > 0xFFFFFFFF:
-        raise ValueError('Value is too large.')
-    if uInt < 0:
-        raise ValueError('Value is already signed.')
-    return constants.STI32.unpack(constants.STUI32.pack(uInt))[0]
-
-
-def unwrapMsg(msg : 'MSGFile') -> Dict:
-    """
-    Takes a recursive message-attachment structure and unwraps it into a linear
-    dictionary for easy iteration. Dictionary contains 4 keys: "attachments" for
-    main message attachments, not including embedded MSG files, "embedded" for
-    attachments representing embedded MSG files, "msg" for all MSG files
-    (including the original in the first index), and "raw_attachments" for raw
-    attachments from signed messages.
-    """
-    from .message_signed_base import MessageSignedBase
-
-    # Here is where we store main attachments.
-    attachments = []
-    # Here is where we are going to store embedded msg files.
-    msgFiles = [msg]
-    # Here is where we store embedded attachments.
-    embedded = []
-    # Here is where we store raw attachments from signed messages.
-    raw = []
-
-    # Normally we would need a recursive function to unwrap a recursive
-    # structure like the message-attachment structure. Essentially, a function
-    # that calls itself. Here, I have designed code capable of circumventing
-    # this to do it in a single function, which is a lot more efficient and
-    # safer. That is why we store the `toProcess` and use a while loop
-    # surrounding a for loop. The for loop would be the main body of the
-    # function, while the append to toProcess would be the recursive call.
-    toProcess = collections.deque((msg,))
-
-    while len(toProcess) > 0:
-        # Remove the last item from the list of things to process, and store it
-        # in `currentItem`. We will be processing it in the for loop.
-        currentItem = toProcess.popleft()
-        # iterate through the attachments and
-        for att in currentItem.attachments:
-            # If it is a regular attachment, add it to the list. Otherwise, add
-            # it to be processed
-            if att.type in (AttachmentType.DATA, AttachmentType.SIGNED):
-                attachments.append(att)
-            elif att.type is AttachmentType.MSG:
-                # Here we do two things. The first is we store it to the output
-                # so we can return it. The second is we add it to the processing
-                # list. The reason this is two steps is because we need to be
-                # able to remove items from the processing list, but can't
-                # do that from the output.
-                embedded.append(att)
-                msgFiles.append(att.data)
-                toProcess.append(att.data)
-        if isinstance(currentItem, MessageSignedBase):
-            raw += currentItem._rawAttachments
-
-    return {
-        'attachments': attachments,
-        'embedded': embedded,
-        'msg': msgFiles,
-        'raw_attachments': raw,
-    }
-
-
-def unwrapMultipart(mp : Union[bytes, str, email.message.Message]) -> Dict:
-    """
-    Unwraps a recursive multipart structure into a dictionary of linear lists.
-    Similar to unwrapMsg, but for multipart. Dictionary contains 3 keys:
-    "attachments" which contains a list of dicts containing processed attachment
-    data as well as the Message instance associated with it, "plain_body" which
-    contains the plain text body, and "html_body" which contains the HTML body.
-
-    For clarification, each instance of processed attachment data is a dict
-    with keys identical to the args used for the SignedAttachment constructor.
-    This makes it easy to expand for use in constructing a SignedAttachment. The
-    only argument missing is "msg" to ensure this function will not require one.
-
-    :param mp: The bytes that make up a multipart, the string that makes up a
-        multipart, or a Message instance from the email module created from the
-        multipart to unwrap. If providing a Message instance, prefer it to be an
-        instance of EmailMessage. If you are doing so, make sure it's policy is
-        default.
-    """
-    # In the event we are generating it, these are the kwargs to use.
-    genKwargs = {
-        '_class': email.message.EmailMessage,
-        'policy': email.policy.default,
-    }
-    # Convert our input into something usable.
-    if isinstance(mp, email.message.EmailMessage):
-        if mp.policy == email.policy.default:
-            mpMessage = mp
-        else:
-            mpMessage = email.message_from_bytes(mp.as_bytes(), **genKwargs)
-    elif isinstance(mp, email.message.Message):
-        mpMessage = email.message_from_bytes(mp.as_bytes(), **genKwargs)
-    elif isinstance(mp, bytes):
-        mpMessage = email.message_from_bytes(mp, **genKwargs)
-    elif isinstance(mp, str):
-        mpMessage = email.message_from_string(mp, **genKwargs)
-    else:
-        raise TypeError(f'Unsupported type "{type(mp)}" provided to unwrapMultipart.')
-
-    # Okay, now that we have it in a useable form, let's do the most basic
-    # unwrapping possible. Once the most basic unwrapping is done, we can
-    # actually process the data. For this, we only care if the section is
-    # multipart or not. If it is, it get's unwrapped too.
-    #
-    # In case you are curious, this is effectively doing a breadth first
-    # traversal of the tree.
-    dataNodes = []
-
-    toProcess = collections.deque((mpMessage,))
-    # I do know about the walk method, but it might *also* walk embedded
-    # messages which we very much don't want.
-    while len(toProcess) > 0:
-        currentItem = toProcess.popleft()
-        # 'multipart' indicates that it shouldn't contain any data itself, just
-        # other nodes to go through.
-        if currentItem.get_content_maintype() == 'multipart':
-            payload = currentItem.get_payload()
-            # For multipart, the payload should be a list, but handle it not
-            # being one.
-            if isinstance(payload, list):
-                toProcess.extend(payload)
-            else:
-                logging.warning('Found multipart node that did not return a list. Appending as a data node.')
-                dataNodes.append(currentItem)
-        else:
-            # The opposite is *not* true. If it's not multipart, always add as a
-            # data node.
-            dataNodes.append(currentItem)
-
-    # At this point, all of our nodes should have processed and we should now
-    # have data nodes. Now let's process them. For anything that was parsed as
-    # a message, we actually want to get it's raw bytes back so it can be saved.
-    # If they user wants to process that message in some way, they can do it
-    # themself.
-    attachments = []
-    plainBody = None
-    htmlBody = None
-
-    for node in dataNodes:
-        # Let's setup our attachment we are going to use.
-        attachment = {
-            'data': None,
-            'name': node.get_filename(),
-            'mimetype': node.get_content_type(),
-            'node': node,
-        }
-
-        # Finally, we need to get the data. As we need to ensure it is bytes,
-        # we may have to do some special processing.
-        data = node.get_content()
-        if isinstance(data, bytes):
-            # If the data is bytes, we are perfectly good.
-            pass
-        elif isinstance(data, email.message.Message):
-            # If it is a message, get it's bytes directly.
-            data = data.as_bytes()
-        elif isinstance(data, str):
-            # If it is a string, let's reverse encode it where possible.
-            # First thing we want to check is if we can find the encoding type.
-            # If we can, use that to reverse the process. Otherwise use utf-8.
-            data = data.encode(node.get_content_charset('utf-8'))
-        else:
-            # We throw an exception to describe the problem if we can't reverse
-            # the problem.
-            raise TypeError(f'Attempted to get bytes for attachment, but could not convert {type(data)} to bytes.')
-
-        attachment['data'] = data
-
-        # Now for the fun part, figuring out if we actually have an attachment.
-        if attachment['name']:
-            attachments.append(attachment)
-        elif attachment['mimetype'] == 'text/plain':
-            if plainBody:
-                logger.warning('Found multiple candidates for plain text body.')
-            plainBody = data
-        elif attachment['mimetype'] == 'text/html':
-            if htmlBody:
-                logger.warning('Found multiple candidates for HTML body.')
-            htmlBody = data
-
-    return {
-        'attachments': attachments,
-        'plain_body': plainBody,
-        'html_body': htmlBody,
-    }
-
-def validateHtml(html : bytes) -> bool:
-    """
-    Checks whether the HTML is considered valid. To be valid, the HTML must, at
-    minimum, contain an <html> tag, a <body> tag, and closing tags for each.
-    """
-    bs = bs4.BeautifulSoup(html, 'html.parser')
-    if not bs.find('html') or not bs.find('body'):
-        return False
-    return True
-
-
-def verifyPropertyId(id : str) -> None:
-    """
-    Determines whether a property ID is valid for vertain functions. Property
-    IDs MUST be a 4 digit hexadecimal string. Property is valid if no exception
-    is raised.
-
-    :raises InvaildPropertyIdError: if the it is not a 4 digit hexadecimal
-        number.
-    """
-    if not isinstance(id, str):
-        raise InvaildPropertyIdError('ID was not a 4 digit hexadecimal string')
-    elif len(id) != 4:
-        raise InvaildPropertyIdError('ID was not a 4 digit hexadecimal string')
-    else:
-        try:
-            int(id, 16)
-        except ValueError:
-            raise InvaildPropertyIdError('ID was not a 4 digit hexadecimal string')
-
-
-def verifyType(_type) -> str:
-    """
-    Verifies that the type is valid. Raises an exception if it is not.
-
-    :raises UnknownTypeError: if the type is not recognized.
-    """
-    if _type is not None:
-        if (_type not in constants.VARIABLE_LENGTH_PROPS_STRING) and (_type not in constants.FIXED_LENGTH_PROPS_STRING):
-            raise UnknownTypeError(f'Unknown type {_type}.')
-
-
-def windowsUnicode(string) -> Optional[str]:
-    return str(string, 'utf-16-le') if string is not None else None
+from __future__ import annotations
+
+"""
+Utility functions of extract_msg.
+"""
+
+
+__all__ = [
+    'addNumToDir', 'addNumToZipDir', 'bitwiseAdjust', 'bitwiseAdjustedAnd',
+    'bytesToGuid', 'ceilDiv', 'cloneOleFile', 'createZipOpen',
+    'dictGetCasedKey', 'divide', 'filetimeToDatetime', 'findWk',
+    'fromTimeStamp', 'getCommandArgs', 'getEncodingName', 'getFullClassName',
+    'hasLen', 'htmlSanitize', 'inputToBytes', 'inputToMsgPath', 'inputToString',
+    'isEncapsulatedRtf', 'isEmptyString', 'knownMsgClass', 'filetimeToUtc',
+    'msgPathToString', 'openMsg', 'openMsgBulk', 'parseType', 'prepareFilename',
+    'properHex', 'roundUp', 'rtfSanitizeHtml', 'rtfSanitizePlain',
+    'setupLogging', 'tryGetMimetype', 'unsignedToSignedInt', 'unwrapMsg',
+    'unwrapMultipart', 'validateHtml', 'verifyPropertyId', 'verifyType',
+    'windowsUnicode',
+]
+
+
+import argparse
+import codecs
+import collections
+import copy
+import datetime
+import email.message
+import email.policy
+import glob
+import json
+import logging
+import logging.config
+import os
+import pathlib
+import shutil
+import struct
+# Not actually sure if this needs to be here for the logging, so just in case.
+import sys
+import zipfile
+
+import bs4
+import olefile
+import tzlocal
+
+from html import escape as htmlEscape
+from typing import Any, Dict, List, Optional, Tuple, TYPE_CHECKING, Union
+
+from . import constants
+from .enums import AttachmentType
+from .exceptions import (
+        ConversionError, ExecutableNotFound, IncompatibleOptionsError,
+        InvalidFileFormatError, InvaildPropertyIdError, TZError,
+        UnknownCodepageError, UnknownTypeError, UnrecognizedMSGTypeError,
+        UnsupportedEncodingError, UnsupportedMSGTypeError
+    )
+
+
+# Allow for nice type checking.
+if TYPE_CHECKING:
+    from .msg import MSGFile
+
+logger = logging.getLogger(__name__)
+logger.addHandler(logging.NullHandler())
+logging.addLevelName(5, 'DEVELOPER')
+
+
+def addNumToDir(dirName : pathlib.Path) -> Optional[pathlib.Path]:
+    """
+    Attempt to create the directory with a '(n)' appended.
+    """
+    for i in range(2, 100):
+        try:
+            newDirName = dirName.with_name(dirName.name + f' ({i})')
+            os.makedirs(newDirName)
+            return newDirName
+        except Exception as e:
+            pass
+    return None
+
+
+def addNumToZipDir(dirName : pathlib.Path, _zip) -> Optional[pathlib.Path]:
+    """
+    Attempt to create the directory with a '(n)' appended.
+    """
+    for i in range(2, 100):
+        newDirName = dirName.with_name(dirName.name + f' ({i})')
+        pathCompare = str(newDirName).rstrip('/') + '/'
+        if not any(x.startswith(pathCompare) for x in _zip.namelist()):
+            return newDirName
+    return None
+
+
+def bitwiseAdjust(inp : int, mask : int) -> int:
+    """
+    Uses a given mask to adjust the location of bits after an operation like
+    bitwise AND. This is useful for things like flags where you are trying to
+    get a small portion of a larger number. Say for example, you had the number
+    0xED (0b11101101) and you needed the adjusted result of the AND operation
+    with 0x70 (0b01110000). The result of the AND operation (0b01100000) and the
+    mask used to get it (0x70) are given to this function and the adjustment
+    will be done automatically.
+
+    :param mask: MUST be greater than 0.
+
+    :raises ValueError: if the mask is not greater than 0.
+    """
+    if mask < 1:
+        raise ValueError('Mask MUST be greater than 0')
+    return inp >> bin(mask)[::-1].index('1')
+
+
+def bitwiseAdjustedAnd(inp : int, mask : int) -> int:
+    """
+    Preforms the bitwise AND operation between :param inp: and :param mask: and
+    adjusts the results based on the rules of the bitwiseAdjust function.
+
+    :raises ValueError: if the mask is not greater than 0.
+    """
+    if mask < 1:
+        raise ValueError('Mask MUST be greater than 0')
+    return (inp & mask) >> bin(mask)[::-1].index('1')
+
+
+def bytesToGuid(bytesInput : bytes) -> str:
+    """
+    Converts a bytes instance to a GUID.
+    """
+    guidVals = constants.ST_GUID.unpack(bytesInput)
+    return f'{{{guidVals[0]:08X}-{guidVals[1]:04X}-{guidVals[2]:04X}-{guidVals[3][:2].hex().upper()}-{guidVals[3][2:].hex().upper()}}}'
+
+
+def ceilDiv(n : int, d : int) -> int:
+    """
+    Returns the int from the ceil division of n / d.
+    ONLY use ints as inputs to this function.
+
+    For ints, this is faster and more accurate for numbers
+    outside the precision range of float.
+    """
+    return -(n // -d)
+
+
+def cloneOleFile(sourcePath, outputPath) -> None:
+    """
+    Uses the OleWriter class to clone the specified OLE file into a new
+    location. Mainly designed for testing.
+    """
+    from .ole_writer import OleWriter
+
+    with olefile.OleFileIO(sourcePath) as f:
+        writer = OleWriter()
+        writer.fromOleFile(f)
+
+    writer.write(outputPath)
+
+
+def createZipOpen(func):
+    """
+    Creates a wrapper for the open function of a ZipFile that will automatically
+    set the current date as the modified time to the current time.
+    """
+    def _open(name, mode, *args, **kwargs):
+        if mode == 'w':
+            name = zipfile.ZipInfo(name, datetime.datetime.now().timetuple())
+
+        return func(name, mode, *args, **kwargs)
+
+    return _open
+
+
+def dictGetCasedKey(_dict : Dict, key : Any) -> Any:
+    """
+    Retrieves the key from the dictionary with the proper casing using a
+    caseless key.
+    """
+    try:
+        return next((x for x in _dict.keys() if x.lower() == key.lower()))
+    except StopIteration:
+        # If we couldn't find the key, raise a KeyError.
+        raise KeyError(key)
+
+
+def divide(string, length : int) -> List:
+    """
+    Divides a string into multiple substrings of equal length. If there is not
+    enough for the last substring to be equal, it will simply use the rest of
+    the string. Can also be used for things like lists and tuples.
+
+    :param string: string to be divided.
+    :param length: length of each division.
+    :returns: list containing the divided strings.
+
+    Example:
+    >>>> a = divide('Hello World!', 2)
+    >>>> print(a)
+    ['He', 'll', 'o ', 'Wo', 'rl', 'd!']
+    >>>> a = divide('Hello World!', 5)
+    >>>> print(a)
+    ['Hello', ' Worl', 'd!']
+    """
+    return [string[length * x:length * (x + 1)] for x in range(int(ceilDiv(len(string), length)))]
+
+
+def filetimeToDatetime(rawTime : int) -> datetime.datetime:
+    """
+    Converts a filetime into a datetime.
+
+    Some values have specialized meanings, listed below:
+        915151392000000000: December 31, 4500, representing a null time. Returns
+            extract_msg.constants.NULL_DATE.
+        915046235400000000: 23:59 on August 31, 4500, representing a null time.
+            Returns extract_msg.constants.NULL_DATE.
+    """
+    try:
+        if rawTime < 116444736000000000:
+            # We can't properly parse this with our current setup, so
+            # we will rely on olefile to handle this one.
+            return olefile.olefile.filetime2datetime(rawTime)
+        elif rawTime == 915151392000000000:
+            # So this is actually a different null date, specifically
+            # supposed to be December 31, 4500, but it's weird that the
+            # same spec has 2 different ones, so we just return the same
+            # one for both.
+            return constants.NULL_DATE
+        elif rawTime == 915046235400000000:
+            return constants.NULL_DATE
+        else:
+            return fromTimeStamp(filetimeToUtc(rawTime))
+    except TZError:
+        # For TZError we just raise it again. It is a fatal error.
+        raise
+    except Exception as e:
+        raise ValueError(f'Timestamp value of {filetimeToUtc(rawTime)} caused an exception. This was probably caused by the time stamp being too far in the future.')
+
+
+def findWk(path = None):
+    """
+    Attempt to find the path of the wkhtmltopdf executable. If :param path: is
+    provided, verifies that it is executable and returns the path if it is.
+
+    :raises ExecutableNotFound: A valid executable could not be found.
+    """
+    if path:
+        if os.path.isfile(path):
+            # Check if executable.
+            if os.access(path, os.X_OK):
+                return path
+            else:
+                raise ExecutableNotFound('Path provided was not a valid executable (execution bit not set).')
+        else:
+            raise ExecutableNotFound('Path provided was not a valid executable (not a file).')
+
+    candidate = shutil.which('wkhtmltopdf')
+    if candidate:
+        return candidate
+
+    raise ExecutableNotFound('Could not find wkhtmltopdf.')
+
+
+def fromTimeStamp(stamp : int) -> datetime.datetime:
+    """
+    Returns a datetime from the UTC timestamp given the current timezone.
+    """
+    try:
+        tz = tzlocal.get_localzone()
+    except Exception as e:
+        # I know "generalized exception catching is bad" but if *any* exception
+        # happens here that is a subclass of Exception then something has gone
+        # wrong with tzlocal.
+        raise TZError(f'Error occured using tzlocal. If you are seeing this, this is likely a problem with your installation ot tzlocal or tzdata.')
+    return datetime.datetime.fromtimestamp(stamp, tz)
+
+
+def getCommandArgs(args) -> argparse.Namespace:
+    """
+    Parse command-line arguments.
+
+    :raises IncompatibleOptionsError: Some options were provided that are
+        incompatible.
+    :raises ValueError: Something about the options was invalid. This could mean
+        an option was specified that requires another option or it could mean
+        that an option was looking for data that was not found.
+    """
+    parser = argparse.ArgumentParser(description = constants.MAINDOC, prog = 'extract_msg')
+    outFormat = parser.add_mutually_exclusive_group()
+    inputFormat = parser.add_mutually_exclusive_group()
+    # --use-content-id, --cid
+    parser.add_argument('--use-content-id', '--cid', dest='cid', action='store_true',
+                        help='Save attachments by their Content ID, if they have one. Useful when working with the HTML body.')
+    # --json
+    outFormat.add_argument('--json', dest='json', action='store_true',
+                        help='Changes to write output files as json.')
+    # --file-logging
+    parser.add_argument('--file-logging', dest='fileLogging', action='store_true',
+                        help='Enables file logging. Implies --verbose level 1.')
+    # --verbose
+    parser.add_argument('-v', '--verbose', dest='verbose', action='count', default=0,
+                        help='Turns on console logging. Specify more than once for higher verbosity.')
+    # --log PATH
+    parser.add_argument('--log', dest='log',
+                        help='Set the path to write the file log to.')
+    # --config PATH
+    parser.add_argument('--config', dest='configPath',
+                        help='Set the path to load the logging config from.')
+    # --out PATH
+    parser.add_argument('--out', dest='outPath',
+                        help='Set the folder to use for the program output. (Default: Current directory)')
+    # --use-filename
+    parser.add_argument('--use-filename', dest='useFilename', action='store_true',
+                        help='Sets whether the name of each output is based on the msg filename.')
+    # --dump-stdout
+    parser.add_argument('--dump-stdout', dest='dumpStdout', action='store_true',
+                        help='Tells the program to dump the message body (plain text) to stdout. Overrides saving arguments.')
+    # --html
+    outFormat.add_argument('--html', dest='html', action='store_true',
+                        help='Sets whether the output should be HTML. If this is not possible, will error.')
+    # --pdf
+    outFormat.add_argument('--pdf', dest='pdf', action='store_true',
+                           help='Saves the body as a PDF. If this is not possible, will error.')
+    # --wk-path PATH
+    parser.add_argument('--wk-path', dest='wkPath',
+                        help='Overrides the path for finding wkhtmltopdf.')
+    # --wk-options OPTIONS
+    parser.add_argument('--wk-options', dest='wkOptions', nargs='*',
+                        help='Sets additional options to be used in wkhtmltopdf. Should be a series of options and values, replacing the - or -- in the beginning with + or ++, respectively. For example: --wk-options "+O Landscape"')
+    # --prepared-html
+    parser.add_argument('--prepared-html', dest='preparedHtml', action='store_true',
+                        help='When used in conjunction with --html, sets whether the HTML output should be prepared for embedded attachments.')
+    # --charset
+    parser.add_argument('--charset', dest='charset', default='utf-8',
+                        help='Character set to use for the prepared HTML in the added tag. (Default: utf-8)')
+    # --raw
+    outFormat.add_argument('--raw', dest='raw', action='store_true',
+                           help='Sets whether the output should be raw. If this is not possible, will error.')
+    # --rtf
+    outFormat.add_argument('--rtf', dest='rtf', action='store_true',
+                           help='Sets whether the output should be RTF. If this is not possible, will error.')
+    # --allow-fallback
+    parser.add_argument('--allow-fallback', dest='allowFallback', action='store_true',
+                        help='Tells the program to fallback to a different save type if the selected one is not possible.')
+    # --skip-body-not-found
+    parser.add_argument('--skip-body-not-found', dest='skipBodyNotFound', action='store_true',
+                        help='Skips saving the body if the body cannot be found, rather than throwing an error.')
+    # --zip
+    parser.add_argument('--zip', dest='zip',
+                        help='Path to use for saving to a zip file.')
+    # --save-header
+    parser.add_argument('--save-header', dest='saveHeader', action='store_true',
+                        help='Store the header in a separate file.')
+    # --attachments-only
+    outFormat.add_argument('--attachments-only', dest='attachmentsOnly', action='store_true',
+                           help='Specify to only save attachments from an msg file.')
+    # --skip-hidden
+    parser.add_argument('--skip-hidden', dest='skipHidden', action='store_true',
+                        help='Skips any attachment marked as hidden (usually ones embedded in the body).')
+    # --no-folders
+    parser.add_argument('--no-folders', dest='noFolders', action='store_true',
+                        help='Stores everything in the location specified by --out. Requires --attachments-only and is incompatible with --out-name.')
+    # --skip-embedded
+    parser.add_argument('--skip-embedded', dest='skipEmbedded', action='store_true',
+                        help='Skips all embedded MSG files when saving attachments.')
+    # --extract-embedded
+    parser.add_argument('--extract-embedded', dest='extractEmbedded', action='store_true',
+                        help='Extracts the embedded MSG files as MSG files instead of running their save functions.')
+    # --skip-not-implemented
+    parser.add_argument('--skip-not-implemented', '--skip-ni', dest='skipNotImplemented', action='store_true',
+                        help='Skips any attachments that are not implemented, allowing saving of the rest of the message.')
+    # --out-name NAME
+    inputFormat.add_argument('--out-name', dest='outName',
+                        help='Name to be used with saving the file output. Cannot be used if you are saving more than one file.')
+    # --glob
+    inputFormat.add_argument('--glob', '--wildcard', dest='glob', action='store_true',
+                        help='Interpret all paths as having wildcards. Incompatible with --out-name.')
+    # --ignore-rtfde
+    parser.add_argument('--ignore-rtfde', dest='ignoreRtfDeErrors', action='store_true',
+                        help='Ignores all errors thrown from RTFDE when trying to save. Useful for allowing fallback to continue when an exception happens.')
+    # --progress
+    parser.add_argument('--progress', dest='progress', action='store_true',
+                        help='Shows what file the program is currently working on during it\'s progress.')
+    # [msg files]
+    parser.add_argument('msgs', metavar='msg', nargs='+',
+                        help='An MSG file to be parsed.')
+
+    options = parser.parse_args(args)
+
+    if options.outName and options.noFolders:
+        raise IncompatibleOptionsError('--out-name is not compatible with --no-folders.')
+
+    if options.dev or options.fileLogging:
+        options.verbose = options.verbose or 1
+
+    # Handle the wkOptions if they exist.
+    if options.wkOptions:
+        wkOptions = []
+        for option in options.wkOptions:
+            if option.startswith('++'):
+                option = '--' + option[2:]
+            elif option.startswith('+'):
+                option = '-' + option[1:]
+
+            # Now that we have corrected to the correct start, split the argument if
+            # necessary.
+            split = option.split(' ')
+            if len(split) == 1:
+                # No spaces means we just pass that directly.
+                wkOptions.append(option)
+            else:
+                wkOptions.append(split[0])
+                wkOptions.append(' '.join(split[1:]))
+
+        options.wkOptions = wkOptions
+
+    # If dump_stdout is True, we need to unset all arguments used in files.
+    # Technically we actually only *need* to unset `out_path`, but that may
+    # change in the future, so let's be thorough.
+    if options.dumpStdout:
+        options.outPath = None
+        options.json = False
+        options.rtf = False
+        options.html = False
+        options.useFilename = False
+        options.cid = False
+
+    if options.glob:
+        if options.outName:
+            raise IncompatibleOptionsError('--out-name is not supported when using wildcards.')
+        fileLists = []
+        for path in options.msgs:
+            fileLists += glob.glob(path)
+
+        if len(fileLists) == 0:
+            raise ValueError('Could not find any msg files using the specified wildcards.')
+        options.msgs = fileLists
+
+    # Make it so outName can only be used on single files.
+    if options.outName and len(options.msgs) > 1:
+        raise IncompatibleOptionsError('--out-name is not supported when saving multiple MSG files.')
+
+    # Handle the verbosity level.
+    if options.verbose == 0:
+        options.logLevel = logging.ERROR
+    elif options.verbose == 1:
+        options.logLevel = logging.WARNING
+    elif options.verbose == 2:
+        options.logLevel = logging.INFO
+    else:
+        options.logLevel = 5
+
+    # If --no-folders is turned on but --attachments-only is not, error.
+    if options.noFolders and not options.attachmentsOnly:
+        raise ValueError('--no-folders requires the --attachments-only option.')
+
+    return options
+
+
+def getEncodingName(codepage : int) -> str:
+    """
+    Returns the name of the encoding with the specified codepage.
+
+    :raises UnknownCodepageError: if the codepage is unrecognized.
+    :raises UnsupportedEncodingError: if the codepage is not supported.
+    """
+    if codepage not in constants.CODE_PAGES:
+        raise UnknownCodepageError(str(codepage))
+    try:
+        codecs.lookup(constants.CODE_PAGES[codepage])
+        return constants.CODE_PAGES[codepage]
+    except LookupError:
+        raise UnsupportedEncodingError(f'The codepage {codepage} ({constants.CODE_PAGES[codepage]}) is not currently supported by your version of Python.')
+
+
+def getFullClassName(inp) -> str:
+    return inp.__class__.__module__ + '.' + inp.__class__.__name__
+
+
+def hasLen(obj) -> bool:
+    """
+    Checks if :param obj: has a __len__ attribute.
+    """
+    return hasattr(obj, '__len__')
+
+
+def htmlSanitize(inp : str) -> str:
+    """
+    Santizes the input for injection into an HTML string. Converts characters
+    into forms that will not be misinterpreted, if necessary.
+    """
+    # First step, do a basic escape of the HTML.
+    inp = htmlEscape(inp)
+
+    # Change newlines to <br/> to they won't be ignored.
+    inp = inp.replace('\r\n', '\n').replace('\n', '<br/>')
+
+    # Escape long sections of spaces to ensure they won't be ignored.
+    inp = constants.RE_HTML_SAN_SPACE.sub((lambda spaces : '&nbsp;' * len(spaces.group(0))),inp)
+
+    return inp
+
+
+def inputToBytes(stringInputVar, encoding) -> bytes:
+    """
+    Converts the input into bytes.
+
+    :raises ConversionError: if the input cannot be converted.
+    """
+    if isinstance(stringInputVar, bytes):
+        return stringInputVar
+    elif isinstance(stringInputVar, str):
+        return stringInputVar.encode(encoding)
+    elif stringInputVar is None:
+        return b''
+    else:
+        raise ConversionError('Cannot convert to bytes.')
+
+
+def inputToMsgPath(inp) -> List:
+    """
+    Converts the input into an msg path.
+
+    :raises ValueError: The path contains an illegal character.
+    """
+    if isinstance(inp, (list, tuple)):
+        inp = '/'.join(inp)
+
+    inp = inputToString(inp, 'utf-8')
+
+    # Validate the path is okay. Normally we would check for '/' and '\', but
+    # we are expecting a string or similar which will use those as path
+    # separators, so we will ignore that for now.
+    if ':' in inp or '!' in inp:
+        raise ValueError('Illegal character ("!" or ":") found in MSG path.')
+
+    ret = [x for x in inp.replace('\\', '/').split('/') if x]
+
+    # One last thing to check: all path segments can be, at most, 31 characters
+    # (32 if you include the null character), so we should verify that.
+    if any(len(x) > 31 for x in ret):
+        raise ValueError('Path segments must not be greater than 31 characters.')
+    return ret
+
+
+def inputToString(bytesInputVar, encoding) -> str:
+    """
+    Converts the input into a string.
+
+    :raises ConversionError: if the input cannot be converted.
+    """
+    if isinstance(bytesInputVar, str):
+        return bytesInputVar
+    elif isinstance(bytesInputVar, bytes):
+        return bytesInputVar.decode(encoding)
+    elif bytesInputVar is None:
+        return ''
+    else:
+        raise ConversionError('Cannot convert to str type.')
+
+
+def isEncapsulatedRtf(inp : bytes) -> bool:
+    """
+    Currently the detection is made to be *extremly* basic, but this will work
+    for now. In the future this will be fixed so that literal text in the body
+    of a message won't cause false detection.
+    """
+    return b'\\fromhtml' in inp
+
+
+def isEmptyString(inp : str) -> bool:
+    """
+    Returns true if the input is None or is an Empty string.
+    """
+    return (inp == '' or inp is None)
+
+
+def knownMsgClass(classType : str) -> bool:
+    """
+    Checks if the specified class type is recognized by the module. Usually used
+    for checking if a type is simply unsupported rather than unknown.
+    """
+    classType = classType.lower()
+    if classType == 'ipm':
+        return True
+
+    for item in constants.KNOWN_CLASS_TYPES:
+        if classType.startswith(item):
+            return True
+
+    return False
+
+
+def filetimeToUtc(inp : int) -> float:
+    """
+    Converts a FILETIME into a unix timestamp.
+    """
+    return (inp - 116444736000000000) / 10000000.0
+
+
+def msgPathToString(inp) -> str:
+    """
+    Converts an MSG path (one of the internal paths inside an MSG file) into a
+    string.
+    """
+    if inp is None:
+        return None
+    if isinstance(inp, (list, tuple)):
+        inp = '/'.join(inp)
+    inp.replace('\\', '/')
+    return inp
+
+
+def openMsg(path, **kwargs) -> MSGFile:
+    """
+    Function to automatically open an MSG file and detect what type it is.
+
+    :param path: Path to the msg file in the system or is the raw msg file.
+    :param prefix: Used for extracting embeded msg files inside the main one.
+        Do not set manually unless you know what you are doing.
+    :param parentMsg: Used for syncronizing named properties instances. Do not
+        set this unless you know what you are doing.
+    :param attachmentClass: Optional, the class the Message object will use for
+        attachments. You probably should not change this value unless you know
+        what you are doing.
+    :param signedAttachmentClass: Optional, the class the object will use for
+        signed attachments.
+    :param filename: Optional, the filename to be used by default when saving.
+    :param delayAttachments: Optional, delays the initialization of attachments
+        until the user attempts to retrieve them. Allows MSG files with bad
+        attachments to be initialized so the other data can be retrieved.
+    :param overrideEncoding: Optional, overrides the specified encoding of the
+        MSG file.
+    :param attachmentErrorBehavior: Optional, the behaviour to use in the event
+        of an error when parsing the attachments.
+    :param recipientSeparator: Optional, Separator string to use between
+        recipients.
+    :param ignoreRtfDeErrors: Optional, specifies that any errors that occur
+        from the usage of RTFDE should be ignored (default: False).
+
+    If :param strict: is set to `True`, this function will raise an exception
+    when it cannot identify what MSGFile derivitive to use. Otherwise, it will
+    log the error and return a basic MSGFile instance.
+
+    :raises UnsupportedMSGTypeError: if the type is recognized but not suppoted.
+    :raises UnrecognizedMSGTypeError: if the type is not recognized.
+    """
+    from .appointment import AppointmentMeeting
+    from .contact import Contact
+    from .meeting_cancellation import MeetingCancellation
+    from .meeting_exception import MeetingException
+    from .meeting_forward import MeetingForwardNotification
+    from .meeting_request import MeetingRequest
+    from .meeting_response import MeetingResponse
+    from .message import Message
+    from .msg import MSGFile
+    from .message_signed import MessageSigned
+    from .post import Post
+    from .task import Task
+    from .task_request import TaskRequest
+
+    # When the initial MSG file is opened, it should *always* delay attachments
+    # so it can get the main class type. We only need to load them after that
+    # if we are directly returning the MSGFile instance *and* delayAttachments
+    # is False.
+    #
+    # So first let's store the original value.
+    delayAttachments = kwargs.get('delayAttachments', False)
+    kwargs['delayAttachments'] = True
+
+    msg = MSGFile(path, **kwargs)
+
+    # Restore the option in the kwargs so we don't have to worry about it.
+    kwargs['delayAttachments'] = delayAttachments
+
+    # After rechecking the docs, all comparisons should be case-insensitive, not
+    # case-sensitive. My reading ability is great.
+    #
+    # Also after consideration, I realized we need to be very careful here, as
+    # other file types (like doc, ppt, etc.) might open but not return a class
+    # type. If the stream is not found, classType returns None, which has no
+    # lower function. So let's make sure we got a good return first.
+    if not msg.classType:
+        if kwargs.get('strict', True):
+            raise InvalidFileFormatError('File was confirmed to be an olefile, but was not an MSG file.')
+        else:
+            # If strict mode is off, we'll just return an MSGFile anyways.
+            logging.critical('Received file that was an olefile but was not an MSG file. Returning MSGFile anyways because strict mode is off.')
+            return msg
+    classType = msg.classType.lower()
+    # Put the message class first as it is most common.
+    if classType.startswith('ipm.note') or classType.startswith('report'):
+        msg.close()
+        if classType.endswith('smime.multipartsigned') or classType.endswith('smime'):
+            return MessageSigned(path, **kwargs)
+        else:
+            return Message(path, **kwargs)
+    elif classType.startswith('ipm.appointment'):
+        msg.close()
+        return AppointmentMeeting(path, **kwargs)
+    elif classType.startswith('ipm.contact') or classType.startswith('ipm.distlist'):
+        msg.close()
+        return Contact(path, **kwargs)
+    elif classType.startswith('ipm.post'):
+        msg.close()
+        return Post(path, **kwargs)
+    elif classType.startswith('ipm.schedule.meeting.request'):
+        msg.close()
+        return MeetingRequest(path, **kwargs)
+    elif classType.startswith('ipm.schedule.meeting.canceled'):
+        msg.close()
+        return MeetingCancellation(path, **kwargs)
+    elif classType.startswith('ipm.schedule.meeting.notification.forward'):
+        msg.close()
+        return MeetingForwardNotification(path, **kwargs)
+    elif classType.startswith('ipm.schedule.meeting.resp'):
+        msg.close()
+        return MeetingResponse(path, **kwargs)
+    elif classType.startswith('ipm.taskrequest'):
+        msg.close()
+        return TaskRequest(path, **kwargs)
+    elif classType.startswith('ipm.task'):
+        msg.close()
+        return Task(path, **kwargs)
+    elif classType.startswith('ipm.ole.class.{00061055-0000-0000-c000-000000000046}'):
+        # Exception objects have a weird class type.
+        msg.close()
+        return MeetingException(path, **kwargs)
+    elif classType == 'ipm':
+        # Unspecified format. It should be equal to this and not just start with
+        # it.
+        if not delayAttachments:
+            msg.attachments
+        return msg
+    elif kwargs.get('strict', True):
+        # Because we are closing it, we need to store it in a variable first.
+        ct = msg.classType
+        msg.close()
+        if knownMsgClass(classType):
+            raise UnsupportedMSGTypeError(f'MSG type "{ct}" currently is not supported by the module. If you would like support, please make a feature request.')
+        raise UnrecognizedMSGTypeError(f'Could not recognize msg class type "{ct}".')
+    else:
+        logger.error(f'Could not recognize msg class type "{msg.classType}". This most likely means it hasn\'t been implemented yet, and you should ask the developers to add support for it.')
+        if not delayAttachments:
+            msg.attachments
+        return msg
+
+
+def openMsgBulk(path, **kwargs) -> Union[List[MSGFile], Tuple[Exception, Union[str, bytes]]]:
+    """
+    Takes the same arguments as openMsg, but opens a collection of msg files
+    based on a wild card. Returns a list if successful, otherwise returns a
+    tuple.
+
+    :param ignoreFailures: If this is True, will return a list of all successful
+        files, ignoring any failures. Otherwise, will close all that
+        successfully opened, and return a tuple of the exception and the path of
+        the file that failed.
+    """
+    files = []
+    for x in glob.glob(str(path)):
+        try:
+            files.append(openMsg(x, **kwargs))
+        except Exception as e:
+            if not kwargs.get('ignoreFailures', False):
+                for msg in files:
+                    msg.close()
+                return (e, x)
+
+    return files
+
+
+def parseType(_type : int, stream, encoding, extras):
+    """
+    Converts the data in :param stream: to a much more accurate type, specified
+    by :param _type:.
+    :param _type: the data's type.
+    :param stream: is the data to be converted.
+    :param encoding: is the encoding to be used for regular strings.
+    :param extras: is used in the case of types like PtypMultipleString.
+    For that example, extras should be a list of the bytes from rest of the
+    streams.
+
+    :raises NotImplementedError: for types with no current support. Most of
+        these types have no documentation of existing in an MSG file.
+    """
+    # WARNING Not done. Do not try to implement anywhere where it is not already implemented.
+    value = stream
+    lengthExtras = len(extras)
+    if _type == 0x0000:  # PtypUnspecified
+        pass
+    elif _type == 0x0001:  # PtypNull
+        if value != b'\x00\x00\x00\x00\x00\x00\x00\x00':
+            # DEBUG
+            logger.warning('Property type is PtypNull, but is not equal to 0.')
+        return None
+    elif _type == 0x0002:  # PtypInteger16
+        return constants.STI16.unpack(value)[0]
+    elif _type == 0x0003:  # PtypInteger32
+        return constants.STI32.unpack(value)[0]
+    elif _type == 0x0004:  # PtypFloating32
+        return constants.STF32.unpack(value)[0]
+    elif _type == 0x0005:  # PtypFloating64
+        return constants.STF64.unpack(value)[0]
+    elif _type == 0x0006:  # PtypCurrency
+        return (constants.STI64.unpack(value)[0]) / 10000.0
+    elif _type == 0x0007:  # PtypFloatingTime
+        value = constants.STF64.unpack(value)[0]
+        return constants.PYTPFLOATINGTIME_START + datetime.timedelta(days = value)
+    elif _type == 0x000A:  # PtypErrorCode
+        from .enums import ErrorCode, ErrorCodeType
+        value = constants.STUI32.unpack(value)[0]
+        try:
+            value = ErrorCodeType(value)
+        except ValueError:
+            logger.warning(f'Error type found that was not from Additional Error Codes. Value was {value}. You should report this to the developers.')
+            # So here, the value should be from Additional Error Codes, but it
+            # wasn't. So we are just returning the int. However, we want to see
+            # if it is a normal error code.
+            try:
+                logger.warning(f'REPORT TO DEVELOPERS: Error type of {ErrorCode(value)} was found.')
+            except ValueError:
+                pass
+        return value
+    elif _type == 0x000B:  # PtypBoolean
+        return constants.ST3.unpack(value)[0] == 1
+    elif _type == 0x000D:  # PtypObject/PtypEmbeddedTable
+        # TODO parsing for this.
+        # Wait, that's the extension for an attachment folder, so parsing this
+        # might not be as easy as we would hope. The function may be released
+        # without support for this.
+        raise NotImplementedError('Current version of extract-msg does not support the parsing of PtypObject/PtypEmbeddedTable in this function.')
+    elif _type == 0x0014:  # PtypInteger64
+        return constants.STI64.unpack(value)[0]
+    elif _type == 0x001E:  # PtypString8
+        return value.decode(encoding)
+    elif _type == 0x001F:  # PtypString
+        return value.decode('utf-16-le')
+    elif _type == 0x0040:  # PtypTime
+        rawTime = constants.ST3.unpack(value)[0]
+        return filetimeToDatetime(rawTime)
+    elif _type == 0x0048:  # PtypGuid
+        return bytesToGuid(value)
+    elif _type == 0x00FB:  # PtypServerId
+        count = constants.STUI16.unpack(value[:2])
+        # If the first byte is a 1 then it uses the ServerID structure.
+        if value[3] == 1:
+            from .structures.misc_id import ServerID
+            return ServerID(value)
+        else:
+            return (count, value[2:count + 2])
+    elif _type == 0x00FD:  # PtypRestriction
+        # TODO parsing for this.
+        raise NotImplementedError('Parsing for type 0x00FD (PtypRestriction) has not yet been implmented. If you need this type, please create a new issue labeled "NotImplementedError: parseType 0x00FD PtypRestriction".')
+    elif _type == 0x00FE:  # PtypRuleAction
+        # TODO parsing for this.
+        raise NotImplementedError('Parsing for type 0x00FE (PtypRuleAction) has not yet been implmented. If you need this type, please create a new issue labeled "NotImplementedError: parseType 0x00FE PtypRuleAction".')
+    elif _type == 0x0102:  # PtypBinary
+        return value
+    elif _type & 0x1000 == 0x1000:  # PtypMultiple
+        # TODO parsing for `multiple` types.
+        if _type in (0x101F, 0x101E): # PtypMultipleString/PtypMultipleString8
+            ret = [x.decode(encoding) for x in extras]
+            lengths = struct.unpack(f'<{len(ret)}i', stream)
+            lengthLengths = len(lengths)
+            if lengthLengths > lengthExtras:
+                logger.warning(f'Error while parsing multiple type. Expected {lengthLengths} stream{"s" if lengthLengths != 1 else ""}, got {lengthExtras}. Ignoring.')
+            for x, y in enumerate(extras):
+                if lengths[x] != len(y):
+                    logger.warning(f'Error while parsing multiple type. Expected length {lengths[x]}, got {len(y)}. Ignoring.')
+            return ret
+        elif _type == 0x1102: # PtypMultipleBinary
+            ret = copy.deepcopy(extras)
+            lengths = tuple(constants.STUI32.unpack(stream[pos*8:(pos+1)*8])[0] for pos in range(len(stream) // 8))
+            lengthLengths = len(lengths)
+            if lengthLengths > lengthExtras:
+                logger.warning(f'Error while parsing multiple type. Expected {lengthLengths} stream{"s" if lengthLengths != 1 else ""}, got {lengthExtras}. Ignoring.')
+            for x, y in enumerate(extras):
+                if lengths[x] != len(y):
+                    logger.warning(f'Error while parsing multiple type. Expected length {lengths[x]}, got {len(y)}. Ignoring.')
+            return ret
+        elif _type in (0x1002, 0x1003, 0x1004, 0x1005, 0x1007, 0x1014, 0x1040, 0x1048):
+            if stream != len(extras):
+                logger.warning(f'Error while parsing multiple type. Expected {stream} entr{"y" if stream == 1 else "ies"}, got {len(extras)}. Ignoring.')
+            if _type == 0x1002: # PtypMultipleInteger16
+                return tuple(constants.STMI16.unpack(x)[0] for x in extras)
+            if _type == 0x1003: # PtypMultipleInteger32
+                return tuple(constants.STMI32.unpack(x)[0] for x in extras)
+            if _type == 0x1004: # PtypMultipleFloating32
+                return tuple(constants.STMF32.unpack(x)[0] for x in extras)
+            if _type == 0x1005: # PtypMultipleFloating64
+                return tuple(constants.STMF64.unpack(x)[0] for x in extras)
+            if _type == 0x1007: # PtypMultipleFloatingTime
+                values = tuple(constants.STMF64.unpack(x)[0] for x in extras)
+                return tuple(constants.PYTPFLOATINGTIME_START + datetime.timedelta(days = amount) for amount in values)
+            if _type == 0x1014: # PtypMultipleInteger64
+                return tuple(constants.STMI64.unpack(x)[0] for x in extras)
+            if _type == 0x1040: # PtypMultipleTime
+                return tuple(filetimeToUtc(constants.ST3.unpack(x)[0]) for x in extras)
+            if _type == 0x1048: # PtypMultipleGuid
+                return tuple(bytesToGuid(x) for x in extras)
+        else:
+            raise NotImplementedError(f'Parsing for type {_type} has not yet been implmented. If you need this type, please create a new issue labeled "NotImplementedError: parseType {_type}".')
+    return value
+
+
+def prepareFilename(filename) -> str:
+    """
+    Adjusts :param filename: so that it can succesfully be used as an actual
+    file name.
+    """
+    # I would use re here, but it tested to be slightly slower than this.
+    return ''.join(i for i in filename if i not in r'\/:*?"<>|' + '\x00').strip()
+
+
+def properHex(inp, length : int = 0) -> str:
+    """
+    Takes in various input types and converts them into a hex string whose
+    length will always be even.
+    """
+    a = ''
+    if isinstance(inp, str):
+        a = ''.join([hex(ord(inp[x]))[2:].rjust(2, '0') for x in range(len(inp))])
+    elif isinstance(inp, bytes):
+        a = inp.hex()
+    elif isinstance(inp, int):
+        a = hex(inp)[2:]
+    if len(a) % 2 != 0:
+        a = '0' + a
+    return a.rjust(length, '0').upper()
+
+
+def roundUp(inp : int, mult : int) -> int:
+    """
+    Rounds :param inp: up to the nearest multiple of :param mult:.
+    """
+    return inp + (mult - inp) % mult
+
+
+def rtfSanitizeHtml(inp : str) -> str:
+    """
+    Sanitizes input to an RTF stream that has encapsulated HTML.
+    """
+    if not inp:
+        return ''
+    output = ''
+    for char in inp:
+        # Check if it is in the right range to be printed directly.
+        if 32 <= ord(char) < 128:
+            # Quick check for handling the HTML escapes. Will eventually
+            # upgrade this code to actually handle all the HTML escapes
+            # but this will do for now.
+            if char == '<':
+                output += r'{\*\htmltag84 &lt;}\htmlrtf <\htmlrtf0 '
+            elif char == '>':
+                output += r'{\*\htmltag84 &gt;}\htmlrtf >\htmlrtf0'
+            else:
+                if char in ('\\', '{', '}'):
+                    output += '\\'
+                output += char
+        elif ord(char) < 32 or 128 <= ord(char) <= 255:
+            # Otherwise, see if it is just a small escape.
+            output += "\\'" + properHex(char, 2)
+        else:
+            # Handle Unicode characters.
+            enc = char.encode('utf-16-le')
+            output += ''.join(f'\\u{x}?' for x in struct.unpack(f'<{len(enc) // 2}h', enc))
+
+    return output
+
+
+def rtfSanitizePlain(inp : str) -> str:
+    """
+    Sanitizes input to a plain RTF stream.
+    """
+    if not inp:
+        return ''
+    output = ''
+    for char in inp:
+        # Check if it is in the right range to be printed directly.
+        if 32 <= ord(char) < 128:
+            if char in ('\\', '{', '}'):
+                output += '\\'
+            output += char
+        elif ord(char) < 32 or 128 <= ord(char) <= 255:
+            # Otherwise, see if it is just a small escape.
+            output += "\\'" + properHex(char, 2)
+        else:
+            # Handle Unicode characters.
+            # Handle Unicode characters.
+            enc = char.encode('utf-16-le')
+            output += ''.join(f'\\u{x}?' for x in struct.unpack(f'<{len(enc) // 2}h', enc))
+
+    return output
+
+
+def setupLogging(defaultPath = None, defaultLevel = logging.WARN, logfile = None, enableFileLogging : bool = False,
+                  env_key = 'EXTRACT_MSG_LOG_CFG') -> bool:
+    """
+    Setup logging configuration
+
+    Args:
+    :param defaultPath: Default path to use for the logging configuration file.
+    :param defaultLevel: Default logging level.
+    :param env_key: Environment variable name to search for, for setting logfile
+        path.
+    :param enableFileLogging: Whether to use a file to log or not.
+
+    Returns:
+        bool: True if the configuration file was found and applied, False otherwise
+    """
+    shippedConfig = pathlib.Path(__file__).parent / 'logging-config'
+    if os.name == 'nt':
+        null = 'NUL'
+        shippedConfig /= 'logging-nt.json'
+    elif os.name == 'posix':
+        null = '/dev/null'
+        shippedConfig /= 'logging-posix.json'
+    # Find logging.json if not provided
+    defaultPath = pathlib.Path(defaultPath) if defaultPath else shippedConfig
+
+    paths = [
+        defaultPath,
+        pathlib.Path('logging.json'),
+        pathlib.Path('../logging.json'),
+        pathlib.Path('../../logging.json'),
+        shippedConfig,
+    ]
+
+    path = None
+
+    for configPath in paths:
+        if configPath.exists():
+            path = configPath
+            break
+
+    value = os.getenv(env_key, None)
+    if value and os.path.exists(value) and os.path.isfile(value):
+        path = pathlib.Path(value)
+
+    if not path:
+        print('Unable to find logging.json configuration file')
+        print('Make sure a valid logging configuration file is referenced in the defaultPath'
+              ' argument, is inside the extract_msg install location, or is available at one '
+              'of the following file-paths:')
+        print(str(paths[1:]))
+        logging.basicConfig(level = defaultLevel)
+        logging.warning('The extract_msg logging configuration was not found - using a basic configuration.'
+                        f'Please check the extract_msg installation directory for "logging-{os.name}.json".')
+        return False
+
+    with open(path, 'rt') as f:
+        config = json.load(f)
+
+    for x in config['handlers']:
+        if 'filename' in config['handlers'][x]:
+            if enableFileLogging:
+                config['handlers'][x]['filename'] = tmp = os.path.expanduser(
+                    os.path.expandvars(logfile if logfile else config['handlers'][x]['filename']))
+                tmp = pathlib.Path(tmp).parent
+                if not tmp.exists:
+                    os.makedirs(tmp)
+            else:
+                config['handlers'][x]['filename'] = null
+
+    try:
+        logging.config.dictConfig(config)
+    except ValueError as e:
+        print('Failed to configure the logger. Did your installation get messed up?')
+        print(e)
+
+    logging.getLogger().setLevel(defaultLevel)
+    return True
+
+
+def tryGetMimetype(att, mimetype : Union[str, None]) -> Union[str, None]:
+    """
+    Uses an optional dependency to try and get the mimetype of an attachment. If
+    the mimetype has already been found, the optional dependency does not exist,
+    or an error occurs in the optional dependency, then the provided mimetype is
+    returned.
+
+    :param att: The attachment to use for getting the mimetype.
+    :param mimetype: The mimetype acquired directly from an attachment stream.
+        If this value evaluates to False, the function will try to determine it.
+    """
+    if mimetype:
+        return mimetype
+
+    # We only try anything if it is a plain attachment or signed attachment.
+    # Web attachments and embedded MSG files are completely ignored.
+    if att.type in (AttachmentType.DATA, AttachmentType.SIGNED):
+        # Try to import our dependency module to use it.
+        try:
+            import magic
+
+            return magic.from_buffer(att.data, mime = True)
+        except ImportError:
+            logger.info('Mimetype not found on attachment, and `mime` dependency not installed. Won\'t try to generate.')
+
+        except Exception:
+            logger.exception('Error occured while using python-magic. This error will be ignored.')
+
+    return mimetype
+
+
+def unsignedToSignedInt(uInt : int) -> int:
+    """
+    Convert the bits of an unsigned int (32-bit) to an int.
+
+    :raises ValueError: The number was not valid.
+    """
+    if uInt > 0xFFFFFFFF:
+        raise ValueError('Value is too large.')
+    if uInt < 0:
+        raise ValueError('Value is already signed.')
+    return constants.STI32.unpack(constants.STUI32.pack(uInt))[0]
+
+
+def unwrapMsg(msg : MSGFile) -> Dict:
+    """
+    Takes a recursive message-attachment structure and unwraps it into a linear
+    dictionary for easy iteration. Dictionary contains 4 keys: "attachments" for
+    main message attachments, not including embedded MSG files, "embedded" for
+    attachments representing embedded MSG files, "msg" for all MSG files
+    (including the original in the first index), and "raw_attachments" for raw
+    attachments from signed messages.
+    """
+    from .message_signed_base import MessageSignedBase
+
+    # Here is where we store main attachments.
+    attachments = []
+    # Here is where we are going to store embedded msg files.
+    msgFiles = [msg]
+    # Here is where we store embedded attachments.
+    embedded = []
+    # Here is where we store raw attachments from signed messages.
+    raw = []
+
+    # Normally we would need a recursive function to unwrap a recursive
+    # structure like the message-attachment structure. Essentially, a function
+    # that calls itself. Here, I have designed code capable of circumventing
+    # this to do it in a single function, which is a lot more efficient and
+    # safer. That is why we store the `toProcess` and use a while loop
+    # surrounding a for loop. The for loop would be the main body of the
+    # function, while the append to toProcess would be the recursive call.
+    toProcess = collections.deque((msg,))
+
+    while len(toProcess) > 0:
+        # Remove the last item from the list of things to process, and store it
+        # in `currentItem`. We will be processing it in the for loop.
+        currentItem = toProcess.popleft()
+        # iterate through the attachments and
+        for att in currentItem.attachments:
+            # If it is a regular attachment, add it to the list. Otherwise, add
+            # it to be processed
+            if att.type in (AttachmentType.DATA, AttachmentType.SIGNED):
+                attachments.append(att)
+            elif att.type is AttachmentType.MSG:
+                # Here we do two things. The first is we store it to the output
+                # so we can return it. The second is we add it to the processing
+                # list. The reason this is two steps is because we need to be
+                # able to remove items from the processing list, but can't
+                # do that from the output.
+                embedded.append(att)
+                msgFiles.append(att.data)
+                toProcess.append(att.data)
+        if isinstance(currentItem, MessageSignedBase):
+            raw += currentItem._rawAttachments
+
+    return {
+        'attachments': attachments,
+        'embedded': embedded,
+        'msg': msgFiles,
+        'raw_attachments': raw,
+    }
+
+
+def unwrapMultipart(mp : Union[bytes, str, email.message.Message]) -> Dict:
+    """
+    Unwraps a recursive multipart structure into a dictionary of linear lists.
+    Similar to unwrapMsg, but for multipart. Dictionary contains 3 keys:
+    "attachments" which contains a list of dicts containing processed attachment
+    data as well as the Message instance associated with it, "plain_body" which
+    contains the plain text body, and "html_body" which contains the HTML body.
+
+    For clarification, each instance of processed attachment data is a dict
+    with keys identical to the args used for the SignedAttachment constructor.
+    This makes it easy to expand for use in constructing a SignedAttachment. The
+    only argument missing is "msg" to ensure this function will not require one.
+
+    :param mp: The bytes that make up a multipart, the string that makes up a
+        multipart, or a Message instance from the email module created from the
+        multipart to unwrap. If providing a Message instance, prefer it to be an
+        instance of EmailMessage. If you are doing so, make sure it's policy is
+        default.
+    """
+    # In the event we are generating it, these are the kwargs to use.
+    genKwargs = {
+        '_class': email.message.EmailMessage,
+        'policy': email.policy.default,
+    }
+    # Convert our input into something usable.
+    if isinstance(mp, email.message.EmailMessage):
+        if mp.policy == email.policy.default:
+            mpMessage = mp
+        else:
+            mpMessage = email.message_from_bytes(mp.as_bytes(), **genKwargs)
+    elif isinstance(mp, email.message.Message):
+        mpMessage = email.message_from_bytes(mp.as_bytes(), **genKwargs)
+    elif isinstance(mp, bytes):
+        mpMessage = email.message_from_bytes(mp, **genKwargs)
+    elif isinstance(mp, str):
+        mpMessage = email.message_from_string(mp, **genKwargs)
+    else:
+        raise TypeError(f'Unsupported type "{type(mp)}" provided to unwrapMultipart.')
+
+    # Okay, now that we have it in a useable form, let's do the most basic
+    # unwrapping possible. Once the most basic unwrapping is done, we can
+    # actually process the data. For this, we only care if the section is
+    # multipart or not. If it is, it get's unwrapped too.
+    #
+    # In case you are curious, this is effectively doing a breadth first
+    # traversal of the tree.
+    dataNodes = []
+
+    toProcess = collections.deque((mpMessage,))
+    # I do know about the walk method, but it might *also* walk embedded
+    # messages which we very much don't want.
+    while len(toProcess) > 0:
+        currentItem = toProcess.popleft()
+        # 'multipart' indicates that it shouldn't contain any data itself, just
+        # other nodes to go through.
+        if currentItem.get_content_maintype() == 'multipart':
+            payload = currentItem.get_payload()
+            # For multipart, the payload should be a list, but handle it not
+            # being one.
+            if isinstance(payload, list):
+                toProcess.extend(payload)
+            else:
+                logging.warning('Found multipart node that did not return a list. Appending as a data node.')
+                dataNodes.append(currentItem)
+        else:
+            # The opposite is *not* true. If it's not multipart, always add as a
+            # data node.
+            dataNodes.append(currentItem)
+
+    # At this point, all of our nodes should have processed and we should now
+    # have data nodes. Now let's process them. For anything that was parsed as
+    # a message, we actually want to get it's raw bytes back so it can be saved.
+    # If they user wants to process that message in some way, they can do it
+    # themself.
+    attachments = []
+    plainBody = None
+    htmlBody = None
+
+    for node in dataNodes:
+        # Let's setup our attachment we are going to use.
+        attachment = {
+            'data': None,
+            'name': node.get_filename(),
+            'mimetype': node.get_content_type(),
+            'node': node,
+        }
+
+        # Finally, we need to get the data. As we need to ensure it is bytes,
+        # we may have to do some special processing.
+        data = node.get_content()
+        if isinstance(data, bytes):
+            # If the data is bytes, we are perfectly good.
+            pass
+        elif isinstance(data, email.message.Message):
+            # If it is a message, get it's bytes directly.
+            data = data.as_bytes()
+        elif isinstance(data, str):
+            # If it is a string, let's reverse encode it where possible.
+            # First thing we want to check is if we can find the encoding type.
+            # If we can, use that to reverse the process. Otherwise use utf-8.
+            data = data.encode(node.get_content_charset('utf-8'))
+        else:
+            # We throw an exception to describe the problem if we can't reverse
+            # the problem.
+            raise TypeError(f'Attempted to get bytes for attachment, but could not convert {type(data)} to bytes.')
+
+        attachment['data'] = data
+
+        # Now for the fun part, figuring out if we actually have an attachment.
+        if attachment['name']:
+            attachments.append(attachment)
+        elif attachment['mimetype'] == 'text/plain':
+            if plainBody:
+                logger.warning('Found multiple candidates for plain text body.')
+            plainBody = data
+        elif attachment['mimetype'] == 'text/html':
+            if htmlBody:
+                logger.warning('Found multiple candidates for HTML body.')
+            htmlBody = data
+
+    return {
+        'attachments': attachments,
+        'plain_body': plainBody,
+        'html_body': htmlBody,
+    }
+
+def validateHtml(html : bytes) -> bool:
+    """
+    Checks whether the HTML is considered valid. To be valid, the HTML must, at
+    minimum, contain an <html> tag, a <body> tag, and closing tags for each.
+    """
+    bs = bs4.BeautifulSoup(html, 'html.parser')
+    if not bs.find('html') or not bs.find('body'):
+        return False
+    return True
+
+
+def verifyPropertyId(id : str) -> None:
+    """
+    Determines whether a property ID is valid for vertain functions. Property
+    IDs MUST be a 4 digit hexadecimal string. Property is valid if no exception
+    is raised.
+
+    :raises InvaildPropertyIdError: if the it is not a 4 digit hexadecimal
+        number.
+    """
+    if not isinstance(id, str):
+        raise InvaildPropertyIdError('ID was not a 4 digit hexadecimal string')
+    elif len(id) != 4:
+        raise InvaildPropertyIdError('ID was not a 4 digit hexadecimal string')
+    else:
+        try:
+            int(id, 16)
+        except ValueError:
+            raise InvaildPropertyIdError('ID was not a 4 digit hexadecimal string')
+
+
+def verifyType(_type) -> str:
+    """
+    Verifies that the type is valid. Raises an exception if it is not.
+
+    :raises UnknownTypeError: if the type is not recognized.
+    """
+    if _type is not None:
+        if (_type not in constants.VARIABLE_LENGTH_PROPS_STRING) and (_type not in constants.FIXED_LENGTH_PROPS_STRING):
+            raise UnknownTypeError(f'Unknown type {_type}.')
+
+
+def windowsUnicode(string) -> Optional[str]:
+    return str(string, 'utf-16-le') if string is not None else None
```

### Comparing `extract_msg-0.40.0/extract_msg.egg-info/PKG-INFO` & `extract_msg-0.41.0/README.rst`

 * *Files 9% similar despite different names*

```diff
@@ -1,282 +1,273 @@
-Metadata-Version: 2.1
-Name: extract-msg
-Version: 0.40.0
-Summary: Extracts emails and attachments saved in Microsoft Outlook's .msg files
-Home-page: https://github.com/TeamMsgExtractor/msg-extractor
-Author: Destiny Peterson & Matthew Walker
-Author-email: arceusthe@gmail.com, mattgwwalker@gmail.com
-License: GPL
-Download-URL: https://github.com/TeamMsgExtractor/msg-extractor/archives/master
-Platform: UNKNOWN
-Requires-Python: >=3.8
-Description-Content-Type: text/x-rst
-Provides-Extra: all
-Provides-Extra: mime
-License-File: LICENSE.txt
-
-|License: GPL v3| |PyPI3| |PyPI2|
-
-extract-msg
-=============
-
-Extracts emails and attachments saved in Microsoft Outlook's .msg files
-
-The python package extract_msg automates the extraction of key email
-data (from, to, cc, date, subject, body) and the email's attachments.
-
-Documentation can be found in the code, on the `wiki`_, and on the
-`read the docs`_ page.
-
-NOTICE
-======
-0.29.* is the branch that supports both Python 2 and Python 3. It is now only
-receiving bug fixes and will not be receiving feature updates.
-
-0.39.* is the last versions that supported Python 3.6 and 3.7. Support for those
-was dropped to allow the use of new features from 3.8 and because the life spans
-of those versions had ended.
-
-This module has a Discord server for general discussion. You can find it here:
-`Discord`_
-
-
-Changelog
----------
--  `Changelog`_
-
-Usage
------
-
-**To use it as a command-line script**:
-
-::
-
-     python -m extract_msg example.msg
-
-This will produce a new folder named according to the date, time and
-subject of the message (for example "2013-07-24_0915 Example"). The
-email itself can be found inside the new folder along with the
-attachments.
-
-The script uses Philippe Lagadec's Python module that reads Microsoft
-OLE2 files (also called Structured Storage, Compound File Binary Format
-or Compound Document File Format). This is the underlying format of
-Outlook's .msg files. This library currently supports Python 3.8 and above.
-
-The script was originally built using Peter Fiskerstrand's documentation of the
-.msg format. Redemption's discussion of the different property types used within
-Extended MAPI was also useful. For future reference, note that Microsoft have
-opened up their documentation of the file format, which is what is currently
-being used for development.
-
-
-#########REWRITE COMMAND LINE USAGE#############
-Currently, the README is in the process of being redone. For now, please
-refer to the usage information provided from the program's help dialog:
-::
-
-    usage: extract_msg [-h] [--use-content-id] [--dev] [--validate] [--json] [--file-logging] [--verbose] [--log LOG] [--config CONFIGPATH] [--out OUTPATH] [--use-filename]
-                   [--dump-stdout] [--html] [--pdf] [--wk-path WKPATH] [--wk-options [WKOPTIONS ...]] [--prepared-html] [--charset CHARSET] [--raw] [--rtf]
-                   [--allow-fallback] [--zip ZIP] [--attachments-only] [--no-folders] [--skip-embedded] [--out-name OUTNAME | --glob] [--ignore-rtfde] [--progress]
-                   msg [msg ...]
-
-    extract_msg: Extracts emails and attachments saved in Microsoft Outlook's .msg files. https://github.com/TeamMsgExtractor/msg-extractor
-
-    positional arguments:
-      msg                   An MSG file to be parsed.
-
-    optional arguments:
-      -h, --help            show this help message and exit
-      --use-content-id, --cid
-                            Save attachments by their Content ID, if they have one. Useful when working with the HTML body.
-      --dev                 Changes to use developer mode. Automatically enables the --verbose flag. Takes precedence over the --validate flag.
-      --validate            Turns on file validation mode. Turns off regular file output.
-      --json                Changes to write output files as json.
-      --file-logging        Enables file logging. Implies --verbose level 1.
-      -v, --verbose         Turns on console logging. Specify more than once for higher verbosity.
-      --log LOG             Set the path to write the file log to.
-      --config CONFIGPATH   Set the path to load the logging config from.
-      --out OUTPATH         Set the folder to use for the program output. (Default: Current directory)
-      --use-filename        Sets whether the name of each output is based on the msg filename.
-      --dump-stdout         Tells the program to dump the message body (plain text) to stdout. Overrides saving arguments.
-      --html                Sets whether the output should be HTML. If this is not possible, will error.
-      --pdf                 Saves the body as a PDF. If this is not possible, will error.
-      --wk-path WKPATH      Overrides the path for finding wkhtmltopdf.
-      --wk-options [WKOPTIONS ...]
-                            Sets additional options to be used in wkhtmltopdf. Should be a series of options and values, replacing the - or -- in the beginning with + or ++,
-                            respectively. For example: --wk-options "+O Landscape"
-      --prepared-html       When used in conjunction with --html, sets whether the HTML output should be prepared for embedded attachments.
-      --charset CHARSET     Character set to use for the prepared HTML in the added tag. (Default: utf-8)
-      --raw                 Sets whether the output should be raw. If this is not possible, will error.
-      --rtf                 Sets whether the output should be RTF. If this is not possible, will error.
-      --allow-fallback      Tells the program to fallback to a different save type if the selected one is not possible.
-      --skip-body-not-found Skips saving the body if the body cannot be found, rather than throwing an error.
-      --zip ZIP             Path to use for saving to a zip file.
-      --save-header         Store the header in a separate file.
-      --attachments-only    Specify to only save attachments from an msg file.
-      --skip-hidden         Skips any attachment marked as hidden (usually ones embedded in the body).
-      --no-folders          When used with --attachments-only, stores everything in the location specified by --out. Incompatible with --out-name.
-      --skip-embedded       Skips all embedded MSG files when saving attachments.
-      --extract-embedded    Extracts the embedded MSG files as MSG files instead of running their save functions.
-      --out-name OUTNAME    Name to be used with saving the file output. Cannot be used if you are saving more than one file.
-      --glob, --wildcard    Interpret all paths as having wildcards. Incompatible with --out-name.
-      --ignore-rtfde        Ignores all errors thrown from RTFDE when trying to save. Useful for allowing fallback to continue when an exception happens.
-      --progress            Shows what file the program is currently working on during it's progress.
-
-**To use this in your own script**, start by using:
-
-::
-
-     import extract_msg
-
-From there, open the MSG file:
-
-::
-
-     msg = extract_msg.openMsg("path/to/msg/file.msg")
-
-Alternatively, if you wish to send a msg binary string instead of a file
-to the ``extract_msg.openMsg`` Method:
-
-::
-
-     msg_raw = b'\xd0\xcf\x11\xe0\xa1\xb1\x1a\xe1\x00 ... \x00\x00\x00'
-     msg = extract_msg.openMsg(msg_raw)
-
-If you want to override the default attachment class and use one of your
-own, simply change the code to:
-
-::
-
-     msg = extract_msg.openMsg("path/to/msg/file.msg", attachmentClass = CustomAttachmentClass)
-
-where ``CustomAttachmentClass`` is your custom class.
-
-#TODO: Finish this section
-
-If you have any questions feel free to contact Destiny at arceusthe [at]
-gmail [dot] com. She is the co-owner and main developer of the project.
-
-If you have issues, it would be best to get help for them by opening a
-new github issue.
-
-Error Reporting
----------------
-
-Should you encounter an error that has not already been reported, please
-do the following when reporting it: \* Make sure you are using the
-latest version of extract_msg (check the version on PyPi). \* State your
-Python version. \* Include the code, if any, that you used. \* Include a
-copy of the traceback.
-
-Supporting The Module
----------------------
-
-If you'd like to donate to help support the development of the module, you can
-donate to Destiny using one of the following services:
-
-* `Buy Me a Coffee`_
-* `Ko-fi`_
-* `Patreon`_
-
-Installation
-------------
-
-You can install using pip:
-
--  Pypi
-
-.. code:: bash
-
-       pip install extract-msg
-
--  Github
-
-.. code:: sh
-
-     pip install git+https://github.com/TeamMsgExtractor/msg-extractor
-
-or you can include this in your list of python dependencies with:
-
-.. code:: python
-
-   # setup.py
-
-   setup(
-       ...
-       dependency_links=['https://github.com/TeamMsgExtractor/msg-extractor/zipball/master'],
-   )
-
-Additionally, this module has the following extras which can be optionally
-installed:
-
-* ``all``: Installs all of the extras.
-* ``mime``: Installs dependency used for mimetype generation when a mimetype is not specified.
-
-Todo
-----
-
-Here is a list of things that are currently on our todo list:
-
-* Tests (ie. unittest)
-* Finish writing a usage guide
-* Improve the intelligence of the saving functions
-* Improve README
-* Create a wiki for advanced usage information
-
-Credits
--------
-
-`Destiny Peterson (The Elemental of Destruction)`_ - Co-owner, principle programmer, knows more about msg files than anyone probably should.
-
-`Matthew Walker`_ - Original developer and co-owner.
-
-`JP Bourget`_ - Senior programmer, readability and organization expert, secondary manager.
-
-`Philippe Lagadec`_ - Python OleFile module developer.
-
-`Joel Kaufman`_ - First implementations of the json and filename flags.
-
-`Dean Malmgren`_ - First implementation of the setup.py script.
-
-`Seamus Tuohy`_ - Developer of the Python RTFDE module. Gave first examples of how to use the module.
-
-`Liam`_ - Significant reorganization and transfer of data.
-
-And thank you to everyone who has opened an issue and helped us track down those pesky bugs.
-
-Extra
------
-
-Check out the new project `msg-explorer`_ that allows you to open MSG files and
-explore their contents in a GUI. It is usually updated within a few days of a
-major release to ensure continued support. Because of this, it is recommended to
-install it to a separate environment (like a vitural env) to not interfere with
-your access to the newest major version of extract-msg.
-
-.. |License: GPL v3| image:: https://img.shields.io/badge/License-GPLv3-blue.svg
-   :target: LICENSE.txt
-
-.. |PyPI3| image:: https://img.shields.io/badge/pypi-0.40.0-blue.svg
-   :target: https://pypi.org/project/extract-msg/0.40.0/
-
-.. |PyPI2| image:: https://img.shields.io/badge/python-3.8+-brightgreen.svg
-   :target: https://www.python.org/downloads/release/python-3816/
-.. _Matthew Walker: https://github.com/mattgwwalker
-.. _Destiny Peterson (The Elemental of Destruction): https://github.com/TheElementalOfDestruction
-.. _JP Bourget: https://github.com/punkrokk
-.. _Philippe Lagadec: https://github.com/decalage2
-.. _Dean Malmgren: https://github.com/deanmalmgren
-.. _Joel Kaufman: https://github.com/joelkaufman
-.. _Liam: https://github.com/LiamPM5
-.. _Seamus Tuohy: https://github.com/seamustuohy
-.. _Discord: https://discord.com/invite/B77McRmzdc
-.. _Buy Me a Coffee: https://www.buymeacoffee.com/DestructionE
-.. _Ko-fi: https://ko-fi.com/destructione
-.. _Patreon: https://www.patreon.com/DestructionE
-.. _msg-explorer: https://pypi.org/project/msg-explorer/
-.. _wiki: https://github.com/TeamMsgExtractor/msg-extractor/wiki
-.. _read the docs: https://msg-extractor.rtfd.io/
-.. _Changelog: https://github.com/TeamMsgExtractor/msg-extractor/blob/master/CHANGELOG.md
-
-
+|License: GPL v3| |PyPI3| |PyPI2|
+
+extract-msg
+=============
+
+Extracts emails and attachments saved in Microsoft Outlook's .msg files
+
+The python package extract_msg automates the extraction of key email
+data (from, to, cc, date, subject, body) and the email's attachments.
+
+Documentation can be found in the code, on the `wiki`_, and on the
+`read the docs`_ page.
+
+NOTICE
+======
+0.29.* is the branch that supports both Python 2 and Python 3. It is now only
+receiving bug fixes and will not be receiving feature updates.
+
+0.39.* is the last versions that supported Python 3.6 and 3.7. Support for those
+was dropped to allow the use of new features from 3.8 and because the life spans
+of those versions had ended.
+
+This module has a Discord server for general discussion. You can find it here:
+`Discord`_
+
+
+Changelog
+---------
+-  `Changelog`_
+
+Usage
+-----
+
+**To use it as a command-line script**:
+
+::
+
+     python -m extract_msg example.msg
+
+This will produce a new folder named according to the date, time and
+subject of the message (for example "2013-07-24_0915 Example"). The
+email itself can be found inside the new folder along with the
+attachments.
+
+The script uses Philippe Lagadec's Python module that reads Microsoft
+OLE2 files (also called Structured Storage, Compound File Binary Format
+or Compound Document File Format). This is the underlying format of
+Outlook's .msg files. This library currently supports Python 3.8 and above.
+
+The script was originally built using Peter Fiskerstrand's documentation of the
+.msg format. Redemption's discussion of the different property types used within
+Extended MAPI was also useful. For future reference, note that Microsoft have
+opened up their documentation of the file format, which is what is currently
+being used for development.
+
+
+#########REWRITE COMMAND LINE USAGE#############
+Currently, the README is in the process of being redone. For now, please
+refer to the usage information provided from the program's help dialog:
+::
+
+    usage: extract_msg [-h] [--use-content-id] [--validate] [--json] [--file-logging] [-v] [--log LOG] [--config CONFIGPATH]
+                       [--out OUTPATH] [--use-filename] [--dump-stdout] [--html] [--pdf] [--wk-path WKPATH]
+                       [--wk-options [WKOPTIONS ...]] [--prepared-html] [--charset CHARSET] [--raw] [--rtf] [--allow-fallback]
+                       [--skip-body-not-found] [--zip ZIP] [--save-header] [--attachments-only] [--skip-hidden] [--no-folders]
+                       [--skip-embedded] [--extract-embedded] [--skip-not-implemented] [--out-name OUTNAME | --glob] [--ignore-rtfde]
+                       [--progress]
+                       msg [msg ...]
+
+    extract_msg: Extracts emails and attachments saved in Microsoft Outlook's .msg files. https://github.com/TeamMsgExtractor/msg-
+    extractor
+
+    positional arguments:
+      msg                   An MSG file to be parsed.
+
+    optional arguments:
+      -h, --help            show this help message and exit
+      --use-content-id, --cid
+                            Save attachments by their Content ID, if they have one. Useful when working with the HTML body.
+      --validate            Turns on file validation mode. Turns off regular file output.
+      --json                Changes to write output files as json.
+      --file-logging        Enables file logging. Implies --verbose level 1.
+      -v, --verbose         Turns on console logging. Specify more than once for higher verbosity.
+      --log LOG             Set the path to write the file log to.
+      --config CONFIGPATH   Set the path to load the logging config from.
+      --out OUTPATH         Set the folder to use for the program output. (Default: Current directory)
+      --use-filename        Sets whether the name of each output is based on the msg filename.
+      --dump-stdout         Tells the program to dump the message body (plain text) to stdout. Overrides saving arguments.
+      --html                Sets whether the output should be HTML. If this is not possible, will error.
+      --pdf                 Saves the body as a PDF. If this is not possible, will error.
+      --wk-path WKPATH      Overrides the path for finding wkhtmltopdf.
+      --wk-options [WKOPTIONS ...]
+                            Sets additional options to be used in wkhtmltopdf. Should be a series of options and values, replacing the -
+                            or -- in the beginning with + or ++, respectively. For example: --wk-options "+O Landscape"
+      --prepared-html       When used in conjunction with --html, sets whether the HTML output should be prepared for embedded
+                            attachments.
+      --charset CHARSET     Character set to use for the prepared HTML in the added tag. (Default: utf-8)
+      --raw                 Sets whether the output should be raw. If this is not possible, will error.
+      --rtf                 Sets whether the output should be RTF. If this is not possible, will error.
+      --allow-fallback      Tells the program to fallback to a different save type if the selected one is not possible.
+      --skip-body-not-found
+                            Skips saving the body if the body cannot be found, rather than throwing an error.
+      --zip ZIP             Path to use for saving to a zip file.
+      --save-header         Store the header in a separate file.
+      --attachments-only    Specify to only save attachments from an msg file.
+      --skip-hidden         Skips any attachment marked as hidden (usually ones embedded in the body).
+      --no-folders          Stores everything in the location specified by --out. Requires --attachments-only and is incompatible with
+                            --out-name.
+      --skip-embedded       Skips all embedded MSG files when saving attachments.
+      --extract-embedded    Extracts the embedded MSG files as MSG files instead of running their save functions.
+      --skip-not-implemented, --skip-ni
+                            Skips any attachments that are not implemented, allowing saving of the rest of the message.
+      --out-name OUTNAME    Name to be used with saving the file output. Cannot be used if you are saving more than one file.
+      --glob, --wildcard    Interpret all paths as having wildcards. Incompatible with --out-name.
+      --ignore-rtfde        Ignores all errors thrown from RTFDE when trying to save. Useful for allowing fallback to continue when an
+                            exception happens.
+      --progress            Shows what file the program is currently working on during it's progress.
+
+**To use this in your own script**, start by using:
+
+::
+
+     import extract_msg
+
+From there, open the MSG file:
+
+::
+
+     msg = extract_msg.openMsg("path/to/msg/file.msg")
+
+Alternatively, if you wish to send a msg binary string instead of a file
+to the ``extract_msg.openMsg`` Method:
+
+::
+
+     msg_raw = b'\xd0\xcf\x11\xe0\xa1\xb1\x1a\xe1\x00 ... \x00\x00\x00'
+     msg = extract_msg.openMsg(msg_raw)
+
+If you want to override the default attachment class and use one of your
+own, simply change the code to:
+
+::
+
+     msg = extract_msg.openMsg("path/to/msg/file.msg", attachmentClass = CustomAttachmentClass)
+
+where ``CustomAttachmentClass`` is your custom class.
+
+#TODO: Finish this section
+
+If you have any questions feel free to contact Destiny at arceusthe [at]
+gmail [dot] com. She is the co-owner and main developer of the project.
+
+If you have issues, it would be best to get help for them by opening a
+new github issue.
+
+Error Reporting
+---------------
+
+Should you encounter an error that has not already been reported, please
+do the following when reporting it: \* Make sure you are using the
+latest version of extract_msg (check the version on PyPi). \* State your
+Python version. \* Include the code, if any, that you used. \* Include a
+copy of the traceback.
+
+Supporting The Module
+---------------------
+
+If you'd like to donate to help support the development of the module, you can
+donate to Destiny using one of the following services:
+
+* `Buy Me a Coffee`_
+* `Ko-fi`_
+* `Patreon`_
+
+Installation
+------------
+
+You can install using pip:
+
+-  Pypi
+
+.. code:: bash
+
+       pip install extract-msg
+
+-  Github
+
+.. code:: sh
+
+     pip install git+https://github.com/TeamMsgExtractor/msg-extractor
+
+or you can include this in your list of python dependencies with:
+
+.. code:: python
+
+   # setup.py
+
+   setup(
+       ...
+       dependency_links=['https://github.com/TeamMsgExtractor/msg-extractor/zipball/master'],
+   )
+
+Additionally, this module has the following extras which can be optionally
+installed:
+
+* ``all``: Installs all of the extras.
+* ``mime``: Installs dependency used for mimetype generation when a mimetype is not specified.
+
+Todo
+----
+
+Here is a list of things that are currently on our todo list:
+
+* Tests (ie. unittest)
+* Finish writing a usage guide
+* Improve the intelligence of the saving functions
+* Improve README
+* Create a wiki for advanced usage information
+
+Credits
+-------
+
+`Destiny Peterson (The Elemental of Destruction)`_ - Co-owner, principle programmer, knows more about msg files than anyone probably should.
+
+`Matthew Walker`_ - Original developer and co-owner.
+
+`JP Bourget`_ - Senior programmer, readability and organization expert, secondary manager.
+
+`Philippe Lagadec`_ - Python OleFile module developer.
+
+`Joel Kaufman`_ - First implementations of the json and filename flags.
+
+`Dean Malmgren`_ - First implementation of the setup.py script.
+
+`Seamus Tuohy`_ - Developer of the Python RTFDE module. Gave first examples of how to use the module and has worked with Destiny to ensure functionality.
+
+`Liam`_ - Significant reorganization and transfer of data.
+
+And thank you to everyone who has opened an issue and helped us track down those pesky bugs.
+
+Extra
+-----
+
+Check out the new project `msg-explorer`_ that allows you to open MSG files and
+explore their contents in a GUI. It is usually updated within a few days of a
+major release to ensure continued support. Because of this, it is recommended to
+install it to a separate environment (like a vitural env) to not interfere with
+your access to the newest major version of extract-msg.
+
+.. |License: GPL v3| image:: https://img.shields.io/badge/License-GPLv3-blue.svg
+   :target: LICENSE.txt
+
+.. |PyPI3| image:: https://img.shields.io/badge/pypi-0.41.0-blue.svg
+   :target: https://pypi.org/project/extract-msg/0.41.0/
+
+.. |PyPI2| image:: https://img.shields.io/badge/python-3.8+-brightgreen.svg
+   :target: https://www.python.org/downloads/release/python-3816/
+.. _Matthew Walker: https://github.com/mattgwwalker
+.. _Destiny Peterson (The Elemental of Destruction): https://github.com/TheElementalOfDestruction
+.. _JP Bourget: https://github.com/punkrokk
+.. _Philippe Lagadec: https://github.com/decalage2
+.. _Dean Malmgren: https://github.com/deanmalmgren
+.. _Joel Kaufman: https://github.com/joelkaufman
+.. _Liam: https://github.com/LiamPM5
+.. _Seamus Tuohy: https://github.com/seamustuohy
+.. _Discord: https://discord.com/invite/B77McRmzdc
+.. _Buy Me a Coffee: https://www.buymeacoffee.com/DestructionE
+.. _Ko-fi: https://ko-fi.com/destructione
+.. _Patreon: https://www.patreon.com/DestructionE
+.. _msg-explorer: https://pypi.org/project/msg-explorer/
+.. _wiki: https://github.com/TeamMsgExtractor/msg-extractor/wiki
+.. _read the docs: https://msg-extractor.rtfd.io/
+.. _Changelog: https://github.com/TeamMsgExtractor/msg-extractor/blob/master/CHANGELOG.md
```

### Comparing `extract_msg-0.40.0/extract_msg.egg-info/SOURCES.txt` & `extract_msg-0.41.0/extract_msg.egg-info/SOURCES.txt`

 * *Files 7% similar despite different names*

```diff
@@ -10,15 +10,14 @@
 extract_msg/appointment.py
 extract_msg/attachment.py
 extract_msg/attachment_base.py
 extract_msg/calendar.py
 extract_msg/calendar_base.py
 extract_msg/constants.py
 extract_msg/contact.py
-extract_msg/dev.py
 extract_msg/enums.py
 extract_msg/exceptions.py
 extract_msg/meeting_cancellation.py
 extract_msg/meeting_exception.py
 extract_msg/meeting_forward.py
 extract_msg/meeting_related.py
 extract_msg/meeting_request.py
@@ -35,29 +34,25 @@
 extract_msg/properties.py
 extract_msg/py.typed
 extract_msg/recipient.py
 extract_msg/signed_attachment.py
 extract_msg/task.py
 extract_msg/task_request.py
 extract_msg/utils.py
-extract_msg/validation.py
 extract_msg.egg-info/PKG-INFO
 extract_msg.egg-info/SOURCES.txt
 extract_msg.egg-info/dependency_links.txt
 extract_msg.egg-info/entry_points.txt
 extract_msg.egg-info/requires.txt
 extract_msg.egg-info/top_level.txt
 extract_msg/_rtf/__init__.py
 extract_msg/_rtf/create_doc.py
 extract_msg/_rtf/inject_rtf.py
 extract_msg/_rtf/token.py
 extract_msg/_rtf/tokenize_rtf.py
-extract_msg/dev_classes/__init__.py
-extract_msg/dev_classes/attachment.py
-extract_msg/dev_classes/message.py
 extract_msg/logging-config/logging-nt.json
 extract_msg/logging-config/logging-posix.json
 extract_msg/structures/__init__.py
 extract_msg/structures/_helpers.py
 extract_msg/structures/business_card.py
 extract_msg/structures/entry_id.py
 extract_msg/structures/misc_id.py
```

### Comparing `extract_msg-0.40.0/setup.py` & `extract_msg-0.41.0/setup.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,50 +1,50 @@
-import os
-from setuptools import setup
-import re
-
-
-# A handful of variables that are used a couple of times.
-github_url = 'https://github.com/TeamMsgExtractor/msg-extractor'
-main_module = 'extract_msg'
-
-# Read in the description from README.
-with open('README.rst', 'rb') as stream:
-    long_description = stream.read().decode('utf-8').replace('\r', '')
-
-# Get the version string this way to avoid issues with modules not being
-# installed before setup.
-version_re = re.compile("__version__ = '(?P<version>[0-9\\.]*)'")
-with open('extract_msg/__init__.py', 'r') as stream:
-    contents = stream.read()
-match = version_re.search(contents)
-version = match.groupdict()['version']
-
-# Read in the dependencies from the virtualenv requirements file.
-dependencies = []
-filename = os.path.join('requirements.txt')
-with open(filename, 'r') as stream:
-    for line in stream:
-        package = line.strip().split('#')[0]
-        if package:
-            dependencies.append(package)
-
-setup(
-    name=main_module,
-    version=version,
-    description="Extracts emails and attachments saved in Microsoft Outlook's .msg files",
-    long_description=long_description,
-    long_description_content_type='text/x-rst',
-    url=github_url,
-    download_url='%s/archives/master' % github_url,
-    author='Destiny Peterson & Matthew Walker',
-    author_email='arceusthe@gmail.com, mattgwwalker@gmail.com',
-    license='GPL',
-    packages=[main_module],
-    py_modules=[main_module],
-    entry_points={
-        'console_scripts': ['extract_msg = extract_msg.__main__:main',]
-    },
-    include_package_data=True,
-    install_requires=dependencies,
-    python_requires='>=3.8',
-)
+import os
+from setuptools import setup
+import re
+
+
+# A handful of variables that are used a couple of times.
+github_url = 'https://github.com/TeamMsgExtractor/msg-extractor'
+main_module = 'extract_msg'
+
+# Read in the description from README.
+with open('README.rst', 'rb') as stream:
+    long_description = stream.read().decode('utf-8').replace('\r', '')
+
+# Get the version string this way to avoid issues with modules not being
+# installed before setup.
+version_re = re.compile("__version__ = '(?P<version>[0-9\\.]*)'")
+with open('extract_msg/__init__.py', 'r') as stream:
+    contents = stream.read()
+match = version_re.search(contents)
+version = match.groupdict()['version']
+
+# Read in the dependencies from the virtualenv requirements file.
+dependencies = []
+filename = os.path.join('requirements.txt')
+with open(filename, 'r') as stream:
+    for line in stream:
+        package = line.strip().split('#')[0]
+        if package:
+            dependencies.append(package)
+
+setup(
+    name=main_module,
+    version=version,
+    description="Extracts emails and attachments saved in Microsoft Outlook's .msg files",
+    long_description=long_description,
+    long_description_content_type='text/x-rst',
+    url=github_url,
+    download_url='%s/archives/master' % github_url,
+    author='Destiny Peterson & Matthew Walker',
+    author_email='arceusthe@gmail.com, mattgwwalker@gmail.com',
+    license='GPL',
+    packages=[main_module],
+    py_modules=[main_module],
+    entry_points={
+        'console_scripts': ['extract_msg = extract_msg.__main__:main',]
+    },
+    include_package_data=True,
+    install_requires=dependencies,
+    python_requires='>=3.8',
+)
```

