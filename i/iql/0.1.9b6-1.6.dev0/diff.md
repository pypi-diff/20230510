# Comparing `tmp/iql-0.1.9b6-py3-none-any.whl.zip` & `tmp/iql-1.6.dev0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,27 +1,27 @@
-Zip file size: 47470 bytes, number of entries: 25
--rw-r--r--  2.0 unx      372 b- defN 23-Apr-21 12:49 iql/__init__.py
--rw-r--r--  2.0 unx      103 b- defN 23-Apr-21 12:49 iql/_version.py
--rw-r--r--  2.0 unx    33829 b- defN 23-Apr-21 12:49 iql/iqmoql.py
--rw-r--r--  2.0 unx     1282 b- defN 23-Apr-21 12:49 iql/options_parser.py
--rw-r--r--  2.0 unx     3233 b- defN 23-Apr-21 12:49 iql/q_cache.py
--rw-r--r--  2.0 unx     2191 b- defN 23-Apr-21 12:49 iql/threading_experimental.py
--rw-r--r--  2.0 unx       77 b- defN 23-Apr-21 12:49 iql/bbg_bql/__init__.py
--rw-r--r--  2.0 unx    10069 b- defN 23-Apr-21 12:49 iql/bbg_bql/bql_datamodel.py
--rw-r--r--  2.0 unx     8975 b- defN 23-Apr-21 12:49 iql/bbg_bql/bql_extension.py
--rw-r--r--  2.0 unx    13694 b- defN 23-Apr-21 12:49 iql/bbg_bql/bql_wrapper.py
--rw-r--r--  2.0 unx      692 b- defN 23-Apr-21 12:49 iql/bbg_bql/debug_tools.py
--rw-r--r--  2.0 unx       77 b- defN 23-Apr-21 12:49 iql/db_connectors/__init__.py
--rw-r--r--  2.0 unx     4311 b- defN 23-Apr-21 12:49 iql/db_connectors/duckdb_connector.py
--rw-r--r--  2.0 unx       77 b- defN 23-Apr-21 12:49 iql/extensions/__init__.py
--rw-r--r--  2.0 unx     3470 b- defN 23-Apr-21 12:49 iql/extensions/aws_s3_extension.py
--rw-r--r--  2.0 unx     7829 b- defN 23-Apr-21 12:49 iql/extensions/edgar_extension.py
--rw-r--r--  2.0 unx     4279 b- defN 23-Apr-21 12:49 iql/extensions/fred_extension.py
--rw-r--r--  2.0 unx     4106 b- defN 23-Apr-21 12:49 iql/extensions/kaggle_extension.py
--rw-r--r--  2.0 unx     2315 b- defN 23-Apr-21 12:49 iql/extensions/pandas_extension.py
--rw-r--r--  2.0 unx      666 b- defN 23-Apr-21 12:49 iql/extensions/template_extension.py
--rw-r--r--  2.0 unx      535 b- defN 23-Apr-21 12:50 iql-0.1.9b6.dist-info/LICENSE
--rw-r--r--  2.0 unx    27298 b- defN 23-Apr-21 12:50 iql-0.1.9b6.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-21 12:50 iql-0.1.9b6.dist-info/WHEEL
--rw-r--r--  2.0 unx        4 b- defN 23-Apr-21 12:50 iql-0.1.9b6.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2041 b- defN 23-Apr-21 12:50 iql-0.1.9b6.dist-info/RECORD
-25 files, 131617 bytes uncompressed, 44184 bytes compressed:  66.4%
+Zip file size: 48164 bytes, number of entries: 25
+-rw-r--r--  2.0 unx      391 b- defN 23-May-10 19:20 iql/__init__.py
+-rw-r--r--  2.0 unx      104 b- defN 23-May-10 19:21 iql/_version.py
+-rw-r--r--  2.0 unx    34989 b- defN 23-May-10 19:20 iql/iqmoql.py
+-rw-r--r--  2.0 unx     1282 b- defN 23-May-10 19:20 iql/options_parser.py
+-rw-r--r--  2.0 unx     3233 b- defN 23-May-10 19:20 iql/q_cache.py
+-rw-r--r--  2.0 unx     2191 b- defN 23-May-10 19:20 iql/threading_experimental.py
+-rw-r--r--  2.0 unx       77 b- defN 23-May-10 19:20 iql/bbg_bql/__init__.py
+-rw-r--r--  2.0 unx    10069 b- defN 23-May-10 19:20 iql/bbg_bql/bql_datamodel.py
+-rw-r--r--  2.0 unx     9162 b- defN 23-May-10 19:20 iql/bbg_bql/bql_extension.py
+-rw-r--r--  2.0 unx    14310 b- defN 23-May-10 19:20 iql/bbg_bql/bql_wrapper.py
+-rw-r--r--  2.0 unx      692 b- defN 23-May-10 19:20 iql/bbg_bql/debug_tools.py
+-rw-r--r--  2.0 unx       77 b- defN 23-May-10 19:20 iql/db_connectors/__init__.py
+-rw-r--r--  2.0 unx     4795 b- defN 23-May-10 19:20 iql/db_connectors/duckdb_connector.py
+-rw-r--r--  2.0 unx       77 b- defN 23-May-10 19:20 iql/extensions/__init__.py
+-rw-r--r--  2.0 unx     3470 b- defN 23-May-10 19:20 iql/extensions/aws_s3_extension.py
+-rw-r--r--  2.0 unx     7829 b- defN 23-May-10 19:20 iql/extensions/edgar_extension.py
+-rw-r--r--  2.0 unx     4279 b- defN 23-May-10 19:20 iql/extensions/fred_extension.py
+-rw-r--r--  2.0 unx     4106 b- defN 23-May-10 19:20 iql/extensions/kaggle_extension.py
+-rw-r--r--  2.0 unx     2495 b- defN 23-May-10 19:20 iql/extensions/pandas_extension.py
+-rw-r--r--  2.0 unx      666 b- defN 23-May-10 19:20 iql/extensions/template_extension.py
+-rw-r--r--  2.0 unx      535 b- defN 23-May-10 19:21 iql-1.6.dev0.dist-info/LICENSE
+-rw-r--r--  2.0 unx    27299 b- defN 23-May-10 19:21 iql-1.6.dev0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-May-10 19:21 iql-1.6.dev0.dist-info/WHEEL
+-rw-r--r--  2.0 unx        4 b- defN 23-May-10 19:21 iql-1.6.dev0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2046 b- defN 23-May-10 19:21 iql-1.6.dev0.dist-info/RECORD
+25 files, 134270 bytes uncompressed, 44868 bytes compressed:  66.6%
```

## zipnote {}

```diff
@@ -54,23 +54,23 @@
 
 Filename: iql/extensions/pandas_extension.py
 Comment: 
 
 Filename: iql/extensions/template_extension.py
 Comment: 
 
-Filename: iql-0.1.9b6.dist-info/LICENSE
+Filename: iql-1.6.dev0.dist-info/LICENSE
 Comment: 
 
-Filename: iql-0.1.9b6.dist-info/METADATA
+Filename: iql-1.6.dev0.dist-info/METADATA
 Comment: 
 
-Filename: iql-0.1.9b6.dist-info/WHEEL
+Filename: iql-1.6.dev0.dist-info/WHEEL
 Comment: 
 
-Filename: iql-0.1.9b6.dist-info/top_level.txt
+Filename: iql-1.6.dev0.dist-info/top_level.txt
 Comment: 
 
-Filename: iql-0.1.9b6.dist-info/RECORD
+Filename: iql-1.6.dev0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## iql/__init__.py

```diff
@@ -1,13 +1,14 @@
 # Copyright (C) 2023, IQMO Corporation [info@iqmo.com]
 # All Rights Reserved
 from multiprocessing import Process, log_to_stderr
 
 from iql.iqmoql import (
     execute,
+    execute_debug,
     configure,
     get_extension,
     list_extensions,
     register_extension,
 )
 from iql.q_cache import clear_caches
```

## iql/_version.py

```diff
@@ -1,3 +1,3 @@
-__version__="0.1.9b6"
-__commit__="59351d7d962a00b6c73ee3baac1288ac58973e1e"
-__commit_short__="59351d7"
+__version__="1.6.dev0"
+__commit__="97842ca6d7a1216c194ffdb5e723b85a0c08590e"
+__commit_short__="97842ca"
```

## iql/iqmoql.py

```diff
@@ -110,28 +110,55 @@
         results.append((keyword, subword, outer, inner))
 
     return results
 
 
 @dataclass
 class IqlResult:
+    name: str
+    query: str
+
     def arrow(self):
         pass
 
     def df_numpy(self):
         pass
 
     def df_arrow(self):
         pass
 
+    def native(self):
+        """Returns whatever the internal representation"""
+        pass
+
+
+@dataclass
+class IqlResultData(IqlResult):
+    name: str
+    query: str
+    _data: object
+
+    def native(self):
+        """Returns whatever the internal representation"""
+        return self._data
+
+    def arrow(self):
+        raise ValueError("Not Implemented")
+
+    def df_numpy(self):
+        raise ValueError("Not Implemented")
+
+    def df_arrow(self):
+        raise ValueError("Not Implemented")
+
 
 class IqlDatabase:
     @abstractmethod
     def execute_query(
-        self, query: str, completed_dfs: Dict[str, DataFrame]
+        self, query: str, completed_results: List[IqlResult]
     ) -> Optional[IqlResult]:
         raise ValueError("Implement Me")
 
     @abstractmethod
     def get_connection(self) -> object:
         raise ValueError("Implement Me")
 
@@ -267,51 +294,55 @@
 
                 sq.dataframe = df
 
                 sq.save_to_cache()
 
                 return df
 
-    def execute_batch(self, queries: List["SubQuery"]) -> Dict[str, DataFrame]:
+    def execute_batch(self, queries: List["SubQuery"]) -> List[IqlResult]:
         """Default implementation runs individually, override for functions that can be batched, such as
         BQL's _many functions.
         Executes all subqueries first, then merges as required.
         SubQueries are executed in a threadpool, which has minimal benefit."""
 
-        completed_dfs = {}
+        completed_results = []
         # context = get_context('spawn')
 
         subqueries_flat = get_subqueries_flat(queries)
         # Get all the queries (and any queries inside SubQueryGroups)
 
         # Executes the ungrouped queries
 
         if te.ENABLED and te.MAX_PROCESSES > 1 and len(queries) > 1:
             te.execute_batch(subqueries_flat, self.execute)
         else:
             for query in subqueries_flat:
-                self.execute(query)  # type: ignore
+                try:
+                    self.execute(query)  # type: ignore
+                except Exception as e:
+                    raise ValueError(f"Error from {query}") from e
 
-        completed_dfs = {}
         # Merge the results
         for query in queries:
             # For single subqueries, this is a noop
             # For subquery groups, this merges the results of the children
             query.merge()
 
             df = query.dataframe
             if df is None and not self.use_path_replacement():
                 raise ValueError(f"Empty DF, {query.get_query()} failed")
             elif df is None:
                 logger.debug("Using path replacement, no DF")
             else:
                 query.dataframe = df  # type: ignore
-                completed_dfs[query.name] = df
 
-        return completed_dfs
+                ir = IqlResultData(name=query.name, query=query.subquery, _data=df)
+                completed_results.append(ir)
+
+        return completed_results
 
     def create_subquery(
         self, subquery: str, name: str, iqc: "IqlQueryContainer"
     ) -> "SubQuery":
         logger.debug("Creating subquery")
         sq = SubQuery(extension=self, subquery=subquery, name=name, iqc=iqc)
         return sq
@@ -339,15 +370,15 @@
             if (
                 len(paramquery) == 2
                 and isinstance(paramquery[0], str)
                 and isinstance(paramquery[1], str)
             ):
                 parameter_name = paramquery[0]
                 param_query = paramquery[1]
-                result = iqc.db.execute_query(param_query, completed_dfs={})  # type: ignore
+                result = iqc.db.execute_query(param_query, completed_results=[])  # type: ignore
 
                 df = result.df_numpy()
                 parameter_values = df[df.columns[0]].values
                 logger.debug(f"Values {parameter_values}")
             else:
                 raise ValueError(f"Invalid options passed to paramquery: {paramquery}")
 
@@ -371,14 +402,19 @@
             parameter_values = None  # type: ignore
 
         if parameter_name is not None:
             assert parameter_values is not None and len(parameter_values) > 0
             sqs: List["SubQuery"] = []
             count = 1
 
+            if not parameter_name.startswith("$"):
+                logger.debug("Parameter name doesn't start with $, inserting one")
+                # This is helpful to avoid replacing the paramquery when substituting
+                parameter_name = f"${parameter_name}"
+
             for v in parameter_values:
                 v_query = query.replace(parameter_name, v)
 
                 sq = create_function(  # type: ignore
                     subquery=v_query, name=f"{name}_{count}", iqc=iqc
                 )
 
@@ -804,34 +840,36 @@
             s
             for s in self.subqueries
             if s.extension.keyword == keyword and s.extension.subword == subword
         ]
 
         return results
 
-    def execute(self) -> Tuple[Optional[DataFrame], List[DataFrame]]:
+    def execute(self) -> Tuple[Optional[DataFrame], List[IqlResult]]:
         """Returns the final df, plus the intermediate subquery dataframes.
         If the query is not a Select, returns a None"""
         # Execute the subqueries
 
-        completed_dfs: Dict[str, DataFrame] = {}
+        completed_results: List[IqlResult] = []
 
         for (keyword, subword), e in _EXTENSIONS.items():
             sqs: List[SubQuery] = self.get_subqueries_by_extension(keyword, subword)  # type: ignore
 
-            e_dfs = e.execute_batch(sqs)  # type: ignore
+            e_results = e.execute_batch(sqs)  # type: ignore
+
+            completed_results += e_results
 
-            for k, df in e_dfs.items():
-                if df is not None:
-                    completed_dfs[k] = df
+        result = self.db.execute_query(query=self.query, completed_results=completed_results)  # type: ignore
 
-        result = self.db.execute_query(query=self.query, completed_dfs=completed_dfs)  # type: ignore
-        df = result.df_numpy()
+        if result is None:
+            df = None
+        else:
+            df = result.df_numpy()
 
-        return (df, completed_dfs)  # type: ignore
+        return (df, completed_results)  # type: ignore
 
 
 class IqlPlan:
     pass
 
 
 def _parameterize_sql_alias(subword, query) -> str:
@@ -860,67 +898,68 @@
 
         newquery = newquery.replace(outer, sql)
         # logger.info(f"After alias replacement {query}")
 
     return newquery
 
 
-def execute_full_results(
+def execute_debug(
     query: str, con: Optional[object] = None
-) -> Tuple[Optional[DataFrame], Optional[List[DataFrame]], IqlPlan]:
+) -> Tuple[bool, Optional[DataFrame], Optional[Dict[str, List[IqlResult]]]]:
+    """Returns the success (True or False), final query result, and the debug results: all the intermediate queries and subqueries."""
     # Connection to database
     get_dbconnector()
     if _DBCONNECTOR is None:
         raise ValueError("DBConnector Not Set")
     if con is None:
         db = _DBCONNECTOR.create_database()
     else:
         db = _DBCONNECTOR.create_database_from_con(con=con)
 
     # Aliases
     query = replace_sql_aliases(query)
 
-    # Placeholder for an IqlPlan (noop for now)
-    iqlplan: IqlPlan = IqlPlan()
-
     try:
         # A single query might contain multiple SQL statements. Parse them out and iterate:
 
         df = None
-        completed_dfs = None
+        completed_result_map = {}
         if ";" not in query:
             # Performance optimization for simple queries
             iqc = IqlQueryContainer(query=query, db=db)
 
             df, completed_dfs = iqc.execute()
         else:
             for statement in sqlparse.parse(query):
                 singlequery = statement.value.strip(";")
                 iqc = IqlQueryContainer(query=singlequery, db=db)
 
                 # Run each statement, but only keep the results from the last one
-                df, completed_dfs = iqc.execute()
+                df, completed_results = iqc.execute()
+
+                # add the final result to the completions
+                final_result = IqlResultData(name="final", query=statement, _data=df)
 
-        # The first result is the query result. The other df's are for debugging purposes
-        # If it's not a select, there won't be response, such as in a COPY (..) TO
+                completed_results.append(final_result)
+                completed_result_map[statement] = completed_results
 
-        return (df, completed_dfs, iqlplan)
+        return (True, df, completed_result_map)
 
     finally:
         if con is None:  # DB was created here, so close it
             db.close_db()
 
 
 def execute(query: str, con: Optional[object] = None) -> Optional[DataFrame]:
     """Executes the given SQL query. Keyword is only used to run a single subquery without SQL."""
 
     if query.strip().startswith("get") or query.strip().startswith("let"):
         query = query.replace('"', '"')
         query = f"""select * from bql("{query}")"""
-    df, completed_dfs, iql_plan = execute_full_results(query, con)
+    success, df, completed_dfs = execute_debug(query, con)
 
     return df
 
 
 def get_dbconnector() -> IqlDatabaseConnector:
     global _DBCONNECTOR
     if _DBCONNECTOR is None:
```

## iql/bbg_bql/bql_extension.py

```diff
@@ -205,15 +205,20 @@
         # Then update the subqueries
         for q in subqueries_flat:
             if q.bqlquery.execution_status == BaseBqlQuery.STATUS_FAILURE:
                 if q.options.get("allow_failure") is None:
                     raise ValueError(
                         f"BQL SubQuery failed {q.bqlquery.exception_msg}: {q.bqlquery.to_bql_query()} {q.options}"
                     )
-            q.execute()
+            try:
+                q.execute()
+            except Exception as e:
+                raise ValueError(
+                    f"Error on q.bqlquery: {q.bqlquery.to_bql_query()}"
+                ) from e
 
         completed_dfs = {}
         # Final step to merge any grouped subqueries.
         for q in subqueries:
             q.merge()
             df = q.dataframe
             completed_dfs[q.name] = df
```

## iql/bbg_bql/bql_wrapper.py

```diff
@@ -192,17 +192,34 @@
 
     if "preferences" not in request_str:
         request_str += "\npreferences (addcols=all)"
 
     return request_str
 
 
-def error_callback(o):
-    # TODO: Pass with some context information using a partial()
+def error_callback(o, errorlist=None):
+    if errorlist is None:
+        logger.info(o)
+        return
+
+    try:
+        e = o[1]
+        long_error = {
+            "message": e.exception_messages,
+            "request_id": e._request_id,
+            "details": e.internal_messages,
+        }
+        errorlist.append(long_error)
+
+    except Exception as e:
+        logger.exception("Couldn't expand error callback")
+        errorlist.append(o)
     logger.warning("Error executing" + str(o))
+    if errorlist is not None:
+        errorlist.append(o)
 
 
 def execute_bql_str_list_async_q(
     queries_input: List[BaseBqlQuery],
     suppress_warning_log: bool = False,
     max_queries: int = _MAX_CONCURRENT,
 ):
@@ -291,36 +308,41 @@
             if "iqmo" in qstr:
                 raise ValueError("IQMO parameters passed to BQL layer, cannot run")
 
             logger.debug(f"Executing {qstr}")
             query_strings.append(qstr)
 
         bqService = get_bqservice()
-        # error_list: List[str] = []
+
+        # TODO: Out of order errors are not handled here. Not an issue in many cases
+        # but is still very likely.
+        errorlist: List[str] = []
 
         if submit_fetch_many_available():
             logger.debug("Using submit fetch many")
+
             gen = bqService.submit_fetch_many(
-                query_strings, on_request_error=error_callback
+                query_strings,
+                on_request_error=partial(error_callback, errorlist=errorlist),
             )
         else:
             gen = bqService.execute_many(
                 query_strings,
-                partial(error_callback),
+                partial(error_callback, errorlist=errorlist),
             )
 
         error_index = 0
 
         logger.info("Waiting for and processing BQL results")
         for r, q in zip(gen, queries):
             try:
                 if r is None:
                     q.execution_status = q.STATUS_FAILURE
                     logger.warn(f"Error executing: {q.to_bql_query()}")
-                    q.exception_msg = "Failure"
+                    q.exception_msg = errorlist[error_index]
                     error_index = error_index + 1
                 else:
                     data = _to_data(r)
                     q._data = data
                     q.execution_status = q.STATUS_COMPLETED
 
             except Exception as e:
```

## iql/db_connectors/duckdb_connector.py

```diff
@@ -1,16 +1,16 @@
 # Copyright (C) 2023, IQMO Corporation [info@iqmo.com]
 # All Rights Reserved
 
 import duckdb
 import logging
 from contextlib import nullcontext
-from typing import Dict, Optional
+from typing import Optional, List
 
-from pandas import DataFrame
+# from pandas import DataFrame
 from pandas import ArrowDtype
 from pyarrow import Table
 
 from iql.iqmoql import IqlDatabaseConnector, IqlDatabase, IqlResult
 import threading
 
 from dataclasses import dataclass
@@ -54,22 +54,25 @@
 
     def df_numpy(self):
         return self._table.to_pandas()
 
     def df_arrow(self):
         return self._table.to_pandas(types_mapper=ArrowDtype)
 
+    def native(self):
+        return self._table
+
 
 @dataclass
 class _DuckDB(IqlDatabase):
     _connection: object
     _started_thread: int
 
     def execute_query(
-        self, query: str, completed_dfs: Optional[Dict[str, DataFrame]] = None
+        self, query: str, completed_results: Optional[List[IqlResult]] = None
     ) -> Optional[DuckDbResult]:
         """param: Each of the completed _dfs are registered to the database.
         threaded: pass True to run in a separate connection, otherwise runs in main connection
         """
 
         threaded = threading.get_ident() != self._started_thread
 
@@ -77,39 +80,42 @@
         with self.get_connection() if threaded else nullcontext(
             self._connection
         ) as con:
             try:
                 # Register each of the dataframes to duckdb, so duckdb can query them
                 # Other database might require a "load" or "from_pandas()" step to load these
                 # to temporary tables.
-                if completed_dfs is not None:
-                    for key, df in completed_dfs.items():
-                        if df is None or (df.empty and len(df.columns) == 0):
+                if completed_results is not None:
+                    # THis scans row by row (=1) to determine column type. Avoids other issues downstream but not efficient.
+                    # Datatype detection is pretty broken for dataframes: it samples every 1000 by default, so if nulls are rare, it won't properly
+                    # interpret. TODO: Revisit, maybe duckdb doesn't need this when using arrow-backed DFs?
+                    # con.execute("SET GLOBAL pandas_analyze_sample = 1;")  # type: ignore
+
+                    for result in completed_results:
+                        data = result.native()
+                        if data is None:
                             continue
-                            # raise ValueError(f"None dataframe for {key}")
-                        con.register(key, df)  # type: ignore
+                        # if df is None or (df.empty and len(df.columns) == 0):
+                        #    continue
+                        # raise ValueError(f"None dataframe for {key}")
+
+                        con.register(result.name, data)  # type: ignore
 
                 d = con.execute(query)  # type: ignore
                 # Don't use con.sql, as it adds a small but
                 # measurable overhead of creating a duckdb relation, that we don't need
                 if d is not None:
                     # logger.debug("Using Pandas format")
-                    try:
-                        table = d.arrow()
-                        return DuckDbResult(_table=table)
-                    except Exception:
-                        # TODO: Detect this more gracefully
-                        logger.debug("Didn't have a result set {str(e)}")
-                        return None
-
+                    table = d.arrow()
+                    return DuckDbResult(name=query, query=query, _table=table)
                 else:
                     return None
             except Exception as e:
                 logger.exception(f"Error executing SQL DFs: {query}")
-                raise e
+                raise ValueError("Error executing {query}") from e
 
     def get_connection(self):
         return self._connection.cursor()  # type: ignore
 
     def close_db(self):
         try:
             if self._connection is None:
```

## iql/extensions/pandas_extension.py

```diff
@@ -1,38 +1,48 @@
 # Copyright (C) 2023, IQMO Corporation [info@iqmo.com]
 # All Rights Reserved
 
 import logging
 from dataclasses import dataclass
+from typing import List
 from pandas import DataFrame
-from iql.iqmoql import IqlExtension, register_extension, SubQuery, IqlDatabase
+from iql.iqmoql import (
+    IqlExtension,
+    register_extension,
+    SubQuery,
+    IqlDatabase,
+    IqlResultData,
+    IqlResult,
+)
 import pyarrow as pa
 import pandas as pd
 
 logger = logging.getLogger(__name__)
 
 
 def get_data(sq: SubQuery, source_query) -> pd.DataFrame:
     db: IqlDatabase = sq.iqc.db  # type: ignore
     input_data = sq.input_data
-    local_dfs = sq.local_dfs
+    local_results: List[IqlResult] = [
+        IqlResultData(_data=ldf, name=k, query=k) for k, ldf in sq.local_dfs
+    ]
 
     # So much work to get Polars and/or PyArrow to work in sklearn
     # Can revisit, but need to work around using onehotencoder
     if input_data is not None:
         if isinstance(input_data, DataFrame):
             return input_data
         elif isinstance(input_data, pa.lib.Table):
             return input_data.to_pandas()  # type: ignore
         else:
             raise ValueError(f"Unexpected type: {type(input_data)}")
 
     else:
         result = db.execute_query(  # type: ignore
-            query=source_query, completed_dfs=local_dfs
+            query=source_query, completed_results=local_results
         )
         if result is None:
             raise ValueError(f"Could not get data for query {source_query}")
         else:
             return result.df_numpy()
```

## Comparing `iql-0.1.9b6.dist-info/LICENSE` & `iql-1.6.dev0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `iql-0.1.9b6.dist-info/METADATA` & `iql-1.6.dev0.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: iql
-Version: 0.1.9b6
+Version: 1.6.dev0
 Summary: SQL Overlay Language with support for Bloomberg BQL, FRED, Edgar, Kaggle and other financial data sources within SQL
 Home-page: https://github.com/iqmo-org/iql_dev
 Author: Paul Timmins
 Author-email: paul@iqmo.com
 Keywords: IQMO Query Language IQMOQL BQL BQUANT FRED EDGAR KAGGLE
 Description-Content-Type: text/markdown
 License-File: LICENSE
```

## Comparing `iql-0.1.9b6.dist-info/RECORD` & `iql-1.6.dev0.dist-info/RECORD`

 * *Files 12% similar despite different names*

```diff
@@ -1,25 +1,25 @@
-iql/__init__.py,sha256=DfBkCF58y3GNp_W2-W6Vs2l2ov1thvCn_MEEc5SouQ4,372
-iql/_version.py,sha256=CYn4tZNXprIlcT2YBFYBuj8QjMywBXvKOrzXhHXdOAY,103
-iql/iqmoql.py,sha256=KRNQ1GFgNaBFF5K6j0jq5ZG8idtDWerpMdLBNWoj5SI,33829
+iql/__init__.py,sha256=2lgdoOHT2dQVh5vg9vJTX0tdlqhYYEOL9iA4P2SgUFg,391
+iql/_version.py,sha256=hViImdEVE_fyZtRpwCm-K2AwEEJlcWlXuk1q9LhlWtI,104
+iql/iqmoql.py,sha256=0igaa2vQ-k6WqO62XHstM8lp8amMUE2aJ5iFMdwIhxo,34989
 iql/options_parser.py,sha256=Sk6iRFCDrAbOZf0yYbUNLVKR5YvvMK8dJLNFPKy0xRc,1282
 iql/q_cache.py,sha256=H3uggWqv3YEC3UdzhT2N-44oY_Ne2kEN6_oJE8QUOxs,3233
 iql/threading_experimental.py,sha256=bKsGee-Y05Rr5z1Pf1P7gBqMHUzc86l5Tbe2CXn25Hc,2191
 iql/bbg_bql/__init__.py,sha256=nCTs4I9SAb24B7wg2Zd0wGsVLwamTu4BpFIIpRK0cDw,77
 iql/bbg_bql/bql_datamodel.py,sha256=1YPVfJVQE3vfaRMtAcKCxUNrrzQTeCm7D7bntIX35xw,10069
-iql/bbg_bql/bql_extension.py,sha256=0SzGZXaiQlTTTLWRxuo1hLIaKBLNWzfkx2VYV05Dk5o,8975
-iql/bbg_bql/bql_wrapper.py,sha256=nW72hMSCIY1hnW_eMTDNw83VQ2YYB3u4tCC7w7atAaw,13694
+iql/bbg_bql/bql_extension.py,sha256=6MDZjFKShhNUzeaeOxcee6M49FRrU7NP1iDTfUUIyfg,9162
+iql/bbg_bql/bql_wrapper.py,sha256=zbZjL7qY-Kg0zWasEvT__DbRWb9gTfLk7RQ0uMxOq28,14310
 iql/bbg_bql/debug_tools.py,sha256=Rfs-HivxSYgGyTrByhPwiZ6QKtCn2iUnuNNmcKf1BtQ,692
 iql/db_connectors/__init__.py,sha256=nCTs4I9SAb24B7wg2Zd0wGsVLwamTu4BpFIIpRK0cDw,77
-iql/db_connectors/duckdb_connector.py,sha256=OmkufYvvg8T-BeWXATBoV3iZWcd9NyuhDGlPHgy_kjs,4311
+iql/db_connectors/duckdb_connector.py,sha256=6nDc2nXkyZ1cRzIReziTBi2dukXV4tQfHJ7mvpyNwWE,4795
 iql/extensions/__init__.py,sha256=nCTs4I9SAb24B7wg2Zd0wGsVLwamTu4BpFIIpRK0cDw,77
 iql/extensions/aws_s3_extension.py,sha256=rCyE9Xoo4eH3pnwxO0g4RgQTQHkNAxVKKmeidFs22XE,3470
 iql/extensions/edgar_extension.py,sha256=DQEsLSMY0J5gw3bLigbRJ7emMUiNEPhbPSCGJDo0Zi0,7829
 iql/extensions/fred_extension.py,sha256=YZbAMy3o8fzZ01ulvO2j5rhEQRsE9BrH96WP9NyrWX0,4279
 iql/extensions/kaggle_extension.py,sha256=h1dSdWiUF-h_J7aZjwqU3Pn2s5kw_XiKcQUT0ElmPVE,4106
-iql/extensions/pandas_extension.py,sha256=ue3izSZOTtbRR9g3_QkjPhWep_Or97aP-r4GP5HxLsw,2315
+iql/extensions/pandas_extension.py,sha256=soG4cxNRzB1lesrXcj5s4JL3eND4wIjsXcRNlTgphVg,2495
 iql/extensions/template_extension.py,sha256=jvF1r-ShKTM0o69wIw9aU448pe4S_lqw5Q86rusnybY,666
-iql-0.1.9b6.dist-info/LICENSE,sha256=fRoQlSrnKvIqTnrbUywcGohiS97ofE1quZqsib7WE0c,535
-iql-0.1.9b6.dist-info/METADATA,sha256=7t4l09p8nqmUxUbZcsNj8t46WEZXbXuenr7UcY4iOGM,27298
-iql-0.1.9b6.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-iql-0.1.9b6.dist-info/top_level.txt,sha256=Tk45SvyMJ3Qip3gIAemqP9BvRhIokV7hGo3MyTS8Q0c,4
-iql-0.1.9b6.dist-info/RECORD,,
+iql-1.6.dev0.dist-info/LICENSE,sha256=fRoQlSrnKvIqTnrbUywcGohiS97ofE1quZqsib7WE0c,535
+iql-1.6.dev0.dist-info/METADATA,sha256=fHSqTzzmhmqHERu-zewTLlxjGomljNumLSaq-FK3a7o,27299
+iql-1.6.dev0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+iql-1.6.dev0.dist-info/top_level.txt,sha256=Tk45SvyMJ3Qip3gIAemqP9BvRhIokV7hGo3MyTS8Q0c,4
+iql-1.6.dev0.dist-info/RECORD,,
```

