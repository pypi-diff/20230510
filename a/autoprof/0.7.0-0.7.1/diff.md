# Comparing `tmp/autoprof-0.7.0-py2.py3-none-any.whl.zip` & `tmp/autoprof-0.7.1-py2.py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,20 +1,20 @@
-Zip file size: 147818 bytes, number of entries: 80
+Zip file size: 149501 bytes, number of entries: 80
 -rw-rw-r--  2.0 unx     3171 b- defN 23-Mar-17 23:11 autoprof/AP_config.py
--rw-rw-r--  2.0 unx     5755 b- defN 23-May-02 20:09 autoprof/__init__.py
+-rw-rw-r--  2.0 unx     5755 b- defN 23-May-10 20:09 autoprof/__init__.py
 -rw-rw-r--  2.0 unx      281 b- defN 23-Mar-17 23:11 autoprof/__main__.py
 -rw-rw-r--  2.0 unx     1092 b- defN 23-May-02 20:08 autoprof/fit/__init__.py
--rw-rw-r--  2.0 unx     6698 b- defN 23-May-02 20:08 autoprof/fit/base.py
+-rw-rw-r--  2.0 unx     6682 b- defN 23-May-04 13:21 autoprof/fit/base.py
 -rw-rw-r--  2.0 unx       30 b- defN 23-Apr-08 19:05 autoprof/fit/gp.py
 -rw-rw-r--  2.0 unx     6704 b- defN 23-Apr-08 19:05 autoprof/fit/gradient.py
--rw-rw-r--  2.0 unx     4884 b- defN 23-May-02 20:08 autoprof/fit/hmc.py
+-rw-rw-r--  2.0 unx     6912 b- defN 23-May-10 20:09 autoprof/fit/hmc.py
 -rw-rw-r--  2.0 unx    13206 b- defN 23-Apr-08 19:05 autoprof/fit/iterative.py
--rw-rw-r--  2.0 unx    31364 b- defN 23-May-02 20:08 autoprof/fit/lm.py
+-rw-rw-r--  2.0 unx    31364 b- defN 23-May-08 01:46 autoprof/fit/lm.py
 -rw-rw-r--  2.0 unx     4317 b- defN 23-May-02 20:08 autoprof/fit/mhmcmc.py
--rw-rw-r--  2.0 unx     5296 b- defN 23-May-02 20:08 autoprof/fit/nuts.py
+-rw-rw-r--  2.0 unx     7109 b- defN 23-May-10 20:09 autoprof/fit/nuts.py
 -rw-rw-r--  2.0 unx     1125 b- defN 23-Apr-21 02:55 autoprof/image/__init__.py
 -rw-rw-r--  2.0 unx    11195 b- defN 23-Apr-21 02:55 autoprof/image/image_header.py
 -rw-rw-r--  2.0 unx    21644 b- defN 23-Apr-21 02:55 autoprof/image/image_object.py
 -rw-rw-r--  2.0 unx     5269 b- defN 23-Apr-21 02:55 autoprof/image/jacobian_image.py
 -rw-rw-r--  2.0 unx     6615 b- defN 23-Apr-21 02:55 autoprof/image/model_image.py
 -rw-rw-r--  2.0 unx    15842 b- defN 23-Apr-21 02:55 autoprof/image/target_image.py
 -rw-rw-r--  2.0 unx    22836 b- defN 23-Apr-21 02:55 autoprof/image/window_object.py
@@ -44,39 +44,39 @@
 -rw-rw-r--  2.0 unx     4332 b- defN 23-Mar-17 23:11 autoprof/models/warp_model.py
 -rw-rw-r--  2.0 unx     3546 b- defN 23-Apr-21 02:55 autoprof/models/wedge_model.py
 -rw-rw-r--  2.0 unx       57 b- defN 23-Feb-16 02:48 autoprof/parse_config/__init__.py
 -rw-rw-r--  2.0 unx     4147 b- defN 23-Mar-17 23:11 autoprof/parse_config/basic_config.py
 -rw-rw-r--  2.0 unx     4590 b- defN 23-Mar-17 23:11 autoprof/parse_config/galfit_config.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Feb-16 02:48 autoprof/parse_config/shared_methods.py
 -rw-rw-r--  2.0 unx       67 b- defN 22-Oct-27 02:37 autoprof/plots/__init__.py
--rw-rw-r--  2.0 unx     6857 b- defN 23-May-02 20:08 autoprof/plots/image.py
+-rw-rw-r--  2.0 unx     6903 b- defN 23-May-04 03:13 autoprof/plots/image.py
 -rw-rw-r--  2.0 unx     7559 b- defN 23-May-01 22:29 autoprof/plots/profile.py
 -rw-rw-r--  2.0 unx     3048 b- defN 23-Mar-17 23:11 autoprof/plots/shared_elements.py
 -rw-rw-r--  2.0 unx    19994 b- defN 23-May-02 20:08 autoprof/plots/visuals.py
 -rw-rw-r--  2.0 unx        0 b- defN 22-Sep-15 14:58 autoprof/utils/__init__.py
 -rw-rw-r--  2.0 unx      800 b- defN 23-Mar-30 13:28 autoprof/utils/angle_operations.py
--rw-rw-r--  2.0 unx     8609 b- defN 23-Mar-17 23:11 autoprof/utils/interpolate.py
+-rw-rw-r--  2.0 unx     9820 b- defN 23-May-10 20:09 autoprof/utils/interpolate.py
 -rw-rw-r--  2.0 unx     6369 b- defN 23-Apr-28 21:02 autoprof/utils/operations.py
 -rw-rw-r--  2.0 unx      963 b- defN 23-Mar-17 23:11 autoprof/utils/optimization.py
 -rw-rw-r--  2.0 unx     5990 b- defN 23-Apr-01 17:55 autoprof/utils/parametric_profiles.py
 -rw-rw-r--  2.0 unx        0 b- defN 22-Dec-16 16:54 autoprof/utils/conversions/__init__.py
 -rw-rw-r--  2.0 unx     2317 b- defN 23-Mar-17 23:11 autoprof/utils/conversions/coordinates.py
 -rw-rw-r--  2.0 unx     1095 b- defN 23-Mar-21 14:13 autoprof/utils/conversions/dict_to_hdf5.py
 -rw-rw-r--  2.0 unx     1829 b- defN 23-Mar-30 13:28 autoprof/utils/conversions/functions.py
 -rw-rw-r--  2.0 unx     2728 b- defN 23-Mar-30 13:28 autoprof/utils/conversions/optimization.py
 -rw-rw-r--  2.0 unx     2536 b- defN 23-Mar-30 13:28 autoprof/utils/conversions/units.py
--rw-rw-r--  2.0 unx      269 b- defN 23-Mar-30 13:28 autoprof/utils/initialize/__init__.py
+-rw-rw-r--  2.0 unx      281 b- defN 23-May-04 13:15 autoprof/utils/initialize/__init__.py
 -rw-rw-r--  2.0 unx     3103 b- defN 23-Mar-30 13:28 autoprof/utils/initialize/center.py
--rw-rw-r--  2.0 unx     3296 b- defN 23-Mar-30 13:28 autoprof/utils/initialize/construct_psf.py
+-rw-rw-r--  2.0 unx     4495 b- defN 23-May-04 13:20 autoprof/utils/initialize/construct_psf.py
 -rw-rw-r--  2.0 unx     3921 b- defN 23-Mar-17 23:11 autoprof/utils/initialize/initialize.py
 -rw-rw-r--  2.0 unx     7036 b- defN 23-Mar-30 13:28 autoprof/utils/initialize/segmentation_map.py
 -rw-rw-r--  2.0 unx        0 b- defN 22-Dec-16 16:54 autoprof/utils/isophote/__init__.py
 -rw-rw-r--  2.0 unx     1085 b- defN 23-Mar-17 23:11 autoprof/utils/isophote/ellipse.py
 -rw-rw-r--  2.0 unx     8531 b- defN 23-Mar-30 13:28 autoprof/utils/isophote/extract.py
 -rw-rw-r--  2.0 unx     7012 b- defN 23-Mar-17 23:11 autoprof/utils/isophote/integrate.py
--rw-rw-r--  2.0 unx    35149 b- defN 23-May-02 20:09 autoprof-0.7.0.dist-info/LICENSE
--rw-rw-r--  2.0 unx     3812 b- defN 23-May-02 20:09 autoprof-0.7.0.dist-info/METADATA
--rw-rw-r--  2.0 unx      110 b- defN 23-May-02 20:09 autoprof-0.7.0.dist-info/WHEEL
--rw-rw-r--  2.0 unx       57 b- defN 23-May-02 20:09 autoprof-0.7.0.dist-info/entry_points.txt
--rw-rw-r--  2.0 unx        9 b- defN 23-May-02 20:09 autoprof-0.7.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     7009 b- defN 23-May-02 20:09 autoprof-0.7.0.dist-info/RECORD
-80 files, 545523 bytes uncompressed, 136686 bytes compressed:  74.9%
+-rw-rw-r--  2.0 unx    35149 b- defN 23-May-10 20:10 autoprof-0.7.1.dist-info/LICENSE
+-rw-rw-r--  2.0 unx     3812 b- defN 23-May-10 20:10 autoprof-0.7.1.dist-info/METADATA
+-rw-rw-r--  2.0 unx      110 b- defN 23-May-10 20:10 autoprof-0.7.1.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       57 b- defN 23-May-10 20:10 autoprof-0.7.1.dist-info/entry_points.txt
+-rw-rw-r--  2.0 unx        9 b- defN 23-May-10 20:10 autoprof-0.7.1.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     7009 b- defN 23-May-10 20:10 autoprof-0.7.1.dist-info/RECORD
+80 files, 551816 bytes uncompressed, 138369 bytes compressed:  74.9%
```

## zipnote {}

```diff
@@ -216,26 +216,26 @@
 
 Filename: autoprof/utils/isophote/extract.py
 Comment: 
 
 Filename: autoprof/utils/isophote/integrate.py
 Comment: 
 
-Filename: autoprof-0.7.0.dist-info/LICENSE
+Filename: autoprof-0.7.1.dist-info/LICENSE
 Comment: 
 
-Filename: autoprof-0.7.0.dist-info/METADATA
+Filename: autoprof-0.7.1.dist-info/METADATA
 Comment: 
 
-Filename: autoprof-0.7.0.dist-info/WHEEL
+Filename: autoprof-0.7.1.dist-info/WHEEL
 Comment: 
 
-Filename: autoprof-0.7.0.dist-info/entry_points.txt
+Filename: autoprof-0.7.1.dist-info/entry_points.txt
 Comment: 
 
-Filename: autoprof-0.7.0.dist-info/top_level.txt
+Filename: autoprof-0.7.1.dist-info/top_level.txt
 Comment: 
 
-Filename: autoprof-0.7.0.dist-info/RECORD
+Filename: autoprof-0.7.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## autoprof/__init__.py

```diff
@@ -1,15 +1,15 @@
 import sys
 import argparse
 import requests
 from .parse_config import galfit_config, basic_config
 from . import models, image, plots, utils, fit, AP_config
 
 # meta data
-__version__ = "0.7.0"
+__version__ = "0.7.1"
 __author__ = "Connor Stone"
 __email__ = "connorstone628@gmail.com"
 
 
 def run_from_terminal() -> None:
     """
     Execute AutoProf from the command line with various options.
```

## autoprof/fit/base.py

```diff
@@ -46,15 +46,15 @@
 
         Attributes:
             model (object): An object representing the model.
             verbose (int): The verbosity level.
             current_state (Tensor): The current state of the model.
             max_iter (int): The maximum number of iterations.
             iteration (int): The current iteration number.
-            save_steps (Union[None, int]): The frequency at which to save intermediate results.
+            save_steps (Optional[str]): Save intermediate results to this path.
             relative_tolerance (float): The relative tolerance for the optimization.
             lambda_history (List[ndarray]): A list of the optimization steps.
             loss_history (List[float]): A list of the optimization losses.
             message (str): An informational message.
         """
 
         self.model = model
```

## autoprof/fit/hmc.py

```diff
@@ -1,26 +1,58 @@
 # Hamiltonian Monte-Carlo
 import os
 from time import time
 from typing import Optional, Sequence
 import warnings
 
 import torch
-from tqdm import tqdm
-import numpy as np
 import pyro
 import pyro.distributions as dist
 from pyro.infer import MCMC as pyro_MCMC
 from pyro.infer import HMC as pyro_HMC
+from pyro.infer.mcmc.adaptation import WarmupAdapter, BlockMassMatrix
+from pyro.ops.welford import WelfordCovariance
 
 from .base import BaseOptimizer
 from .. import AP_config
 
 __all__ = ["HMC"]
 
+###########################################
+# !Overwrite pyro configuration behavior!
+# currently this is the only way to provide
+# mass matrix manually
+###########################################
+def new_configure(self, mass_matrix_shape, adapt_mass_matrix=True, options={}):
+    """
+    Sets up an initial mass matrix.
+    
+    :param dict mass_matrix_shape: a dict that maps tuples of site names to the shape of
+        the corresponding mass matrix. Each tuple of site names corresponds to a block.
+    :param bool adapt_mass_matrix: a flag to decide whether an adaptation scheme will be used.
+    :param dict options: tensor options to construct the initial mass matrix.
+    """
+    inverse_mass_matrix = {}
+    for site_names, shape in mass_matrix_shape.items():
+        self._mass_matrix_size[site_names] = shape[0]
+        diagonal = len(shape) == 1
+        inverse_mass_matrix[site_names] = (
+            torch.full(shape, self._init_scale, **options)
+            if diagonal
+            else torch.eye(*shape, **options) * self._init_scale
+        )
+        if adapt_mass_matrix:
+            adapt_scheme = WelfordCovariance(diagonal=diagonal)
+            self._adapt_scheme[site_names] = adapt_scheme
+
+    if len(self.inverse_mass_matrix.keys()) == 0:
+        self.inverse_mass_matrix = inverse_mass_matrix
+BlockMassMatrix.configure = new_configure
+############################################
+
 class HMC(BaseOptimizer):
     """Hamiltonian Monte-Carlo sampler wrapper for the Pyro package.
 
     This MCMC algorithm uses gradients of the Chi^2 to more
     efficiently explore the probability distribution. Consider using
     the NUTS sampler instead of HMC, as it is generally better in most
     aspects.
@@ -28,50 +60,45 @@
     More information on HMC can be found at:
     https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo,
     https://arxiv.org/abs/1701.02434, and
     http://www.mcmchandbook.net/HandbookChapter5.pdf
 
     Args:
         model (AutoProf_Model): The model which will be sampled.
-        initial_state (Optional[Sequence]): A 1D array with the values for each
-            parameter in the model. Note that these values should be in the form
-            of "as_representation" in the model.
-        max_iter (int, optional): The number of sampling steps to perform.
-            Default is 1000.
-        epsilon (float, optional): The length of the integration step to perform
-            for each leapfrog iteration. The momentum update will be of order
-            elipson * score. Default is 1e-5.
-        leapfrog_steps (int, optional): Number of steps to perform with leapfrog
-            integrator per sample of the HMC. Default is 20.
-        mass_matrix (float or array, optional): Mass matrix which can tune the
-            behavior in each dimension to ensure better mixing when sampling.
-            Default is the identity.
+        initial_state (Optional[Sequence], optional): A 1D array with the values for each parameter in the model. These values should be in the form of "as_representation" in the model. Defaults to None.
+        max_iter (int, optional): The number of sampling steps to perform. Defaults to 1000.
+        epsilon (float, optional): The length of the integration step to perform for each leapfrog iteration. The momentum update will be of order epsilon * score. Defaults to 1e-5.
+        leapfrog_steps (int, optional): Number of steps to perform with leapfrog integrator per sample of the HMC. Defaults to 20.
+        inv_mass (float or array, optional): Inverse Mass matrix (covariance matrix) which can tune the behavior in each dimension to ensure better mixing when sampling. Defaults to the identity.
+        progress_bar (bool, optional): Whether to display a progress bar during sampling. Defaults to True.
+        prior (distribution, optional): Prior distribution for the parameters. Defaults to None.
+        warmup (int, optional): Number of warmup steps before actual sampling begins. Defaults to 100.
+        hmc_kwargs (dict, optional): Additional keyword arguments for the HMC sampler. Defaults to {}.
+        mcmc_kwargs (dict, optional): Additional keyword arguments for the MCMC process. Defaults to {}.
 
     """
     
     def __init__(
         self,
         model: "AutoProf_Model",
         initial_state: Optional[Sequence] = None,
         max_iter: int = 1000,
         **kwargs
     ):
         super().__init__(model, initial_state, max_iter=max_iter, **kwargs)
 
+        self.inv_mass = kwargs.get("inv_mass", None)
         self.epsilon = kwargs.get("epsilon", 1e-3)
         self.leapfrog_steps = kwargs.get("leapfrog_steps", 20)
         self.progress_bar = kwargs.get("progress_bar", True)
         self.prior = kwargs.get("prior", None)
         self.warmup = kwargs.get("warmup", 100)
         self.hmc_kwargs = kwargs.get("hmc_kwargs", {})
         self.mcmc_kwargs = kwargs.get("mcmc_kwargs", {})
         self.acceptance = None
-        
-        if "mass_matrix" not in self.hmc_kwargs and "mass_matrix" in kwargs:
-            self.hmc_kwargs["mass_matrix"] = kwargs.get("mass_matrix")
 
     def fit(
         self,
         state: Optional[torch.Tensor] = None,
     ):
         """Performs MCMC sampling using Hamiltonian Monte-Carlo step.
 
@@ -105,17 +132,20 @@
         hmc_kwargs = {
             "jit_compile": True,
             "ignore_jit_warnings": True,
             "full_mass": True,
             "step_size": self.epsilon,
             "num_steps": self.leapfrog_steps,
             "adapt_step_size": False,
+            "adapt_mass_matrix": self.inv_mass is None,
         }
         hmc_kwargs.update(self.hmc_kwargs)
         hmc_kernel = pyro_HMC(step, **hmc_kwargs)
+        if self.inv_mass is not None:
+            hmc_kernel.mass_matrix_adapter.inverse_mass_matrix = {("x",): self.inv_mass}
 
         # Provide an initial guess for the parameters
         init_params = {"x": self.model.get_parameter_vector(as_representation=True)}
 
         # Run MCMC with the HMC sampler and the initial guess
         mcmc_kwargs = {
             "num_samples": self.max_iter,
```

## autoprof/fit/nuts.py

```diff
@@ -5,20 +5,53 @@
 import warnings
 
 import torch
 import pyro
 import pyro.distributions as dist
 from pyro.infer import MCMC as pyro_MCMC
 from pyro.infer import NUTS as pyro_NUTS
+from pyro.infer.mcmc.adaptation import WarmupAdapter, BlockMassMatrix
+from pyro.ops.welford import WelfordCovariance
 
 from .base import BaseOptimizer
 from .. import AP_config
 
 __all__ = ["NUTS"]
 
+###########################################
+# !Overwrite pyro configuration behavior!
+# currently this is the only way to provide
+# mass matrix manually
+###########################################
+def new_configure(self, mass_matrix_shape, adapt_mass_matrix=True, options={}):
+    """
+    Sets up an initial mass matrix.
+    
+    :param dict mass_matrix_shape: a dict that maps tuples of site names to the shape of
+        the corresponding mass matrix. Each tuple of site names corresponds to a block.
+    :param bool adapt_mass_matrix: a flag to decide whether an adaptation scheme will be used.
+    :param dict options: tensor options to construct the initial mass matrix.
+    """
+    inverse_mass_matrix = {}
+    for site_names, shape in mass_matrix_shape.items():
+        self._mass_matrix_size[site_names] = shape[0]
+        diagonal = len(shape) == 1
+        inverse_mass_matrix[site_names] = (
+            torch.full(shape, self._init_scale, **options)
+            if diagonal
+            else torch.eye(*shape, **options) * self._init_scale
+        )
+        if adapt_mass_matrix:
+            adapt_scheme = WelfordCovariance(diagonal=diagonal)
+            self._adapt_scheme[site_names] = adapt_scheme
+
+    if len(self.inverse_mass_matrix.keys()) == 0:
+        self.inverse_mass_matrix = inverse_mass_matrix
+BlockMassMatrix.configure = new_configure
+############################################
 
 class NUTS(BaseOptimizer):
     """No U-Turn Sampler (NUTS) implementation for Hamiltonian Monte Carlo
     (HMC) based MCMC sampling.
 
     This is a wrapper for the Pyro package: https://docs.pyro.ai/en/stable/index.html
 
@@ -33,18 +66,18 @@
     More information on HMC and NUTS can be found at:
     https://en.wikipedia.org/wiki/Hamiltonian_Monte_Carlo,
     https://arxiv.org/abs/1701.02434, and
     http://www.mcmchandbook.net/HandbookChapter5.pdf
 
     Args:
         model (AutoProf_Model): The model which will be sampled.
-        initial_state (Optional[Sequence], optional): A 1D array with the values for each parameter in the model.
-            Note that these values should be in the form of "as_representation" in the model. Defaults to None.
+        initial_state (Optional[Sequence], optional): A 1D array with the values for each parameter in the model. These values should be in the form of "as_representation" in the model. Defaults to None.
         max_iter (int, optional): The number of sampling steps to perform. Defaults to 1000.
-        mass (Optional[Tensor], optional): Mass matrix for the Hamiltonian system. Defaults to None.
+        epsilon (float, optional): The step size for the NUTS sampler. Defaults to 1e-3.
+        inv_mass (Optional[Tensor], optional): Inverse Mass matrix (covariance matrix) for the Hamiltonian system. Defaults to None.
         progress_bar (bool, optional): If True, display a progress bar during sampling. Defaults to True.
         prior (Optional[Distribution], optional): Prior distribution for the model parameters. Defaults to None.
         warmup (int, optional): Number of warmup (or burn-in) steps to perform before sampling. Defaults to 100.
         nuts_kwargs (Dict[str, Any], optional): A dictionary of additional keyword arguments to pass to the NUTS sampler. Defaults to {}.
         mcmc_kwargs (Dict[str, Any], optional): A dictionary of additional keyword arguments to pass to the MCMC function. Defaults to {}.
 
     Methods:
@@ -58,15 +91,15 @@
         model: "AutoProf_Model",
         initial_state: Optional[Sequence] = None,
         max_iter: int = 1000,
         **kwargs
     ):
         super().__init__(model, initial_state, max_iter=max_iter, **kwargs)
         
-        self.mass = kwargs.get("mass", None)
+        self.inv_mass = kwargs.get("inv_mass", None)
         self.epsilon = kwargs.get("epsilon", 1e-3)
         self.progress_bar = kwargs.get("progress_bar", True)
         self.prior = kwargs.get("prior", None)
         self.warmup = kwargs.get("warmup", 100)
         self.nuts_kwargs = kwargs.get("nuts_kwargs", {})
         self.mcmc_kwargs = kwargs.get("mcmc_kwargs", {})
         
@@ -99,17 +132,20 @@
         # Set up the NUTS sampler
         nuts_kwargs = {
             "jit_compile": True,
             "ignore_jit_warnings": True,
             "step_size": self.epsilon,
             "full_mass": True,
             "adapt_step_size": True,
+            "adapt_mass_matrix": self.inv_mass is None,
         }
         nuts_kwargs.update(self.nuts_kwargs)
         nuts_kernel = pyro_NUTS(step, **nuts_kwargs)
+        if self.inv_mass is not None:
+            nuts_kernel.mass_matrix_adapter.inverse_mass_matrix = {("x",): self.inv_mass}
 
         # Provide an initial guess for the parameters
         init_params = {"x": self.model.get_parameter_vector(as_representation=True)}
 
         # Run MCMC with the NUTS sampler and the initial guess
         mcmc_kwargs = {
             "num_samples": self.max_iter,
```

## autoprof/plots/image.py

```diff
@@ -22,15 +22,15 @@
         for i in range(len(target.image_list)):
             target_image(fig, ax[i], target.image_list[i], window=window, **kwargs)
         return fig, ax
     if window is None:
         window = target.window
     dat = np.copy(target[window].data.detach().cpu().numpy())
     if target.has_mask:
-        dat[target[window].mask] = np.nan
+        dat[target[window].mask.detach().cpu().numpy()] = np.nan
 
     sky = np.nanmedian(dat)
     noise = iqr(dat[np.isfinite(dat)]) / 2
     vmin = sky - 5 * noise
     vmax = sky + 5 * noise
 
     im = ax.imshow(
@@ -99,15 +99,15 @@
         sample_image = flux_to_sb(
             sample_image, target.pixelscale.item(), target.zeropoint.item()
         )
         del imshow_kwargs["norm"]
         imshow_kwargs["cmap"] = imshow_kwargs["cmap"].reversed()
 
     if target_mask and target.has_mask:
-        sample_image[target.mask] = np.nan
+        sample_image[target.mask.detach().cpu().numpy()] = np.nan
     im = ax.imshow(
         sample_image,
         **imshow_kwargs,
     )
     if showcbar:
         if target.zeropoint is not None:
             clb = fig.colorbar(im, ax=ax, label="Surface Brightness")
```

## autoprof/utils/interpolate.py

```diff
@@ -3,26 +3,50 @@
 import matplotlib.pyplot as plt
 from astropy.convolution import convolve, convolve_fft
 from torch.nn.functional import conv2d
 from .operations import fft_convolve_torch
 
 
 def _h_poly(t):
+    """Helper function to compute the 'h' polynomial matrix used in the
+    cubic spline.
+    
+    Args:
+        t (Tensor): A 1D tensor representing the normalized x values.
+    
+    Returns:
+        Tensor: A 2D tensor of size (4, len(t)) representing the 'h' polynomial matrix.
+
+    """
+
     tt = t[None, :] ** (torch.arange(4, device=t.device)[:, None])
     A = torch.tensor(
         [[1, 0, -3, 2], [0, 1, -2, 1], [0, 0, 3, -2], [0, 0, -1, 1]],
         dtype=t.dtype,
         device=t.device,
     )
     return A @ tt
 
+def cubic_spline_torch(x: torch.Tensor, y: torch.Tensor, xs: torch.Tensor, extend: str = "const") -> torch.Tensor:
+    """Compute the 1D cubic spline interpolation for the given data points
+    using PyTorch.
+
+    Args:
+        x (Tensor): A 1D tensor representing the x-coordinates of the known data points.
+        y (Tensor): A 1D tensor representing the y-coordinates of the known data points.
+        xs (Tensor): A 1D tensor representing the x-coordinates of the positions where
+                     the cubic spline function should be evaluated.
+        extend (str, optional): The method for handling extrapolation, either "const" or "linear".
+                                Default is "const".
+                                "const": Use the value of the last known data point for extrapolation.
+                                "linear": Use linear extrapolation based on the last two known data points.
+    
+    Returns:
+        Tensor: A 1D tensor representing the interpolated values at the specified positions (xs).
 
-def cubic_spline_torch(x, y, xs, extend="const"):
-    """
-    1d Cubic spline function implimented for pytorch
     """
     m = (y[1:] - y[:-1]) / (x[1:] - x[:-1])
     m = torch.cat([m[[0]], (m[1:] + m[:-1]) / 2, m[[-1]]])
     idxs = torch.searchsorted(x[:-1], xs) - 1
     dx = x[idxs + 1] - x[idxs]
     hh = _h_poly((xs - x[idxs]) / dx)
     ret = (
```

## autoprof/utils/initialize/__init__.py

```diff
@@ -1,9 +1,9 @@
 from .center import center_of_mass
 from .initialize import isophotes
-from .construct_psf import construct_psf, gaussian_psf
+from .construct_psf import construct_psf, gaussian_psf, moffat_psf
 from .segmentation_map import (
     centroids_from_segmentation_map,
     windows_from_segmentation_map,
     scale_windows,
     filter_windows,
 )
```

## autoprof/utils/initialize/construct_psf.py

```diff
@@ -1,30 +1,65 @@
 import numpy as np
 
 from .center import Lanczos_peak, center_of_mass, GaussianDensity_Peak
 from ..interpolate import shift_Lanczos_np, point_Lanczos
 
 
-def gaussian_psf(sigma, img_width, pixelscale):
+def gaussian_psf(sigma, img_width, pixelscale, upsample = 4):
     assert img_width % 2 == 1, "psf images should have an odd shape"
 
+    # Number of super sampled pixels
+    N = img_width * upsample
+    # Grid of centered pixel locations
     XX, YY = np.meshgrid(
         np.linspace(
-            -(img_width - 1) * pixelscale / 2,
-            (img_width - 1) * pixelscale / 2,
-            img_width,
+            -(N - 1) * pixelscale / (2*upsample),
+            (N - 1) * pixelscale / (2*upsample),
+            N,
         ),
         np.linspace(
-            -(img_width - 1) * pixelscale / 2,
-            (img_width - 1) * pixelscale / 2,
-            img_width,
+            -(N - 1) * pixelscale / (2*upsample),
+            (N - 1) * pixelscale / (2*upsample),
+            N,
         ),
     )
+    # Evaluate the Gaussian at each pixel
     ZZ = np.exp(-0.5 * (XX ** 2 + YY ** 2) / sigma ** 2)
 
+    # Reduce the super-sampling back to native resolution
+    ZZ = ZZ.reshape(img_width, upsample, img_width, upsample).sum(axis = (1,3)) / (upsample**2)
+
+    # Normalize the PSF
+    return ZZ / np.sum(ZZ)
+
+def moffat_psf(n, Rd, img_width, pixelscale, upsample = 4):
+    assert img_width % 2 == 1, "psf images should have an odd shape"
+
+    # Number of super sampled pixels
+    N = img_width * upsample
+    # Grid of centered pixel locations
+    XX, YY = np.meshgrid(
+        np.linspace(
+            -(N - 1) * pixelscale / (2*upsample),
+            (N - 1) * pixelscale / (2*upsample),
+            N,
+        ),
+        np.linspace(
+            -(N - 1) * pixelscale / (2*upsample),
+            (N - 1) * pixelscale / (2*upsample),
+            N,
+        ),
+    )
+    # Evaluate the Moffat at each pixel
+    ZZ = 1. / (1. + (XX ** 2 + YY ** 2) / (Rd**2)) ** n
+
+    # Reduce the super-sampling back to native resolution
+    ZZ = ZZ.reshape(img_width, upsample, img_width, upsample).sum(axis = (1,3)) / (upsample**2)
+
+    # Normalize the PSF
     return ZZ / np.sum(ZZ)
 
 
 def construct_psf(
     stars, image, sky_est, size=51, mask=None, keep_init=False, Lanczos_scale=3
 ):
     """Given a list of initial guesses for star center locations, finds
```

## Comparing `autoprof-0.7.0.dist-info/LICENSE` & `autoprof-0.7.1.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `autoprof-0.7.0.dist-info/METADATA` & `autoprof-0.7.1.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: autoprof
-Version: 0.7.0
+Version: 0.7.1
 Summary: A fast, flexible, differentiable, and automated astronomical image modelling tool for precise parallel multi-wavelength photometry
 Home-page: https://github.com/ConnorStoneAstro/AutoProf
 Author: Connor Stone
 Author-email: connorstone628@gmail.com
 License: GPL-3.0 license
 Platform: UNKNOWN
 Classifier: Development Status :: 1 - Planning
```

## Comparing `autoprof-0.7.0.dist-info/RECORD` & `autoprof-0.7.1.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 autoprof/AP_config.py,sha256=fIxYQr2lxsjA3ONiSLuKMAKmL2BPM7Xz99L3gGab8AQ,3171
-autoprof/__init__.py,sha256=1OR5y4Er-gdnp0JnyBkOq-r5qAfSo3s6ILT-jC0mdiU,5755
+autoprof/__init__.py,sha256=-CTrJYpAh3bXle9byON1krFOjy5b0juH5mHxsps-r6Q,5755
 autoprof/__main__.py,sha256=Ce_QoW2_-x3o3ZXbErfBFzJ_M20JzoaB3dUvwzAhXx4,281
 autoprof/fit/__init__.py,sha256=vPVo-YP7Ns-Y9hsAI_riY93kTtIi1FD5yw6Mdw3bQUY,1092
-autoprof/fit/base.py,sha256=C_FhJa8dwD631vgD_Tansqn_E0ZNmA75KBu7bmT1DqQ,6698
+autoprof/fit/base.py,sha256=XqH9gP9BgtFX05vO6aUg40XpDJ8jLTn1DmWhtF5HGvs,6682
 autoprof/fit/gp.py,sha256=PvMC6LeAIYWwDteVVo3AY7lb_TkQOY2-C5yWfK4CpUY,30
 autoprof/fit/gradient.py,sha256=N1RzlOkWjo0yoNxD483v6EVFtvNODiypLkCy7WoeEQw,6704
-autoprof/fit/hmc.py,sha256=HX11L2YANm-Oyo4gqceMCPuy5zPb7acpK1gYvKINSjs,4884
+autoprof/fit/hmc.py,sha256=4g0KS4U_mLbUT6VrNOcEG1bgXginFC2h0FQ-qZEiZok,6912
 autoprof/fit/iterative.py,sha256=5Jaa5ks3gsr0u1stvMNSZbCpJ71Q4E1RGhVV8SGWnJA,13206
 autoprof/fit/lm.py,sha256=kNPkGjTv9izC5oMAV56EMkBP7vHf8XyYqhUIJUK-x4k,31364
 autoprof/fit/mhmcmc.py,sha256=-3f_LfXFzB1KivEhHqdfUT38CpLw5JE_7_6aKWNjOJY,4317
-autoprof/fit/nuts.py,sha256=Ahq4uFryFXc1KqJgwIj1EwiNdRVqV6tf18Sa-CrQuLY,5296
+autoprof/fit/nuts.py,sha256=7DHgU_27_Eai7LF-Y_imDq4JUzbaiVSBzmYNszxHRPY,7109
 autoprof/image/__init__.py,sha256=ksiEV0RXh6C7szKH1TQQm6kAWG_S2fx4-4NqAmAyMLc,1125
 autoprof/image/image_header.py,sha256=EZc6YXArsirO5TIYOHzAcQXQseINYGmQBK6RbU637cI,11195
 autoprof/image/image_object.py,sha256=qqZ6hKfp3c0et4om-AmagH7Np4vZmjxaROJ_ysq81z8,21644
 autoprof/image/jacobian_image.py,sha256=1s3eAq3xB353i_srThMZVaJ7Wp-aXu0POLfvZ1JQSgg,5269
 autoprof/image/model_image.py,sha256=kcGG1_d-mYMUmDsYcJ9bTA7XNecS1rbt4dkRbcPNoLk,6615
 autoprof/image/target_image.py,sha256=y-_69PPjh2kKO5C9MoF4F3GeJdRtEekhblb_4U_Bd18,15842
 autoprof/image/window_object.py,sha256=DbOnZQmbYMQKB1T_Z-Fpc6PdEENFIGxy7QSGLY0s4jI,22836
@@ -43,38 +43,38 @@
 autoprof/models/warp_model.py,sha256=5r_RniJvEDQFVm60FtXQsUucHIeBOY6AG3RXjof_oxo,4332
 autoprof/models/wedge_model.py,sha256=VKOs0mEYm3WUB-xj_CePEWDxZVj63hxmrKVmiqHtVqw,3546
 autoprof/parse_config/__init__.py,sha256=CT6gEcILfcEdz3I5nbgqKeno8tyGZsMtHmfXQUWejUA,57
 autoprof/parse_config/basic_config.py,sha256=amQEkpKoDp04RVYXNrO4lO0j4T_G1BK7MaLmemtaN-4,4147
 autoprof/parse_config/galfit_config.py,sha256=0HqkIJwgv3XKiW2EZAidXqneDQRaOkgfMxNksxKwuBY,4590
 autoprof/parse_config/shared_methods.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 autoprof/plots/__init__.py,sha256=p8lf0eFHXeZ7-3s0SHRb3zIH1pR6x_jnMxIPUHaEPls,67
-autoprof/plots/image.py,sha256=ApzbOLJQWaHm8PAinkvuYF0Yg7UJG6Swx1iMdxaLO9I,6857
+autoprof/plots/image.py,sha256=1u2WhxvLDbIfC4hTW8tXkN6u2Grj6zkc7sLYrK-RVSs,6903
 autoprof/plots/profile.py,sha256=zyyFTrW-u44d9xt4bX0euAXz765KU7XGZfrmQvgYC8I,7559
 autoprof/plots/shared_elements.py,sha256=-9cuoMXOSZh7uB32Fkn2R5wCFecNU3WIGvVrjmP8ESY,3048
 autoprof/plots/visuals.py,sha256=NQPn6pQPxDUhETndE6AaXpeRCwl-dzuKuThaSlvH7Vs,19994
 autoprof/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 autoprof/utils/angle_operations.py,sha256=oJp9g9v5v7SGzuDRXILg7B0d2CcXygT3GXAzoUbtPGk,800
-autoprof/utils/interpolate.py,sha256=LCI4utAYOay8IsNQIpq0FHhj6MUpigOYii5cEnEhADA,8609
+autoprof/utils/interpolate.py,sha256=_60G41dDv17blkuFOomxDCQtMu_boNnChV5-a6g3KfQ,9820
 autoprof/utils/operations.py,sha256=LLO8LB02L3sJMsmlKiH3XS2m4dZBFxwq2aN8o8v0evs,6369
 autoprof/utils/optimization.py,sha256=VkAusKnyc4zyztbceazKADVy85g6VV7qqYIw6V7cQos,963
 autoprof/utils/parametric_profiles.py,sha256=JY6reeVkATmuPkhKY7cWPgrnpZaM--simb-8mS2xh1A,5990
 autoprof/utils/conversions/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 autoprof/utils/conversions/coordinates.py,sha256=zXdOxPurvoh3szKaEKx02jRCK_z1JfWeg17Z1Hl9a7g,2317
 autoprof/utils/conversions/dict_to_hdf5.py,sha256=XIy_JvX8Nrp-9N3sk5F3gIY2YLX5I88HxEYWbPGbfsU,1095
 autoprof/utils/conversions/functions.py,sha256=YEKL5WAZvBQkR_P0DK255SIYtJoRzQmnbcEoCbweHIs,1829
 autoprof/utils/conversions/optimization.py,sha256=FGlTum_ddqPDXYSN2mkFJUuRaPj385chL49nV3HABa8,2728
 autoprof/utils/conversions/units.py,sha256=KtYFzdH1_vG7JAPWiAkrAISfPmsN_0GNk9aJbFWLXEc,2536
-autoprof/utils/initialize/__init__.py,sha256=2hHVSbdm3biev-i8o8LMf-IB-PSQ2ezIuqjCZHmhiFc,269
+autoprof/utils/initialize/__init__.py,sha256=3loeT7k8s7wtWy_RZvGgTyxnlLKCe3AzpPUBI995Qz0,281
 autoprof/utils/initialize/center.py,sha256=PiL0-oXOzY-J3IUoK-bJy_w1Fv7LZZwdEcN7-kRJcZM,3103
-autoprof/utils/initialize/construct_psf.py,sha256=DaIQhQOn9cqn7q_NGIK8zWXNL1WV4n2hiSTeDOlBIao,3296
+autoprof/utils/initialize/construct_psf.py,sha256=Ai_drJ50Bi2xQx4UcJpjOCkU3k24lejWolNmHPl0nnc,4495
 autoprof/utils/initialize/initialize.py,sha256=V1Epy8vudmquOxSB5S-moCcS7bvjdr5qze6IcqihsSs,3921
 autoprof/utils/initialize/segmentation_map.py,sha256=6fG5U4y5P6MDnX4_6ROBdRhUq6TxgbwVG1V3MaLf7-c,7036
 autoprof/utils/isophote/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 autoprof/utils/isophote/ellipse.py,sha256=p2SGzU067jBIBrKjhYKpnJQF7MSThMcnLajsaXeJ23k,1085
 autoprof/utils/isophote/extract.py,sha256=ousarHmkj7GrgAZ6mO3G-QY0tXjhd8bBh6lHzb--d6U,8531
 autoprof/utils/isophote/integrate.py,sha256=jNOCbSYC1dZO1pasEMcRUqZCpt43DEPVME4Hsa37DKQ,7012
-autoprof-0.7.0.dist-info/LICENSE,sha256=OXLcl0T2SZ8Pmy2_dmlvKuetivmyPd5m1q-Gyd-zaYY,35149
-autoprof-0.7.0.dist-info/METADATA,sha256=EqzXeEQgLzd0XQcApSWz0xfEhZchDYplC61btcBmHhk,3812
-autoprof-0.7.0.dist-info/WHEEL,sha256=kGT74LWyRUZrL4VgLh6_g12IeVl_9u9ZVhadrgXZUEY,110
-autoprof-0.7.0.dist-info/entry_points.txt,sha256=CJw03tyO_XyE5_-xxRzbAg74ITHASY47DhUiRVsn67s,57
-autoprof-0.7.0.dist-info/top_level.txt,sha256=8N1I5eyEKnh1QOUENsiy7fDvtU-sfyRCYsUJPzrvPvc,9
-autoprof-0.7.0.dist-info/RECORD,,
+autoprof-0.7.1.dist-info/LICENSE,sha256=OXLcl0T2SZ8Pmy2_dmlvKuetivmyPd5m1q-Gyd-zaYY,35149
+autoprof-0.7.1.dist-info/METADATA,sha256=CXfkh4uuM16RabDX_UA_uQnRKUsMNF3JMXcWv2sOhZA,3812
+autoprof-0.7.1.dist-info/WHEEL,sha256=kGT74LWyRUZrL4VgLh6_g12IeVl_9u9ZVhadrgXZUEY,110
+autoprof-0.7.1.dist-info/entry_points.txt,sha256=CJw03tyO_XyE5_-xxRzbAg74ITHASY47DhUiRVsn67s,57
+autoprof-0.7.1.dist-info/top_level.txt,sha256=8N1I5eyEKnh1QOUENsiy7fDvtU-sfyRCYsUJPzrvPvc,9
+autoprof-0.7.1.dist-info/RECORD,,
```

